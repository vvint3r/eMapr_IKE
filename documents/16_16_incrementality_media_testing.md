## 16. Incrementality & Media Testing

### Block 1

**Source:** `docx`  
**Original headings:** A/B Testing & Marketing Experimentation - Consolidated Table of Contents > 2. Metrics & Measurement > 2.5 Marketing-Specific Metrics

**Mapping:** score=0.61 reason=keyword:incrementality|head='2.5 Marketing-Specific Metrics'

#### 2.5.1 Return on Ad Spend (ROAS)
#### 2.5.2 Incrementality & Lift
#### 2.5.3 Net Lift (Cannibalization Adjusted)
#### 2.5.4 Brand Lift & Awareness

---

### Block 2

**Source:** `docx`  
**Original headings:** A/B Testing & Marketing Experimentation - Consolidated Table of Contents > 5. Experimental Design > 5.3 Traffic & Sample Management

**Mapping:** score=0.61 reason=keyword:holdout|head='5.3 Traffic & Sample Management'

#### 5.3.1 Split Ratios & Traffic Allocation
#### 5.3.2 Control Group Design
#### 5.3.3 Holdout Groups
#### 5.3.4 Historical Controls
#### 5.3.5 Power-Optimized Designs
#### 5.3.6 D-Optimal Designs

---

### Block 3

**Source:** `docx`  
**Original headings:** A/B Testing & Marketing Experimentation - Consolidated Table of Contents > 16. Incrementality & Media Testing > 16.1 Incrementality Measurement

**Mapping:** score=0.708 reason=heading_fuzzy|head='16.1 Incrementality Measurement'

#### 16.1.1 Incrementality Fundamentals
#### 16.1.2 Holdout Experiments
#### 16.1.3 Audience Split & Suppression
#### 16.1.4 Ghost Ads
#### 16.1.5 PSA Controls
#### 16.1.6 Conversion Lift Studies

---

### Block 4

**Source:** `docx`  
**Original headings:** A/B Testing & Marketing Experimentation - Consolidated Table of Contents > 16. Incrementality & Media Testing > 16.3 Brand & Awareness Testing

**Mapping:** score=0.61 reason=keyword:brand lift|head='16.3 Brand & Awareness Testing'

#### 16.3.1 Brand Lift Studies
#### 16.3.2 Survey-Based Measurement
#### 16.3.3 Perception & Intent Changes

---

### Block 5

**Source:** `docx`  
**Original headings:** A/B Testing & Marketing Experimentation - Consolidated Table of Contents > 16. Incrementality & Media Testing > 16.5 Walled-Garden Platforms

**Mapping:** score=0.61 reason=keyword:walled-garden|head='16.5 Walled-Garden Platforms'

#### 16.5.1 Walled-Garden Lift Studies
#### 16.5.2 Platform Constraints
#### 16.5.3 Conversion Value Mapping

---

### Block 6

**Source:** `docx`  
**Original headings:** A/B Testing & Marketing Experimentation - Consolidated Table of Contents > 18. Channel-Specific Testing > 18.1 Paid Media Channels

**Mapping:** score=0.61 reason=keyword:audience split|head='18.1 Paid Media Channels'

#### 18.1.1 Bid & Budget Tests
#### 18.1.2 Creative MVT
#### 18.1.3 Frequency Capping
#### 18.1.4 Reach vs Frequency Optimization
#### 18.1.5 Audience Split Tests
#### 18.1.6 Geo-Split for Paid Media

---

### Block 7

**Source:** `docx`  
**Original headings:** A/B Testing & Marketing Experimentation - Consolidated Table of Contents > 18. Channel-Specific Testing > 18.4 SEO & Content

**Mapping:** score=0.61 reason=keyword:holdout|head='18.4 SEO & Content'

#### 18.4.1 SEO Experiments with Holdouts
#### 18.4.2 Headline Testing
#### 18.4.3 Content Format Testing

---

### Block 8

**Source:** `md`  
**Original headings:** Marketing Experimentation Framework > 10\. Example End-to-End Experiment: Affirm Checkout Optimization > Stage 5: Decision

**Mapping:** score=0.61 reason=keyword:holdout|head='Stage 5: Decision'

**Recommendation:** Ship to 100% with 1-week staged rollout

**Holdout:** 5% control for long-term monitoring

**Next Steps:** Explore further optimization for desktop experience

---

### Block 9

**Source:** `md`  
**Original headings:** Marketing Experimentation Framework > 2\. Experiment Design (The Engine Room) > **2.2. Test Types**

**Mapping:** score=0.61 reason=keyword:holdout|head='**2.2. Test Types**'

* A/B Testing: 1 variable, 2 variants.

* Multivariate Testing: Multiple variables, combinations.

* Multicell Experiments: Multiple treatments in structured factorial design.  
  Geo Experiments: Geographic split testing.

* Holdout Groups: Baseline groups excluded from intervention.

---

### Block 10

**Source:** `md`  
**Original headings:** Marketing Experimentation Framework > 5\. Advanced Topics in Experimentation > 6\. Real-World Execution & Strategy > **6.3. Common Interview Scenarios**

**Mapping:** score=0.61 reason=keyword:incrementality|head='**6.3. Common Interview Scenarios**'

* “You ran an A/B test and saw no significance — what next?”

* “You saw a 20% lift. What checks do you run before declaring success?”

* “How would you design a test for a new landing page?”

* “How do you test the incrementality of a retargeting campaign?”

---

### Block 11

**Source:** `md`  
**Original headings:** Marketing Experimentation Framework > Structured Learning Sequence for Marketing Experimentation \[Continued\] > 7\) Observed uplift vs. causal lift — don’t confuse correlation with incrementality

**Mapping:** score=0.61 reason=keyword:incrementality|head='7\) Observed uplift vs. causal lift — don’t confuse correlation with incrementality'

* Observed uplift: the raw difference between those who saw a change and those who didn’t (often biased by selection).

* Causal lift (incrementality): the difference versus what would have happened otherwise, established via a valid counterfactual (control group or robust quasi-experiment).

Airbnb example:  
 Retargeted users’ booking rate is 8% vs. 4% for non-retargeted — observed \+4pp. After a holdout experiment, you find treated \= 6%, holdout \= 5.2% ⇒ causal lift \= \+0.8pp. Your iROAS will be calculated from that incremental revenue only.

---

### Block 12

**Source:** `md`  
**Original headings:** 25 A/B Testing Concepts You Must Know: Interview Refresher > Conclusion

**Mapping:** score=0.61 reason=keyword:incrementality|head='Conclusion'

A/B Testing is one of the most important and widely applied data science concepts with numerous applications in growth optimization – be it product experimentation (optimizing onboarding flows, increasing CTRs, server side optimizations etc.) OR for marketing acquisition (creative testing, incrementality testing, geo-split testing) and many more. With so many potential applications, it is very likely that you will be gauged on your knowledge of A/B testing in interviews – specifically for product data science/analytics or marketing data science/analytics roles.

---

---

### Block 13

**Source:** `md`  
**Original headings:** 25 A/B Testing Concepts You Must Know: Interview Refresher > Next-Level A/B Testing: Repeatable, Rapid, and Flexible Product Experimentation > In-Depth Summary of Key Topics > **Chapter 1: Why Experimentation Rate, Quality, and Cost Matter**

**Mapping:** score=0.61 reason=keyword:survey|head='**Chapter 1: Why Experimentation Rate, Quality, and Cost Matter**'

This chapter establishes the book's core framework. It introduces the fictitious company, MarketMax, which is at an "intermediate" stage of experimentation, facing challenges with testing space, quality, and process bottlenecks as it scales. A key practice introduced is the Experimentation Workshop, a method for platform teams to gather feedback and identify pain points by surveying users. The source provides a mind map and sample questions to guide such a workshop, covering topics like pre-launch verification, monitoring, and coordination.

---


