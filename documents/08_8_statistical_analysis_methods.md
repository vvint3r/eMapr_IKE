## 8. Statistical Analysis Methods

### Block 1

**Source:** `docx`  
**Original headings:** A/B Testing & Marketing Experimentation - Consolidated Table of Contents > 8. Statistical Analysis Methods > 8.1 Frequentist Inference

**Mapping:** score=0.61 reason=keyword:t-test|head='8.1 Frequentist Inference'

#### 8.1.1 T-tests (Pooled, Welch)
#### 8.1.2 Z-tests (Proportions)
#### 8.1.3 Chi-Square & Fisher's Exact Tests
#### 8.1.4 ANOVA & ANCOVA
#### 8.1.5 Linear & Logistic Regression
#### 8.1.6 Generalized Linear Models (GLM)

---

### Block 2

**Source:** `docx`  
**Original headings:** A/B Testing & Marketing Experimentation - Consolidated Table of Contents > 8. Statistical Analysis Methods > 8.3 Non-Parametric Methods

**Mapping:** score=0.61 reason=keyword:non-parametric|head='8.3 Non-Parametric Methods'

#### 8.3.1 Mann-Whitney U Test
#### 8.3.2 Wilcoxon Tests
#### 8.3.3 Median & Quantile Analysis
#### 8.3.4 Robust Methods

---

### Block 3

**Source:** `docx`  
**Original headings:** A/B Testing & Marketing Experimentation - Consolidated Table of Contents > 9. Variance Reduction Techniques > 9.2 Covariate Adjustment

**Mapping:** score=0.61 reason=keyword:ancova|head='9.2 Covariate Adjustment'

#### 9.2.1 Regression Controls
#### 9.2.2 ANCOVA
#### 9.2.3 Control Variates

---

### Block 4

**Source:** `docx`  
**Original headings:** A/B Testing & Marketing Experimentation - Consolidated Table of Contents > 10. Sequential Testing & Monitoring > 10.3 Advanced Sequential Methods

**Mapping:** score=0.61 reason=keyword:bayes|head='10.3 Advanced Sequential Methods'

#### 10.3.1 Sequential Probability Ratio Test (SPRT)
#### 10.3.2 Always-Valid P-values
#### 10.3.3 E-values
#### 10.3.4 Bayesian Monitoring

---

### Block 5

**Source:** `docx`  
**Original headings:** A/B Testing & Marketing Experimentation - Consolidated Table of Contents > 12. Results Interpretation & Analysis > 12.3 Special Analysis Cases

**Mapping:** score=0.621 reason=heading_fuzzy|head='12.3 Special Analysis Cases'

#### 12.3.1 Non-Inferiority Testing
#### 12.3.2 Equivalence Testing (TOST)
#### 12.3.3 Superiority Testing

---

### Block 6

**Source:** `docx`  
**Original headings:** A/B Testing & Marketing Experimentation - Consolidated Table of Contents > 16. Incrementality & Media Testing > 16.4 Marketing Mix Modeling (MMM)

**Mapping:** score=0.61 reason=keyword:bayes|head='16.4 Marketing Mix Modeling (MMM)'

#### 16.4.1 MMM Fundamentals
#### 16.4.2 Long-Term ROI Measurement
#### 16.4.3 Saturation & Concavity
#### 16.4.4 MMM Calibration with Geo-Lift
#### 16.4.5 Bayesian MMM
#### 16.4.6 MMM Integration with Experiments

---

### Block 7

**Source:** `docx`  
**Original headings:** A/B Testing & Marketing Experimentation - Consolidated Table of Contents > 22. Tools & Technology Ecosystem > 22.3 Statistical & Analysis Tools

**Mapping:** score=0.812 reason=heading_fuzzy|head='22.3 Statistical & Analysis Tools'

#### 22.3.1 Power Calculators
#### 22.3.2 Statistical Software (R, Python, SPSS)
#### 22.3.3 CUPED Libraries
#### 22.3.4 Causal Inference Libraries
#### 22.3.5 Geo-Lift Tooling
#### 22.3.6 MMM Stack
#### 22.3.7 Bandit Frameworks

---

### Block 8

**Source:** `md`  
**Original headings:** End to End Statistics for Data Science

**Mapping:** score=0.61 reason=keyword:bayes|head='End to End Statistics for Data Science'

In data science, statistics, especially data science statistics, are crucial for analysis and decision-making. Data scientists use descriptive statistics and Bayesian methods to interpret complex datasets within big data. Tools like Excel help visualize data clearly. In computer science, linear models and statistical techniques are key for understanding data patterns and guiding decisions. Mastering statistics for data science is vital to uncover insights and develop effective strategies across industries. These methods enable professionals to transform raw data into actionable knowledge, ensuring informed and impactful outcomes in diverse fields.

---

### Block 9

**Source:** `md`  
**Original headings:** End to End Statistics for Data Science > Learning Outcomes

**Mapping:** score=0.61 reason=keyword:regression|head='Learning Outcomes'

- Develop the skills to analyze and interpret complex datasets, making data-driven decisions as a proficient data analyst  
- Gain expertise in SQL, enabling efficient data extraction, manipulation, and management of large-scale databases  
- Grasp the fundamental concepts of linear algebra, crucial for advanced data analytics and machine learning methodologies  
- Learn to apply linear regression techniques to model relationships within statistical data, enhancing predictive analytics capabilities  
- Understand and implement various data analytics methodologies, ensuring robust and accurate data analysis, with a strong emphasis on stats for data science  
- Explore the integration of artificial intelligence in data analytics, leveraging AI to uncover deeper insights and automate data-driven tasks  
- Master the techniques for analyzing statistical data, transforming raw data into actionable insights

---

### Block 10

**Source:** `md`  
**Original headings:** End to End Statistics for Data Science > Properties of Statistics > Bayes' Theorem

**Mapping:** score=0.61 reason=keyword:bayes|head='Bayes' Theorem'

Bayes' Theorem is a method for calculating conditional probability. The probability of an event occurring if it is related to one or more other events is known as conditional probability. For example, your chances of finding a parking space are affected by the time of day you park, where you park, and what conventions are taking place at any given time.

---

### Block 11

**Source:** `md`  
**Original headings:** Marketing Experimentation Framework > 10\. Example End-to-End Experiment: Affirm Checkout Optimization > Stage 4: Analysis

**Mapping:** score=0.61 reason=keyword:z-test|head='Stage 4: Analysis'

**Method:** Two-proportion z-test with CUPED

**Results:** 23% lift (95% CI: 18%-28%), p \< 0.001

**Segments:** Larger effect for mobile users (28% vs 19%)

---

### Block 12

**Source:** `md`  
**Original headings:** Marketing Experimentation Framework > Statistical Planning > Sample Size Calculation

**Mapping:** score=0.61 reason=keyword:z-test|head='Sample Size Calculation'

Based on:

- Baseline rate (e.g., 10% CTR)  
- Minimum detectable effect (MDE) (e.g., 1.5%)  
- Power (commonly 80%)  
- Significance level (alpha \= 0.05)

**Formula for two-proportion z-test:** n \= 2 × (Z\_α/2 \+ Z\_β)² × p̄(1-p̄) / (Δ)²

---

### Block 13

**Source:** `md`  
**Original headings:** Marketing Experimentation Framework > Statistical Analysis & Models > Bayesian Inference

**Mapping:** score=0.61 reason=keyword:bayes|head='Bayesian Inference'

- For continuous monitoring (i.e., decision-making mid-test)  
- Gives a probability that variant is better, rather than p-value

---

### Block 14

**Source:** `md`  
**Original headings:** Marketing Experimentation Framework > Statistical Analysis & Models > Regression Models

**Mapping:** score=0.61 reason=keyword:regression|head='Regression Models'

**Logistic regression to control for covariates:** Conversion \~ Treatment \+ Device \+ Merchant\_Category \+ Time\_of\_Day

**Uplift modeling:** Estimate individual treatment effects (ITE)

---

### Block 15

**Source:** `md`  
**Original headings:** Marketing Experimentation Framework > A/B Testing Foundations > IV. Statistical Analysis & Interpretation

**Mapping:** score=0.722 reason=heading_fuzzy|head='IV. Statistical Analysis & Interpretation'

* **Determining Sample Size & Duration**  
  * Using sample size calculators.  
  * The dangers of peeking at results early and stopping tests prematurely.  
  * Avoiding "Seasonality" bias by running tests for full business cycles (e.g., a full week).  
* **Interpreting Results**  
  * **Statistical Significance:** Is the result reliable?  
  * **Confidence Intervals:** The range of plausible values for the true effect size.  
  * **Practical Significance (Lift):** Is the observed improvement (e.g., 5% lift in conversions) meaningful for the business?  
* **Common Pitfalls & How to Avoid Them**  
  * **False Positives (Type I Error):** Concluding a difference exists when it doesn't.  
  * **False Negatives (Type II Error):** Failing to detect a real difference.  
  * **Simpson's Paradox:** A trend appears in different segments but disappears or reverses when combined.  
  * **Multiple Testing Problem / P-hacking:** Inflating false positive rates by testing too many metrics or variants without correction.  
  * **Novelty Effect:** Users temporarily reacting to a change simply because it's new.

---

### Block 16

**Source:** `md`  
**Original headings:** Marketing Experimentation Framework > 3\. Measurement & Statistical Rigor > **3.2. Statistical Methods**

**Mapping:** score=0.712 reason=heading_fuzzy|head='**3.2. Statistical Methods**'

* T-tests / Z-tests

* Chi-squared tests (categorical data)

* ANOVA (multi-group comparison)

* Regression models (to control for covariates)

* Bayesian vs. Frequentist methods

---

### Block 17

**Source:** `md`  
**Original headings:** Marketing Experimentation Framework > 4\. Interpreting & Iterating > **4.2. Post-Test Segmentation**

**Mapping:** score=0.61 reason=keyword:t-test|head='**4.2. Post-Test Segmentation**'

* Heterogeneous Treatment Effects

* Responders vs. Non-responders

* Causal Lift in subpopulations

---


