#### SELECT sender_id, COUNT(DISTINCT receiver_id)  AS message_count

FROM messages  m1 WHERE DATE_PART('year', sent_date) = 2022 GROUP BY sender_id ORDER BY message_count DESC LIMIT 2;

---

#### -- Question 66

-- Table: Sales -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | sale_date     | date    | -- | fruit         | enum    | -- | sold_num      | int     | -- +---------------+---------+ -- (sale_date,fruit) is the primary key for this table. -- This table contains the sales of "apples" and "oranges" sold each day. -- Write an SQL query to report the difference between number of apples and oranges sold each day. -- Return the result table ordered by sale_date in format ('YYYY-MM-DD'). -- The query result format is in the following example: -- Sales table: -- +------------+------------+-------------+ -- | sale_date  | fruit      | sold_num    | -- +------------+------------+-------------+ -- | 2020-05-01 | apples     | 10          | -- | 2020-05-01 | oranges    | 8           | -- | 2020-05-02 | apples     | 15          | -- | 2020-05-02 | oranges    | 15          | -- | 2020-05-03 | apples     | 20          | -- | 2020-05-03 | oranges    | 0           | -- | 2020-05-04 | apples     | 15          | -- | 2020-05-04 | oranges    | 16          | -- +------------+------------+-------------+ -- Result table: -- +------------+--------------+ -- | sale_date  | diff         | -- +------------+--------------+ -- | 2020-05-01 | 2            | -- | 2020-05-02 | 0            | -- | 2020-05-03 | 20           | -- | 2020-05-04 | -1           | -- +------------+--------------+ -- Day 2020-05-01, 10 apples and 8 oranges were sold (Difference  10 - 8 = 2). -- Day 2020-05-02, 15 apples and 15 oranges were sold (Difference 15 - 15 = 0). -- Day 2020-05-03, 20 apples and 0 oranges were sold (Difference 20 - 0 = 20). -- Day 2020-05-04, 15 apples and 16 oranges were sold (Difference 15 - 16 = -1). -- Solution Select sale_date, sold_num-sold as diff from ((select * from sales where fruit = 'apples') a join (select sale_date as sale, fruit, sold_num as sold from sales where fruit = 'oranges') b on a.sale_date = b.sale)

---

#### WITH cte AS(

SELECT user_id1,user_id2 FROM friendship_1264 UNION SELECT user_id2,user_id1 FROM friendship_1264 ), friends AS( SELECT user_id2 AS friends FROM cte WHERE user_id1 = 1 ) SELECT DISTINCT page_id FROM likes_1264 WHERE user_id IN (SELECT * FROM friends) AND page_id NOT IN (SELECT DISTINCT page_id FROM likes_1264 WHERE user_id = 1) ORDER BY 1; --------------------------- OR ---------------------------- WITH likes AS ( SELECT user_id,ARRAY_AGG(page_id) as liked_pages FROM likes_1264 GROUP BY user_id ),friends AS ( SELECT user_id1,user_id2,page_id FROM friendship_1264 f JOIN likes_1264 l ON f.user_id1 = l.user_id UNION ALL SELECT user_id2,user_id1,page_id FROM friendship_1264 f JOIN likes_1264 l ON f.user_id2 = l.user_id ),reco AS( SELECT f.user_id1 AS from_user, f.user_id2 AS friend, f.page_id AS page_to_reco, liked_pages AS friend_already_liked_pages FROM friends f JOIN likes l ON f.user_id2 = l.user_id AND (NOT f.page_id = ANY (liked_pages)) ) SELECT DISTINCT page_to_reco FROM reco WHERE friend = 1 ORDER BY page_to_reco;

---

#### WITH install_dates AS(

SELECT player_id,MIN(event_date) AS install_date FROM activity_1097 GROUP BY player_id ), new AS( SELECT i.player_id,i.install_date,a.event_date FROM install_dates i LEFT JOIN activity_1097 a ON i.player_id = a.player_id AND i.install_date + 1 = a.event_date ) SELECT install_date,COUNT(player_id),ROUND(COUNT(event_date)::NUMERIC/COUNT(player_id),2) FROM new GROUP BY install_date;

---

#### SELECT t1.team_name AS home_team,t2.team_name AS away_team

FROM teams_2339 t1 INNER JOIN teams_2339 t2 ON t1.team_name <> t2.team_name;

---

#### WITH RECURSIVE months AS (

select 1 as m union select m+1 as m from months where m<=11 ), cte AS ( SELECT mn.m,SUM(COALESCE(ar.ride_distance,0)) AS ride_distance,SUM(COALESCE(ar.ride_duration,0)) AS ride_duration, CASE WHEN m BETWEEN 1 AND 3 THEN 'q1' WHEN m BETWEEN 4 AND 6 THEN 'q2' WHEN m BETWEEN 7 AND 9 THEN 'q3' ELSE 'q4' END AS quater FROM accepted_rides_1651 ar INNER JOIN rides_1651 r ON ar.ride_id = r.ride_id AND EXTRACT(year FROM requested_at) = 2020 RIGHT JOIN months mn ON mn.m = EXTRACT(month FROM requested_at) GROUP BY mn.m ) SELECT m, ROUND(AVG(ride_distance) OVER (ORDER BY m ROWS BETWEEN CURRENT ROW AND 2 FOLLOWING),2) AS average_ride_distance, ROUND(AVG(ride_duration) OVER (ORDER BY m ROWS BETWEEN CURRENT ROW AND 2 FOLLOWING),2) AS average_ride_duration FROM cte;

---

#### SELECT MIN(ABS(ABS(a.x)-ABS(b.x))) AS shortest

FROM point_613 a JOIN point_613 b ON a.x <> b.x;

---

#### SELECT extra,COUNT(DISTINCT post_id)

FROM actions_1113 WHERE extra IS NOT NULL AND action_date = DATE '2019-07-05'-1 GROUP BY extra;

---

#### SELECT  COALESCE(advertiser.user_id, daily_pay.user_id) AS user_id,

CASE WHEN paid IS NULL THEN 'CHURN' WHEN (paid IS NOT NULL AND status = 'CHURN') THEN 'RESURRECT' WHEN (paid IS NOT NULL AND status IN ('EXISTING', 'NEW', 'RESURRECT')) THEN 'EXISTING' WHEN (paid IS NOT NULL AND status IS NULL) THEN 'NEW' END AS new_status FROM advertiser FULL OUTER JOIN daily_pay USING(user_id) ORDER BY user_id;

---

#### -- Question 62

-- Table: Activity -- +--------------+---------+ -- | Column Name  | Type    | -- +--------------+---------+ -- | player_id    | int     | -- | device_id    | int     | -- | event_date   | date    | -- | games_played | int     | -- +--------------+---------+ -- (player_id, event_date) is the primary key of this table. -- This table shows the activity of players of some game. -- Each row is a record of a player who logged in and played a number of games (possibly 0) before logging out on some day using some device. -- Write an SQL query that reports for each player and date, how many games played so far by the player. That is, the total number of games played by the player until that date. Check the example for clarity. -- The query result format is in the following example: -- Activity table: -- +-----------+-----------+------------+--------------+ -- | player_id | device_id | event_date | games_played | -- +-----------+-----------+------------+--------------+ -- | 1         | 2         | 2016-03-01 | 5            | -- | 1         | 2         | 2016-05-02 | 6            | -- | 1         | 3         | 2017-06-25 | 1            | -- | 3         | 1         | 2016-03-02 | 0            | -- | 3         | 4         | 2018-07-03 | 5            | -- +-----------+-----------+------------+--------------+ -- Result table: -- +-----------+------------+---------------------+ -- | player_id | event_date | games_played_so_far | -- +-----------+------------+---------------------+ -- | 1         | 2016-03-01 | 5                   | -- | 1         | 2016-05-02 | 11                  | -- | 1         | 2017-06-25 | 12                  | -- | 3         | 2016-03-02 | 0                   | -- | 3         | 2018-07-03 | 5                   | -- +-----------+------------+---------------------+ -- For the player with id 1, 5 + 6 = 11 games played by 2016-05-02, and 5 + 6 + 1 = 12 games played by 2017-06-25. -- For the player with id 3, 0 + 5 = 5 games played by 2018-07-03. -- Note that for each player we only care about the days when the player logged in. -- Solution select player_id, event_date, sum(games_played) over(partition by player_id order by event_date) as games_played_so_far from activity order by 1,2

---

#### SELECT product_id,SUM(quantity) AS total_quantity

FROM sales_1068 GROUP BY product_id;

---

#### WITH cte1 AS(

SELECT fail_date AS dt,'failed' AS status FROM failed_1225 WHERE EXTRACT(YEAR from fail_date) = 2019 UNION SELECT success_date AS dt,'succeeded' AS status FROM succeeded_1225 WHERE EXTRACT(YEAR from success_date) = 2019 ), cte2 AS ( SELECT *, LAG(status) OVER (ORDER BY dt) AS lagged_status FROM cte1 ), cte3 AS ( SELECT *, (CASE WHEN status = lagged_status THEN 0 ELSE 1 END) AS marker FROM cte2 ), cte4 AS ( SELECT *, SUM(marker) OVER (ORDER BY dt) AS rolling_sum FROM cte3 ) SELECT MAX(status) AS period_state, MIN(dt) AS start_date, MAX(dt) AS end_date FROM cte4 GROUP BY rolling_sum; --------------------------------------------------------------------------------------------------------------------------------------------- --Simplified Query --------------------------------------------------------------------------------------------------------------------------------------------- WITH tasks AS ( SELECT fail_date AS dt,'failed' AS status FROM failed_1225 UNION SELECT success_date AS dt,'succeeded' AS status FROM succeeded_1225 ), ranked AS ( SELECT *, ROW_NUMBER() OVER (ORDER BY dt)-ROW_NUMBER() OVER (PARTITION BY status ORDER BY dt) AS diff FROM tasks WHERE dt BETWEEN '01-01-2019' AND '31-12-2019' ORDER BY dt ) SELECT status, MIN(dt) AS start_date,MAX(dt) AS end_date FROM ranked GROUP BY status,diff ORDER BY start_date;

---

#### -- Question 48

-- Table: Employees -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | id            | int     | -- | name          | varchar | -- +---------------+---------+ -- id is the primary key for this table. -- Each row of this table contains the id and the name of an employee in a company. -- Table: EmployeeUNI -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | id            | int     | -- | unique_id     | int     | -- +---------------+---------+ -- (id, unique_id) is the primary key for this table. -- Each row of this table contains the id and the corresponding unique id of an employee in the company. -- Write an SQL query to show the unique ID of each user, If a user doesn't have a unique ID replace just show null. -- Return the result table in any order. -- The query result format is in the following example: -- Employees table: -- +----+----------+ -- | id | name     | -- +----+----------+ -- | 1  | Alice    | -- | 7  | Bob      | -- | 11 | Meir     | -- | 90 | Winston  | -- | 3  | Jonathan | -- +----+----------+ -- EmployeeUNI table: -- +----+-----------+ -- | id | unique_id | -- +----+-----------+ -- | 3  | 1         | -- | 11 | 2         | -- | 90 | 3         | -- +----+-----------+ -- EmployeeUNI table: -- +-----------+----------+ -- | unique_id | name     | -- +-----------+----------+ -- | null      | Alice    | -- | null      | Bob      | -- | 2         | Meir     | -- | 3         | Winston  | -- | 1         | Jonathan | -- +-----------+----------+ -- Alice and Bob don't have a unique ID, We will show null instead. -- The unique ID of Meir is 2. -- The unique ID of Winston is 3. -- The unique ID of Jonathan is 1. -- Solution select unique_id, name from employees e left join employeeuni u on e.id = u.id order by e.id

---

#### -- Question 79

-- Table: Points -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | id            | int     | -- | x_value       | int     | -- | y_value       | int     | -- +---------------+---------+ -- id is the primary key for this table. -- Each point is represented as a 2D Dimensional (x_value, y_value). -- Write an SQL query to report of all possible rectangles which can be formed by any two points of the table. -- Each row in the result contains three columns (p1, p2, area) where: -- p1 and p2 are the id of two opposite corners of a rectangle and p1 < p2. -- Area of this rectangle is represented by the column area. -- Report the query in descending order by area in case of tie in ascending order by p1 and p2. -- Points table: -- +----------+-------------+-------------+ -- | id       | x_value     | y_value     | -- +----------+-------------+-------------+ -- | 1        | 2           | 8           | -- | 2        | 4           | 7           | -- | 3        | 2           | 10          | -- +----------+-------------+-------------+ -- Result table: -- +----------+-------------+-------------+ -- | p1       | p2          | area        | -- +----------+-------------+-------------+ -- | 2        | 3           | 6           | -- | 1        | 2           | 2           | -- +----------+-------------+-------------+ -- p1 should be less than p2 and area greater than 0. -- p1 = 1 and p2 = 2, has an area equal to |2-4| * |8-7| = 2. -- p1 = 2 and p2 = 3, has an area equal to |4-2| * |7-10| = 6. -- p1 = 1 and p2 = 3 It's not possible because the rectangle has an area equal to 0. -- Solution select p1.id as p1, p2.id as p2, abs(p1.x_value-p2.x_value)*abs(p1.y_value-p2.y_value) as area from points p1 cross join points p2 where p1.x_value!=p2.x_value and p1.y_value!=p2.y_value and p1.id<p2.id order by area desc, p1, p2

---

#### WITH ranked_first_column AS (

SELECT first_col, ROW_NUMBER() OVER (ORDER BY first_col) AS rn FROM data_2159 ), ranked_second_column AS ( SELECT second_col, ROW_NUMBER() OVER (ORDER BY second_col DESC) AS rn FROM data_2159 ) SELECT f.first_col,s.second_col FROM ranked_first_column f JOIN ranked_second_column s ON f.rn = s.rn;

---

#### -- Question 74

-- Table Salaries: -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | company_id    | int     | -- | employee_id   | int     | -- | employee_name | varchar | -- | salary        | int     | -- +---------------+---------+ -- (company_id, employee_id) is the primary key for this table. -- This table contains the company id, the id, the name and the salary for an employee. -- Write an SQL query to find the salaries of the employees after applying taxes. -- The tax rate is calculated for each company based on the following criteria: -- 0% If the max salary of any employee in the company is less than 1000$. -- 24% If the max salary of any employee in the company is in the range [1000, 10000] inclusive. -- 49% If the max salary of any employee in the company is greater than 10000$. -- Return the result table in any order. Round the salary to the nearest integer. -- The query result format is in the following example: -- Salaries table: -- +------------+-------------+---------------+--------+ -- | company_id | employee_id | employee_name | salary | -- +------------+-------------+---------------+--------+ -- | 1          | 1           | Tony          | 2000   | -- | 1          | 2           | Pronub        | 21300  | -- | 1          | 3           | Tyrrox        | 10800  | -- | 2          | 1           | Pam           | 300    | -- | 2          | 7           | Bassem        | 450    | -- | 2          | 9           | Hermione      | 700    | -- | 3          | 7           | Bocaben       | 100    | -- | 3          | 2           | Ognjen        | 2200   | -- | 3          | 13          | Nyancat       | 3300   | -- | 3          | 15          | Morninngcat   | 1866   | -- +------------+-------------+---------------+--------+ -- Result table: -- +------------+-------------+---------------+--------+ -- | company_id | employee_id | employee_name | salary | -- +------------+-------------+---------------+--------+ -- | 1          | 1           | Tony          | 1020   | -- | 1          | 2           | Pronub        | 10863  | -- | 1          | 3           | Tyrrox        | 5508   | -- | 2          | 1           | Pam           | 300    | -- | 2          | 7           | Bassem        | 450    | -- | 2          | 9           | Hermione      | 700    | -- | 3          | 7           | Bocaben       | 76     | -- | 3          | 2           | Ognjen        | 1672   | -- | 3          | 13          | Nyancat       | 2508   | -- | 3          | 15          | Morninngcat   | 5911   | -- +------------+-------------+---------------+--------+ -- For company 1, Max salary is 21300. Employees in company 1 have taxes = 49% -- For company 2, Max salary is 700. Employees in company 2 have taxes = 0% -- For company 3, Max salary is 7777. Employees in company 3 have taxes = 24% -- The salary after taxes = salary - (taxes percentage / 100) * salary -- For example, Salary for Morninngcat (3, 15) after taxes = 7777 - 7777 * (24 / 100) = 7777 - 1866.48 = 5910.52, which is rounded to 5911. -- Solution with t1 as ( select company_id, employee_id, employee_name, salary as sa, max(salary) over(partition by company_id) as maximum from salaries) select company_id, employee_id, employee_name, case when t1.maximum<1000 then t1.sa when t1.maximum between 1000 and 10000 then round(t1.sa*.76,0) else round(t1.sa*.51,0) end as salary from t1

---

#### -- Question 54

-- Table: NPV -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | id            | int     | -- | year          | int     | -- | npv           | int     | -- +---------------+---------+ -- (id, year) is the primary key of this table. -- The table has information about the id and the year of each inventory and the corresponding net present value. -- Table: Queries -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | id            | int     | -- | year          | int     | -- +---------------+---------+ -- (id, year) is the primary key of this table. -- The table has information about the id and the year of each inventory query. -- Write an SQL query to find the npv of all each query of queries table. -- Return the result table in any order. -- The query result format is in the following example: -- NPV table: -- +------+--------+--------+ -- | id   | year   | npv    | -- +------+--------+--------+ -- | 1    | 2018   | 100    | -- | 7    | 2020   | 30     | -- | 13   | 2019   | 40     | -- | 1    | 2019   | 113    | -- | 2    | 2008   | 121    | -- | 3    | 2009   | 12     | -- | 11   | 2020   | 99     | -- | 7    | 2019   | 0      | -- +------+--------+--------+ -- Queries table: -- +------+--------+ -- | id   | year   | -- +------+--------+ -- | 1    | 2019   | -- | 2    | 2008   | -- | 3    | 2009   | -- | 7    | 2018   | -- | 7    | 2019   | -- | 7    | 2020   | -- | 13   | 2019   | -- +------+--------+ -- Result table: -- +------+--------+--------+ -- | id   | year   | npv    | -- +------+--------+--------+ -- | 1    | 2019   | 113    | -- | 2    | 2008   | 121    | -- | 3    | 2009   | 12     | -- | 7    | 2018   | 0      | -- | 7    | 2019   | 0      | -- | 7    | 2020   | 30     | -- | 13   | 2019   | 40     | -- +------+--------+--------+ -- The npv value of (7, 2018) is not present in the NPV table, we consider it 0. -- The npv values of all other queries can be found in the NPV table. -- Solution select q.id, q.year, coalesce(n.npv,0) as npv from queries q left join npv n on q.id = n.id and q.year=n.year

---

#### WITH International_Call AS

( SELECT SUM( CASE WHEN caller.country_id !=  receiver.country_id THEN 1.0 ELSE 0.0 END ) AS Number_internationals FROM phone_calls AS pc INNER JOIN phone_info AS caller ON pc.caller_id = caller.caller_id INNER JOIN phone_info AS receiver ON pc.receiver_id = receiver.caller_id ) SELECT ROUND( (Number_internationals * 100 / (SELECT COUNT(*) FROM phone_calls)) , 1 ) FROM International_Call

---

#### SELECT u.product_id,ROUND(SUM(u.units*p.price)::NUMERIC/SUM(u.units),2)

FROM unit_sold_1251 u INNER JOIN prices_1251 p ON u.purchase_date BETWEEN p.start_date AND p.end_date AND u.product_id = p.product_id GROUP BY u.product_id;

---

#### SELECT p1.id AS p1,p2.id AS p2,ABS(p1.x_value-p2.x_value)*ABS(p1.y_value-p2.y_value) AS area

FROM points_1459 p1 INNER JOIN points_1459 p2 ON p1.id < p2.id AND ABS(p1.x_value-p2.x_value)*ABS(p1.y_value-p2.y_value)<>0 ORDER BY area DESC;

---

#### SELECT product_id

FROM products_1757 WHERE low_fats = 'Y' AND recyclable = 'Y';

---

#### SELECT user_id, spend, transaction_date

FROM ( SELECT *,ROW_NUMBER () OVER (PARTITION BY user_id ORDER BY transaction_date) AS RD FROM transactions ) AS T WHERE RD = 3

---

#### WITH CTE AS

( SELECT user_id, SUM( CASE WHEN DATE_PART('MONTH', event_date) = 6 AND DATE_PART('YEAR', event_date) = 2022 THEN 1 ELSE 0 END ) AS jun, SUM( CASE WHEN DATE_PART('MONTH', event_date) = 7 AND DATE_PART('YEAR', event_date) = 2022 THEN 1 ELSE 0 END ) AS jul FROM user_actions GROUP BY user_id ) SELECT '7' AS month, COUNT(user_id) AS monthly_active_users FROM CTE WHERE jun > 0 AND jul > 0;

---

#### WITH managers AS(

SELECT manager_id FROM employee_570 GROUP BY manager_id HAVING COUNT(manager_id)>=5 ) SELECT name FROM employee_570 WHERE id IN (SELECT * FROM managers);

---

#### -- Question 106

-- Table: Student -- +---------------------+---------+ -- | Column Name         | Type    | -- +---------------------+---------+ -- | student_id          | int     | -- | student_name        | varchar | -- +---------------------+---------+ -- student_id is the primary key for this table. -- student_name is the name of the student. -- Table: Exam -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | exam_id       | int     | -- | student_id    | int     | -- | score         | int     | -- +---------------+---------+ -- (exam_id, student_id) is the primary key for this table. -- Student with student_id got score points in exam with id exam_id. -- A "quite" student is the one who took at least one exam and didn't score neither the high score nor the low score. -- Write an SQL query to report the students (student_id, student_name) being "quiet" in ALL exams. -- Don't return the student who has never taken any exam. Return the result table ordered by student_id. -- The query result format is in the following example. -- Student table: -- +-------------+---------------+ -- | student_id  | student_name  | -- +-------------+---------------+ -- | 1           | Daniel        | -- | 2           | Jade          | -- | 3           | Stella        | -- | 4           | Jonathan      | -- | 5           | Will          | -- +-------------+---------------+ -- Exam table: -- +------------+--------------+-----------+ -- | exam_id    | student_id   | score     | -- +------------+--------------+-----------+ -- | 10         |     1        |    70     | -- | 10         |     2        |    80     | -- | 10         |     3        |    90     | -- | 20         |     1        |    80     | -- | 30         |     1        |    70     | -- | 30         |     3        |    80     | -- | 30         |     4        |    90     | -- | 40         |     1        |    60     | -- | 40         |     2        |    70     | -- | 40         |     4        |    80     | -- +------------+--------------+-----------+ -- Result table: -- +-------------+---------------+ -- | student_id  | student_name  | -- +-------------+---------------+ -- | 2           | Jade          | -- +-------------+---------------+ -- For exam 1: Student 1 and 3 hold the lowest and high score respectively. -- For exam 2: Student 1 hold both highest and lowest score. -- For exam 3 and 4: Studnet 1 and 4 hold the lowest and high score respectively. -- Student 2 and 5 have never got the highest or lowest in any of the exam. -- Since student 5 is not taking any exam, he is excluded from the result. -- So, we only return the information of Student 2. -- Solution with t1 as( select student_id from (select *, min(score) over(partition by exam_id) as least, max(score) over(partition by exam_id) as most from exam) a where least = score or most = score) select distinct student_id, student_name from exam join student using (student_id) where student_id != all(select student_id from t1) order by 1

---

#### -- Question 63

-- Table: Enrollments -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | student_id    | int     | -- | course_id     | int     | -- | grade         | int     | -- +---------------+---------+ -- (student_id, course_id) is the primary key of this table. -- Write a SQL query to find the highest grade with its corresponding course for each student. In case of a tie, you should find the course with the smallest course_id. The output must be sorted by increasing student_id. -- The query result format is in the following example: -- Enrollments table: -- +------------+-------------------+ -- | student_id | course_id | grade | -- +------------+-----------+-------+ -- | 2          | 2         | 95    | -- | 2          | 3         | 95    | -- | 1          | 1         | 90    | -- | 1          | 2         | 99    | -- | 3          | 1         | 80    | -- | 3          | 2         | 75    | -- | 3          | 3         | 82    | -- +------------+-----------+-------+ -- Result table: -- +------------+-------------------+ -- | student_id | course_id | grade | -- +------------+-----------+-------+ -- | 1          | 2         | 99    | -- | 2          | 2         | 95    | -- | 3          | 3         | 82    | -- +------------+-----------+-------+ -- Solution select student_id, course_id, grade from( select student_id, course_id, grade, rank() over(partition by student_id order by grade desc, course_id) as rk from enrollments) a where a.rk = 1

---

#### SELECT eu.unique_id,e.name

FROM employee_1378 e LEFT JOIN employee_uni_1378 eu ON e.id = eu.id ORDER BY e.name;

---

#### ü•á Question 1: The Classic Second Highest Salary

The Challenge: Find the employee with the second highest salary without using LIMIT or OFFSET. Why It Matters: This tests your ranking skills and alternative thinking. Every data team needs someone who can find ‚Äúsecond best‚Äù scenarios ‚Äî second highest sales, second most active users, etc. The Magic Solution: SELECT DISTINCT salary FROM ( SELECT salary, DENSE_RANK() OVER (ORDER BY salary DESC) as rank FROM employees ) ranked WHERE rank = 2; Pro Tip: Use DENSE_RANK() instead of RANK() to handle salary ties properly! üéØ üî• Question 2: Consecutive Login Streak The Challenge: Find users who logged in for 3 or more consecutive days. Why It‚Äôs Gold: User engagement analysis is HUGE in data roles. Companies want to know who their most loyal users are and identify patterns in user behavior. The Brilliant Approach: WITH login_groups AS ( SELECT user_id, login_date, DATE_SUB(login_date, INTERVAL ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) DAY ) as group_identifier FROM user_logins ), streak_counts AS ( SELECT user_id, COUNT(*) as consecutive_days FROM login_groups GROUP BY user_id, group_identifier ) SELECT user_id FROM streak_counts WHERE consecutive_days >= 3; The Secret: Subtract row numbers from dates to group consecutive sequences! üß† üí∞ Question 3: Running Total with Reset Condition The Challenge: Calculate running sales total that resets to zero whenever there‚Äôs a return (negative amount). Why Interviewers Love It: Real business logic! E-commerce and finance teams deal with this constantly ‚Äî tracking cumulative values that reset under certain conditions. The Smart Solution: WITH reset_groups AS ( SELECT *, SUM(CASE WHEN amount < 0 THEN 1 ELSE 0 END) OVER (ORDER BY date ROWS UNBOUNDED PRECEDING) as reset_group FROM transactions ) SELECT transaction_id, date, amount, SUM(CASE WHEN amount > 0 THEN amount ELSE 0 END) OVER (PARTITION BY reset_group ORDER BY date) as running_total FROM reset_groups; üï≥Ô∏è Question 4: Finding Missing Sequential Numbers The Challenge: Identify gaps in a sequence of IDs (like missing order numbers). Why It‚Äôs Critical: Data quality issues are everywhere! Missing records can indicate system problems, and finding gaps is essential for data integrity checks. The Detective Work: WITH expected_sequence AS ( SELECT generate_series( (SELECT MIN(order_id) FROM orders), (SELECT MAX(order_id) FROM orders) ) as expected_id ) SELECT expected_id as missing_order_id FROM expected_sequence e LEFT JOIN orders o ON e.expected_id = o.order_id WHERE o.order_id IS NULL; üìä Question 5: Pivot Table Without PIVOT Function The Challenge: Transform rows to columns manually (convert monthly sales data to show each month as a column). Why It‚Äôs Powerful: Not all databases support PIVOT, and understanding the manual approach shows deep SQL knowledge. Plus, dynamic reporting often requires this skill. The Transformation: SELECT product_id, SUM(CASE WHEN MONTH(sale_date) = 1 THEN amount ELSE 0 END) as Jan, SUM(CASE WHEN MONTH(sale_date) = 2 THEN amount ELSE 0 END) as Feb, SUM(CASE WHEN MONTH(sale_date) = 3 THEN amount ELSE 0 END) as Mar, SUM(CASE WHEN MONTH(sale_date) = 4 THEN amount ELSE 0 END) as Apr FROM sales GROUP BY product_id; üéØ Question 6: Top N Per Group The Challenge: Find the top 3 highest-paid employees in each department. Why It‚Äôs Essential: Every business needs to analyze top performers, best-selling products, or highest-value customers within different categories. The Ranking Magic: SELECT department, employee_name, salary FROM ( SELECT department, employee_name, salary, ROW_NUMBER() OVER (PARTITION BY department ORDER BY salary DESC) as rank FROM employees ) ranked WHERE rank <= 3; üîÑ Question 7: Self-Join for Hierarchical Data The Challenge: Find all employees and their managers‚Äô names from an employee table that references itself. Why It Matters: Organizational data, category hierarchies, and parent-child relationships are everywhere in business data. The Relationship Builder: SELECT e.employee_name as employee, m.employee_name as manager FROM employees e LEFT JOIN employees m ON e.manager_id = m.employee_id; üìà Question 8: Moving Average Calculation The Challenge: Calculate a 7-day moving average of daily sales. Why It‚Äôs Valuable: Smoothing out data trends is crucial for forecasting and identifying patterns in noisy data. The Smooth Operator: SELECT sale_date, daily_sales, AVG(daily_sales) OVER ( ORDER BY sale_date ROWS BETWEEN 6 PRECEDING AND CURRENT ROW ) as moving_avg_7_days FROM daily_sales ORDER BY sale_date; üé™ Question 9: Complex Date Calculations The Challenge: Find customers who made purchases in consecutive months. Why It‚Äôs Tricky: Date logic trips up many candidates, but it‚Äôs fundamental for subscription analysis, customer lifecycle tracking, and retention studies. The Time Traveler: WITH monthly_purchases AS ( SELECT customer_id, DATE_TRUNC('month', purchase_date) as purchase_month FROM purchases GROUP BY customer_id, DATE_TRUNC('month', purchase_date) ), month_sequences AS ( SELECT customer_id, purchase_month, LAG(purchase_month) OVER (PARTITION BY customer_id ORDER BY purchase_month) as prev_month FROM monthly_purchases ) SELECT DISTINCT customer_id FROM month_sequences WHERE purchase_month = prev_month + INTERVAL '1 month'; üèÜ Question 10: Recursive CTE for Organizational Hierarchy The Challenge: Show the complete reporting chain from CEO down to all employees. Why It‚Äôs Advanced: Recursive queries demonstrate sophisticated SQL knowledge and are essential for hierarchical data analysis. The Hierarchy Explorer: WITH RECURSIVE org_hierarchy AS ( -- Base case: CEO (no manager) SELECT employee_id, employee_name, manager_id, 1 as level FROM employees WHERE manager_id IS NULL UNION ALL -- Recursive case: employees with managers SELECT e.employee_id, e.employee_name, e.manager_id, oh.level + 1 FROM employees e JOIN org_hierarchy oh ON e.manager_id = oh.employee_id ) SELECT * FROM org_hierarchy ORDER BY level, employee_name; üí° Question 11: Conditional Aggregation The Challenge: Calculate different metrics based on conditions in a single query. Why It‚Äôs Smart: Efficient reporting often requires multiple calculations in one pass, reducing query complexity and improving performance. The Multi-Calculator: SELECT product_category, COUNT(*) as total_orders, COUNT(CASE WHEN order_status = 'completed' THEN 1 END) as completed_orders, COUNT(CASE WHEN order_status = 'cancelled' THEN 1 END) as cancelled_orders, AVG(CASE WHEN order_status = 'completed' THEN order_amount END) as avg_completed_amount FROM orders GROUP BY product_category; üîç Question 12: Finding Duplicate Records The Challenge: Identify and handle duplicate customer records based on email and phone. Why It‚Äôs Real: Data quality issues are everywhere, and deduplication is a daily task for data engineers. The Duplicate Detective: -- Find duplicates SELECT email, phone, COUNT(*) as duplicate_count FROM customers GROUP BY email, phone HAVING COUNT(*) > 1; -- Remove duplicates (keep latest) DELETE FROM customers WHERE customer_id NOT IN ( SELECT MAX(customer_id) FROM customers GROUP BY email, phone ); üìÖ Question 13: Date Range Overlaps The Challenge: Find overlapping date ranges in a booking system. Why It‚Äôs Practical: Scheduling conflicts, resource allocation, and availability checking are common business problems. The Overlap Finder: SELECT a.booking_id as booking1, b.booking_id as booking2, a.start_date, a.end_date, b.start_date, b.end_date FROM bookings a JOIN bookings b ON a.resource_id = b.resource_id WHERE a.booking_id < b.booking_id AND a.start_date <= b.end_date AND b.start_date <= a.end_date; üé≤ Question 14: Percentile Calculations The Challenge: Find customers in the top 10% by purchase amount. Why It‚Äôs Important: Percentile analysis helps identify high-value customers, outliers, and performance benchmarks. The Percentile Pro: SELECT customer_id, total_purchases, PERCENT_RANK() OVER (ORDER BY total_purchases) as percentile_rank FROM ( SELECT customer_id, SUM(purchase_amount) as total_purchases FROM purchases GROUP BY customer_id ) customer_totals WHERE PERCENT_RANK() OVER (ORDER BY total_purchases) >= 0.9; üîó Question 15: Complex JOIN Scenarios The Challenge: Find customers who bought Product A but never bought Product B. Why It‚Äôs Clever: This tests your understanding of different JOIN types and set operations ‚Äî crucial for customer segmentation and behavior analysis. The Exclusion Expert: SELECT DISTINCT c.customer_id, c.customer_name FROM customers c JOIN purchases p1 ON c.customer_id = p1.customer_id JOIN products pr1 ON p1.product_id = pr1.product_id LEFT JOIN ( SELECT DISTINCT p2.customer_id FROM purchases p2 JOIN products pr2 ON p2.product_id = pr2.product_id WHERE pr2.product_name = 'Product B' ) product_b_buyers ON c.customer_id = product_b_buyers.customer_id WHERE pr1.product_name = 'Product A' AND product_b_buyers.customer_id IS NULL; üìä Question 16: Dynamic SQL for Reporting The Challenge: Create a query that shows sales by different time periods (daily, weekly, monthly) in one result. Why It‚Äôs Advanced: Flexible reporting requirements often need dynamic grouping and multiple aggregation levels. The Time Bender: SELECT 'Daily' as period_type, DATE(sale_date) as period, SUM(amount) as total_sales FROM sales GROUP BY DATE(sale_date) UNION ALL SELECT 'Weekly' as period_type, DATE_TRUNC('week', sale_date) as period, SUM(amount) as total_sales FROM sales GROUP BY DATE_TRUNC('week', sale_date) UNION ALL SELECT 'Monthly' as period_type, DATE_TRUNC('month', sale_date) as period, SUM(amount) as total_sales FROM sales GROUP BY DATE_TRUNC('month', sale_date) ORDER BY period_type, period; üéØ Question 17: Cohort Analysis The Challenge: Analyze customer retention by signup month. Why It‚Äôs Gold: Cohort analysis is fundamental for understanding user lifecycle, churn rates, and business growth patterns. The Cohort Master: WITH customer_cohorts AS ( SELECT customer_id, DATE_TRUNC('month', signup_date) as cohort_month, DATE_TRUNC('month', purchase_date) as purchase_month FROM customers c JOIN purchases p ON c.customer_id = p.customer_id ), cohort_data AS ( SELECT cohort_month, purchase_month, COUNT(DISTINCT customer_id) as customers, EXTRACT(MONTH FROM AGE(purchase_month, cohort_month)) as period_number FROM customer_cohorts GROUP BY cohort_month, purchase_month ) SELECT cohort_month, period_number, customers, FIRST_VALUE(customers) OVER (PARTITION BY cohort_month ORDER BY period_number) as cohort_size, ROUND(customers * 100.0 / FIRST_VALUE(customers) OVER (PARTITION BY cohort_month ORDER BY period_number), 2) as retention_rate FROM cohort_data ORDER BY cohort_month, period_number; üöÄ Question 18: Performance Optimization The Challenge: Optimize a slow query that finds customers with no purchases in the last 6 months. Why It‚Äôs Critical: Query performance directly impacts business operations, and optimization skills separate senior engineers from juniors. The Speed Demon: -- Slow approach (avoid this) SELECT c.customer_id, c.customer_name FROM customers c WHERE NOT EXISTS ( SELECT 1 FROM purchases p WHERE p.customer_id = c.customer_id AND p.purchase_date >= CURRENT_DATE - INTERVAL '6 months' ); -- Optimized approach SELECT c.customer_id, c.customer_name FROM customers c LEFT JOIN ( SELECT DISTINCT customer_id FROM purchases WHERE purchase_date >= CURRENT_DATE - INTERVAL '6 months' ) recent_buyers ON c.customer_id = recent_buyers.customer_id WHERE recent_buyers.customer_id IS NULL; üé™ Question 19: Advanced Window Functions The Challenge: Calculate the difference between each employee‚Äôs salary and the department average. Why It‚Äôs Sophisticated: Window functions with multiple aggregation levels show advanced analytical thinking. The Window Wizard: SELECT employee_name, department, salary, AVG(salary) OVER (PARTITION BY department) as dept_avg_salary, salary - AVG(salary) OVER (PARTITION BY department) as salary_diff_from_avg, CASE WHEN salary > AVG(salary) OVER (PARTITION BY department) THEN 'Above Average' WHEN salary < AVG(salary) OVER (PARTITION BY department) THEN 'Below Average' ELSE 'Average' END as performance_category FROM employees; üèÅ Question 20: The Ultimate Challenge ‚Äî Data Pipeline Logic The Challenge: Create a complete data transformation that combines multiple business rules. Why It‚Äôs The Final Boss: This tests everything ‚Äî JOINs, aggregations, window functions, conditional logic, and business understanding. The Grand Finale: WITH customer_metrics AS ( SELECT c.customer_id, c.customer_name, c.signup_date, COUNT(p.purchase_id) as total_purchases, SUM(p.amount) as total_spent, MAX(p.purchase_date) as last_purchase_date, AVG(p.amount) as avg_purchase_amount FROM customers c LEFT JOIN purchases p ON c.customer_id = p.customer_id GROUP BY c.customer_id, c.customer_name, c.signup_date ), customer_segments AS ( SELECT *, CASE WHEN total_spent >= 1000 AND total_purchases >= 5 THEN 'VIP' WHEN total_spent >= 500 OR total_purchases >= 3 THEN 'Regular' WHEN total_purchases > 0 THEN 'Occasional' ELSE 'Inactive' END as customer_segment, CASE WHEN last_purchase_date >= CURRENT_DATE - INTERVAL '30 days' THEN 'Active' WHEN last_purchase_date >= CURRENT_DATE - INTERVAL '90 days' THEN 'At Risk' WHEN last_purchase_date IS NOT NULL THEN 'Churned' ELSE 'Never Purchased' END as activity_status FROM customer_metrics ) SELECT customer_segment, activity_status, COUNT(*) as customer_count, AVG(total_spent) as avg_total_spent, AVG(total_purchases) as avg_total_purchases FROM customer_segments GROUP BY customer_segment, activity_status ORDER BY customer_segment, activity_status; üéâ Your Next Steps to Interview Success Congratulations! You‚Äôve just mastered 20 SQL scenarios that will make you stand out in any data interview. But here‚Äôs the secret sauce ‚Äî practice these with real data. Pro Tips for Interview Day: üó£Ô∏è Talk through your thought process ‚Äî Interviewers love seeing how you think üéØ Ask clarifying questions ‚Äî Show you understand business context ‚ö° Mention performance considerations ‚Äî Discuss indexes, query optimization üîÑ Suggest alternative approaches ‚Äî Show you know multiple solutions

---

#### SELECT COALESCE(e.employee_id,s.employee_id)

FROM employees_1965 e FULL OUTER JOIN salaries_1965 s ON e.employee_id = s.employee_id WHERE e.name IS NULL OR s.salary IS NULL;

---

#### SELECT TO_CHAR(trans_date,'YYYY-MM') AS month,country,

COUNT(id) AS trans_count, COUNT(CASE WHEN state = 'approved' THEN 1 ELSE NULL END) AS approved_count, SUM(amount) AS trans_total_amount FROM transactions_1193 GROUP BY month,country ORDER BY month;

---

#### SELECT DISTINCT p1.user_id

FROM purchases_2228 p1 INNER JOIN purchases_2228 p2 ON p1.purchase_id <> p2.purchase_id AND p1.user_id = p2.user_id AND ABS(EXTRACT(DAY FROM p1.purchase_date)-EXTRACT(DAY FROM p2.purchase_date))<=7

---

#### SELECT s.machine_id,ROUND(AVG(e.timestamp-s.timestamp)::NUMERIC,3) AS processing_time

FROM activity_1661 s INNER JOIN activity_1661 e ON s.activity_type = 'start' AND e.activity_type = 'end' AND s.machine_id = e.machine_id AND s.process_id = e.process_id GROUP BY s.machine_id;

---

#### SELECT activity_date,COUNT(DISTINCT user_id)

FROM activity_1141 WHERE activity_date <= '2019-07-27' AND activity_date >= DATE '2019-07-27'-30 GROUP BY activity_date;

---

#### WITH platforms AS (

SELECT UNNEST(ARRAY['Android','IOS','Web']) AS pf ), activities AS ( SELECT UNNEST(ARRAY['Programming','Sports','Reading']) AS act ), combinations AS ( SELECT * FROM platforms p CROSS JOIN activities a ) SELECT c.pf AS platform,c.act AS experiment_name,COALESCE(COUNT(e.experiment_id),0) AS num_experiments FROM combinations c LEFT JOIN experiments_1990 e ON e.platform = c.pf AND e.experiment_name = c.act GROUP BY c.pf,c.act;

---

#### SELECT SUM(CASE WHEN  review_stars >= 4 THEN 1 ELSE 0 END) AS business_count,

SUM(CASE WHEN  review_stars >= 4 THEN 1 ELSE 0 END) * 100 / COUNT(*) AS  top_rated_pct FROM reviews

---

#### WITH cte AS(

SELECT *, ROW_NUMBER() OVER (PARTITION BY seller_id ORDER BY order_date) AS rn FROM orders_1159 ), cte2 AS( SELECT seller_id,item_id FROM cte WHERE rn = 2 ) SELECT u.user_id, CASE WHEN c.item_id=i.item_id THEN 'yes' ELSE 'no' END AS "2nd_item_fav_brand" FROM users_1159 u INNER JOIN items_1159 i ON u.favorite_brand = i.item_brand LEFT JOIN cte2 c ON u.user_id = c.seller_id ORDER BY 1;

---

#### SELECT tweet_id

FROM tweets_1683 WHERE LENGTH(content)>15;

---

#### WITH ny AS (

SELECT COUNT(student_id) AS ny_cnt FROM newyork_2072 WHERE score >= 90 ), cf AS ( SELECT COUNT(student_id) AS cf_cnt FROM california_2072 WHERE score >= 90 ) SELECT CASE WHEN ny_cnt > cf_cnt THEN 'New York University' WHEN ny_cnt < cf_cnt THEN 'California University' ELSE 'No Winner' END AS winner FROM ny INNER JOIN cf ON true;

---

#### -- Question 16

-- A pupil Tim gets homework to identify whether three line segments could possibly form a triangle. -- However, this assignment is very heavy because there are hundreds of records to calculate. -- Could you help Tim by writing a query to judge whether these three sides can form a triangle, -- assuming table triangle holds the length of the three sides x, y and z. -- | x  | y  | z  | -- |----|----|----| -- | 13 | 15 | 30 | -- | 10 | 20 | 15 | -- For the sample data above, your query should return the follow result: -- | x  | y  | z  | triangle | -- |----|----|----|----------| -- | 13 | 15 | 30 | No       | -- | 10 | 20 | 15 | Yes      | -- Solution select x, y, z, case when x+y > z and x+z > y and  y+z > x  then 'Yes' when x=y and y=z then 'Yes' else 'No' end as Triangle from triangle

---

#### SELECT DISTINCT c1.seat_id

FROM cinema_603 c1 INNER JOIN cinema_603 c2 ON ABS(c1.seat_id-c2.seat_id)=1 WHERE c1.free AND c2.free; ------------------------------------------------------------------------------------------------------------------------------- WITH cte AS( SELECT seat_id,free, LEAD(free) OVER() as next_seat, LAG(free) OVER() as prev_seat FROM cinema_603 ) SELECT DISTINCT seat_id FROM cte WHERE (free=1 AND next_seat=1) OR (free=1 AND prev_seat=1); ------------------------------------------------------------------------------------------------------------------------------- WITH ranked AS ( SELECT *, seat_id-ROW_NUMBER () OVER (ORDER BY seat_id) AS diff FROM cinema_603 WHERE free = 1 ), consecutive_free_seats AS ( SELECT *, COUNT(seat_id) OVER (PARTITION BY diff) AS cnt FROM ranked ) SELECT seat_id FROM consecutive_free_seats WHERE cnt >= 2;

---

#### SELECT problem_id

FROM problems_2026 WHERE (likes*100.0/(likes+dislikes)) < 60 ORDER BY problem_id;

---

#### -- Question7

-- There is a table courses with columns: student and class -- Please list out all classes which have more than or equal to 5 students. -- For example, the table: -- +---------+------------+ -- | student | class      | -- +---------+------------+ -- | A       | Math       | -- | B       | English    | -- | C       | Math       | -- | D       | Biology    | -- | E       | Math       | -- | F       | Computer   | -- | G       | Math       | -- | H       | Math       | -- | I       | Math       | -- +---------+------------+ -- Solution select class from courses group by class having count(distinct student)>=5

---

#### -- Question 64

-- Table: Books -- +----------------+---------+ -- | Column Name    | Type    | -- +----------------+---------+ -- | book_id        | int     | -- | name           | varchar | -- | available_from | date    | -- +----------------+---------+ -- book_id is the primary key of this table. -- Table: Orders -- +----------------+---------+ -- | Column Name    | Type    | -- +----------------+---------+ -- | order_id       | int     | -- | book_id        | int     | -- | quantity       | int     | -- | dispatch_date  | date    | -- +----------------+---------+ -- order_id is the primary key of this table. -- book_id is a foreign key to the Books table. -- Write an SQL query that reports the books that have sold less than 10 copies in the last year, excluding books that have been available for less than 1 month from today. Assume today is 2019-06-23. -- The query result format is in the following example: -- Books table: -- +---------+--------------------+----------------+ -- | book_id | name               | available_from | -- +---------+--------------------+----------------+ -- | 1       | "Kalila And Demna" | 2010-01-01     | -- | 2       | "28 Letters"       | 2012-05-12     | -- | 3       | "The Hobbit"       | 2019-06-10     | -- | 4       | "13 Reasons Why"   | 2019-06-01     | -- | 5       | "The Hunger Games" | 2008-09-21     | -- +---------+--------------------+----------------+ -- Orders table: -- +----------+---------+----------+---------------+ -- | order_id | book_id | quantity | dispatch_date | -- +----------+---------+----------+---------------+ -- | 1        | 1       | 2        | 2018-07-26    | -- | 2        | 1       | 1        | 2018-11-05    | -- | 3        | 3       | 8        | 2019-06-11    | -- | 4        | 4       | 6        | 2019-06-05    | -- | 5        | 4       | 5        | 2019-06-20    | -- | 6        | 5       | 9        | 2009-02-02    | -- | 7        | 5       | 8        | 2010-04-13    | -- +----------+---------+----------+---------------+ -- Result table: -- +-----------+--------------------+ -- | book_id   | name               | -- +-----------+--------------------+ -- | 1         | "Kalila And Demna" | -- | 2         | "28 Letters"       | -- | 5         | "The Hunger Games" | -- +-----------+--------------------+ -- Solution select b.book_id, name from (select * from books where available_from < '2019-05-23') b left join (select * from orders where dispatch_date > '2018-06-23') a on a.book_id = b.book_id group by b.book_id, name having coalesce(sum(quantity),0)<10

---

#### -- Question 5

-- There is a table World -- +-----------------+------------+------------+--------------+---------------+ -- | name            | continent  | area       | population   | gdp           | -- +-----------------+------------+------------+--------------+---------------+ -- | Afghanistan     | Asia       | 652230     | 25500100     | 20343000      | -- | Albania         | Europe     | 28748      | 2831741      | 12960000      | -- | Algeria         | Africa     | 2381741    | 37100000     | 188681000     | -- | Andorra         | Europe     | 468        | 78115        | 3712000       | -- | Angola          | Africa     | 1246700    | 20609294     | 100990000     | -- +-----------------+------------+------------+--------------+---------------+ -- A country is big if it has an area of bigger than 3 million square km or a population of more than 25 million. -- Write a SQL solution to output big countries' name, population and area. -- For example, according to the above table, we should output: -- +--------------+-------------+--------------+ -- | name         | population  | area         | -- +--------------+-------------+--------------+ -- | Afghanistan  | 25500100    | 652230       | -- | Algeria      | 37100000    | 2381741      | -- +--------------+-------------+--------------+ -- Solution Select name, population, area from world where population > 25000000 OR area>3000000

---

#### WITH ranked AS(

SELECT id,student, LAG(id) OVER (w) AS lag, LEAD(id) OVER (w) AS lead FROM seat_626 WINDOW w AS (ORDER BY id) ) SELECT CASE WHEN MOD(id,2) = 1 AND lead IS NOT NULL THEN lead WHEN MOD(id,2) = 0 THEN lag ELSE id END AS id, student FROM ranked ORDER BY id;

---

#### SELECT user_id,

tweet_date, ROUND( AVG(tweet_count) OVER(PARTITION BY user_id ORDER BY tweet_date ROWS BETWEEN 2 PRECEDING AND CURRENT ROW) , 2 ) FROM tweets;

---

#### SELECT card_name,

issued_amount FROM ( SELECT card_name, issued_amount, DENSE_RANK() OVER(PARTITION BY card_name ORDER BY issue_year, issue_month) AS rank FROM monthly_cards_issued ) AS TP WHERE rank = 1 ORDER BY issued_amount DESC;

---

#### WITH all_matches AS(

SELECT home_team_id,away_team_id,home_team_goals,away_team_goals FROM matches_1841 UNION SELECT away_team_id,home_team_id,away_team_goals,home_team_goals FROM matches_1841 ), report_data AS ( SELECT *, CASE WHEN home_team_goals < away_team_goals THEN 0 WHEN home_team_goals > away_team_goals THEN 3 ELSE 1 END AS home_team_points, CASE WHEN home_team_goals < away_team_goals THEN 3 WHEN home_team_goals > away_team_goals THEN 0 ELSE 1 END AS away_team_points FROM all_matches ) SELECT t.team_name AS team_name, COUNT(t.team_name) AS matches_played, SUM(home_team_points) AS points, SUM(home_team_goals) AS goals_for, SUM(away_team_goals) AS goals_against, SUM(home_team_goals)-SUM(away_team_goals) AS goals_diff FROM report_data r INNER JOIN teams_1841 t ON r.home_team_id = t.team_id GROUP BY t.team_name ORDER BY points DESC,goals_diff DESC,t.team_name;

---

#### -- Question 4

-- Select all employee's name and bonus whose bonus is < 1000. -- Table:Employee -- +-------+--------+-----------+--------+ -- | empId |  name  | supervisor| salary | -- +-------+--------+-----------+--------+ -- |   1   | John   |  3        | 1000   | -- |   2   | Dan    |  3        | 2000   | -- |   3   | Brad   |  null     | 4000   | -- |   4   | Thomas |  3        | 4000   | -- +-------+--------+-----------+--------+ -- empId is the primary key column for this table. -- Table: Bonus -- +-------+-------+ -- | empId | bonus | -- +-------+-------+ -- | 2     | 500   | -- | 4     | 2000  | -- +-------+-------+ -- empId is the primary key column for this table. -- Example ouput: -- +-------+-------+ -- | name  | bonus | -- +-------+-------+ -- | John  | null  | -- | Dan   | 500   | -- | Brad  | null  | -- +-------+-------+ -- Solution Select E.name, B.bonus From Employee E left join Bonus B on E.empId = B.empId where B.bonus< 1000 or B.Bonus IS NULL

---

#### -- Question 35

-- Table: Activity -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | user_id       | int     | -- | session_id    | int     | -- | activity_date | date    | -- | activity_type | enum    | -- +---------------+---------+ -- There is no primary key for this table, it may have duplicate rows. -- The activity_type column is an ENUM of type ('open_session', 'end_session', 'scroll_down', 'send_message'). -- The table shows the user activities for a social media website. -- Note that each session belongs to exactly one user. -- Write an SQL query to find the average number of sessions per user for a period of 30 days ending 2019-07-27 inclusively, rounded to 2 decimal places. The sessions we want to count for a user are those with at least one activity in that time period. -- The query result format is in the following example: -- Activity table: -- +---------+------------+---------------+---------------+ -- | user_id | session_id | activity_date | activity_type | -- +---------+------------+---------------+---------------+ -- | 1       | 1          | 2019-07-20    | open_session  | -- | 1       | 1          | 2019-07-20    | scroll_down   | -- | 1       | 1          | 2019-07-20    | end_session   | -- | 2       | 4          | 2019-07-20    | open_session  | -- | 2       | 4          | 2019-07-21    | send_message  | -- | 2       | 4          | 2019-07-21    | end_session   | -- | 3       | 2          | 2019-07-21    | open_session  | -- | 3       | 2          | 2019-07-21    | send_message  | -- | 3       | 2          | 2019-07-21    | end_session   | -- | 3       | 5          | 2019-07-21    | open_session  | -- | 3       | 5          | 2019-07-21    | scroll_down   | -- | 3       | 5          | 2019-07-21    | end_session   | -- | 4       | 3          | 2019-06-25    | open_session  | -- | 4       | 3          | 2019-06-25    | end_session   | -- +---------+------------+---------------+---------------+ -- Result table: -- +---------------------------+ -- | average_sessions_per_user | -- +---------------------------+ -- | 1.33                      | -- +---------------------------+ -- User 1 and 2 each had 1 session in the past 30 days while user 3 had 2 sessions so the average is (1 + 1 + 2) / 3 = 1.33. -- Solution select ifnull(round(avg(a.num),2),0) as average_sessions_per_user from ( select count(distinct session_id) as num from activity where activity_date between '2019-06-28' and '2019-07-27' group by user_id) a

---

#### -- Question 13

-- Suppose that a website contains two tables, -- the Customers table and the Orders table. Write a SQL query to find all customers who never order anything. -- Table: Customers. -- +----+-------+ -- | Id | Name  | -- +----+-------+ -- | 1  | Joe   | -- | 2  | Henry | -- | 3  | Sam   | -- | 4  | Max   | -- +----+-------+ -- Table: Orders. -- +----+------------+ -- | Id | CustomerId | -- +----+------------+ -- | 1  | 3          | -- | 2  | 1          | -- +----+------------+ -- Using the above tables as example, return the following: -- +-----------+ -- | Customers | -- +-----------+ -- | Henry     | -- | Max       | -- +-----------+ -- Solution Select Name as Customers from Customers where id != All(select c.id from Customers c, Orders o where c.id = o.Customerid)

---

#### WITH cte AS(

SELECT requester_id AS uid FROM request_accepted_602 UNION ALL SELECT accepter_id AS uid FROM request_accepted_602 ) SELECT uid,COUNT(uid) num_of_friends FROM cte GROUP BY uid ORDER BY num_of_friends DESC LIMIT 1; --Answer of follow-up question: WITH cte AS( SELECT requester_id AS uid FROM request_accepted_602 UNION ALL SELECT accepter_id AS uid FROM request_accepted_602 ) SELECT uid FROM cte GROUP BY uid HAVING COUNT(uid) = (SELECT COUNT(uid) num_of_friends FROM cte GROUP BY uid ORDER BY num_of_friends DESC LIMIT 1);

---

#### WITH grouped_sales AS (

SELECT product_id,user_id,SUM(quantity) AS quantity FROM sales_2324 GROUP BY product_id,user_id ), ranked_sales AS ( SELECT s.product_id,s.user_id,s.quantity*p.price AS spent, RANK() OVER (PARTITION BY s.user_id ORDER BY s.quantity*p.price DESC) AS rnk FROM grouped_sales s INNER JOIN product_2324 p ON s.product_id = p.product_id ) SELECT user_id,product_id FROM ranked_sales WHERE rnk = 1;

---

#### WITH cte AS (

SELECT *, MAX(salary) OVER (PARTITION BY company_id) AS max_salary FROM salaries_1468 ) SELECT *, ROUND( CASE WHEN max_salary<1000 THEN salary WHEN max_salary<=10000 THEN salary-(salary*24)/100 ELSE salary-(salary*49)/100 END) AS new_salary FROM cte;

---

#### WITH accounts AS (

SELECT account_id FROM subscriptions_2020 WHERE EXTRACT(YEAR FROM start_date)<=2021 AND EXTRACT(YEAR FROM end_date)>=2021 ) SELECT COUNT(DISTINCT account_id) AS accounts_count FROM streams_2020 WHERE EXTRACT(YEAR FROM stream_date) <> 2021 AND account_id IN (SELECT * FROM accounts);

---

#### -- Question 15

-- Write a SQL query to get the second highest salary from the Employee table. -- +----+--------+ -- | Id | Salary | -- +----+--------+ -- | 1  | 100    | -- | 2  | 200    | -- | 3  | 300    | -- +----+--------+ -- For example, given the above Employee table, the query should return 200 as the second highest salary. -- If there is no second highest salary, then the query should return null. -- +---------------------+ -- | SecondHighestSalary | -- +---------------------+ -- | 200                 | -- +---------------------+ -- Solution select max(salary) as SecondHighestSalary from employee where salary ! = (Select max(salary) from employee)

---

#### WITH cte AS(

SELECT *, SUM(weight) OVER (ORDER BY turn) AS wsum FROM queue_1204 ) SELECT person_name FROM cte WHERE turn = (SELECT MAX(turn) FROM cte WHERE wsum<=1000);

---

#### SELECT emp.employee_id,

emp.name FROM employee AS emp INNER JOIN employee AS mang ON emp.manager_id = mang.employee_id AND emp.salary > mang.salary;

---

#### WITH Oredered_Product_Selling AS

( SELECT category_name, product_name, DENSE_RANK() OVER(PARTITION BY category_name ORDER BY sales_quantity DESC, rating DESC)AS Rank FROM products INNER JOIN product_sales USING(product_id) ) SELECT category_name, product_name FROM Oredered_Product_Selling WHERE Rank = 1 ORDER BY category_name, product_name;

---

#### SELECT user_id, COUNT(product_id) AS product_num

FROM user_transactions GROUP BY user_id HAVING SUM(spend) >= 1000 ORDER BY COUNT(product_id) DESC, SUM(spend) DESC LIMIT 3;

---

#### -- (Works for 3 consecutive contests only)

WITH gold_medal_users AS ( SELECT DISTINCT gold_medal AS usr FROM contests_1811 GROUP BY gold_medal HAVING COUNT(contest_id) = 3 ), all_users AS ( SELECT gold_medal AS usr,contest_id FROM contests_1811 UNION ALL SELECT silver_medal AS usr,contest_id FROM contests_1811 UNION ALL SELECT bronz_medal AS usr,contest_id FROM contests_1811 ), consecutive_medal_users AS ( SELECT DISTINCT a1.usr FROM all_users a1 INNER JOIN all_users a2 ON a1.usr = a2.usr AND a1.contest_id - 1 = a2.contest_id INNER JOIN all_users a3 ON a1.usr = a3.usr AND a1.contest_id + 1 = a3.contest_id ), inerview_candidates AS ( SELECT usr FROM gold_medal_users UNION SELECT usr FROM consecutive_medal_users ) SELECT name,mail FROM inerview_candidates ic INNER JOIN users_1811 u ON ic.usr = u.user_id; --OR-- (Generic Query : Works for any number of consecutive contests) WITH gold_medal_users AS ( SELECT DISTINCT gold_medal AS usr FROM contests_1811 GROUP BY gold_medal HAVING COUNT(contest_id) = 3 ), all_users AS ( SELECT gold_medal AS usr,contest_id FROM contests_1811 UNION ALL SELECT silver_medal AS usr,contest_id FROM contests_1811 UNION ALL SELECT bronz_medal AS usr,contest_id FROM contests_1811 ), ranked_users AS ( SELECT *, contest_id-ROW_NUMBER() OVER (PARTITION BY usr ORDER BY contest_id) AS diff FROM all_users ), consecutive_medal_users AS ( SELECT usr,contest_id, COUNT(diff) OVER (PARTITION BY usr,diff) AS num_consecutive_contests FROM ranked_users ), inerview_candidates AS ( SELECT usr FROM gold_medal_users UNION SELECT DISTINCT usr FROM consecutive_medal_users WHERE num_consecutive_contests >= 3 ) SELECT name,mail FROM inerview_candidates ic INNER JOIN users_1811 u ON ic.usr = u.user_id;

---

#### -- Question 68

-- Table: Queue -- +-------------+---------+ -- | Column Name | Type    | -- +-------------+---------+ -- | person_id   | int     | -- | person_name | varchar | -- | weight      | int     | -- | turn        | int     | -- +-------------+---------+ -- person_id is the primary key column for this table. -- This table has the information about all people waiting for an elevator. -- The person_id and turn columns will contain all numbers from 1 to n, where n is the number of rows in the table. -- The maximum weight the elevator can hold is 1000. -- Write an SQL query to find the person_name of the last person who will fit in the elevator without exceeding the weight limit. It is guaranteed that the person who is first in the queue can fit in the elevator. -- The query result format is in the following example: -- Queue table -- +-----------+-------------------+--------+------+ -- | person_id | person_name       | weight | turn | -- +-----------+-------------------+--------+------+ -- | 5         | George Washington | 250    | 1    | -- | 3         | John Adams        | 350    | 2    | -- | 6         | Thomas Jefferson  | 400    | 3    | -- | 2         | Will Johnliams    | 200    | 4    | -- | 4         | Thomas Jefferson  | 175    | 5    | -- | 1         | James Elephant    | 500    | 6    | -- +-----------+-------------------+--------+------+ -- Result table -- +-------------------+ -- | person_name       | -- +-------------------+ -- | Thomas Jefferson  | -- +-------------------+ -- Queue table is ordered by turn in the example for simplicity. -- In the example George Washington(id 5), John Adams(id 3) and Thomas Jefferson(id 6) will enter the elevator as their weight sum is 250 + 350 + 400 = 1000. -- Thomas Jefferson(id 6) is the last person to fit in the elevator because he has the last turn in these three people. -- Solution With t1 as ( select *, sum(weight) over(order by turn) as cum_weight from queue order by turn) select t1.person_name from t1 where turn = (select max(turn) from t1 where t1.cum_weight<=1000)

---

#### SELECT d.name AS Department,e.name AS Employee,e.salary AS Salary

FROM employee_184 e JOIN department_184 d ON e.department_id = d.id WHERE (e.department_id,e.salary) IN (SELECT department_id,MAX(salary) FROM employee_184 GROUP BY department_id); (OR) WITH cte AS( SELECT d.name AS Department,e.name AS Employee, DENSE_RANK() OVER w rnk FROM employee_184 e JOIN department_184 d ON e.department_id = d.id WINDOW w AS (PARTITION BY d.name ORDER BY e.salary DESC) ) SELECT Department,Employee FROM cte WHERE rnk = 1;

---

#### SELECT sell_date,COUNT(DISTINCT product) AS num_sold,STRING_AGG(DISTINCT product,',' ORDER BY product) AS products

FROM activities_1484 GROUP BY sell_date ORDER BY sell_date;

---

#### WITH categorized_members AS (

SELECT v.member_id, CASE WHEN COUNT(p.visit_id)*100/COUNT(v.visit_id)>=80 THEN 'Diamond' WHEN COUNT(p.visit_id)*100/COUNT(v.visit_id)>=50 AND COUNT(p.visit_id)*100/COUNT(v.visit_id)< 80 THEN 'Gold' WHEN COUNT(p.visit_id)*100/COUNT(v.visit_id)< 50 THEN 'Silver' END AS category FROM visits_2051 v LEFT JOIN purchases_2051 p ON v.visit_id = p.visit_id GROUP BY v.member_id ) SELECT m.*,COALESCE(category,'Bronze') AS category FROM members_2051 m LEFT JOIN categorized_members c ON m.member_id=c.member_id ORDER BY m.member_id;

---

#### SELECT part,

assembly_step FROM parts_assembly WHERE finish_date IS NULL;

---

#### SELECT SUM(b.apple_count+COALESCE(c.apple_count,0)) AS apple_count,SUM(b.orange_count+COALESCE(c.orange_count,0)) AS orange_count

FROM boxes_1715 b LEFT JOIN chests_1715 c ON b.chest_id = c.chest_id;

---

#### -- Question 34

-- Table: Product -- +--------------+---------+ -- | Column Name  | Type    | -- +--------------+---------+ -- | product_id   | int     | -- | product_name | varchar | -- | unit_price   | int     | -- +--------------+---------+ -- product_id is the primary key of this table. -- Table: Sales -- +-------------+---------+ -- | Column Name | Type    | -- +-------------+---------+ -- | seller_id   | int     | -- | product_id  | int     | -- | buyer_id    | int     | -- | sale_date   | date    | -- | quantity    | int     | -- | price       | int     | -- +------ ------+---------+ -- This table has no primary key, it can have repeated rows. -- product_id is a foreign key to Product table. -- Write an SQL query that reports the products that were only sold in spring 2019. That is, between 2019-01-01 and 2019-03-31 inclusive. -- The query result format is in the following example: -- Product table: -- +------------+--------------+------------+ -- | product_id | product_name | unit_price | -- +------------+--------------+------------+ -- | 1          | S8           | 1000       | -- | 2          | G4           | 800        | -- | 3          | iPhone       | 1400       | -- +------------+--------------+------------+ -- Sales table: -- +-----------+------------+----------+------------+----------+-------+ -- | seller_id | product_id | buyer_id | sale_date  | quantity | price | -- +-----------+------------+----------+------------+----------+-------+ -- | 1         | 1          | 1        | 2019-01-21 | 2        | 2000  | -- | 1         | 2          | 2        | 2019-02-17 | 1        | 800   | -- | 2         | 2          | 3        | 2019-06-02 | 1        | 800   | -- | 3         | 3          | 4        | 2019-05-13 | 2        | 2800  | -- +-----------+------------+----------+------------+----------+-------+ -- Result table: -- +-------------+--------------+ -- | product_id  | product_name | -- +-------------+--------------+ -- | 1           | S8           | -- +-------------+--------------+ -- The product with id 1 was only sold in spring 2019 while the other two were sold after. -- Solution select distinct a.product_id, product_name from sales a join product b on a.product_id = b.product_id where a.product_id in (select product_id from sales where sale_date >= '2019-01-01' and sale_date <= '2019-03-31') and a.product_id not in (select product_id from sales where sale_date > '2019-03-31' or sale_date < '2019-01-01')

---

#### SELECT score,

DENSE_RANK() OVER(w) as rank FROM scores_178 WINDOW w AS (ORDER BY score DESC);

---

#### What is Pattern Matching in SQL?

SQL pattern matching provides for pattern search in data if you have no clue as to what that word should be. This kind of SQL query uses wildcards to match a string pattern, rather than writing the exact word. The LIKE operator is used in conjunction with SQL Wildcards to fetch the required information. Using the % wildcard to perform a simple search The % wildcard matches zero or more characters of any type and can be used to define wildcards both before and after the pattern. Search a student in your database with first name beginning with the letter K: SELECT * FROM students WHERE first_name LIKE 'K%' Omitting the patterns using the NOT keyword Use the NOT keyword to select records that don't match the pattern. This query returns all students whose first name does not begin with K. SELECT * FROM students WHERE first_name NOT LIKE 'K%' Matching a pattern anywhere using the % wildcard twice Search for a student in the database where he/she has a K in his/her first name. SELECT * FROM students WHERE first_name LIKE '%Q%' Using the _ wildcard to match pattern at a specific position The _ wildcard matches exactly one character of any type. It can be used in conjunction with % wildcard. This query fetches all students with letter K at the third position in their first name. SELECT * FROM students WHERE first_name LIKE '__K%' Matching patterns for a specific length The _ wildcard plays an important role as a limitation when it matches exactly one character. It limits the length and position of the matched results. For example - SELECT *   /* Matches first names with three or more letters */ FROM students WHERE first_name LIKE '___%' SELECT *   /* Matches first names with exactly four characters */ FROM students WHERE first_name LIKE '____'

---

#### How to create empty tables with the same structure as another table?

Creating empty tables with the same structure can be done smartly by fetching the records of one table into a new table using the INTO operator while fixing a WHERE clause to be false for all records. Hence, SQL prepares the new table with a duplicate structure to accept the fetched records but since no records get fetched due to the WHERE clause in action, nothing is inserted into the new table. SELECT * INTO Students_copy FROM Students WHERE 1 = 2;

---

#### What is a Recursive Stored Procedure?

A stored procedure that calls itself until a boundary condition is reached, is called a recursive stored procedure. This recursive function helps the programmers to deploy the same set of code several times as and when required. Some SQL programming languages limit the recursion depth to prevent an infinite loop of procedure calls from causing a stack overflow, which slows down the system and may lead to system crashes. DELIMITER $$     /* Set a new delimiter => $$ */ CREATE PROCEDURE calctotal( /* Create the procedure */ IN number INT,   /* Set Input and Ouput variables */ OUT total INT ) BEGIN DECLARE score INT DEFAULT NULL;   /* Set the default value => "score" */ SELECT awards FROM achievements   /* Update "score" via SELECT query */ WHERE id = number INTO score; IF score IS NULL THEN SET total = 0;   /* Termination condition */ ELSE CALL calctotal(number+1);   /* Recursive call */ SET total = total + score;   /* Action after recursion */ END IF; END $$     /* End of procedure */ DELIMITER ;     /* Reset the delimiter */

---

#### What is a Stored Procedure?

A stored procedure is a subroutine available to applications that access a relational database management system (RDBMS). Such procedures are stored in the database data dictionary. The sole disadvantage of stored procedure is that it can be executed nowhere except in the database and occupies more memory in the database server. It also provides a sense of security and functionality as users who can't access the data directly can be granted access via stored procedures. DELIMITER $$ CREATE PROCEDURE FetchAllStudents() BEGIN SELECT *  FROM myDB.students; END $$ DELIMITER ;

---

#### What is Collation? What are the different types of Collation Sensitivity?

Collation refers to a set of rules that determine how data is sorted and compared. Rules defining the correct character sequence are used to sort the character data. It incorporates options for specifying case sensitivity, accent marks, kana character types, and character width. Below are the different types of collation sensitivity: Case sensitivity: A and a are treated differently. Accent sensitivity: a and √° are treated differently. Kana sensitivity: Japanese kana characters Hiragana and Katakana are treated differently. Width sensitivity: Same character represented in single-byte (half-width) and double-byte (full-width) are treated differently.

---

#### What are the differences between OLTP and OLAP?

OLTP stands for Online Transaction Processing, is a class of software applications capable of supporting transaction-oriented programs. An important attribute of an OLTP system is its ability to maintain concurrency. OLTP systems often follow a decentralized architecture to avoid single points of failure. These systems are generally designed for a large audience of end-users who conduct short transactions. Queries involved in such databases are generally simple, need fast response times, and return relatively few records. A number of transactions per second acts as an effective measure for such systems. OLAP stands for Online Analytical Processing, a class of software programs that are characterized by the relatively low frequency of online transactions. Queries are often too complex and involve a bunch of aggregations. For OLAP systems, the effectiveness measure relies highly on response time. Such systems are widely used for data mining or maintaining aggregated, historical data, usually in multi-dimensional schemas.

---

#### What is OLTP?

OLTP stands for Online Transaction Processing, is a class of software applications capable of supporting transaction-oriented programs. An essential attribute of an OLTP system is its ability to maintain concurrency. To avoid single points of failure, OLTP systems are often decentralized. These systems are usually designed for a large number of users who conduct short transactions. Database queries are usually simple, require sub-second response times, and return relatively few records. Here is an insight into the working of an OLTP system [ Note - The figure is not important for interviews ] -

---

#### What is User-defined function? What are its various types?

The user-defined functions in SQL are like functions in any other programming language that accept parameters, perform complex calculations, and return a value. They are written to use the logic repetitively whenever required. There are two types of SQL user-defined functions: Scalar Function: As explained earlier, user-defined scalar functions return a single scalar value. Table-Valued Functions: User-defined table-valued functions return a table as output. Inline: returns a table data type based on a single SELECT statement. Multi-statement: returns a tabular result-set but, unlike inline, multiple SELECT statements can be used inside the function body.

---

#### What is a UNIQUE constraint?

A UNIQUE constraint ensures that all values in a column are different. This provides uniqueness for the column(s) and helps identify each row uniquely. Unlike primary key, there can be multiple unique constraints defined per table. The code syntax for UNIQUE is quite similar to that of PRIMARY KEY and can be used interchangeably. CREATE TABLE Students (   /* Create table with a single field as unique */ ID INT NOT NULL UNIQUE Name VARCHAR(255) ); CREATE TABLE Students (   /* Create table with multiple fields as unique */ ID INT NOT NULL LastName VARCHAR(255) FirstName VARCHAR(255) NOT NULL CONSTRAINT PK_Student UNIQUE (ID, FirstName) ); ALTER TABLE Students   /* Set a column as unique */ ADD UNIQUE (ID); ALTER TABLE Students   /* Set multiple columns as unique */ ADD CONSTRAINT PK_Student   /* Naming a unique constraint */ UNIQUE (ID, FirstName);

---

#### What is a Query?

A query is a request for data or information from a database table or combination of tables. A database query can be either a select query or an action query. SELECT fname, lname    /* select query */ FROM myDb.students WHERE student_id = 1; UPDATE myDB.students    /* action query */ SET fname = 'Captain', lname = 'America' WHERE student_id = 1;

---

#### What is Data Integrity?

Data Integrity is the assurance of accuracy and consistency of data over its entire life-cycle and is a critical aspect of the design, implementation, and usage of any system which stores, processes, or retrieves data. It also defines integrity constraints to enforce business rules on the data when it is entered into an application or a database. logo Practice Problems Solve these problems to ace this concept Engineers Joined Easy

---

#### 11 Mins

Solve Job Offer Hard

---

#### 23 Mins

Solve

---

#### What is the difference between Clustered and Non-clustered index?

As explained above, the differences can be broken down into three small factors - Clustered index modifies the way records are stored in a database based on the indexed column. A non-clustered index creates a separate entity within the table which references the original table. Clustered index is used for easy and speedy retrieval of data from the database, whereas, fetching records from the non-clustered index is relatively slower. In SQL, a table can have a single clustered index whereas it can have multiple non-clustered indexes.

---

#### What is an Index? Explain its different types.

A database index is a data structure that provides a quick lookup of data in a column or columns of a table. It enhances the speed of operations accessing data from a database table at the cost of additional writes and memory to maintain the index data structure. CREATE INDEX index_name   /* Create Index */ ON table_name (column_1, column_2); DROP INDEX index_name;   /* Drop Index */ There are different types of indexes that can be created for different purposes: Unique and Non-Unique Index: Unique indexes are indexes that help maintain data integrity by ensuring that no two rows of data in a table have identical key values. Once a unique index has been defined for a table, uniqueness is enforced whenever keys are added or changed within the index. CREATE UNIQUE INDEX myIndex ON students (enroll_no); Non-unique indexes, on the other hand, are not used to enforce constraints on the tables with which they are associated. Instead, non-unique indexes are used solely to improve query performance by maintaining a sorted order of data values that are used frequently. Clustered and Non-Clustered Index: Clustered indexes are indexes whose order of the rows in the database corresponds to the order of the rows in the index. This is why only one clustered index can exist in a given table, whereas, multiple non-clustered indexes can exist in the table. The only difference between clustered and non-clustered indexes is that the database manager attempts to keep the data in the database in the same order as the corresponding keys appear in the clustered index. Clustering indexes can improve the performance of most query operations because they provide a linear-access path to data stored in the database.

---

#### What is a Cross-Join?

Cross join can be defined as a cartesian product of the two tables included in the join. The table after join contains the same number of rows as in the cross-product of the number of rows in the two tables. If a WHERE clause is used in cross join then the query will work like an INNER JOIN. SELECT stu.name, sub.subject FROM students AS stu CROSS JOIN subjects AS sub;

---

#### What is a Self-Join?

A self JOIN is a case of regular join where a table is joined to itself based on some relation between its own column(s). Self-join uses the INNER JOIN or LEFT JOIN clause and a table alias is used to assign different names to the table within the query. SELECT A.emp_id AS "Emp_ID",A.emp_name AS "Employee", B.emp_id AS "Sup_ID",B.emp_name AS "Supervisor" FROM employee A, employee B WHERE A.emp_sup = B.emp_id;

---

#### What is a Join? List its different types.

The SQL Join clause is used to combine records (rows) from two or more tables in a SQL database based on a related column between the two. There are four different types of JOINs in SQL: (INNER) JOIN: Retrieves records that have matching values in both tables involved in the join. This is the widely used join for queries. SELECT * FROM Table_A JOIN Table_B; SELECT * FROM Table_A INNER JOIN Table_B; LEFT (OUTER) JOIN: Retrieves all the records/rows from the left and the matched records/rows from the right table. SELECT * FROM Table_A A LEFT JOIN Table_B B ON A.col = B.col; RIGHT (OUTER) JOIN: Retrieves all the records/rows from the right and the matched records/rows from the left table. SELECT * FROM Table_A A RIGHT JOIN Table_B B ON A.col = B.col; FULL (OUTER) JOIN: Retrieves all the records where there is a match in either the left or right table. SELECT * FROM Table_A A FULL JOIN Table_B B ON A.col = B.col;

---

#### What is a Foreign Key?

A FOREIGN KEY comprises of single or collection of fields in a table that essentially refers to the PRIMARY KEY in another table. Foreign key constraint ensures referential integrity in the relation between two tables. The table with the foreign key constraint is labeled as the child table, and the table containing the candidate key is labeled as the referenced or parent table. CREATE TABLE Students (   /* Create table with foreign key - Way 1 */ ID INT NOT NULL Name VARCHAR(255) LibraryID INT PRIMARY KEY (ID) FOREIGN KEY (Library_ID) REFERENCES Library(LibraryID) ); CREATE TABLE Students (   /* Create table with foreign key - Way 2 */ ID INT NOT NULL PRIMARY KEY Name VARCHAR(255) LibraryID INT FOREIGN KEY (Library_ID) REFERENCES Library(LibraryID) ); ALTER TABLE Students   /* Add a new foreign key */ ADD FOREIGN KEY (LibraryID) REFERENCES Library (LibraryID);

---

#### What is a Subquery? What are its types?

A subquery is a query within another query, also known as a nested query or inner query. It is used to restrict or enhance the data to be queried by the main query, thus restricting or enhancing the output of the main query respectively. For example, here we fetch the contact information for students who have enrolled for the maths subject: SELECT name, email, mob, address FROM myDb.contacts WHERE roll_no IN ( SELECT roll_no FROM myDb.students WHERE subject = 'Maths'); There are two types of subquery - Correlated and Non-Correlated. A correlated subquery cannot be considered as an independent query, but it can refer to the column in a table listed in the FROM of the main query. A non-correlated subquery can be considered as an independent query and the output of the subquery is substituted in the main query. logo Practice Problems Solve these problems to ace this concept Study Selection Medium

---

#### 23 Mins

Solve Job Offers 2.0 Hard

---

#### 46 Mins

Solve

---

#### What is a Primary Key?

The PRIMARY KEY constraint uniquely identifies each row in a table. It must contain UNIQUE values and has an implicit NOT NULL constraint. A table in SQL is strictly restricted to have one and only one primary key, which is comprised of single or multiple fields (columns). CREATE TABLE Students (   /* Create table with a single field as primary key */ ID INT NOT NULL Name VARCHAR(255) PRIMARY KEY (ID) ); CREATE TABLE Students (   /* Create table with multiple fields as primary key */ ID INT NOT NULL LastName VARCHAR(255) FirstName VARCHAR(255) NOT NULL, CONSTRAINT PK_Student PRIMARY KEY (ID, FirstName) ); ALTER TABLE Students   /* Set a column as primary key */ ADD PRIMARY KEY (ID); ALTER TABLE Students   /* Set multiple columns as primary key */ ADD CONSTRAINT PK_Student   /*Naming a Primary Key*/ PRIMARY KEY (ID, FirstName); logo Practice Problems Solve these problems to ace this concept Student Query Easy

---

#### 10 Mins

Solve Country Filtration Easy

---

#### 8 Mins

Solve

---

#### What are Constraints in SQL?

Constraints are used to specify the rules concerning data in the table. It can be applied for single or multiple fields in an SQL table during the creation of the table or after creating using the ALTER TABLE command. The constraints are: NOT NULL - Restricts NULL value from being inserted into a column. CHECK - Verifies that all values in a field satisfy a condition. DEFAULT - Automatically assigns a default value if no value has been specified for the field. UNIQUE - Ensures unique values to be inserted into the field. INDEX - Indexes a field providing faster retrieval of records. PRIMARY KEY - Uniquely identifies each record in a table. FOREIGN KEY - Ensures referential integrity for a record in another table.

---

#### What are Tables and Fields?

A table is an organized collection of data stored in the form of rows and columns. Columns can be categorized as vertical and rows as horizontal. The columns in a table are called fields while the rows can be referred to as records.

---

#### What is the difference between SQL and MySQL?

SQL is a standard language for retrieving and manipulating structured databases. On the contrary, MySQL is a relational database management system, like SQL Server, Oracle or IBM DB2, that is used to manage SQL databases.

---

#### What is SQL?

SQL stands for Structured Query Language. It is the standard language for relational database management systems. It is especially useful in handling organized data comprised of entities (variables) and relations between different entities of the data.

---

#### What is RDBMS? How is it different from DBMS?

RDBMS stands for Relational Database Management System. The key difference here, compared to DBMS, is that RDBMS stores data in the form of a collection of tables, and relations can be defined between the common fields of these tables. Most modern database management systems like MySQL, Microsoft SQL Server, Oracle, IBM DB2, and Amazon Redshift are based on RDBMS.

---

#### What is DBMS?

DBMS stands for Database Management System. DBMS is a system software responsible for the creation, retrieval, updation, and management of the database. It ensures that our data is consistent, organized, and is easily accessible by serving as an interface between the database and its end-users or application software.

---

#### What is Database?

A database is an organized collection of data, stored and retrieved digitally from a remote or local computer system. Databases can be vast and complex, and such databases are developed using fixed design and modeling approaches.

---

#### What is the SELECT statement?

SELECT operator in SQL is used to select data from a database. The data returned is stored in a result table, called the result-set. SELECT * FROM myDB.students;

---

#### What are some common clauses used with SELECT query in SQL?

Some common SQL clauses used in conjuction with a SELECT query are as follows: WHERE clause in SQL is used to filter records that are necessary, based on specific conditions. ORDER BY clause in SQL is used to sort the records based on some field(s) in ascending (ASC) or descending order (DESC). SELECT * FROM myDB.students WHERE graduation_year = 2019 ORDER BY studentID DESC; GROUP BY clause in SQL is used to group records with identical data and can be used in conjunction with some aggregation functions to produce summarized results from the database. HAVING clause in SQL is used to filter records in combination with the GROUP BY clause. It is different from WHERE, since the WHERE clause cannot filter aggregated records. SELECT COUNT(studentId), country FROM myDB.students WHERE country != "INDIA" GROUP BY country HAVING COUNT(studentID) > 5;

---

#### What are UNION, MINUS and INTERSECT commands?

The UNION operator combines and returns the result-set retrieved by two or more SELECT statements. The MINUS operator in SQL is used to remove duplicates from the result-set obtained by the second SELECT query from the result-set obtained by the first SELECT query and then return the filtered results from the first. The INTERSECT clause in SQL combines the result-set fetched by the two SELECT statements where records from one match the other and then returns this intersection of result-sets. Certain conditions need to be met before executing either of the above statements in SQL - Each SELECT statement within the clause must have the same number of columns The columns must also have similar data types The columns in each SELECT statement should necessarily have the same order SELECT name FROM Students   /* Fetch the union of queries */ UNION SELECT name FROM Contacts; SELECT name FROM Students   /* Fetch the union of queries with duplicates*/ UNION ALL SELECT name FROM Contacts; SELECT name FROM Students   /* Fetch names from students */ MINUS     /* that aren't present in contacts */ SELECT name FROM Contacts; SELECT name FROM Students   /* Fetch names from students */ INTERSECT    /* that are present in contacts as well */ SELECT name FROM Contacts;

---

#### What is Cursor? How to use a Cursor?

A database cursor is a control structure that allows for the traversal of records in a database. Cursors, in addition, facilitates processing after traversal, such as retrieval, addition, and deletion of database records. They can be viewed as a pointer to one row in a set of rows. Working with SQL Cursor: DECLARE a cursor after any variable declaration. The cursor declaration must always be associated with a SELECT Statement. Open cursor to initialize the result set. The OPEN statement must be called before fetching rows from the result set. FETCH statement to retrieve and move to the next row in the result set. Call the CLOSE statement to deactivate the cursor. Finally use the DEALLOCATE statement to delete the cursor definition and release the associated resources. DECLARE @name VARCHAR(50)   /* Declare All Required Variables */ DECLARE db_cursor CURSOR FOR   /* Declare Cursor Name*/ SELECT name FROM myDB.students WHERE parent_name IN ('Sara', 'Ansh') OPEN db_cursor   /* Open cursor and Fetch data into @name */ FETCH next FROM db_cursor INTO @name CLOSE db_cursor   /* Close the cursor and deallocate the resources */ DEALLOCATE db_cursor

---

#### What are Entities and Relationships?

Entity: An entity can be a real-world object, either tangible or intangible, that can be easily identifiable. For example, in a college database, students, professors, workers, departments, and projects can be referred to as entities. Each entity has some associated properties that provide it an identity. Relationships: Relations or links between entities that have something to do with each other. For example - The employee's table in a company's database can be associated with the salary table in the same database.

---

#### List the different types of relationships in SQL.

One-to-One - This can be defined as the relationship between two tables where each record in one table is associated with the maximum of one record in the other table. One-to-Many & Many-to-One - This is the most commonly used relationship where a record in a table is associated with multiple records in the other table. Many-to-Many - This is used in cases when multiple instances on both sides are needed for defining a relationship. Self-Referencing Relationships - This is used when a table needs to define a relationship with itself.

---

#### What is an Alias in SQL?

An alias is a feature of SQL that is supported by most, if not all, RDBMSs. It is a temporary name assigned to the table or table column for the purpose of a particular SQL query. In addition, aliasing can be employed as an obfuscation technique to secure the real names of database fields. A table alias is also called a correlation name. An alias is represented explicitly by the AS keyword but in some cases, the same can be performed without it as well. Nevertheless, using the AS keyword is always a good practice. SELECT A.emp_name AS "Employee"  /* Alias using AS keyword */ B.emp_name AS "Supervisor" FROM employee A, employee B   /* Alias without AS keyword */ WHERE A.emp_sup = B.emp_id;

---

#### What is a View?

A view in SQL is a virtual table based on the result-set of an SQL statement. A view contains rows and columns, just like a real table. The fields in a view are fields from one or more real tables in the database.

---

#### What is Normalization?

Normalization represents the way of organizing structured data in the database efficiently. It includes the creation of tables, establishing relationships between them, and defining rules for those relationships. Inconsistency and redundancy can be kept in check based on these rules, hence, adding flexibility to the database.

---

#### What is Denormalization?

Denormalization is the inverse process of normalization, where the normalized schema is converted into a schema that has redundant information. The performance is improved by using redundancy and keeping the redundant data consistent. The reason for performing denormalization is the overheads produced in the query processor by an over-normalized structure.

---

#### What are the various forms of Normalization?

Normal Forms are used to eliminate or reduce redundancy in database tables. The different forms are as follows: First Normal Form: A relation is in first normal form if every attribute in that relation is a single-valued attribute. If a relation contains a composite or multi-valued attribute, it violates the first normal form. Let's consider the following students table. Each student in the table, has a name, his/her address, and the books they issued from the public library - Students Table Student 	Address 	Books Issued 	Salutation Sara 	Amanora Park Town 94 	Until the Day I Die (Emily Carpenter), Inception (Christopher Nolan)	Ms. Ansh	62nd Sector A-10 	The Alchemist (Paulo Coelho), Inferno (Dan Brown) 	Mr. Sara 	24th Street Park Avenue 	Beautiful Bad (Annie Ward), Woman 99 (Greer Macallister)	Mrs. Ansh 	Windsor Street 777 	Dracula (Bram Stoker)	Mr. As we can observe, the Books Issued field has more than one value per record, and to convert it into 1NF, this has to be resolved into separate individual records for each book issued. Check the following table in 1NF form - Students Table (1st Normal Form) Student 	Address 	Books Issued 	Salutation Sara	Amanora Park Town 94	Until the Day I Die (Emily Carpenter) 	Ms. Sara	Amanora Park Town 94	Inception (Christopher Nolan) 	Ms. Ansh	62nd Sector A-10	The Alchemist (Paulo Coelho) 	Mr. Ansh	62nd Sector A-10	Inferno (Dan Brown) 	Mr. Sara	24th Street Park Avenue	Beautiful Bad (Annie Ward) 	Mrs. Sara	24th Street Park Avenue	Woman 99 (Greer Macallister) 	Mrs. Ansh	Windsor Street 777	Dracula (Bram Stoker) 	Mr. Second Normal Form: A relation is in second normal form if it satisfies the conditions for the first normal form and does not contain any partial dependency. A relation in 2NF has no partial dependency, i.e., it has no non-prime attribute that depends on any proper subset of any candidate key of the table. Often, specifying a single column Primary Key is the solution to the problem. Examples - Example 1 - Consider the above example. As we can observe, the Students Table in the 1NF form has a candidate key in the form of [Student, Address] that can uniquely identify all records in the table. The field Books Issued (non-prime attribute) depends partially on the Student field. Hence, the table is not in 2NF. To convert it into the 2nd Normal Form, we will partition the tables into two while specifying a new Primary Key attribute to identify the individual records in the Students table. The Foreign Key constraint will be set on the other table to ensure referential integrity. Students Table (2nd Normal Form) Student_ID 	Student	Address 	Salutation 1	Sara	Amanora Park Town 94 	Ms. 2	Ansh	62nd Sector A-10 	Mr. 3	Sara	24th Street Park Avenue 	Mrs. 4	Ansh	Windsor Street 777 	Mr. Books Table (2nd Normal Form) Student_ID 	Book Issued 1	Until the Day I Die (Emily Carpenter) 1	Inception (Christopher Nolan) 2	The Alchemist (Paulo Coelho) 2	Inferno (Dan Brown) 3	Beautiful Bad (Annie Ward) 3	Woman 99 (Greer Macallister) 4	Dracula (Bram Stoker) Example 2 - Consider the following dependencies in relation to R(W,X,Y,Z) WX -> Y    [W and X together determine Y] XY -> Z    [X and Y together determine Z] Here, WX is the only candidate key and there is no partial dependency, i.e., any proper subset of WX doesn‚Äôt determine any non-prime attribute in the relation. Third Normal Form A relation is said to be in the third normal form, if it satisfies the conditions for the second normal form and there is no transitive dependency between the non-prime attributes, i.e., all non-prime attributes are determined only by the candidate keys of the relation and not by any other non-prime attribute. Example 1 - Consider the Students Table in the above example. As we can observe, the Students Table in the 2NF form has a single candidate key Student_ID (primary key) that can uniquely identify all records in the table. The field Salutation (non-prime attribute), however, depends on the Student Field rather than the candidate key. Hence, the table is not in 3NF. To convert it into the 3rd Normal Form, we will once again partition the tables into two while specifying a new Foreign Key constraint to identify the salutations for individual records in the Students table. The Primary Key constraint for the same will be set on the Salutations table to identify each record uniquely. Students Table (3rd Normal Form) Student_ID 	Student 	Address 	Salutation_ID 1	Sara	Amanora Park Town 94 	1 2	Ansh	62nd Sector A-10 	2 3	Sara	24th Street Park Avenue 	3 4	Ansh	Windsor Street 777 	1 Books Table (3rd Normal Form) Student_ID	Book Issued 1	Until the Day I Die (Emily Carpenter) 1	Inception (Christopher Nolan) 2	The Alchemist (Paulo Coelho) 2	Inferno (Dan Brown) 3	Beautiful Bad (Annie Ward) 3	Woman 99 (Greer Macallister) 4	Dracula (Bram Stoker) Salutations Table (3rd Normal Form) Salutation_ID	Salutation 1	Ms. 2	Mr. 3	Mrs. Example 2 - Consider the following dependencies in relation to R(P,Q,R,S,T) P -> QR     [P together determine C] RS -> T     [B and C together determine D] Q -> S T -> P For the above relation to exist in 3NF, all possible candidate keys in the above relation should be {P, RS, QR, T}. Boyce-Codd Normal Form A relation is in Boyce-Codd Normal Form if satisfies the conditions for third normal form and for every functional dependency, Left-Hand-Side is super key. In other words, a relation in BCNF has non-trivial functional dependencies in form X ‚Äì> Y, such that X is always a super key. For example - In the above example, Student_ID serves as the sole unique identifier for the Students Table and Salutation_ID for the Salutations Table, thus these tables exist in BCNF. The same cannot be said for the Books Table and there can be several books with common Book Names and the same Student_ID.

---

#### What are the TRUNCATE, DELETE and DROP statements?

DELETE statement is used to delete rows from a table. DELETE FROM Candidates WHERE CandidateId > 1000; TRUNCATE command is used to delete all the rows from the table and free the space containing the table. TRUNCATE TABLE Candidates; DROP command is used to remove an object from the database. If you drop a table, all the rows in the table are deleted and the table structure is removed from the database. DROP TABLE Candidates;

---

#### What is the difference between DROP and TRUNCATE statements?

If a table is dropped, all things associated with the tables are dropped as well. This includes - the relationships defined on the table with other tables, the integrity checks and constraints, access privileges and other grants that the table has. To create and use the table again in its original form, all these relations, checks, constraints, privileges and relationships need to be redefined. However, if a table is truncated, none of the above problems exist and the table retains its original structure.

---

#### What is the difference between DELETE and TRUNCATE statements?

The TRUNCATE command is used to delete all the rows from the table and free the space containing the table. The DELETE command deletes only the rows from the table based on the condition given in the where clause or deletes all the rows from the table if no condition is specified. But it does not free the space containing the table.

---

#### What are Aggregate and Scalar functions?

An aggregate function performs operations on a collection of values to return a single scalar value. Aggregate functions are often used with the GROUP BY and HAVING clauses of the SELECT statement. Following are the widely used SQL aggregate functions: AVG() - Calculates the mean of a collection of values. COUNT() - Counts the total number of records in a specific table or view. MIN() - Calculates the minimum of a collection of values. MAX() - Calculates the maximum of a collection of values. SUM() - Calculates the sum of a collection of values. FIRST() - Fetches the first element in a collection of values. LAST() - Fetches the last element in a collection of values. Note: All aggregate functions described above ignore NULL values except for the COUNT function. A scalar function returns a single value based on the input value. Following are the widely used SQL scalar functions: LEN() - Calculates the total length of the given field (column). UCASE() - Converts a collection of string values to uppercase characters. LCASE() - Converts a collection of string values to lowercase characters. MID() - Extracts substrings from a collection of string values in a table. CONCAT() - Concatenates two or more strings. RAND() - Generates a random collection of numbers of a given length. ROUND() - Calculates the round-off integer value for a numeric field (or decimal point values). NOW() - Returns the current date & time. FORMAT() - Sets the format to display a collection of values. PostgreSQL Interview Questions

---

#### What is PostgreSQL?

PostgreSQL was first called Postgres and was developed by a team led by Computer Science Professor Michael Stonebraker in 1986. It was developed to help developers build enterprise-level applications by upholding data integrity by making systems fault-tolerant. PostgreSQL is therefore an enterprise-level, flexible, robust, open-source, and object-relational DBMS that supports flexible workloads along with handling concurrent users. It has been consistently supported by the global developer community. Due to its fault-tolerant nature, PostgreSQL has gained widespread popularity among developers.

---

#### What is the capacity of a table in PostgreSQL?

The maximum size of PostgreSQL is 32TB.

---

#### What is the importance of the TRUNCATE statement?

TRUNCATE TABLE name_of_table statement removes the data efficiently and quickly from the table. The truncate statement can also be used to reset values of the identity columns along with data cleanup as shown below: TRUNCATE TABLE name_of_table RESTART IDENTITY; We can also use the statement for removing data from multiple tables all at once by mentioning the table names separated by comma as shown below: TRUNCATE TABLE table_1, table_2, table_3;

---

#### Define tokens in PostgreSQL?

A token in PostgreSQL is either a keyword, identifier, literal, constant, quotes identifier, or any symbol that has a distinctive personality. They may or may not be separated using a space, newline or a tab. If the tokens are keywords, they are usually commands with useful meanings. Tokens are known as building blocks of any PostgreSQL code.

---

#### What are partitioned tables called in PostgreSQL?

Partitioned tables are logical structures that are used for dividing large tables into smaller structures that are called partitions. This approach is used for effectively increasing the query performance while dealing with large database tables. To create a partition, a key called partition key which is usually a table column or an expression, and a partitioning method needs to be defined. There are three types of inbuilt partitioning methods provided by Postgres: Range Partitioning: This method is done by partitioning based on a range of values. This method is most commonly used upon date fields to get monthly, weekly or yearly data. In the case of corner cases like value belonging to the end of the range, for example: if the range of partition 1 is 10-20 and the range of partition 2 is 20-30, and the given value is 10, then 10 belongs to the second partition and not the first. List Partitioning: This method is used to partition based on a list of known values. Most commonly used when we have a key with a categorical value. For example, getting sales data based on regions divided as countries, cities, or states. Hash Partitioning: This method utilizes a hash function upon the partition key. This is done when there are no specific requirements for data division and is used to access data individually. For example, you want to access data based on a specific product, then using hash partition would result in the dataset that we require. The type of partition key and the type of method used for partitioning determines how positive the performance and the level of manageability of the partitioned table are.

---

#### How can we start, restart and stop the PostgreSQL server?

To start the PostgreSQL server, we run: service postgresql start Once the server is successfully started, we get the below message: Starting PostgreSQL: ok To restart the PostgreSQL server, we run: service postgresql restart Once the server is successfully restarted, we get the message: Restarting PostgreSQL: server stopped ok To stop the server, we run the command: service postgresql stop Once stopped successfully, we get the message: Stopping PostgreSQL: server stopped ok

---

#### What is the command used for creating a database in PostgreSQL?

The first step of using PostgreSQL is to create a database. This is done by using the createdb command as shown below: createdb db_name After running the above command, if the database creation was successful, then the below message is shown: CREATE DATABASE

---

#### How will you change the datatype of a column?

This can be done by using the ALTER TABLE statement as shown below: Syntax: ALTER TABLE tname ALTER COLUMN col_name [SET DATA] TYPE new_data_type;

---

#### How do you define Indexes in PostgreSQL?

Indexes are the inbuilt functions in PostgreSQL which are used by the queries to perform search more efficiently on a table in the database. Consider that you have a table with thousands of records and you have the below query that only a few records can satisfy the condition, then it will take a lot of time to search and return those rows that abide by this condition as the engine has to perform the search operation on every single to check this condition. This is undoubtedly inefficient for a system dealing with huge data. Now if this system had an index on the column where we are applying search, it can use an efficient method for identifying matching rows by walking through only a few levels. This is called indexing. Select * from some_table where table_col=120

---

#### Define sequence.

A sequence is a schema-bound, user-defined object which aids to generate a sequence of integers. This is most commonly used to generate values to identity columns in a table. We can create a sequence by using the CREATE SEQUENCE statement as shown below: CREATE SEQUENCE serial_num START 100; To get the next number 101 from the sequence, we use the nextval() method as shown below: SELECT nextval('serial_num'); We can also use this sequence while inserting new records using the INSERT command: INSERT INTO ib_table_name VALUES (nextval('serial_num'), 'interviewbit');

---

#### What are string constants in PostgreSQL?

They are character sequences bound within single quotes. These are using during data insertion or updation to characters in the database. There are special string constants that are quoted in dollars. Syntax: $tag$<string_constant>$tag$ The tag in the constant is optional and when we are not specifying the tag, the constant is called a double-dollar string literal.

---

#### How can you get a list of all databases in PostgreSQL?

This can be done by using the command \l -> backslash followed by the lower-case letter L.

---

#### How can you delete a database in PostgreSQL?

This can be done by using the DROP DATABASE command as shown in the syntax below: DROP DATABASE database_name; If the database has been deleted successfully, then the following message would be shown: DROP DATABASE

---

#### What are ACID properties? Is PostgreSQL compliant with ACID?

ACID stands for Atomicity, Consistency, Isolation, Durability. They are database transaction properties which are used for guaranteeing data validity in case of errors and failures. Atomicity: This property ensures that the transaction is completed in all-or-nothing way. Consistency: This ensures that updates made to the database is valid and follows rules and restrictions. Isolation: This property ensures integrity of transaction that are visible to all other transactions. Durability: This property ensures that the committed transactions are stored permanently in the database. PostgreSQL is compliant with ACID properties.

---

#### Can you explain the architecture of PostgreSQL?

The architecture of PostgreSQL follows the client-server model. The server side comprises of background process manager, query processer, utilities and shared memory space which work together to build PostgreSQL‚Äôs instance that has access to the data. The client application does the task of connecting to this instance and requests data processing to the services. The client can either be GUI (Graphical User Interface) or a web application. The most commonly used client for PostgreSQL is pgAdmin.

---

#### What do you understand by multi-version concurrency control?

MVCC or Multi-version concurrency control is used for avoiding unnecessary database locks when 2 or more requests tries to access or modify the data at the same time. This ensures that the time lag for a user to log in to the database is avoided. The transactions are recorded when anyone tries to access the content. For more information regarding this, you can refer here.

---

#### What do you understand by command enable-debug?

The command enable-debug is used for enabling the compilation of all libraries and applications. When this is enabled, the system processes get hindered and generally also increases the size of the binary file. Hence, it is not recommended to switch this on in the production environment. This is most commonly used by developers to debug the bugs in their scripts and help them spot the issues. For more information regarding how to debug, you can refer here.

---

#### How do you check the rows affected as part of previous transactions?

SQL standards state that the following three phenomena should be prevented whilst concurrent transactions. SQL standards define 4 levels of transaction isolations to deal with these phenomena. Dirty reads: If a transaction reads data that is written due to concurrent uncommitted transaction, these reads are called dirty reads. Phantom reads: This occurs when two same queries when executed separately return different rows. For example, if transaction A retrieves some set of rows matching search criteria. Assume another transaction B retrieves new rows in addition to the rows obtained earlier for the same search criteria. The results are different. Non-repeatable reads: This occurs when a transaction tries to read the same row multiple times and gets different values each time due to concurrency. This happens when another transaction updates that data and our current transaction fetches that updated data, resulting in different values. To tackle these, there are 4 standard isolation levels defined by SQL standards. They are as follows: Read Uncommitted ‚Äì The lowest level of the isolations. Here, the transactions are not isolated and can read data that are not committed by other transactions resulting in dirty reads. Read Committed ‚Äì This level ensures that the data read is committed at any instant of read time. Hence, dirty reads are avoided here. This level makes use of read/write lock on the current rows which prevents read/write/update/delete of that row when the current transaction is being operated on. Repeatable Read ‚Äì The most restrictive level of isolation. This holds read and write locks for all rows it operates on. Due to this, non-repeatable reads are avoided as other transactions cannot read, write, update or delete the rows. Serializable ‚Äì The highest of all isolation levels. This guarantees that the execution is serializable where execution of any concurrent operations are guaranteed to be appeared as executing serially. The following table clearly explains which type of unwanted reads the levels avoid: Isolation levels 	Dirty Reads 	Phantom Reads 	Non-repeatable reads Read Uncommitted 	Might occur	Might occur	Might occur Read Committed 	Won‚Äôt occur	Might occur	Might occur Repeatable Read	Won‚Äôt occur	Might occur	Won‚Äôt occur Serializable	Won‚Äôt occur	Won‚Äôt occur	Won‚Äôt occur

---

#### What can you tell about WAL (Write Ahead Logging)?

Write Ahead Logging is a feature that increases the database reliability by logging changes before any changes are done to the database. This ensures that we have enough information when a database crash occurs by helping to pinpoint to what point the work has been complete and gives a starting point from the point where it was discontinued. For more information, you can refer here.

---

#### What is the main disadvantage of deleting data from an existing table using the DROP TABLE command?

DROP TABLE command deletes complete data from the table along with removing the complete table structure too. In case our requirement entails just remove the data, then we would need to recreate the table to store data in it. In such cases, it is advised to use the TRUNCATE command.

---

#### How do you perform case-insensitive searches using regular expressions in PostgreSQL?

To perform case insensitive matches using a regular expression, we can use POSIX (~*) expression from pattern matching operators. For example: 'interviewbit' ~* '.*INTervIewBit.*'

---

#### How will you take backup of the database in PostgreSQL?

We can achieve this by using the pg_dump tool for dumping all object contents in the database into a single file. The steps are as follows: Step 1: Navigate to the bin folder of the PostgreSQL installation path. C:\>cd C:\Program Files\PostgreSQL\10.0\bin Step 2: Execute pg_dump program to take the dump of data to a .tar folder as shown below: pg_dump -U postgres -W -F t sample_data > C:\Users\admin\pgbackup\sample_data.tar The database dump will be stored in the sample_data.tar file on the location specified.

---

#### Does PostgreSQL support full text search?

Full-Text Search is the method of searching single or collection of documents stored on a computer in a full-text based database. This is mostly supported in advanced database systems like SOLR or ElasticSearch. However, the feature is present but is pretty basic in PostgreSQL.

---

#### What are parallel queries in PostgreSQL?

Parallel Queries support is a feature provided in PostgreSQL for devising query plans capable of exploiting multiple CPU processors to execute the queries faster.

---

#### Differentiate between commit and checkpoint.

The commit action ensures that the data consistency of the transaction is maintained and it ends the current transaction in the section. Commit adds a new record in the log that describes the COMMIT to the memory. Whereas, a checkpoint is used for writing all changes that were committed to disk up to SCN which would be kept in datafile headers and control files. Conclusion: SQL is a language for the database. It has a vast scope and robust capability of creating and manipulating a variety of database objects using commands like CREATE, ALTER, DROP, etc, and also in loading the database objects using commands like INSERT. It also provides options for Data Manipulation using commands like DELETE, TRUNCATE and also does effective retrieval of data using cursor commands like FETCH, SELECT, etc. There are many such commands which provide a large amount of control to the programmer to interact with the database in an efficient way without wasting many resources. The popularity of SQL has grown so much that almost every programmer relies on this to implement their application's storage functionalities thereby making it an exciting language to learn. Learning this provides the developer a benefit of understanding the data structures used for storing the organization's data and giving an additional level of control and in-depth understanding of the application. PostgreSQL being an open-source database system having extremely robust and sophisticated ACID, Indexing, and Transaction supports has found widespread popularity among the developer community. References and Resources: PostgreSQL Download PostgreSQL Tutorial SQL Guide SQL Server Interview Questions SQL Query Interview Questions and Answers SQL Interview Questions for Data Science MySQL Interview Questions DBMS Interview Questions PL SQL Interview Questions MongoDB Interview Questions Database Testing Interview Questions SQL Vs MySQL PostgreSQL vs MySQL Difference Between SQL and PLSQL Difference between RDBMS and DBMS SQL Vs NoSQL SQL IDE SQL Projects MySQL Commands SQL Books OLTP vs OLAP SQL MCQ 1. An SQL query to delete a table from the database and memory while keeping the structure of the table intact? DROP TABLE table_name; DROP FROM TABLE table_name; DELETE FROM TABLE table_name; TRUNCATE TABLE table_name; 2. What is a pre-requisite for creating a database in PostgreSQL?To create a database in PostgreSQL, you must have the special CREATEDB privilege or Super user privilege or CREATEDB privilege Admin privilege CREATEDBL privilege and Super user privilege Just run the script 3. Which of the following is known as a virtual table in SQL? SELF JOIN INNER JOIN VIEW NONE 4. What is the main advantage of a clustered index over a non-clustered index? It is easier to create and manipulate. It requires extra memory but allows for speedy retrieval of records. It does not require additional memory and allows for speedy retrieval of records. None of the above. 5. SQL query used to fetch unique values from a field? SELECT UNIQUE column_name FROM table_name; SELECT DISTINCT column_name FROM table_name; SELECT column_name FROM table_name WHERE COUNT(column_name) = 1; SELECT UNIQUE column_name FROM table_name WHERE COUNT(column_name) = 1; 6. Which statement is used to update data in the database? MODIFY UPDATE ALTER TABLE SAVE AS 7. Which statement is false for the ORDER BY statement? Requires a ASC or DESC keyword explicitly to sort the result set. Sorts the result set in descending order using the DESC keyword. Can sort based on multiple columns None of the above. 8. What statement is used for adding data to PostgreSQL? UPDATE ADD APPEND INSERT 9. Normalization which has neither composite values nor partial dependencies? Second Normal Formal Third Normal Form Boyce-Codd Normal Form All of the above 10. What does SQL stand for? Structured Question Language Strong Query Language Structured Query Language Strong Question Language 11. Which statement is true for a PRIMARY KEY constraint? Primary key defines a realtionship between two tables. A table in SQL must have a primary key associated with it to uniquely identify its records. A table in SQL is indexed by default based on its primary key. Primary key may or may not be unique but can be comprised of multiple fields. 12. What is the order of results shown by default if the ASC or DESC parameter is not specified with the ORDER BY command? Results are shown in descending order Results are shown in ascending order Results display is random Results are shown in ascending and descending order alternately. 13. What allows us to define how various tables are related to each other formally in a database? Views Foreign Key Constraints Primary Key Constraints Database manager 14. What is the name of the component that requests data to the PostgreSQL server? Client Thin Client Workstation Interface 15. What languages are supported by PostgreSQL? PL/pgSQL, PL/Tcl, PL/Perl and PL/Python PL/pgSQL, PL/Pcl, PL/Ruby and PL/Java PL/Perl, PL/Dcl, PL/Dtl and PL/Dml Only SQL 16. What command is used for restoring the backup of PostgreSQL which was created using pg_dump? psql -R db_dump.psql db_name psql -r db_dump.psql db_name psql -f db_dump.psql db_name psql -F db_dump.psql db_name 17. Query to select all records with "bar" in their name? SELECT * FROM people WHERE name = "%bar%"; SELECT * FROM people WHERE name LIKE "%bar%"; SELECT * FROM people WHERE name IN ("bar"); SELECT * FROM people WHERE name = "_bar_" 18. Which command is used to tell PostgreSQL to make all changes made to the database permanent? Submit Execute Apply Commit 19. Which statement is false for a FOREIGN KEY constraint? Foreign key defines a relationship between two tables. Foreign Key is automatically created when two tables are joined. Foreign Key uniquely identifies all the records in the referenced table. Foreign key may or may not be unique but can be comprised of multiple fields. 20. What is a Query? A SELECT or UPDATE statement in SQL. A request for data from a table in the database. A request to input data from the user. A request for data from single or multiple tables in the database.

---

#### SELECT

COUNT(CASE WHEN EXTRACT(ISODOW FROM submit_date) > 5 THEN 1 ELSE NULL END) AS weekend_cnt, COUNT(CASE WHEN EXTRACT(ISODOW FROM submit_date) <= 5 THEN 1 ELSE NULL END) AS working_cnt FROM tasks_2298;

---

#### SELECT DISTINCT salary

FROM employee_176 ORDER BY salary DESC LIMIT 1 OFFSET 1;

---

#### -- Question 89

-- Table point_2d holds the coordinates (x,y) of some unique points (more than two) in a plane. -- Write a query to find the shortest distance between these points rounded to 2 decimals. -- | x  | y  | -- |----|----| -- | -1 | -1 | -- | 0  | 0  | -- | -1 | -2 | -- The shortest distance is 1.00 from point (-1,-1) to (-1,2). So the output should be: -- | shortest | -- |----------| -- | 1.00     | -- Note: The longest distance among all the points are less than 10000. -- Solution select round(a.shortest,2) as shortest from( select sqrt(pow((p1.x-p2.x),2)+pow((p1.y-p2.y),2)) as shortest from point_2d p1 cross join point_2d p2 where p1.x!=p2.x or p1.y!=p2.y order by sqrt(pow((p1.x-p2.x),2)+pow((p1.y-p2.y),2)) limit 1) a

---

#### SELECT  drug,

(total_sales - cogs) AS total_profit FROM pharmacy_sales ORDER BY total_profit DESC LIMIT 3;

---

#### 11 Airbnb SQL Interview Questions - Can You Solve Them?

By Nick Singh (Ex-Facebook & Best-Selling Data Science Author) Updated on April 30, 2025 At Airbnb, SQL is used day-to-day for analyzing customer behavior to improve property recommendations and monitoring system performance for seamless booking experiences. Unsurprisingly this is why Airbnb LOVES to ask SQL problems in interviews for Data Analyst, Data Science, and BI jobs. In case you want to ace the SQL Assessment, we've curated 11 Airbnb SQL interview questions to practice, which are similar to recently asked questions at Airbnb ‚Äì able to answer them all? Airbnb SQL Interview Questions 11 Airbnb SQL Interview Questions SQL Question 1: Booking Referral Source The strategy team in Airbnb is trying to analyze the impact of Covid-19 during 2021. To do so, they need you to write a query that outputs the average vacant days across the AirBnbs in 2021. Some properties have gone out of business, so you should only analyze rentals that are currently active. Round the results to a whole number. Assumptions: is_active field equals to 1 when the property is active, and 0 otherwise. In cases where the check-in or check-out date is in another year other than 2021, limit the calculation to the beginning or end of the year 2021 respectively. Listing can be active even if there are no bookings throughout the year. bookings Table: Column Name	Type listing_id	integer checkin_date	date checkout_date	date bookings Example Input: listing_id	checkin_date	checkout_date 1	08/17/2021 00:00:00	08/19/2021 00:00:00 1	08/19/2021 00:00:00	08/25/2021 00:00:00 2	08/19/2021 00:00:00	09/22/2021 00:00:00 3	12/23/2021 00:00:00	01/05/2022 00:00:00 listings Table: Column Name	Type listing_id	integer is_active	integer listings Example Input: listing_id	is_active 1	1 2	0 3	1 Example Output: avg_vacant_days 357 Explanation: Property 1 was rented for 8 days, thus the property has 365 - 8 = 357 vacant days. Property 2 is excluded as it is not active. Property 3 was rented out for 12 days, thus the property as 365 - 12 = 353 vacant days. Average vacant days are 355 days. (357 + 353 / 2). The dataset you are querying against may have different input & output - this is just an example! Answer: WITH listing_vacancies AS ( SELECT listings.listing_id, 365 - COALESCE( SUM( CASE WHEN checkout_date>'12/31/2021' THEN '12/31/2021' ELSE checkout_date END - CASE WHEN checkin_date<'01/01/2021' THEN '01/01/2021' ELSE checkin_date END ),0) AS vacant_days FROM listings LEFT JOIN bookings ON listings.listing_id = bookings.listing_id WHERE listings.is_active = 1 GROUP BY listings.listing_id) SELECT ROUND(AVG(vacant_days)) FROM listing_vacancies; To solve this question join DataLemur Premium to try this Airbnb SQL interview question:Airbnb SQL Interview Question SQL Question 2: Analyzing Monthly Average Ratings of Airbnb Property Listings Given the reviews table with columns: review_id, user_id, submit_date, listing_id, stars, write a SQL query to get the average rating of each Airbnb property listing per month. The submit_date column represents when the review was submitted. The listing_id column represents the unique ID of the Airbnb property, and stars represents the rating given by the user where 1 is the lowest and 5 is the highest rating. reviews Example Input: review_id	user_id	submit_date	listing_id	stars 6171	123	01/02/2022 00:00:00	50001	4 7802	265	01/15/2022 00:00:00	69852	4 5293	362	01/22/2022 00:00:00	50001	3 6352	192	02/05/2022 00:00:00	69852	3 4517	981	02/10/2022 00:00:00	69852	2 Answer: SELECT EXTRACT(MONTH from submit_date) as mth, listing_id, AVG(stars) as avg_stars FROM reviews GROUP BY mth, listing_id ORDER BY listing_id, mth; This SQL query will first group the data by month and listing_id. For each group, it calculates the average stars rating. The EXTRACT(MONTH from submit_date) function is used to get the month from submit_date. The AVG(stars) function is used to calculate the average stars rating. In the end, it orders the results by listing_id and mth. Example Output: mth	listing_id	avg_stars 1	50001	3.50 1	69852	4.00 2	69852	2.50 p.s. Window functions show up super frequently during SQL interviews, so practice the 27+ window function questions on DataLemur DataLemur SQL Questions SQL Question 3: Average Vacant Days The strategy team in Airbnb is trying to analyze the impact of Covid-19 during 2021. To do so, they need you to write a query that outputs the average vacant days across the AirBnbs in 2021. Some properties have gone out of business, so you should only analyze rentals that are currently active. Round the results to a whole number. Assumptions: is_active field equals to 1 when the property is active, and 0 otherwise. In cases where the check-in or check-out date is in another year other than 2021, limit the calculation to the beginning or end of the year 2021 respectively. Listing can be active even if there are no bookings throughout the year. bookings Table: Column Name	Type listing_id	integer checkin_date	date checkout_date	date bookings Example Input: listing_id	checkin_date	checkout_date 1	08/17/2021 00:00:00	08/19/2021 00:00:00 1	08/19/2021 00:00:00	08/25/2021 00:00:00 2	08/19/2021 00:00:00	09/22/2021 00:00:00 3	12/23/2021 00:00:00	01/05/2022 00:00:00 listings Table: Column Name	Type listing_id	integer is_active	integer listings Example Input: listing_id	is_active 1	1 2	0 3	1 Example Output: avg_vacant_days 357 Solution: WITH listing_vacancies AS ( SELECT listings.listing_id, 365 - COALESCE( SUM( CASE WHEN checkout_date>'12/31/2021' THEN '12/31/2021' ELSE checkout_date END - CASE WHEN checkin_date<'01/01/2021' THEN '01/01/2021' ELSE checkin_date END ),0) AS vacant_days FROM listings LEFT JOIN bookings ON listings.listing_id = bookings.listing_id WHERE listings.is_active = 1 GROUP BY listings.listing_id) SELECT ROUND(AVG(vacant_days)) FROM listing_vacancies; To solve this question on DataLemur's free interactive site, try this Airbnb SQL interview question:Airbnb SQL Interview Question SQL Question 4: Retrieve Housing Data from Specific Cities You're a data analyst at Airbnb and you've been tasked with retrieving housing data from specific cities. You want to find all Airbnb listings in San Francisco and New York that have at least 10 reviews and an average rating equal to or above 4.5. Assume you have two tables: a listings table with the ID of the housing, its name, city, and the total number of reviews; and a reviews table with the ID of the listing, the review ID, the rating, and the date submitted. listings Example Input: listing_id	name	city	reviews_count 10001	"Central Loft"	"San Francisco"	15 10002	"Cozy Apartment"	"New York"	20 10003	"Sunny Studio"	"San Francisco"	8 10004	"Stylish Suite"	"Las Vegas"	13 10005	"Dreamy Duplex"	"New York"	5 reviews Example Input: listing_id	review_id	stars	submit_date 10001	15001	4.5	2022-06-08 10001	15002	5.0	2022-06-10 10002	15003	4.0	2022-06-18 10002	15004	5.0	2022-07-26 10003	15005	3.5	2022-07-05 10004	15006	4.5	2022-06-08 10005	15007	3.0	2022-06-10 Answer: SELECT l.listing_id, l.name, l.city, avg(r.stars) as average_rating FROM listings l JOIN reviews r ON l.listing_id = r.listing_id WHERE l.city in ('San Francisco', 'New York') AND l.reviews_count >= 10 GROUP BY l.listing_id HAVING avg(r.stars) >= 4.5; The above query works as follows: We join the listings table (alias 'l') with the reviews table (alias 'r') using the listing_id as the common column between the two tables. In the WHERE clause, we filter the cities to "San Francisco" and "New York", and the reviews_count to be at least 10. In the GROUP BY clause, we group by listing_id. This allows us to calculate the average rating for each listing. In the HAVING clause, we filter the average rating to be at least 4.5. By joining the tables, filtering, grouping, and running the average function, we're able to get the desired listings in those cities with the specific review conditions. SQL Question 5: What is the purpose of the SQL constraint UNIQUE? The UNIQUE constraint is used to ensure the uniqueness of the data in a column or set of columns in a table. It prevents the insertion of duplicate values in the specified column or columns and helps to ensure the integrity and reliability of the data in the database. For example, say you were on the Marketing Analytics team at Airbnb and were doing some automated keyword research: Your keyword database might store SEO data like this: CREATE TABLE keywords ( keyword_id INTEGER PRIMARY KEY, keyword VARCHAR(255) NOT NULL UNIQUE, search_volume INTEGER NOT NULL, competition FLOAT NOT NULL ); In this example, the UNIQUE constraint is applied to the "keyword" field to ensure that each keyword is unique. This helps to ensure the integrity of the data in the database and prevents errors that could occur if two rows had the same keyword. SQL Question 6: Find the Average Number of Guests per Booking in Each City for Airbnb As an analyst at Airbnb, one of the most useful insights you could provide would be to understand the average number of guests per booking across locations. For this question, we would like you to write a SQL query that will find the average number of guests per booking in each city. bookings Example Input: booking_id	property_id	guests	booking_date 101	4523	3	01/01/2022 102	9871	2	01/05/2022 103	4523	4	02/10/2022 104	7452	1	02/20/2022 105	9871	3	03/01/2022 properties Example Input: property_id	city 4523	New York 9871	Los Angeles 7452	Chicago Example Output: city	average_guests New York	3.5 Los Angeles	2.5 Chicago	1.0 Answer: SELECT p.city, AVG(b.guests) AS average_guests FROM bookings b JOIN properties p ON b.property_id = p.property_id GROUP BY p.city; In this query, we first join the bookings and properties tables on property_id, allowing us to access both the city and guests columns in the same query. We then group by city, so we get a separate row for each city in our output. For each group, we calculate the average number of guests. To practice a very similar question try this interactive Robinhood Cities With Completed Trades Question which is similar for requiring SQL analysis grouped by city or this Amazon Average Review Ratings Question which is similar for needing an average calculation. SQL Question 7: What's the difference between relational and non-relational databases? While both types of databases are used to store data (no duh!), relational databases and non-relational (also known as NoSQL databases) differ in a few important ways, most importantly on the way data is stored. Relational databases use a data model consisting of tables and rows, while NoSQL databases use a variety of data models, including document, key-value, columnar, and graph storage formats. This added flexibilty makes NoSQL databases great for non-tabular data (like hierarchal data or JSON data), or data where the type/format is constantly evolving. With this added flexibility, comes one big weakness ‚Äì you won't get ACID-compliance. That means, unlike relational databases which are typically adhere to the ACID properties (atomic, consistent, isolated, and durable), you don't get as strong guarentees with most non-relational databases. SQL Question 8: Analyzing click-through rates for Airbnb Listing Views and Bookings The scenario is that Airbnb wants to analyze the click-through conversion rates (CTRs) of their listings. The CTR is calculated by dividing the number of bookings by the number of listing views, giving a proportion of views that resulted in a booking. Consider you have two tables: one showing all the views for a listing (listing_views) and another one showing all bookings (bookings). listing_views Example Input: view_id	user_id	visit_date	listing_id 101	10	7/08/2022	1001 102	12	7/08/2022	1002 103	14	7/09/2022	1001 104	10	7/10/2022	1003 105	13	7/11/2022	1002 bookings Example Input: booking_id	user_id	booking_date	listing_id 201	10	7/09/2022	1001 202	12	7/10/2022	1002 203	15	7/12/2022	1003 204	13	7/13/2022	1002 205	12	7/14/2022	1001 The question is to write a SQL query to find the CTR for every unique listing in July 2022. Answer: Here is a PostgreSQL query answer: WITH total_views AS ( SELECT listing_id, COUNT(*) AS view_count FROM listing_views WHERE DATE_TRUNC('month', visit_date) = '2022-07-01' GROUP BY listing_id ), total_bookings AS ( SELECT listing_id, COUNT(*) AS booking_count FROM bookings WHERE DATE_TRUNC('month', booking_date) = '2022-07-01' GROUP BY listing_id ) SELECT V.listing_id, B.booking_count::decimal / NULLIF(V.view_count, 0) AS CTR FROM total_views V LEFT JOIN total_bookings B ON V.listing_id = B.listing_id; The query utilises two subqueries (total_views and total_bookings) to calculate the counts of views and bookings respectively for each listing for the month of July. The final query joins these subqueries via a LEFT JOIN (to include those listings which were viewed but never booked), and calculates the CTR as booking_count / view_count. The NULLIF function is used to avoid division by zero error. To practice a similar SQL problem on DataLemur's free online SQL coding environment, solve this Meta SQL interview question:Facebook App CTR SQL Interview question SQL Question 9: The Most Popular City for Airbnb Stays As a data analyst for Airbnb, you've been asked to determine the city that has had the most bookings (reservations) in the past year. You are given two tables - a 'bookings' table with booking IDs, user IDs, listing IDs, and booking dates, and a 'listings' table with listing IDs, city locations, and host IDs. Provide a SQL query that returns the city with the maximum number of bookings, along with the number of bookings. bookings Example Input: booking_id	user_id	listing_id	booking_date 101	123	50001	06/08/2022 102	265	69852	06/10/2022 103	362	50001	06/18/2022 104	192	69852	07/26/2022 105	981	69852	07/05/2022 listings Example Input: listing_id	city	host_id 50001	Amsterdam	876 69852	Barcelona	974 Answer: SELECT l.city, COUNT(b.booking_id) AS num_bookings FROM bookings b JOIN listings l ON b.listing_id = l.listing_id GROUP BY l.city ORDER BY num_bookings DESC LIMIT 1; This query works by joining the 'bookings' table with the 'listings' table on the shared 'listing_id'. After joining, the 'city' in the 'listings' table is grouped by, and for each city, the number of bookings is counted (by counting the 'booking_id' in the 'bookings' table). The results are then ordered by the number of bookings in descending order, and finally, the top result (the city with the most bookings) is selected. undefined SQL Question 10: What's the SQL command INTERSECT do, and when would you use it? The SQL command INTERSECT merges the results of multiple SELECT statements and keeps only those rows that are present in all sets. For example, say you were doing an HR Analytics project for Airbnb, and had access to Airbnb's employees and contractors data. Assume that some employees were previously contractors, and vice versa, and thus would show up in both tables. You could use INTERSECT operator to find all contractors who also show up in the employees table: SELECT first_name, last_name FROM airbnb_contractors INTERSECT SELECT first_name, last_name FROM airbnb_employees SQL Question 11: Analyze Host Listings and Booking Transactions As an Airbnb data analyst, you have been asked to analyze the performance of hosts' listings in the past year. Your task is to identify the top 10 listings with the most bookings. There are two tables involved. One is the 'hosts' table that provides details about each host and its respective listing. The other one is 'bookings' table that records each booking transaction. The 'hosts' table: host_id	listing_id	listing_name	city 101	201	Penthouse	New York 102	202	Ocean View	San Francisco 103	203	Country House	Austin The 'bookings' table: booking_id	user_id	listing_id	booking_date 301	401	201	06/08/2022 302	402	202	06/10/2022 303	403	202	07/10/2022 304	404	203	08/08/2022 305	405	201	09/08/2022 Remarks: Both tables can be joined on the 'listing_id' field. Answer: SELECT H.listing_id, H.listing_name, COUNT(B.booking_id) AS number_of_bookings FROM hosts H LEFT JOIN bookings B ON H.listing_id = B.listing_id GROUP BY H.listing_id, H.listing_name ORDER BY number_of_bookings DESC LIMIT 10; This query first joins the 'hosts' and 'bookings' tables based on the 'listing_id' field. It then groups the result by 'listing_id' and 'listing_name' from the 'hosts' table. For each group, it calculates the total number of bookings, and finally sorts the groups based on this count in descending order. It returns the top 10 listings with the most bookings.

---

#### WITH orders_stat AS (

SELECT 	order_id, AVG(quantity) AS avg_quantity, MAX(quantity) AS max_quantity FROM orders_details_1867 GROUP BY order_id ) SELECT order_id FROM orders_stat WHERE max_quantity > ALL( SELECT avg_quantity FROM orders_stat);

---

#### SELECT ROUND(SUM(yearly_seat_cost * num_seats) / COUNT(*)::DECIMAL, 2)

FROM contracts;

---

#### SELECT *

FROM patients_1527 WHERE conditions LIKE '% DIAB1%' OR conditions LIKE 'DIAB1%';

---

#### -- Question 78

-- Table Variables: -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | name          | varchar | -- | value         | int     | -- +---------------+---------+ -- name is the primary key for this table. -- This table contains the stored variables and their values. -- Table Expressions: -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | left_operand  | varchar | -- | operator      | enum    | -- | right_operand | varchar | -- +---------------+---------+ -- (left_operand, operator, right_operand) is the primary key for this table. -- This table contains a boolean expression that should be evaluated. -- operator is an enum that takes one of the values ('<', '>', '=') -- The values of left_operand and right_operand are guaranteed to be in the Variables table. -- Write an SQL query to evaluate the boolean expressions in Expressions table. -- Return the result table in any order. -- The query result format is in the following example. -- Variables table: -- +------+-------+ -- | name | value | -- +------+-------+ -- | x    | 66    | -- | y    | 77    | -- +------+-------+ -- Expressions table: -- +--------------+----------+---------------+ -- | left_operand | operator | right_operand | -- +--------------+----------+---------------+ -- | x            | >        | y             | -- | x            | <        | y             | -- | x            | =        | y             | -- | y            | >        | x             | -- | y            | <        | x             | -- | x            | =        | x             | -- +--------------+----------+---------------+ -- Result table: -- +--------------+----------+---------------+-------+ -- | left_operand | operator | right_operand | value | -- +--------------+----------+---------------+-------+ -- | x            | >        | y             | false | -- | x            | <        | y             | true  | -- | x            | =        | y             | false | -- | y            | >        | x             | true  | -- | y            | <        | x             | false | -- | x            | =        | x             | true  | -- +--------------+----------+---------------+-------+ -- As shown, you need find the value of each boolean exprssion in the table using the variables table. -- Solution with t1 as( select e.left_operand, e.operator, e.right_operand, v.value as left_val, v_1.value as right_val from expressions e join variables v on v.name = e.left_operand join variables v_1 on v_1.name = e.right_operand) select t1.left_operand, t1.operator, t1.right_operand, case when t1.operator = '<' then (select t1.left_val< t1.right_val) when t1.operator = '>' then (select t1.left_val > t1.right_val) when t1.operator = '=' then (select t1.left_val = t1.right_val) else FALSE END AS VALUE from t1

---

#### SELECT user_id, DATE_PART('DAY', MAX(post_date) - MIN(post_date)) AS days_between

FROM posts WHERE DATE_PART('YEAR', post_date) = 2021 GROUP BY user_id HAVING COUNT(user_id) > 1;

---

#### WITH CT AS

( SELECT user_id, COUNT(tweet_id)  tweet_bucket FROM tweets WHERE DATE_PART('YEAR', tweet_date) = 2022 GROUP BY user_id ) SELECT tweet_bucket, COUNT(user_id) users_num FROM CT GROUP BY tweet_bucket;

---

#### 2

119	Top 2 countries by bookings  airbnb	hard 10%

---

#### 2

120	First ever booking  airbnb	hard 10%

---

#### 2

121	Week over week change of first ever bookings  airbnb	hard 14%

---

#### 4

122	Top country by wow growth  airbnb	hard 13%

---

#### 2

123	Top listing in the United States, United Kingdom and Canada  airbnb	medium 10%

---

#### 2

Status	Title	Solution	Difficulty

---

#### SELECT w.name AS warehouse_name,SUM(p.width*p.height*p.length*w.units) AS volume

FROM warehouse_1571 w INNER JOIN products_1571 p ON w.product_id = p.product_id GROUP BY w.name;

---

#### SQL

Below is a compact Airbnb-style schema we‚Äôll use for all questions, followed by 30 SQL prompts that mirror what‚Äôs typically tested (joins, aggregations, filters, subqueries, self-joins, window functions, pivoting/conditional agg, date ops, CTEs, semi/anti joins, etc.). I‚Äôve kept each question self-contained and tagged the target concepts. Working schema (columns you can assume exist) ‚óè listings(listing_id, host_id, city, country, room_type, n_bedrooms, created_at, is_active) ‚óè hosts(host_id, host_since, superhost_flag, country) ‚óè guests(guest_id, signup_dt, country) ‚óè bookings(booking_id, listing_id, guest_id, checkin_dt, checkout_dt, booked_dt, status, nights, guests_count, price_usd) ‚óè reviews(review_id, booking_id, listing_id, guest_id, review_dt, rating, review_text) ‚óè calendar(listing_id, dt, available_flag, nightly_price_usd) ‚óè search_sessions(session_id, guest_id, search_dt, device, country, origin_channel) ‚óè search_results(session_id, listing_id, position, clicked_flag, booked_flag) ‚óè marketing_campaigns(campaign_id, channel, campaign_name, start_dt, end_dt, country) ‚óè ad_impressions(imp_id, campaign_id, guest_id, imp_dt) ‚óè ad_clicks(click_id, campaign_id, guest_id, click_dt) ‚óè product_events(event_dt, guest_id, listing_id, event_name, session_id) ‚óè countries(country, region) 30 SQL interview-style prompts (Airbnb context) # Scenario / Prompt 1 Monthly bookings and GMV. For each YYYY-MM, compute total confirmed bookings and GMV (sum(price_usd)) for active listings only. Tables bookings, listings 2 Host-level performance. Top 10 hosts by GMV last 90 days; include bookings count, distinct guests, and share of bookings with nights >= 7. 3 Occupancy rate. For the last full calendar month, compute occupancy rate per city: booked_nights / total_nights using calendar.available_flag and bookings (confirmed only). 4 Search-to-book funnel. By channel, last 30 days: sessions, clicks, bookings, and CTR/BTB rates. 5 Repeat guests. % of bookings in last 180 days from guests with ‚â•2 prior confirmed bookings (any time before the booking‚Äôs booked_dt). bookings, listings, hosts calendar, bookings, listings search_sessions, search_results bookings Concepts Tested Filter, join, group by month Join, filters, agg w/ conditional sums Date math, joins, aggregation Semi-joins, conditional agg Correlated subquery or window lag/count 6 Review coverage. For each city: share of bookings that received a review within 30 days of checkout. 7 Superhost uplift. Compare average rating and GMV for superhosts vs non-superhosts in the last quarter; return group, bookings, avg_rating, avg_price, GMV. 8 Cancellations. Weekly cancellation rate (status = 'canceled') by room_type; include 3-week moving average. 9 Search ranking effect. Compute conversion to booking by position bucket (1‚Äì3, 4‚Äì10, >10) controlling for device and country. 10 Longest stays. For each country, list the single longest nights stay in last year with listing & host details (ties keep highest price_usd). 11 Guest lifecycle. For each guest, report f irst_booking_dt, days_to_second_booking, and whether they churned (no bookings last 365d). 12 Activation cohort. Monthly host cohorts by host_since and their month-2 GMV (GMV in cohort_month+1). 13 Price dispersion. For active listings in a city, compute median nightly price over last 60 days and IQR from calendar. bookings, reviews, listings hosts, bookings, reviews, listings bookings, listings search_results, search_sessions bookings, listings, hosts bookings, guests hosts, bookings, listings calendar, listings Left join, date diff, conditional agg Joins, grouping, window alt: none Window (moving avg), date binning Case/pivot, multi-dim group Row_number partition, top-1 per group Window (min/lead), derived flags Cohorts via date trunc + joins Percentiles (approx or window), filter 14 Calendar integrity check. Find listings that were unavailable (available_flag=0) on any date where a booking overlapped but nights were priced at 0 or NULL. 15 Attribution (last touch). Within a 7-day attribution window ending at booked_dt, assign each booking to the most recent ad click per guest; output channel-level GMV. 16 Marketing reach & frequency. For a date range, compute unique guests reached and average frequency by campaign. 17 Cross-sell signal. Among guests who booked ‚â•2 cities in the last year, top 10 city pairs by count (unordered pairs). 18 Supply growth. 3-month rolling new listings by region (countries), and % change vs prior 3-month window. 19 Time to first review. For each listing created in the last year, days from created_at to f irst review_dt; return P50 and P90 by city. 20 Click quality. For sessions with ‚â•1 click, compute probability a clicked listing gets booked within 48h; return by device. 21 Room-type mix. For each city, share of active supply by room_type and Herfindahl index (HHI) of room types. calendar, bookings bookings, ad_clicks, marketing_campaigns ad_impressions bookings, listings listings, countries listings, reviews search_sessions, search_results listings Interval overlap, data QA Window over time, last-touch join Distinct count, ratio Self-join or set ops, combinatorics Rolling sums, joins, pct change First-value via min, percentiles Filters, time window, conditional agg Pivot via conditional sums, HHI calc 22 Price vs rating elasticity proxy. Correlate listing‚Äôs median price (last 90d) with average rating (last 365d) by city; return Pearson r. 23 Host multi-listing behavior. Flag hosts with ‚â•N active listings and compute their share of city GMV last quarter. 24 Cancellation window abuse. Identify guests with ‚â•2 cancellations within 24h of booked_dt across different listings in past 180d. 25 Underpriced blackout. Find top 50 listings where calendar shows available_flag=1 but nightly_price_usd is below the city‚Äôs 10th percentile in the next 14 days. 26 Session to search gap. Compute median minutes from first product_events.event_name='sessio n_start' to first search per session. 27 Geo expansion. For new countries launched in last 18 months (first listing), report month-over-month bookings for first 6 months post-launch. 28 Review bias. Compare average rating for stays ‚â§2 nights vs ‚â•7 nights, controlling for city (return city-level deltas). 29 Seasonality index. For each city, compute monthly seasonality index = month_GMV / avg_month_GMV using 24 months of history. calendar, reviews, listings listings, bookings bookings calendar, listings product_events listings, bookings bookings, reviews, listings bookings, listings Aggregation to features, corr formula Threshold f iltering, share of total Self-join on guest, time diff Percentiles by group, date f ilter Window by session, time diff Launch detection, aligned windows Join, group, diff calculations Window avg over partition 30 Booking lead time distribution. For last quarter, output deciles of lead time (booked_dt‚Üícheckin_dt) by room_type. bookings, listings Date diff, percentiles by group Notes on expected approaches (best practices) ‚óè Prefer date_trunc('month', ‚Ä¶) or DATE_TRUNC('month', ‚Ä¶) depending on Presto/Hive. ‚óè Use CTEs for readability, especially when deriving features (e.g., lead time, cohorts). ‚óè For percentiles in Presto: approx_percentile(x, 0.5); in Hive: percentile_approx. ‚óè For rolling windows, use window frames: avg(x) over (partition by k order by d rows between 2 preceding and current row). ‚óè For interval overlaps: GREATEST(start1, start2) < LEAST(end1, end2). ‚óè For attribution: row_number() over (partition by booking_id order by click_dt desc) after joining clicks ‚â§ booked_dt and within window. ‚óè For distinct counts at scale, approximate functions (HLL/approx_distinct) may be acceptable if the engine supports them. If you‚Äôd like, I can provide answer keys for any subset (e.g., 1‚Äì10) tailored to Presto/Hive syntax and optimized for readability and performance. Below is a compact, interview-style set of 30 Airbnb-context SQL questions spanning the usual segments (joins, aggregation, filtering, subqueries, self-joins, windowing, date/time, arrays/maps, set ops, funnels/retention, and experiment/marketing measurement). They are framed for Presto/Hive-style SQL (Airbnb commonly uses SQL engines in that family) and align with the role‚Äôs emphasis on experimentation/causal methods, product & growth metrics, and building robust reporting/metrics. (Careers at Airbnb) Starter schema (assumed) Table users listings bookings reviews calendar search_events sessions marketing_impre ssions marketing_click s payments refunds experiments Key columns (subset) user_id (PK), created_at (ts), country, device_type listing_id (PK), host_id, city, room_type, created_at booking_id (PK), user_id, listing_id, checkin_date (date), checkout_date (date), status (‚Äòconfirmed‚Äô, ‚Äòcancelled‚Äô), booked_at (ts), total_price (decimal), coupon_code review_id, booking_id, user_id, listing_id, rating (int), reviewed_at (ts) listing_id, dt (date), is_available (bool), price (decimal) event_ts (ts), user_id, query, city, result_count, device_type session_id, user_id, session_start (ts), session_end (ts), source (utm_source), medium (utm_medium) imp_id, user_id, campaign_id, imp_ts (ts), channel, cost click_id, user_id, campaign_id, click_ts (ts), channel payment_id, booking_id, paid_at (ts), amount, method refund_id, booking_id, refunded_at (ts), amount exp_name, user_id, variant (‚Äòcontrol‚Äô, ‚Äòtreatment‚Äô), assigned_ts hosts messages host_id (PK), joined_at (ts), country message_id, booking_id, from_user_id, to_user_id, sent_at (ts) Use these columns as needed; not every column will be used per question. 30 interview-style SQL questions (Airbnb themed) # Segment 1 Filtering + Agg 2 Joins Scenario New guest conversion Prompt (what to return) Among users created in last 90 days, % with ‚â•1 confirmed booking within 30 days of signup. Search‚Üíbooking By device, weekly search‚Üíbooking conversion: users with a search this week who booked within 7 days after f irst search. 3 Window fn Repeat bookers Top 10 cities by share of repeat guests in last 12 months (repeat = ‚â•2 confirmed bookings). 4 Self-join Re-engagement Users inactive ‚â•180 days who returned to book; compute days since prior booking at return time. Key concepts tested Date filters, conditional agg Join on user & time window Grouping, window percent Self-join by user, LAG 5 Subquery Listing quality 6 Window fn Host activation funnel 7 Anti-join For listings with ‚â•10 reviews, output avg rating and count; keep top decile by avg rating per city. For new hosts (joined last quarter), compute time from join to first booking; report P50/P90 by host country. Unreviewed stays Bookings completed 14+ days ago with no review yet; list booking_id, user_id, listing_id. 8 String/date Peak pricing For calendar, find month/day-of-week combos with highest median price per city (last year). 9 Joins + CASE Cancellation rate By room_type and month, cancellation rate = cancelled / (cancelled+confirmed). 10 Window fn Greatest-N per group 11 CTE + Window Sessionization sanity 12 Arrays/Maps Query analysis For each city, top 3 listings by nights booked in the last 90 days. Break ties by total revenue. Compute avg sessions/user/week and median session duration by source for past 8 weeks. From search_events.query, count searches containing any of ['pool','pet','wifi'] by device, week. Aggregation, percentile filter DATEDIFF, percentiles LEFT/ANTI join DATE_TRUNC, extract DOW Conditional sums ROW_NUMBER, ORDER BY multi TIMESTAMP math, pctls Simple substring/regex 13 Dedup 14 Funnel (semi-joins) 15 Retention 16 Marketing join 17 MMM prep (SQL) 18 CUPED inputs 19 Guardrails 20 Percentiles Identity stitching Booking funnel Clicks table may have dup events. Dedup by (user_id, campaign_id, minute(click_ts)). Count unique clicks/day. Build 3-step funnel: search ‚Üí listing view (assume sessions page events) ‚Üí booking; output step rates by city. 8-week retention Weekly cohort retention for guests by signup week; return CohortWeek, WeekK, RetainedUsers. CPA by channel Feature table Join marketing_clicks to first booking within 7 days post-click; compute CPA and CVR by channel. Create weekly panel with bookings, revenue, and ad spend by channel (sum(marketing_impression s.cost)). Pre-period metric For an experiment on new search UI, compute each user‚Äôs pre-period mean daily searches (baseline covariate). Abuse spike Price dispersion In experiment, report week-over-week % change in cancellation rate and refund rate by variant. For each city, P10, P50, P90 of nightly price (from calendar) restricted to available nights. QUALIFY ROW_NUMBER Semi-join, distinct users Cohort labeling, joins Attribution, first touch Time bucketing, panel Pre window agg Joins, ratios, WoW approx_percentile 21 Multi-table join 22 Set ops 23 Rollups 24 QA outliers Host response Supply vs demand KPI cube Price sanity 25 Window fn RFM proxy 26 Time zones Booking hour 27 Joins + CASE Net revenue For completed bookings, compute median host response time (first message after guest message). Cities with demand growth (bookings +20% YoY) but supply growth (active listings) <5% YoY. Produce a cube of bookings/revenue by (city, room_type, device_type), including subtotals and grand total. Identify listings whose median price is >5√ó city median in a month (potential data issues). For each user, compute recency (days since last booking), frequency (bookings last 365d), and monetary (sum revenue). Distribution of booked_at by local listing time zone hour; assume listing city‚ÜíTZ mapping table city_tz. Net revenue = payments ‚àí refunds; report by month and room_type for past 12 months. Self join by time, MIN Intersections, YoY GROUPING SETS/ROLLUP Median by group, compare MAX over user, sums TZ conversion Joins, arithmetic 28 Self-join Cannibalization 29 Window fn SLA breaches 30 UDF/Regex Coupon lift For users in experiment with new pricing, compute if first booking post-assignment was cheaper than their prior booking (same city). For support messages during a booking, % of first host replies > 12 hours; breakdown by city. For bookings with coupon_code, estimate incremental lift proxy: avg revenue with coupon vs similar listings without (same city, room_type, month). Pairwise compare FIRST_VALUE/MIN, CASE Matched grouping Notes for practicing these: ‚óè Favor CTEs to keep logic modular; many prompts are naturally multi-step (e.g., build user cohorts, then join to outcomes). ‚óè Prefer window functions for ‚Äúfirst/last/next‚Äù (e.g., ROW_NUMBER for ‚Äúfirst booking after X‚Äù, LAG/LEAD for diffs). ‚óè For Presto/Hive percentiles use approx_percentile(x, 0.5) or percentile_approx depending on engine. ‚óè When attribution windows are involved (e.g., Q16), explicitly define lookback/forward windows (7 days here) and choose first or last touch consistently. ‚óè When you need top-N per group (Q10), use ROW_NUMBER() OVER (PARTITION BY group ORDER BY metric DESC) + WHERE rn <= N. ‚óè Guardrail metrics (Q19) should be pre-specified and computed alongside primary outcomes to avoid p-hacking. If you want, I can provide worked solutions next (Presto/Hive-style), one block per question with readable line widths and short comments, or prioritize the areas you want to drill (e.g., window functions + A/B).

---

#### WITH all_recommendations AS (

SELECT l1.user_id AS user_id1,l2.user_id AS user_id2,COUNT(l1.song_id) AS listened_songs FROM listens_1917 l1 INNER JOIN listens_1917 l2 ON l1.user_id <> l2.user_id AND l1.song_id = l2.song_id AND l1.day = l2.day GROUP BY l1.user_id,l2.user_id HAVING COUNT(l1.song_id)>=3 ), friends AS ( SELECT user1_id,user2_id FROM friendship_1917 UNION SELECT user2_id,user1_id FROM friendship_1917 ) SELECT r.user_id1,r.user_id2 FROM all_recommendations r LEFT JOIN friends f ON f.user1_id = r.user_id1 AND f.user2_id = r.user_id2 WHERE f.user1_id IS NULL;

---

#### WITH cte AS(

SELECT id,month, SUM(salary) OVER w AS salary, ROW_NUMBER() OVER w AS row_num, COUNT(*) OVER w1 AS count FROM employee_579 WINDOW w AS (PARTITION BY id ORDER BY month), w1 AS (PARTITION BY id) ) SELECT id,month,salary FROM cte WHERE row_num<count ORDER BY id,month DESC; ----------------------------- OR ----------------------------- SELECT e1.id,e1.month,SUM(e2.salary) FROM employee_579 e1 JOIN employee_579 e2 ON e1.id = e2.id AND e1.month - e2.month BETWEEN 0 AND 2 WHERE (e1.id,e1.month) NOT IN (SELECT id,MAX(MONTH) FROM employee_579 GROUP BY id) GROUP BY e1.id,e1.month ORDER BY e1.id,e1.month DESC;

---

#### -- Question 6

-- X city opened a new cinema, many people would like to go to this cinema. -- The cinema also gives out a poster indicating the movies‚Äô ratings and descriptions. -- Please write a SQL query to output movies with an odd numbered ID and a description that is not 'boring'. -- Order the result by rating. -- For example, table cinema: -- +---------+-----------+--------------+-----------+ -- |   id    | movie     |  description |  rating   | -- +---------+-----------+--------------+-----------+ -- |   1     | War       |   great 3D   |   8.9     | -- |   2     | Science   |   fiction    |   8.5     | -- |   3     | irish     |   boring     |   6.2     | -- |   4     | Ice song  |   Fantacy    |   8.6     | -- |   5     | House card|   Interesting|   9.1     | -- +---------+-----------+--------------+-----------+ -- For the example above, the output should be: -- +---------+-----------+--------------+-----------+ -- |   id    | movie     |  description |  rating   | -- +---------+-----------+--------------+-----------+ -- |   5     | House card|   Interesting|   9.1     | -- |   1     | War       |   great 3D   |   8.9     | -- +---------+-----------+--------------+-----------+ -- Solution Select * from cinema where id%2=1 and description not in ('boring') order by rating desc

---

#### SELECT seller_name

FROM seller_1607 WHERE seller_id NOT IN (SELECT DISTINCT seller_id FROM orders_1607 WHERE EXTRACT(YEAR FROM sale_date) = 2020);

---

#### WITH ranked AS(

SELECT *, ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY activity_date) AS rnk FROM traffic_1107 WHERE activity = 'login' ) SELECT activity_date,COUNT(DISTINCT user_id) FROM ranked WHERE ('2019-06-30'::DATE-activity_date)<=90 AND rnk =1 GROUP BY activity_date; --(OR) WITH ranked AS( SELECT user_id,MIN(activity_date) AS activity_date FROM traffic_1107 WHERE activity = 'login' GROUP BY user_id ) SELECT activity_date,COUNT(user_id) FROM ranked WHERE ('2019-06-30'::DATE-activity_date)<=90 GROUP BY activity_date;

---

#### -- Question 32

-- Write a SQL query to delete all duplicate email entries in a table named Person, keeping only unique emails based on its smallest Id. -- +----+------------------+ -- | Id | Email            | -- +----+------------------+ -- | 1  | john@example.com | -- | 2  | bob@example.com  | -- | 3  | john@example.com | -- +----+------------------+ -- Id is the primary key column for this table. -- For example, after running your query, the above Person table should have the following rows: -- +----+------------------+ -- | Id | Email            | -- +----+------------------+ -- | 1  | john@example.com | -- | 2  | bob@example.com  | -- +----+------------------+ -- Solution With t1 as ( Select *, row_number() over(partition by email order by id) as rk from person ) Delete from person where id in (Select t1.id from t1 where t1.rk>1)

---

#### -- Question 116

-- Table Activities: -- +-------------+---------+ -- | Column Name | Type    | -- +-------------+---------+ -- | sell_date   | date    | -- | product     | varchar | -- +-------------+---------+ -- There is no primary key for this table, it may contains duplicates. -- Each row of this table contains the product name and the date it was sold in a market. -- Write an SQL query to find for each date, the number of distinct products sold and their names. -- The sold-products names for each date should be sorted lexicographically. -- Return the result table ordered by sell_date. -- The query result format is in the following example. -- Activities table: -- +------------+-------------+ -- | sell_date  | product     | -- +------------+-------------+ -- | 2020-05-30 | Headphone   | -- | 2020-06-01 | Pencil      | -- | 2020-06-02 | Mask        | -- | 2020-05-30 | Basketball  | -- | 2020-06-01 | Bible       | -- | 2020-06-02 | Mask        | -- | 2020-05-30 | T-Shirt     | -- +------------+-------------+ -- Result table: -- +------------+----------+------------------------------+ -- | sell_date  | num_sold | products                     | -- +------------+----------+------------------------------+ -- | 2020-05-30 | 3        | Basketball,Headphone,T-shirt | -- | 2020-06-01 | 2        | Bible,Pencil                 | -- | 2020-06-02 | 1        | Mask                         | -- +------------+----------+------------------------------+ -- For 2020-05-30, Sold items were (Headphone, Basketball, T-shirt), we sort them lexicographically and separate them by comma. -- For 2020-06-01, Sold items were (Pencil, Bible), we sort them lexicographically and separate them by comma. -- For 2020-06-02, Sold item is (Mask), we just return it. -- Solution select sell_date, count(distinct product) as num_sold, group_concat(distinct product) as products from activities group by 1 order by 1

---

#### -- Question 96

-- Write a query to print the sum of all total investment values in 2016 (TIV_2016), to a scale of 2 decimal places, for all policy holders who meet the following criteria: -- Have the same TIV_2015 value as one or more other policyholders. -- Are not located in the same city as any other policyholder (i.e.: the (latitude, longitude) attribute pairs must be unique). -- Input Format: -- The insurance table is described as follows: -- | Column Name | Type          | -- |-------------|---------------| -- | PID         | INTEGER(11)   | -- | TIV_2015    | NUMERIC(15,2) | -- | TIV_2016    | NUMERIC(15,2) | -- | LAT         | NUMERIC(5,2)  | -- | LON         | NUMERIC(5,2)  | -- where PID is the policyholder's policy ID, TIV_2015 is the total investment value in 2015, TIV_2016 is the total investment value in 2016, LAT is the latitude of the policy holder's city, and LON is the longitude of the policy holder's city. -- Sample Input -- | PID | TIV_2015 | TIV_2016 | LAT | LON | -- |-----|----------|----------|-----|-----| -- | 1   | 10       | 5        | 10  | 10  | -- | 2   | 20       | 20       | 20  | 20  | -- | 3   | 10       | 30       | 20  | 20  | -- | 4   | 10       | 40       | 40  | 40  | -- Sample Output -- | TIV_2016 | -- |----------| -- | 45.00    | -- Explanation -- The first record in the table, like the last record, meets both of the two criteria. -- The TIV_2015 value '10' is as the same as the third and forth record, and its location unique. -- The second record does not meet any of the two criteria. Its TIV_2015 is not like any other policyholders. -- And its location is the same with the third record, which makes the third record fail, too. -- So, the result is the sum of TIV_2016 of the first and last record, which is 45. -- Solution select sum(TIV_2016) TIV_2016 from (select *, count(*) over (partition by TIV_2015) as c1, count(*) over (partition by LAT, LON) as c2 from insurance ) t where c1 > 1 and c2 = 1;

---

#### WITH duplicate_id_higher AS (

SELECT p1.id AS higher_id FROM person_196_ans p1 JOIN person_196_ans p2 ON p1.email = p2.email AND p1.id > p2.id ) DELETE FROM person_196_ans WHERE id IN (SELECT higher_id FROM duplicate_id_higher);

---

#### Which is faster, python list or Numpy arrays, and why?

NumPy arrays are quicker than Python lists when it comes to numerical computations. NumPy is a Python library for array processing, and it offers several functions for performing operations on arrays in an efficient manner. One of the reasons NumPy arrays are faster than Python lists is that NumPy arrays are written in C, whereas Python lists are written in Python. This implies that operations on NumPy arrays are written in a compiled language and hence are faster than operations on Python lists, which are written in an interpreted language.

---

#### What is the difference between a python list and a tuple?

A list in Python is a sequence of objects of varying kinds. Lists are mutable, i.e., you can alter the value of a list item or insert or delete items in a list. Lists are defined using square brackets and a comma-delimited list of values. A tuple is also an ordered list of objects, but it is immutable, meaning that you cannot alter the value of a tuple object or add or delete elements from a tuple. Lists are initiated using square brackets ([ ‚Äù ]), whereas tuples are initiated using parentheses ((‚Äù, )). Lists have a number of built-in methods for adding, deleting, and manipulating elements, but tuples don‚Äôt have these methods. Generally, tuples are quicker than lists in Python

---

#### What are python sets? Explain some of the properties of sets.

In Python, a set is an unordered collection of unique objects. Sets are often used to store a collection of distinct objects and to perform membership tests (i.e., to check if an object is in the set). Sets are defined using curly braces ({ and }) and a comma-separated list of values. Here are some key properties of sets in Python: Sets are unordered: Sets do not have a specific order, so you cannot index or slice them like you can with lists or tuples. Sets are unique: Sets only allow unique objects, so if you try to add a duplicate object to a set, it will not be added. Sets are mutable: You can add or remove elements from a set using the add and remove methods. Sets are not indexed: Sets do not support indexing or slicing, so you cannot access individual elements of a set using an index. Sets are not hashable: Sets are mutable, so they cannot be used as keys in dictionaries or as elements in other sets. If you need to use a mutable object as a key or an element in a set, you can use a tuple or a frozen set (an immutable version of a set).

---

#### What is the difference between split and join?

Split and join are both functions of python strings, but they are completely different when it comes to functioning. The split function is used to create a list from strings based on some delimiter, for eg. space. a = ‚ÄòThis is a string‚Äô Li = a.split(‚Äò ‚Äò) print(li) Output: [‚ÄòThis‚Äô, ‚Äòis‚Äô, ‚Äòa‚Äô, ‚Äòstring‚Äô] The join() method is a built-in function of Python‚Äôs str class that concatenates a list of strings into a single string. It is called on a delimiter string and invoked with a list of strings to be joined. The delimiter string is inserted between each string in the list when the strings are concatenated. Here is an example of how to use the join() method: ‚Äú ‚Äú.join(li) Output: This is a string Here the list is joined with a space in between.

---

#### Explain the logical operations in python.

In Python, the logical operations and, or, and not can be used to perform boolean operations on truth values (True and False). The and operator returns True if both the operands are True, and False otherwise. The or operator returns True if either of the operands is True, and False if both operands are False. The not operator inverts the boolean value of its operand. If the operand is True, not return False, and if the operand is False, not return True.

---

#### Explain the top 5 functions used for python strings.

Here are the top 5 Python string functions: Function	Description len()	Returns the length of a string. strip()	Removes leading and trailing whitespace from a string. split()	Splits a string into a list of substrings based on a delimiter. replace()	Replaces all occurrences of a specified string with another string. upper()	Converts a string to uppercase. lower()	Converts a string to lowercase. s = 'Hello, World!' len(s)                  # 13 s.strip()               # 'Hello, World!' s.split(',')            # ['Hello', ' World!'] s.replace('World', 'Universe')  # 'Hello, Universe!' s.upper()               # 'HELLO, WORLD!' s.lower()               # 'hello, world!'

---

#### What is the use of the pass keyword in python?

pass is a null statement that does nothing. It is often used as a placeholder where a statement is required syntactically, but no action needs to be taken. For example, if you want to define a function or a class but haven‚Äôt yet decided what it should do, you can use pass as a placeholder.

---

#### What is the use of the continue keyword in python?

continue is used in a loop to skip over the current iteration and move on to the next one. When continue is encountered, the current iteration of the loop is terminated, and the next one begins. Intermediate Interview Python Data Science Questions

---

#### What are immutable and mutable data types?

In Python, an immutable object is an object whose state cannot be modified after it is created. This means that you can‚Äôt change the value of an immutable object once it is created. Examples of immutable objects in Python include numbers (such as integers, floats, and complex numbers), strings, and tuples. On the other hand, a mutable object is an object whose state can be modified after it is created. This means that you can change the value of a mutable object after it is created. Examples of mutable objects in Python include lists and dictionaries. Understanding the difference between immutable and mutable objects in Python is important because it can affect how you use and manipulate data in your code. For example, if you have a list of numbers and you want to sort the list in ascending order, you can use the built-in sort() method to do this. However, if you have a tuple of numbers, you can‚Äôt use the sort() method because tuples are immutable. Instead, you would have to create a new sorted tuple from the original tuple.

---

#### What is the use of try and accept block in python

The try and except block in Python are used to handle exceptions. An exception is an error that occurs during the execution of a program. The try block contains code that might cause an exception to be raised. The except block contains code that is executed if an exception is raised during the execution of the try block. Using a try-except block will save the code from an error to occur and can be executed with a message or output we want in the except block.

---

#### What are 2 mutable and 2 immutable data types in python?

2 mutable data types are: Dictionary List You can change/edit the values in a python dictionary and a list. It is not necessary to make a new list which means that it satisfies the property of mutability. 2 immutable data types are: Tuples String You cannot edit a string or a value in a tuple once it is created. You need to either assign the values to the tuple or make a new tuple.

---

#### What are python functions, and how do they help in code optimization?

In Python, a function is a block of code that can be called by other parts of your program. Functions are useful because they allow you to reuse code and divide your code into logical blocks that can be tested and maintained separately. To call a function in Python, you simply use the function name followed by a pair of parentheses and any necessary arguments. The function may or may not return a value that depends on the usage of the turn statement. Functions can also help in code optimization: Code reuse: Functions allow you to reuse code by encapsulating it in a single place and calling it multiple times from different parts of your program. This can help to reduce redundancy and make your code more concise and easier to maintain. Improved readability: By dividing your code into logical blocks, functions can make your code more readable and easier to understand. This can make it easier to identify bugs and make changes to your code. Easier testing: Functions allow you to test individual blocks of code separately, which can make it easier to find and fix bugs. Improved performance: Functions can also help to improve the performance of your code by allowing you to use optimized code libraries or by allowing the Python interpreter to optimize the code more effectively.

---

#### Why does NumPy have huge popularity in the field of data science?

NumPy (short for Numerical Python) is a popular library for scientific computing in Python. It has gained a lot of popularity in the data science community because it provides fast and efficient tools for working with large arrays and matrices of numerical data. NumPy provides fast and efficient operations on arrays and matrices of numerical data. It uses optimized C and Fortran code behind the scenes to perform these operations, which makes them much faster than equivalent operations using Python‚Äôs built-in data structures. It provides fast and efficient tools for working with large arrays and matrices of numerical data. NumPy provides a large number of functions for performing mathematical and statistical operations on arrays and matrices. It allows you to work with large amounts of data efficiently. It provides tools for handling large datasets that would not fit in memory, such as functions for reading and writing data to disk and for loading only a portion of a dataset into memory at a time. NumPy integrates well with other scientific computing libraries in Python, such as SciPy (Scientific Python) and pandas. This makes it easy to use NumPy with other libraries to perform more complex data science tasks.

---

#### Explain list comprehension and dict comprehension.

List comprehension and dict comprehension are both concise ways to create new lists or dictionaries from existing iterables. List comprehension is a concise way to create a list. It consists of square brackets containing an expression followed by a for clause, then zero or more for or if clauses. The result is a new list that evaluates the expression in the context of the for and if clauses. Dict comprehension is a concise way to create a dictionary. It consists of curly braces containing a key-value pair, followed by a for clause, then zero or more for or if clauses. A result is a new dictionary that evaluates the key-value pair in the context of the for and if clauses.

---

#### What are global and local variables in python?

In Python, a variable that is defined outside of any function or class is a global variable, while a variable that is defined inside a function or class is a local variable. A global variable can be accessed from anywhere in the program, including inside functions and classes. However, a local variable can only be accessed within the function or class in which it is defined. It is important to note that you can use the same name for a global variable and a local variable, but the local variable will take precedence over the global variable within the function or class in which it is defined. # This is a global variable x = 10 def func(): # This is a local variable x = 5 print(x)my_function func() print(x) Output: This will print 5 and then 10 In the example above, the x variable inside the func() function is a local variable, so it takes precedence over the global variable x. Therefore, when x is printed inside the function, it prints 5; when it is printed outside the function, it prints 10.

---

#### What is an ordered dictionary?

An ordered dictionary, also known as an OrderedDict, is a subclass of the built-in Python dictionary class that maintains the order of elements in which they were added. In a regular dictionary, the order of elements is determined by the hash values of their keys, which can change over time as the dictionary grows and evolves. An ordered dictionary, on the other hand, uses a doubly linked list to remember the order of elements, so that the order of elements is preserved regardless of how the dictionary changes.

---

#### What is the difference between return and yield keywords?

Return is used to exit a function and return a value to the caller. When a return statement is encountered, the function terminates immediately, and the value of the expression following the return statement is returned to the caller. yield, on the other hand, is used to define a generator function. A generator function is a special kind of function that produces a sequence of values one at a time, instead of returning a single value. When a yield statement is encountered, the generator function produces a value and suspends its execution, saving its state for later Advanced Python Interview Questions

---

#### What are lambda functions in python, and why are they important?

In Python, a lambda function is a small anonymous function. You can use lambda functions when you don‚Äôt want to define a function using the def keyword. Lambda functions are useful when you need a small function for a short period of time. They are often used in combination with higher-order functions, such as map(), filter(), and reduce(). Here‚Äôs an example of a lambda function in Python: x = lambda a : a + 10 x(5) 15 In this example, the lambda function takes one argument (a) and adds 10 to it. The lambda function returns the result of this operation when it is called. Lambda functions are important because they allow you to create small anonymous functions in a concise way. They are often used in functional programming, a programming paradigm that emphasizes using functions to solve problems.

---

#### What is the use of the ‚Äòassert‚Äô keyword in python?

In Python, the assert statement is used to test a condition. If the condition is True, then the program continues to execute. If the condition is False, then the program raises an AssertionError exception. The assert statement is often used to check the internal consistency of a program. For example, you might use an assert statement to check that a list is sorted before performing a binary search on the list. It‚Äôs important to note that the assert statement is used for debugging purposes and is not intended to be used as a way to handle runtime errors. In production code, you should use try and except blocks to handle exceptions that might be raised at runtime.

---

#### What are decorators in python?

In Python, decorators are a way to modify or extend the functionality of a function, method, or class without changing their source code. Decorators are typically implemented as functions that take another function as an argument and return a new function that has the desired behavior. A decorator is a special function that starts with the @ symbol and is placed immediately before the function, method, or class it decorates. The @ symbol is used to indicate that the following function is a decorator. Interview Questions Regarding EDA and Statistics Let us look at data science interview questions and answers regarding EDA and Statistics. Beginner Interview Questions on Statistics

---

#### How to perform univariate analysis for numerical and categorical variables?

Univariate analysis is a statistical technique used to analyze and describe the characteristics of a single variable. It is a useful tool for understanding the distribution, central tendency, and dispersion of a variable, as well as identifying patterns and relationships within the data. Here are the steps for performing univariate analysis for numerical and categorical variables: For numerical variables: Calculate descriptive statistics such as the mean, median, mode, and standard deviation to summarize the distribution of the data. Visualize the distribution of the data using plots such as histograms, boxplots, or density plots. Check for outliers and anomalies in the data. Check for normality in the data using statistical tests or visualizations such as a Q-Q plot. For categorical variables. Calculate the frequency or count of each category in the data. Calculate the percentage or proportion of each category in the data. Visualize the distribution of the data using plots such as bar plots or pie charts. Check for imbalances or abnormalities in the distribution of the data. Note that the specific steps for performing univariate analysis may vary depending on the specific needs and goals of the analysis. It is important to carefully plan and execute the analysis in order to accurately and effectively describe and understand the data.

---

#### What are the different ways in which we can find outliers in the data?

Outliers are data points that are significantly different from the majority of the data. They can be caused by errors, anomalies, or unusual circumstances, and they can have a significant impact on statistical analyses and machine learning models. Therefore, it is important to identify and handle outliers appropriately in order to obtain accurate and reliable results. Here are some common ways to find outliers in the data: Visual inspection: Outliers can often be identified by visually inspecting the data using plots such as histograms, scatterplots, or boxplots. Summary statistics: Outliers can sometimes be identified by calculating summary statistics such as the mean, median, or interquartile range, and comparing them to the data. For example, if the mean is significantly different from the median, it could indicate the presence of outliers. Z-score: The z-score of a data point is a measure of how many standard deviations it is from the mean. Data points with a z-score greater than a certain threshold (e.g., 3 or 4) can be considered outliers. There are many other methods for detecting outliers in the data, and the appropriate method will depend on the specific characteristics and needs of the data. It is important to carefully evaluate and choose the most appropriate method for identifying outliers in order to obtain accurate and reliable results.

---

#### What are the different ways by which you can impute the missing values in the dataset?

There are several ways that you can impute null values (i.e., missing values) in a dataset: Drop rows: One option is to simply drop rows with null values from the dataset. This is a simple and fast method, but it can be problematic if a large number of rows are dropped, as it can significantly reduce the sample size and impact the statistical power of the analysis. Drop columns: Another option is to drop columns with null values from the dataset. This can be a good option if the number of null values is large compared to the number of non-null values, or if the column is not relevant to the analysis. Imputation with mean or median: One common method of imputation is to replace null values with the mean or median of the non-null values in the column. This can be a good option if the data are missing at random and the mean or median is a reasonable representation of the data. Imputation with mode: Another option is to replace null values with the mode (i.e., the most common value) of the non-null values in the column. This can be a good option for categorical data where the mode is a meaningful representation of the data. Imputation with a predictive model: Another method of imputation is to use a predictive model to estimate the missing values based on the other available data. This can be a more complex and time-consuming method, but it can be more accurate if the data are not missing at random and there is a strong relationship between the missing values and the other data.

---

#### What are Skewness in statistics and its types?

Skewness is a measure of the symmetry of a distribution. A distribution is symmetrical if it is shaped like a bell curve, with most of the data points concentrated around the mean. A distribution is skewed if it is not symmetrical, with more data points concentrated on one side of the mean than the other. There are two types of skewness: positive skewness and negative skewness. Positive skewness: Positive skewness occurs when the distribution has a long tail on the right side, with the majority of the data points concentrated on the left side of the mean. Positive skewness indicates that there are a few extreme values on the right side of the distribution that is pulling the mean to the right. Negative skewness: Negative skewness occurs when the distribution has a long tail on the left side, with the majority of the data points concentrated on the right side of the mean. Negative skewness indicates that there are a few extreme values on the left side of the distribution that is pulling the mean to the left. data science interview questions

---

#### What are the measures of central tendency?

In statistics, measures of central tendency are values that represent the center of a dataset. There are three main measures of central tendency: mean, median, and mode. The mean is the arithmetic average of a dataset and is calculated by adding all the values in the dataset and dividing by the number of values. The mean is sensitive to outliers, or values that are significantly higher or lower than the majority of the other values in the dataset. The median is the middle value of a dataset when the values are arranged in order from smallest to largest. To find the median, you must first arrange the values in order and then locate the middle value. If there is an odd number of values, the median is the middle value. If there is an even number of values, the median is the mean of the two middle values. The median is not sensitive to outliers. The mode is the value that occurs most frequently in a dataset. A dataset may have multiple modes or no modes at all. The mode is not sensitive to outliers.

---

#### Can you explain the difference between descriptive and inferential statistics?

Descriptive statistics is used to summarize and describe a dataset by using measures of central tendency (mean, median, mode) and measures of spread (standard deviation, variance, range). Inferential statistics is used to make inferences about a population based on a sample of data and using statistical models, hypothesis testing and estimation.

---

#### What are the key elements of an EDA report and how do they contribute to understanding a dataset?

The key elements of an EDA report include univariate analysis, bivariate analysis, missing data analysis, and basic data visualization. Univariate analysis helps in understanding the distribution of individual variables, bivariate analysis helps in understanding the relationship between variables, missing data analysis helps in understanding the quality of data, and data visualization provides a visual interpretation of the data. Intermediate Interview Questions on Statistics for Data Science Q28 What is the central limit theorem? The Central Limit Theorem is a fundamental concept in statistics that states that as the sample size increases, the distribution of the sample mean will approach a normal distribution. This is true regardless of the underlying distribution of the population from which the sample is drawn. This means that even if the individual data points in a sample are not normally distributed, by taking the average of a large enough number of them, we can use normal distribution-based methods to make inferences about the population.

---

#### Mention the two kinds of target variables for predictive modeling.

The two kinds of target variables are: Numerical/Continuous variables ‚Äì Variables whose values lie within a range, could be any value in that range and the time of prediction; values are not bound to be from the same range too. For example: Height of students ‚Äì 5; 5.1; 6; 6.7; 7; 4.5; 5.11 Here the range of the values is (4,7) And, the height of some new students can/cannot be any value from this range. Categorical variable ‚Äì Variables that can take on one of a limited, and usually fixed, number of possible values, assigning each individual or other unit of observation to a particular group on the basis of some qualitative property. A categorical variable that can take on exactly two values is termed a binary variable or a dichotomous variable. Categorical variables with more than two possible values are called polytomous variables For example Exam Result: Pass, Fail (Binary categorical variable) The blood type of a person: A, B, O, AB (polytomous categorical variable)

---

#### What will be the case in which the Mean, Median, and Mode will be the same for the dataset?

The mean, median, and mode of a dataset will all be the same if and only if the dataset consists of a single value that occurs with 100% frequency. For example, consider the following dataset: 3, 3, 3, 3, 3, 3. The mean of this dataset is 3, the median is 3, and the mode is 3. This is because the dataset consists of a single value (3) that occurs with 100% frequency. On the other hand, if the dataset contains multiple values, the mean, median, and mode will generally be different. For example, consider the following dataset: 1, 2, 3, 4, 5. The mean of this dataset is 3, the median is 3, and the mode is 1. The dataset contains multiple values, and no value occurs with 100% frequency. It is important to note that outliers or extreme values in the dataset can affect the mean, median, and mode. If the dataset contains extreme values, the mean and median may be significantly different from the mode, even if the dataset consists of a single value that occurs with a high frequency.

---

#### What is the difference between Variance and Bias in Statistics?

In statistics, variance, and bias are two measures of the quality or accuracy of a model or estimator. Variance: Variance measures the amount of spread or dispersion in a dataset. It is calculated as the average squared deviation from the mean. A high variance indicates that the data are spread out and may be more prone to error, while a low variance indicates that the data are concentrated around the mean and may be more accurate. Bias: Bias refers to the difference between the expected value of an estimator and the true value of the parameter being estimated. A high bias indicates that the estimator is consistently under or overestimating the true value, while a low bias indicates that the estimator is more accurate. It is important to consider both variance and bias when evaluating the quality of a model or estimator. A model with low bias and high variance may be prone to overfitting, while a model with high bias and low variance may be prone to underfitting. Finding the right balance between bias and variance is an important aspect of model selection and optimization. Data Science interview question

---

#### What is the difference between Type I and Type II errors?

Two types of errors can occur in hypothesis testing: Type I errors and Type II errors. A Type I error, also known as a ‚Äúfalse positive,‚Äù occurs when the null hypothesis is true but is rejected. This type of error is denoted by the Greek letter alpha (Œ±) and is usually set at a level of 0.05. This means that there is a 5% chance of making a Type I error or a false positive. A Type II error, also known as a ‚Äúfalse negative,‚Äù occurs when the null hypothesis is false but is not rejected. This type of error is denoted by the Greek letter beta (Œ≤) and is often represented as 1 ‚Äì Œ≤, where Œ≤ is the power of the test. The power of the test is the probability of correctly rejecting the null hypothesis when it is false. It‚Äôs important to try to minimize the chances of both types of errors in hypothesis testing. Data Science interview questions

---

#### What is the Confidence Interval in statistics?

The confidence interval is the range within which we expect the results to lie if we repeat the experiment. It is the mean of the result plus and minus the expected variation. The standard error of the estimate determines the latter, while the center of the interval coincides with the mean of the estimate. The most common confidence interval is 95%.

---

#### Can you explain the concept of correlation and covariance?

Correlation is a statistical measure that describes the strength and direction of a linear relationship between two variables. A positive correlation indicates that the two variables increase or decrease together, while a negative correlation indicates that the two variables move in opposite directions. Covariance is a measure of the joint variability of two random variables. It is used to measure how two variables are related. Advanced Statistics Interview Questions

---

#### Why is hypothesis testing useful for a data scientist?

Hypothesis testing is a statistical technique used in data science to evaluate the validity of a claim or hypothesis about a population. It is used to determine whether there is sufficient evidence to support a claim or hypothesis and to assess the statistical significance of the results. There are many situations in data science where hypothesis testing is useful. For example, it can be used to test the effectiveness of a new marketing campaign, to determine if there is a significant difference between the means of two groups, to evaluate the relationship between two variables, or to assess the accuracy of a predictive model. Hypothesis testing is an important tool in data science because it allows data scientists to make informed decisions based on data, rather than relying on assumptions or subjective opinions. It helps data scientists to draw conclusions about the data that are supported by statistical evidence, and to communicate their findings in a clear and reliable manner. Hypothesis testing is therefore a key component of the scientific method and a fundamental aspect of data science practice.

---

#### What is a chi-square test of independence used for in statistics?

A chi-square test of independence is a statistical test used to determine whether there is a significant association between two categorical variables. It is used to test the null hypothesis that the two variables are independent, meaning that the value of one variable does not depend on the value of the other variable. The chi-square test of independence involves calculating a chi-square statistic and comparing it to a critical value to determine the probability of the observed relationship occurring by chance. If the probability is below a certain threshold (e.g., 0.05), the null hypothesis is rejected and it is concluded that there is a significant association between the two variables. The chi-square test of independence is commonly used in data science to evaluate the relationship between two categorical variables, such as the relationship between gender and purchasing behavior, or the relationship between education level and voting preference. It is an important tool for understanding the relationship between different variables and for making informed decisions based on the data.

---

#### What is the significance of the p-value?

The p-value is used to determine the statistical significance of a result. In hypothesis testing, the p-value is used to assess the probability of obtaining a result that is at least as extreme as the one observed, given that the null hypothesis is true. If the p-value is less than the predetermined level of significance (usually denoted as alpha, Œ±), then the result is considered statistically significant and the null hypothesis is rejected. The significance of the p-value is that it allows researchers to make decisions about the data based on a predetermined level of confidence. By setting a level of significance before conducting the statistical test, researchers can determine whether the results are likely to have occurred by chance or if there is a real effect present in the data.

---

#### What are the different types of sampling techniques used by data analysts?

There are many different types of sampling techniques that data analysts can use, but some of the most common ones include: Simple random sampling: This is a basic form of sampling in which each member of the population has an equal chance of being selected for the sample. Stratified random sampling: This technique involves dividing the population into subgroups (or strata) based on certain characteristics, and then selecting a random sample from each stratum. Cluster sampling: This technique involves dividing the population into smaller groups (or clusters), and then selecting a random sample of clusters. Systematic sampling: This technique involves selecting every kth member of the population to be included in the sample.

---

#### What is Bayes‚Äô theorem and how is it used in data science?

Bayes‚Äô theorem is a mathematical formula that describes the probability of an event occurring, based on prior knowledge of conditions that might be related to the event. In data science, Bayes‚Äô theorem is often used in Bayesian statistics and machine learning, for tasks such as classification, prediction, and estimation. Bayes' Threorem

---

#### What is the difference between a parametric and a non-parametric test?

A parametric test is a statistical test that assumes that the data follows a specific probability distribution, such as a normal distribution. A non-parametric test does not make any assumptions about the underlying probability distribution of the data. Interview Questions Related to Machine Learning Let us look at data science interview questions and answers regarding Machine Learning. Beginner ML Interview Questions for Data Science

---

#### What is the difference between feature selection and extraction?

Feature selection is the technique in which we filter the features that should be fed to the model. This is the task in which we select the most relevant features. The features that clearly do not hold any importance in determining the prediction of the model are rejected. Feature selection on the other hand is the process by which the features are extracted from the raw data. It involves transforming raw data into a set of features that can be used to train an ML model. Both of these are very important as they help in filtering the features for our ML model which helps in determining the accuracy of the model.

---

#### What are the 5 assumptions for linear regression?

Here are the 5 assumptions of linear regression: Linearity: There is a linear relationship between the independent variables and the dependent variable. Independence of errors: The errors (residuals) are independent of each other. Homoscedasticity: The variance of the errors is constant across all predicted values. Normality: The errors follow a normal distribution. Independence of predictors: The independent variables are not correlated with each other.

---

#### What is the difference between linear and nonlinear regression?

Linear regression is the method in which is used to find the relationship between a dependent and one or more independent variables. The model finds the best-fit line, which is a linear function (y = mx +c) that helps in fitting the model in such a way that the error is minimum considering all the data points. So the decision boundary of a linear regression function is linear. A non-Linear regression is used to model the relationship between a dependent and one or more independent variables by a non-linear equation. The non-linear regression models are more flexible and are able to find the more complex relationship between variables.

---

#### How will you identify underfitting in a model?

Underfitting occurs when a statistical model or machine learning algorithm is not able to capture the underlying trend of the data. This can happen for a variety of reasons, but one common cause is that the model is too simple and is not able to capture the complexity of the data Here is how to identify underfitting in a model: The training error of an underfitting error will be high, i.e., the model will not be able to learn from the training data and will perform poorly on the training data. The validation error of an underfitting model will also be high as it will perform poorly on the new data as well.

---

#### How will you identify overfitting in a model?

Overfitting in a model occurs when the model learns the whole training data instead of taking signals/hints from the data and the model performs extremely well on training data and performs poorly on the testing data. The testing error of the model is high compared to the training error. The bias of an overfitting model is low whereas the variance is high. Data Science interview questions

---

#### What are some of the techniques to avoid overfitting?

Some techniques that can be used to avoid overfitting; Train-validation-test split: One way to avoid overfitting is to split your data into training, validation, and test sets. The model is trained on the training set and then evaluated on the validation set. The hyperparameters are then tuned based on the performance on the validation set. Once the model is finalized, it is evaluated on the test set. Early stopping: Another way to avoid overfitting is to use early stopping. This involves training the model until the validation error reaches a minimum, and then stopping the training process. Regularization: Regularization is a technique that can be used to prevent overfitting by adding a penalty term to the objective function. This term encourages the model to have small weights, which can help reduce the complexity of the model and prevent overfitting. Ensemble methods: Ensemble methods involve training multiple models and then combining their predictions to make a final prediction. This can help reduce overfitting by averaging out the predictions of the individual models, which can help reduce the variance of the final prediction.

---

#### What are some of the techniques to avoid underfitting?

Some techniques to prevent underfitting in a model: Feature selection: It is important to choose the right feature required for training a model as the selection of the wrong feature can result in underfitting. Increasing the number of features helps to avoid underfitting Using a more complex machine-learning model Using Hyperparameter tuning to fine tune the parameters in the model Noise: If there is more noise in the data, the model will not be able to detect the complexity of the dataset.

---

#### What is Multicollinearity?

Multicollinearity occurs when two or more predictor variables in a multiple regression model are highly correlated. This can lead to unstable and inconsistent coefficients, and make it difficult to interpret the results of the model. In other words, multicollinearity occurs when there is a high degree of correlation between two or more predictor variables. This can make it difficult to determine the unique contribution of each predictor variable to the response variable, as the estimates of their coefficients may be influenced by the other correlated variables.

---

#### Explain regression and classification problems.

Regression is a method of modeling the relationship between one or more independent variables and a dependent variable. The goal of regression is to understand how the independent variables are related to the dependent variable and to be able to make predictions about the value of the dependent variable based on new values of the independent variables. A classification problem is a type of machine learning problem where the goal is to predict a discrete label for a given input. In other words, it is a problem of identifying to which set of categories a new observation belongs, on the basis of a training set of data containing observations.

---

#### What is the difference between K-means and KNN?

K-means and KNN (K-Nearest Neighbors) are two different machine learning algorithms. K-means is a clustering algorithm that is used to divide a group of data points into K clusters, where each data point belongs to the cluster with the nearest mean. It is an iterative algorithm that assigns data points to a cluster and then updates the cluster centroid (mean) based on the data points assigned to it. On the other hand, KNN is a classification algorithm that is used to classify data points based on their similarity to other data points. It works by finding the K data points in the training set that are most similar to the data point being classified, and then it assigns the data point to the class that is most common among those K data points. So, in summary, K-means is used for clustering, and KNN is used for classification.

---

#### What is the difference between Sigmoid and Softmax ?

In Sigmoid function if your output is binary (0,1) then use the sigmoid function for the output layer. The sigmoid function appears in the output layer of the deep learning models and is used for predicting probability-based outputs. The softmax function is another type of Activation Function used in neural networks to compute probability distribution from a vector of real numbers. This function is mainly used in multi-class models where it returns probabilities of each class, with the target class having the highest probability. The primary difference between the sigmoid and softmax Activation function is that while the former is used in binary classification, the latter is used for multivariate classification machine learning interview questions

---

#### Can we use logistic regression for multiclass classification?

Yes, logistic regression can be used for multiclass classification. Logistic regression is a classification algorithm that is used to predict the probability of a data point belonging to a certain class. It is a binary classification algorithm, which means that it can only handle two classes. However, there are ways to extend logistic regression to multiclass classification. One way to do this is to use one-vs-all (OvA) or one-vs-rest (OvR) strategy, where you train K logistic regression classifiers, one for each class, and assign a data point to the class that has the highest predicted probability. This is called OvA if you train one classifier for each class, and the other class is the ‚Äúrest‚Äù of the classes. This is called OvR if you train one classifier for each class, and the other class is the ‚Äúall‚Äù of the classes. Another way to do this is to use multinomial logistic regression, which is a generalization of logistic regression to the case where you have more than two classes. In multinomial logistic regression, you train a logistic regression classifier for each pair of classes, and you use the predicted probabilities to assign a data point to the class that has the highest probability. So, in summary, logistic regression can be used for multiclass classification using OvA/OvR or multinomial logistic regression.

---

#### Can you explain the bias-variance tradeoff in the context of supervised machine learning?

In supervised machine learning, the goal is to build a model that can make accurate predictions on unseen data. However, there is a tradeoff between the model‚Äôs ability to fit the training data well (low bias) and its ability to generalize to new data (low variance). A model with high bias tends to underfit the data, which means that it is not flexible enough to capture the patterns in the data. On the other hand, a model with high variance tends to overfit the data, which means that it is too sensitive to noise and random fluctuations in the training data. The bias-variance tradeoff refers to the tradeoff between these two types of errors. A model with low bias and high variance is likely to overfit the data, while a model with high bias and low variance is likely to underfit the data. To balance the tradeoff between bias and variance, we need to find a model with the right complexity level for the problem at hand. If the model is too simple, it will have high bias and low variance, but it will not be able to capture the underlying patterns in the data. If the model is too complex, it will have low bias and high variance, but it will be sensitive to the noise in the data and it will not generalize well to new data.

---

#### How do you decide whether a model is suffering from high bias or high variance?

There are several ways to determine whether a model is suffering from high bias or high variance. Some common methods are: Split the data into a training set and a test set, and check the performance of the model on both sets. If the model performs well on the training set but poorly on the test set, it is likely to suffer from high variance (overfitting). If the model performs poorly on both sets, it is likely suffering from high bias (underfitting). Use cross-validation to estimate the performance of the model. If the model has high variance, the performance will vary significantly depending on the data used for training and testing. If the model has high bias, the performance will be consistently low across different splits of the data. Plot the learning curve, which shows the performance of the model on the training set and the test set as a function of the number of training examples. A model with high bias will have a high training error and a high test error, while a model with high variance will have a low training error and a high test error.

---

#### What are some techniques for balancing bias and variance in a model?

There are several techniques that can be used to balance the bias and variance in a model, including: Increasing the model complexity by adding more parameters or features: This can help the model capture more complex patterns in the data and reduce bias, but it can also increase variance if the model becomes too complex. Reducing the model complexity by removing parameters or features: This can help the model avoid overfitting and reduce variance, but it can also increase bias if the model becomes too simple. Using regularization techniques: These techniques constrain the model complexity by penalizing large weights, which can help the model avoid overfitting and reduce variance. Some examples of regularization techniques are L1 regularization, L2 regularization, and elastic net regularization. Splitting the data into a training set and a test set: This allows us to evaluate the model‚Äôs generalization ability and tune the model complexity to achieve a good balance between bias and variance. Using cross-validation: This is a technique for evaluating the model‚Äôs performance on different splits of the data and averaging the results to get a more accurate estimate of the model‚Äôs generalization ability.

---

#### How do you choose the appropriate evaluation metric for a classification problem, and how do you interpret the results of the evaluation?

There are many evaluation metrics that you can use for a classification problem, and the appropriate metric depends on the specific characteristics of the problem and the goals of the evaluation. Some common evaluation metrics for classification include: Accuracy: This is the most common evaluation metric for classification. It measures the percentage of correct predictions made by the model. Precision: This metric measures the proportion of true positive predictions among all positive predictions made by the model. Recall: This metric measures the proportion of true positive predictions among all actual positive cases in the test set. F1 Score: This is the harmonic mean of precision and recall. It is a good metric to use when you want to balance precision and recall. AUC-ROC: This metric measures the ability of the model to distinguish between positive and negative classes. It is commonly used for imbalanced classification problems. To interpret the results of the evaluation, you should consider the specific characteristics of the problem and the goals of the evaluation. For example, if you are trying to identify fraudulent transactions, you may be more interested in maximizing precision, because you want to minimize the number of false alarms. On the other hand, if you are trying to diagnose a disease, you may be more interested in maximizing recall, because you want to minimize the number of missed diagnoses.

---

#### What is the difference between K-means and hierarchical clustering and when to use what?

K-means and hierarchical clustering are two different methods for clustering data. Both methods can be useful in different situations. K-means is a centroid-based algorithm, or a distance-based algorithm, where we calculate the distances to assign a point to a cluster. K-means is very fast and efficient in terms of computational time, but it can fail to find the global optimum because it uses random initializations for the centroid seeds. Hierarchical clustering, on the other hand, is a density-based algorithm that does not require us to specify the number of clusters beforehand. It builds a hierarchy of clusters by creating a tree-like diagram, called a dendrogram. There are two main types of hierarchical clustering: agglomerative and divisive. Agglomerative clustering starts with individual points as separate clusters and merges them into larger clusters, while divisive clustering starts with all points in one cluster and divides them into smaller clusters. Hierarchical clustering is a slow algorithm and requires a lot of computational resources, but it is more accurate than K-means. So, when to use K-means and when to use hierarchical clustering? It really depends on the size and structure of your data, as well as the resources you have available. If you have a large dataset and you want to cluster it quickly, then K-means might be a good choice. If you have a small dataset or if you want more accurate clusters, then hierarchical clustering might be a better choice. interview questions

---

#### How can you handle imbalanced classes in a logistic regression model?

There are several ways to handle imbalanced classes in a logistic regression model. Some approaches include: Undersampling the majority class: This involves randomly selecting a subset of the majority class samples to use in training the model. This can help to balance the class distribution, but it may also throw away valuable information. Oversampling the minority class: This involves generating synthetic samples of the minority class to add to the training set. One popular method for generating synthetic samples is called SMOTE (Synthetic Minority Oversampling Technique). Adjusting the class weights: Many machine learning algorithms allow you to adjust the weighting of each class. In logistic regression, you can do this by setting the class_weight parameter to ‚Äúbalanced‚Äù. This will automatically weight the classes inversely proportional to their frequency, so that the model pays more attention to the minority class. Using a different evaluation metric: In imbalanced classification tasks, it is often more informative to use evaluation metrics that are sensitive to class imbalance, such as precision, recall, and the F1 score. Using a different algorithm: Some algorithms, such as decision trees and Random Forests, are more robust to imbalanced classes and may perform better on imbalanced datasets.

---

#### When not to use PCA for dimensionality reduction?

There are several situations when you may not want to use Principal Component Analysis (PCA) for dimensionality reduction: When the data is not linearly separable: PCA is a linear technique, so it may not be effective at reducing the dimensionality of data that is not linearly separable. The data has categorical features: PCA is designed to work with continuous numerical data and may not be effective at reducing the dimensionality of data with categorical features. When the data has a large number of missing values: PCA is sensitive to missing values and may not work well with data sets that have a large number of missing values. The goal is to preserve the relationships between the original features: PCA is a technique that looks for patterns in the data and creates new features that are combinations of the original features. As a result, it may not be the best choice if the goal is to preserve the relationships between the original features. When the data is highly imbalanced: PCA is sensitive to class imbalances and may not produce good results on highly imbalanced data sets.

---

#### What is Gradient descent?

Gradient descent is an optimization algorithm used in machine learning to find the values of parameters (coefficients and bias) of a model that minimize the cost function. It is a first-order iterative optimization algorithm that follows the negative gradient of the cost function to converge to the global minimum. In gradient descent, the model‚Äôs parameters are initialized with random values, and the algorithm iteratively updates the parameters in the opposite direction of the gradient of the cost function with respect to the parameters. The size of the update is determined by the learning rate, which is a hyperparameter that controls how fast the algorithm converges to the global minimum. As the algorithm updates the parameters, the cost function decreases and the model‚Äôs performance improves

---

#### What is the difference between MinMaxScaler and StandardScaler?

Both the MinMaxScaler and StandardScaler are tools used to transform the features of a dataset so that they can be better modeled by machine learning algorithms. However, they work in different ways. MinMaxScaler scales the features of a dataset by transforming them to a specific range, usually between 0 and 1. It does this by subtracting the minimum value of each feature from all the values in that feature, and then dividing the result by the range (i.e., the difference between the minimum and maximum values). This transformation is given by the following equation: x_scaled = (x - x_min) / (x_max - x_min) StandardScaler standardizes the features of a dataset by transforming them to have zero mean and unit variance. It does this by subtracting the mean of each feature from all the values in that feature, and then dividing the result by the standard deviation. This transformation is given by the following equation: x_scaled = (x - mean(x)) / std(x) In general, StandardScaler is more suitable for datasets where the distribution of the features is approximately normal, or Gaussian. MinMaxScaler is more suitable for datasets where the distribution is skewed or where there are outliers. However, it is always a good idea to visualize the data and understand the distribution of the features before choosing a scaling method.

---

#### What is the difference between Supervised and Unsupervised learning?

In supervised learning, the training set you feed to the algorithm includes the desired solutions, called labels. Ex = Spam Filter (Classification problem) k-Nearest Neighbors Linear Regression Logistic Regression Support Vector Machines (SVMs) Decision Trees and Random Forests Neural networks In unsupervised learning, the training data is unlabeled. Let‚Äôs say, The system tries to learn without a teacher. Clustering K-Means DBSCAN Hierarchical Cluster Analysis (HCA) Anomaly detection and novelty detection One-class SVM Isolation Forest Visualization and dimensionality reduction Principal Component Analysis (PCA) Kernel PCA Locally Linear Embedding (LLE) t-Distributed Stochastic Neighbor Embedding (t-SNE)

---

#### What are some common methods for hyperparameter tuning?

There are several common methods for hyperparameter tuning: Grid Search: This involves specifying a set of values for each hyperparameter, and the model is trained and evaluated using a combination of all possible hyperparameter values. This can be computationally expensive, as the number of combinations grows exponentially with the number of hyperparameters. Random Search: This involves sampling random combinations of hyperparameters and training and evaluating the model for each combination. This is less computationally intensive than grid search, but may be less effective at finding the optimal set of hyperparameters.

---

#### How do you decide the size of your validation and test sets?

You can validate the size of your test sets in the following ways: Size of the dataset: In general, the larger the dataset, the larger the validation and test sets can be. This is because there is more data to work with, so the validation and test sets can be more representative of the overall dataset. Complexity of the model: If the model is very simple, it may not require as much data to validate and test. On the other hand, if the model is very complex, it may require more data to ensure that it is robust and generalizes well to unseen data. Level of uncertainty: If the model is expected to perform very well on the task, the validation and test sets can be smaller. However, if the performance of the model is uncertain or the task is very challenging, it may be helpful to have larger validation and test sets to get a more accurate assessment of the model‚Äôs performance. Resources available: The size of the validation and test sets may also be limited by the computational resources available. It may not be practical to use very large validation and test sets if it takes a long time to train and evaluate the model.

---

#### How do you evaluate a model‚Äôs performance for a multi-class classification problem?

One approach for evaluating a multi-class classification model is to calculate a separate evaluation metric for each class, and then calculate a macro or micro average. The macro average gives equal weight to all the classes, while the micro average gives more weight to the classes with more observations. Additionally, some commonly used metrics for multi-class classification problems such as confusion matrix, precision, recall, F1 score, Accuracy and ROC-AUC can also be used.

---

#### What is the difference between Statistical learning and Machine Learning with their examples?

Statistical learning and machine learning are both methods used to make predictions or decisions based on data. However, there are some key differences between the two approaches: Statistical learning focuses on making predictions or decisions based on a statistical model of the data. The goal is to understand the relationships between the variables in the data and make predictions based on those relationships. Machine learning, on the other hand, focuses on making predictions or decisions based on patterns in the data, without necessarily trying to understand the relationships between the variables. Statistical learning methods often rely on strong assumptions about the data distribution, such as normality or independence of errors. Machine learning methods, on the other hand, are often more robust to violations of these assumptions. Statistical learning methods are generally more interpretable because the statistical model can be used to understand the relationships between the variables in the data. Machine learning methods, on the other hand, are often less interpretable, because they are based on patterns in the data rather than explicit relationships between variables. For example, linear regression is a statistical learning method that assumes a linear relationship between the predictor and target variables and estimates the coefficients of the linear model using an optimization algorithm. Random forests is a machine learning method that builds an ensemble of decision trees and makes predictions based on the average of the predictions of the individual trees.

---

#### How is normalized data beneficial for making models in data science?

Improved model performance: Normalizing the data can improve the performance of some machine learning models, particularly those that are sensitive to the scale of the input data. For example, normalizing the data can improve the performance of algorithms such as K-nearest neighbors and neural networks. Easier feature comparison: Normalizing the data can make it easier to compare the importance of different features. Without normalization, features with large scales can dominate the model, making it difficult to determine the relative importance of other features. Reduced impact of outliers: Normalizing the data can reduce the impact of outliers on the model, as they are scaled down along with the rest of the data. This can improve the robustness of the model and prevent it from being influenced by extreme values. Improved interpretability: Normalizing the data can make it easier to interpret the results of the model, as the coefficients and feature importances are all on the same scale. It is important to note that normalization is not always necessary or beneficial for all models. It is necessary to carefully evaluate the specific characteristics and needs of the data and the model in order to determine whether normalization is appropriate. Intermediate ML Interview Questions

---

#### Why is the harmonic mean calculated in the f1 score and not the mean?

The F1 score is a metric that combines precision and recall. Precision is the number of true positive results divided by the total number of positive results predicted by the classifier, and recall is the number of true positive results divided by the total number of positive results in the ground truth. The harmonic mean of precision and recall is used to calculate the F1 score because it is more forgiving of imbalanced class proportions than the arithmetic mean. If the harmonic means were not used, the F1 score would be higher because it would be based on the arithmetic mean of precision and recall, which would give more weight to the high precision and less weight to the low recall. The use of the harmonic mean in the F1 score helps to balance the precision and recall and gives a more accurate overall assessment of the classifier‚Äôs performance. intrview questions

---

#### What are some ways to select features?

Here are some ways to select the features: Filter methods: These methods use statistical scores to select the most relevant features. Example: Correlation coefficient: Selects features that are highly correlated with the target variable. Chi-squared test: Selects features that are independent of the target variable. Wrapper methods: These methods use a learning algorithm to select the best features. For example Forward selection: Begins with an empty set of features and adds one feature at a time until the performance of the model is optimal. Backward selection: Begins with the full set of features and removes one feature at a time until the performance of the model is optimal. Embedded methods: These methods learn which features are most important while the model is being trained. Example: Lasso regression: Regularizes the model by adding a penalty term to the loss function that shrinks the coefficients of the less important features to zero. Ridge regression: Regularizes the model by adding a penalty term to the loss function that shrinks the coefficients of all features towards zero, but does not set them to zero. Feature Importance: We can also use the feature importance parameter which gives us the most important features considered by the model

---

#### What is the difference between bagging boosting difference?

Both bagging and boosting are ensemble learning techniques that help in improving the performance of the model. Bagging is the technique in which different models are trained on the dataset that we have and then the average of the predictions of these models is taken into consideration. The intuition behind taking the predictions of all the models and then averaging the results is making more diverse and generalized predictions that can be more accurate. Boosting is the technique in which different models are trained but they are trained in a sequential manner. Each successive model corrects the error made by the previous model. This makes the model strong resulting in the least error.

---

#### What is the difference between stochastic gradient boosting and XGboost?

XGBoost is an implementation of gradient boosting that is specifically designed to be efficient, flexible, and portable. Stochastic XGBoost is a variant of XGBoost that uses a more randomized approach to building decision trees, which can make the resulting model more robust to overfitting. Both XGBoost and stochastic XGBoost are popular choices for building machine-learning models and can be used for a wide range of tasks, including classification, regression, and ranking. The main difference between the two is that XGBoost uses a deterministic tree construction algorithm, while stochastic XGBoost uses a randomized tree construction algorithm.

---

#### What is the difference between catboost and XGboost?

Difference between Catboost and XGboost: Catboost handles categorical features better than XGboost. In catboost, the categorical features are not required to be one-hot encoded which saves a lot of time and memory. XGboost on the other hand can also handle categorical features but they needed to be one-hot encoded first. XGboost requires manual processing of the data while Catboost does not. They have some differences in the way that they build decision trees and make predictions. Catboost is faster than XGboost and builds symmetric(balanced) trees, unlike XGboost.

---

#### What is the difference between linear and nonlinear classifiers

The difference between the linear and nonlinear classifiers is the nature of the decision boundary. In a linear classifier, the decision boundary is a linear function of the input. In other words, the boundary is a straight line, a plane, or a hyperplane. ex: Linear Regression, Logistic Regression, LDA A non-linear classifier is one in which the decision boundary is not a linear function of the input.  This means that the classifier cannot be represented by a linear function of the input features. Non-linear classifiers can capture more complex relationships between the input features and the label, but they can also be more prone to overfitting, especially if they have a lot of parameters. ex: KNN, Decision Tree, Random Forest ML interview questions

---

#### What are parametric and nonparametric models?

A parametric model is a model that is described by a fixed number of parameters. These parameters are estimated from the data using a maximum likelihood estimation procedure or some other method, and they are used to make predictions about the response variable. Nonparametric models do not assume any specific form for the relationship between variables. They are more flexible than parametric models. They can fit a wider variety of data shapes. However, they have fewer interpretable parameters. This can make them harder to understand.

---

#### How can we use cross-validation to overcome overfitting?

The cross-validation technique can be used to identify if the model is underfitting or overfitting but it cannot be used to overcome either of the problems. We can only compare the performance of the model on two different sets of data and find if the data is overfitting or underfitting, or generalized.

---

#### How can you convert a numerical variable to a categorical variable and when can it be useful?

There are several ways to convert a numerical variable to a categorical variable. One common method is to use binning, which involves dividing the numerical variable into a set of bins or intervals and treating each bin as a separate category. Another way to convert a numerical variable to a categorical one is through ‚Äúdiscretization.‚Äù This means dividing the range into intervals. Each interval is then treated as a separate category. It helps create a more detailed view of the data. This conversion is useful when the numerical variable has limited values. Grouping these values can make patterns clearer. It also highlights trends instead of focusing on raw numbers.

---

#### What are generalized linear models?

Generalized Linear Models are a flexible family of models. They describe the relationship between a response variable and one or more predictors. GLMs offer more flexibility than traditional linear models. In linear models, the response is normally distributed. The relationship with predictors is assumed to be linear. GLMs relax these rules. The response can follow different distributions. The relationship can also be non-linear. Common GLMs include logistic regression for binary data, Poisson regression for counts, and exponential regression for time-to-event data.

---

#### What is the difference between ridge and lasso regression? How do they differ in terms of their approach to model selection and regularization?

Ridge regression and lasso regression are both techniques used to prevent overfitting in linear models by adding a regularization term to the objective function. They differ in how they define the regularization term. In ridge regression, the regularization term is defined as the sum of the squared coefficients (also called the L2 penalty). This results in a smooth optimization surface, which can help the model generalize better to unseen data. Ridge regression has the effect of driving the coefficients towards zero, but it does not set any coefficients exactly to zero. This means that all features are retained in the model, but their impact on the output is reduced. On the other hand, lasso regression defines the regularization term as the sum of the absolute values of the coefficients (also called the L1 penalty). This has the effect of driving some coefficients exactly to zero, effectively selecting a subset of the features to use in the model. This can be useful for feature selection, as it allows the model to automatically select the most important features. However, the optimization surface for lasso regression is not smooth, which can make it more difficult to train the model. In summary, ridge regression shrinks the coefficients of all features towards zero, while lasso regression sets some coefficients exactly to zero. Both techniques can be useful for preventing overfitting, but they differ in how they handle model selection and regularization.

---

#### How does the step size (or learning rate) of an optimization algorithm impact the convergence of the optimization process in logistic regression?

The step size, or learning rate, controls how big the steps are during optimization. In logistic regression, we minimize the negative log-likelihood to find the best coefficients. If the step size is too large, the algorithm may overshoot the minimum. It can oscillate or even diverge. If the step size is too small, progress will be slow. The algorithm may take a long time to converge. Therefore, it is important to choose an appropriate step size in order to ensure the convergence of the optimization process. In general, a larger step size can lead to faster convergence, but it also increases the risk of overshooting the minimum. A smaller step size will be safer, but it will also be slower. There are several approaches for choosing an appropriate step size. One common approach is to use a fixed step size for all iterations. Another approach is to use a decreasing step size, which starts out large and decreases over time. This can help the optimization algorithm to make faster progress at the beginning and then fine-tune the coefficients as it gets closer to the minimum.

---

#### What is overfitting in decision trees, and how can it be mitigated?

Overfitting in decision trees occurs when the model is too complex and has too many branches, leading to poor generalization to new, unseen data. This is because the model has ‚Äúlearned‚Äù the patterns in the training data too well, and is not able to generalize these patterns to new, unseen data. There are several ways to mitigate overfitting in decision trees: Pruning: This involves removing branches from the tree that do not add significant value to the model‚Äôs predictions. Pruning can help reduce the complexity of the model and improve its generalization ability. Limiting tree depth: By restricting the depth of the tree, you can prevent the tree from becoming too complex and overfitting the training data. Using ensembles: Ensemble methods such as random forests and gradient boosting can help reduce overfitting by aggregating the predictions of multiple decision trees. Using cross-validation: By evaluating the model‚Äôs performance on multiple train-test splits, you can get a better estimate of the model‚Äôs generalization performance and reduce the risk of overfitting.

---

#### Why is SVM called a large margin classifier?

Support Vector Machine, is called a large margin classifier because it seeks to find a hyperplane with the largest possible margin, or distance, between the positive and negative classes in the feature space. The margin is the distance between the hyperplane and the nearest data points, and is used to define the decision boundary of the model. By maximizing the margin, the SVM classifier is able to better generalize to new, unseen data and is less prone to overfitting. The larger the margin, the lower the uncertainty around the decision boundary, and the more confident the model is in its predictions. Therefore, the goal of the SVM algorithm is to find a hyperplane with the largest possible margin, which is why it is called a large margin classifier. machin learning, data science interview questions

---

#### What is hinge loss?

Hinge loss is a loss function used in support vector machines (SVMs) and other linear classification models. It is defined as the loss that is incurred when a prediction is incorrect. The hinge loss for a single example is defined as: loss = max(0, 1 ‚Äì y * f(x)) where y is the true label (either -1 or 1) and f(x) is the predicted output of the model. The predicted output is the inner product between the input features and the model weights, plus a bias term. Hinge loss is used in SVMs because it is convex. It penalizes predictions that are not confident and correct. The loss is zero when the prediction is correct. It increases as confidence in a wrong prediction grows. This pushes the model to be confident but careful. It discourages predictions far from the true label. Advanced ML Interview Questions

---

#### What will happen if we increase the number of neighbors in KNN?

Increasing the number of neighbors in KNN makes the classifier more conservative. The decision boundary becomes smoother. This helps reduce overfitting. However, it may miss subtle patterns in the data. A larger k creates a simpler model. This lowers overfitting but increases the risk of underfitting. To avoid both issues, choosing the right k is important. It should balance complexity and simplicity. It‚Äôs best to test different k values. Then, pick the one that works best for your dataset.

---

#### What will happen in the decision tree if the max depth is increased?

Increasing the max depth of a decision tree will increase the complexity of the model and make it more prone to overfitting. If you increase the max depth of a decision tree, the tree will be able to make more complex and nuanced decisions, which can improve the model‚Äôs ability to fit the training data well. However, if the tree is too deep, it may become overly sensitive to the specific patterns in the training data and not generalize well to unseen data. interview question, data science interview questions

---

#### What is the difference between extra trees and random forests?

The main difference between the two algorithms is how the decision trees are constructed. In a Random Forest, the decision trees are constructed using bootstrapped samples of the training data and a random subset of the features. This results in each tree being trained on a slightly different set of data and features, leading to a greater diversity of trees and a lower variance. In an Extra Trees classifier, the decision trees are constructed in a similar way, but instead of selecting a random subset of the features at each split, the algorithm selects the best split among a random subset of the features. This results in a greater number of random splits and a higher degree of randomness, leading to a lower bias and a higher variance.

---

#### When to use one-hot encoding and label encoding?

One-hot encoding and label encoding are two different techniques that can be used to encode categorical variables as numerical values. They are often used in machine learning models as a preprocessing step before fitting the model to the data. One-hot encoding is used for categorical variables without any natural order. It creates binary columns for each category, using 1 for presence and 0 for absence, helping preserve uniqueness and avoid false ordinal assumptions. Label encoding is used when categories have a natural order, assigning each a unique integer to reflect that order. One-hot suits nominal data, while label encoding fits ordinal data, though the final choice depends on the model and dataset.

---

#### What is the problem with using label encoding for nominal data?

Label encoding is a method of encoding categorical variables as numerical values, which can be beneficial in certain situations. However, there are some potential problems that you should be aware of when using label encoding for nominal data. One problem with label encoding is that it can create an ordinal relationship between categories where none exists If you have a categorical variable with three categories: ‚Äúred‚Äù, ‚Äúgreen‚Äù, and ‚Äúblue‚Äù, and you apply label encoding to map these categories to numerical values 0, 1, and 2, the model may assume that the category ‚Äúgreen‚Äù is somehow ‚Äúbetween‚Äù the categories ‚Äúred‚Äù and ‚Äúblue‚Äù. This can be a problem if your model depends on the assumption that the categories are independent of one another. Another problem with label encoding is that it can lead to unexpected results if you have an imbalanced dataset. For example, if one category is much more common than the others, it will be assigned a much lower numerical value, which could lead the model to give it less importance than it deserves.

---

#### When can one-hot encoding be a problem?

One-hot encoding can be a problem in certain situations because it can create a large number of new columns in the dataset, which can make the data more difficult to work with and potentially lead to overfitting. One-hot encoding creates a new binary column for each category in a categorical variable. If you have a categorical variable with many categories, this can result in a very large number of new columns. Another problem with one-hot encoding is that it can lead to overfitting. Especially if you have a small dataset and a large number of categories. When you create many new columns for each category, you are effectively increasing the number of features in the dataset. This can lead to overfitting, because the model may be able to memorize the training data, but it will not generalize well to new data. Finally, one-hot encoding can also be a problem if you need to add new categories to the dataset in the future. If you have already one-hot encoded the existing categories. Ensure new categories are added clearly to avoid confusion or unexpected results.

---

#### What can be an appropriate encoding technique when you have hundreds of categorical values in a column?

A few techniques can be used when we have hundreds of columns in a categorical variable. Frequency encoding: This involves replacing each category with the frequency of that category in the dataset. This can work well if the categories have a natural ordinal relationship based on their frequency. Target encoding: This involves replacing each category with the mean of the target variable for that category. This can be effective if the categories have a clear relationship with the target variable.

---

#### What are the sources of randomness in random forest ?

Random forests are an ensemble learning method that involves training multiple decision trees on different subsets of the data and averaging the predictions of the individual trees to make a final prediction. There are several sources of randomness in the process of training a random forest: Bootstrapped samples: When training each decision tree, the algorithm creates a bootstrapped sample of the data by sampling with replacement from the original training set. This means that some data points will be included in the sample multiple times. While others will not be included at all. This creates variation between the training sets of different trees. Random feature selection: When training each decision tree, the algorithm selects a random subset of the features to consider at each split. This means that different trees will consider different sets of features, leading to variation in the learned trees. Random threshold selection: When training each decision tree, the algorithm selects a random threshold for each feature to determine the optimal split. This means that different trees will split on different thresholds, leading to variation in the learned trees.

---

#### How do you decide which feature to split on at each node of the tree?

When training a decision tree, the algorithm must choose the feature to split on at each node of the tree. There are several strategies that can be used to decide which feature to split on, including: Greedy search: The algorithm selects the feature that maximizes a splitting criterion (such as information gain or Gini impurity) at each step. Random Search: The algorithm selects the feature to split on at random at each step. Exhaustive search: The algorithm considers all possible splits and selects the one that maximizes the splitting criterion. Forward search: The algorithm starts with an empty tree and adds splits one by one, selecting the split that maximizes the splitting criterion at each step. Backward search: The algorithm starts with a fully grown tree and prunes split one by one, selecting the split to remove that results in the smallest decrease in the splitting criterion.

---

#### What is the significance of C in SVM?

In the support vector machine (SVM) algorithm, the parameter C is a hyperparameter that controls the trade-off between maximizing the margin and minimizing the misclassification error. C controls the penalty for misclassifying training examples. A smaller C means a higher penalty. The model tries to classify all examples correctly, even with a smaller margin. A larger C means a lower penalty. The model allows some misclassifications to get a larger margin. In practice, you can think of C as controlling the flexibility of the model. A smaller value of C will result in a more rigid model that may be more prone to underfitting, while a larger value of C will result in a more flexible model that may be more prone to overfitting. Choose C carefully using cross-validation to balance bias-variance and ensure good performance on unseen data.

---

#### How do c and gamma affect overfitting in SVM?

In support vector machines (SVMs), the regularization parameter C and the kernel parameter gamma are used to control overfitting. C is the penalty for misclassification. A smaller value of C means a larger penalty for misclassification. The model becomes more conservative. It tries harder to avoid mistakes. This can reduce overfitting. However, it may also make the model too cautious. As a result, generalization performance might suffer. Gamma is a parameter that controls the complexity of the model. A smaller value of gamma means a more complex model, which can lead to overfitting. A larger value of gamma means a simpler model, which can help prevent overfitting but may also result in a model that is too simple to accurately capture the underlying relationships in the data. Finding the best values for C and gamma is a balance between bias and variance. It usually requires testing different values. The model‚Äôs performance should be checked on a validation set. This helps identify the best parameter settings.

---

#### How do you choose the number of models to use in a Boosting or Bagging ensemble?

The number of models to use in an ensemble is usually determined by the trade-off between performance and computational cost. As a general rule of thumb, increasing the number of models will improve the performance of the ensemble, but at the cost of increasing the computational cost. In practice, the number of models is determined by Cross validation which is used to determine the optimal number of models based on the evaluation metric chosen.

---

#### In which scenarios Boosting and Bagging are preferred over single models?

Both boosting and bagging are used to improve model performance. They help when individual models have high variance or high bias. Bagging reduces the variance of a model. Boosting reduces bias and improves generalization error. Both methods are useful for models that are sensitive to training data. They also help when there is a high risk of overfitting.

---

#### Can you explain the ROC curve and AUC score and how they are used to evaluate a model‚Äôs performance?

A ROC (Receiver Operating Characteristic) curve is a graphical representation of the performance of a binary classification model. It plots the true positive rate (TPR) against the false positive rate (FPR) at different thresholds. AUC (Area Under the Curve) is the area under the ROC curve. It gives a single number that represents the model‚Äôs overall performance. AUC is useful because it considers all possible thresholds, not just a single point on the ROC curve.

---

#### How do you approach setting the threshold in a binary classification problem when you want to adjust precision and recall by yourself?

When setting the threshold in a binary classification problem, it‚Äôs important to consider the trade-off between precision and recall. Precision is the ratio of true positives to all predicted positives. Recall is the ratio of true positives to all actual positives. To adjust these metrics, first train the model and evaluate it on a validation set. This set should have a similar distribution to the test data. Then, use a confusion matrix to visualize performance. It shows true positives, false positives, true negatives, and false negatives. This helps identify the current prediction threshold. Once you know the threshold, you can adjust it to balance precision and recall. Increasing the threshold boosts precision but lowers recall. Decreasing it raises recall but reduces precision. Always consider the specific use case. In medical diagnosis, high recall is vital to catch all positives. In fraud detection, high precision is key to avoid false alarms. The right balance depends on the cost of false positives and false negatives in your scenario.

---

#### What is the difference between LDA (Linear Discriminant Analysis) and PCA (Principal Component Analysis)?

The difference between LDA (Linear Discriminant Analysis) and PCA (Principal Component Analysis) are: Feature	PCA (Principal Component Analysis)	LDA (Linear Discriminant Analysis) Type	Unsupervised	Supervised Purpose	Find directions of maximum variance in the data	Maximize class separability Use Case	Pattern discovery, data compression	Classification tasks (e.g., face, iris, fingerprint recognition) Based On	Variance in data	Labels and class distribution Components	Principal components (orthogonal directions of maximum variance)	Linear discriminants (directions that best separate classes) Data Projection	Projects data onto directions of highest variance	Projects data onto directions that best separate the classes Orthogonality	Components are mutually orthogonal	Components are not necessarily orthogonal Output	Lower-dimensional subspace preserving most variance	Lower-dimensional subspace maximizing class discrimination

---

#### How does the Naive Bayes algorithm compare to other supervised learning algorithms?

Naive Bayes is a simple and fast algorithm that works well with high-dimensional data and small training sets. It also performs well on datasets with categorical variables and missing data, which are common in many real-world problems. It is good for text classification, spam filtering, and sentiment analysis. However, due to the assumption of independence among features, it does not perform good for problems having high correlation among features. It also often fails to capture the interactions among features, which can result in poor performance on some datasets. Therefore, it is often used as a baseline or starting point, and then other algorithms like SVM, and Random Forest can be used to improve the performance.

---

#### Can you explain the concept of the ‚Äúkernel trick‚Äù and its application in Support Vector Machines (SVMs)?

The kernel trick is a technique used in SVMs. It transforms input data into a higher-dimensional feature space. This makes the data linearly separable. The trick replaces the standard inner product with a kernel function. The kernel computes the inner product in a higher-dimensional space. It does this without calculating the actual coordinates. This helps SVMs handle non-linearly separable data. Common kernel functions include the polynomial kernel, RBF kernel, and sigmoid kernel.

---

#### SELECT merchant_id,

SUM(CASE WHEN LOWER(payment_method) = 'apple pay' THEN transaction_amount ELSE 0 END) total_transaction FROM transactions GROUP BY merchant_id ORDER BY total_transaction DESC;

---

#### SELECT DISTINCT salary

FROM employee_176 ORDER BY salary DESC LIMIT 1 OFFSET N-1;

---

#### WITH ranked AS (

SELECT *, RANK() OVER (PARTITION BY city_id ORDER BY degree DESC,day) AS rnk FROM weather_2314 ) SELECT city_id,day,degree FROM ranked WHERE rnk = 1 ORDER BY city_id;

---

#### -- Question 114

-- Table: Product -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | product_id    | int     | -- | product_name  | varchar | -- +---------------+---------+ -- product_id is the primary key for this table. -- product_name is the name of the product. -- Table: Sales -- +---------------------+---------+ -- | Column Name         | Type    | -- +---------------------+---------+ -- | product_id          | int     | -- | period_start        | varchar | -- | period_end          | date    | -- | average_daily_sales | int     | -- +---------------------+---------+ -- product_id is the primary key for this table. -- period_start and period_end indicates the start and end date for sales period, both dates are inclusive. -- The average_daily_sales column holds the average daily sales amount of the items for the period. -- Write an SQL query to report the Total sales amount of each item for each year, with corresponding product name, product_id, product_name and report_year. -- Dates of the sales years are between 2018 to 2020. Return the result table ordered by product_id and report_year. -- The query result format is in the following example: -- Product table: -- +------------+--------------+ -- | product_id | product_name | -- +------------+--------------+ -- | 1          | LC Phone     | -- | 2          | LC T-Shirt   | -- | 3          | LC Keychain  | -- +------------+--------------+ -- Sales table: -- +------------+--------------+-------------+---------------------+ -- | product_id | period_start | period_end  | average_daily_sales | -- +------------+--------------+-------------+---------------------+ -- | 1          | 2019-01-25   | 2019-02-28  | 100                 | -- | 2          | 2018-12-01   | 2020-01-01  | 10                  | -- | 3          | 2019-12-01   | 2020-01-31  | 1                   | -- +------------+--------------+-------------+---------------------+ -- Result table: -- +------------+--------------+-------------+--------------+ -- | product_id | product_name | report_year | total_amount | -- +------------+--------------+-------------+--------------+ -- | 1          | LC Phone     |    2019     | 3500         | -- | 2          | LC T-Shirt   |    2018     | 310          | -- | 2          | LC T-Shirt   |    2019     | 3650         | -- | 2          | LC T-Shirt   |    2020     | 10           | -- | 3          | LC Keychain  |    2019     | 31           | -- | 3          | LC Keychain  |    2020     | 31           | -- +------------+--------------+-------------+--------------+ -- LC Phone was sold for the period of 2019-01-25 to 2019-02-28, and there are 35 days for this period. Total amount 35*100 = 3500. -- LC T-shirt was sold for the period of 2018-12-01 to 2020-01-01, and there are 31, 365, 1 days for years 2018, 2019 and 2020 respectively. -- LC Keychain was sold for the period of 2019-12-01 to 2020-01-31, and there are 31, 31 days for years 2019 and 2020 respectively. -- Solution SELECT b.product_id, a.product_name, a.yr AS report_year, CASE WHEN YEAR(b.period_start)=YEAR(b.period_end) AND a.yr=YEAR(b.period_start) THEN DATEDIFF(b.period_end,b.period_start)+1 WHEN a.yr=YEAR(b.period_start) THEN DATEDIFF(DATE_FORMAT(b.period_start,'%Y-12-31'),b.period_start)+1 WHEN a.yr=YEAR(b.period_end) THEN DAYOFYEAR(b.period_end) WHEN a.yr>YEAR(b.period_start) AND a.yr<YEAR(b.period_end) THEN 365 ELSE 0 END * average_daily_sales AS total_amount FROM (SELECT product_id,product_name,'2018' AS yr FROM Product UNION SELECT product_id,product_name,'2019' AS yr FROM Product UNION SELECT product_id,product_name,'2020' AS yr FROM Product) a JOIN Sales b ON a.product_id=b.product_id HAVING total_amount > 0 ORDER BY b.product_id,a.yr

---

#### WITH friends AS (

SELECT user1_id,user2_id FROM friendship_1892 UNION ALL SELECT user2_id,user1_id FROM friendship_1892 ), possible_recommendation AS ( SELECT f.user1_id,f.user2_id,l2.page_id FROM friends f INNER JOIN likes_1892 l1 ON f.user1_id = l1.user_id INNER JOIN likes_1892 l2 ON f.user2_id = l2.user_id AND l1.page_id <> l2.page_id ) SELECT user1_id,page_id,COUNT(DISTINCT user2_id) AS friends_likes FROM possible_recommendation WHERE (user1_id,page_id) NOT IN (SELECT * FROM likes_1892) GROUP BY user1_id,page_id ORDER BY user1_id,page_id;

---

#### -- Question 91

-- Table: Activity -- +--------------+---------+ -- | Column Name  | Type    | -- +--------------+---------+ -- | player_id    | int     | -- | device_id    | int     | -- | event_date   | date    | -- | games_played | int     | -- +--------------+---------+ -- (player_id, event_date) is the primary key of this table. -- This table shows the activity of players of some game. -- Each row is a record of a player who logged in and played a number of games (possibly 0) -- before logging out on some day using some device. -- Write an SQL query that reports the fraction of players that logged in again -- on the day after the day they first logged in, rounded to 2 decimal places. -- In other words, you need to count the number of players that logged in for at least two consecutive -- days starting from their first login date, then divide that number by the total number of players. -- The query result format is in the following example: -- Activity table: -- +-----------+-----------+------------+--------------+ -- | player_id | device_id | event_date | games_played | -- +-----------+-----------+------------+--------------+ -- | 1         | 2         | 2016-03-01 | 5            | -- | 1         | 2         | 2016-03-02 | 6            | -- | 2         | 3         | 2017-06-25 | 1            | -- | 3         | 1         | 2016-03-02 | 0            | -- | 3         | 4         | 2018-07-03 | 5            | -- +-----------+-----------+------------+--------------+ -- Result table: -- +-----------+ -- | fraction  | -- +-----------+ -- | 0.33      | -- +-----------+ -- Only the player with id 1 logged back in after the first day he had logged in so the answer is 1/3 = 0.33 -- Solution With t as (select player_id, min(event_date) over(partition by player_id) as min_event_date, case when event_date- min(event_date) over(partition by player_id) = 1 then 1 else 0 end as s from Activity) select round(sum(t.s)/count(distinct t.player_id),2) as fraction from t

---

#### Entry-Level SQL Interview Questions for Data Analysts

These SQL interview questions for data analyst freshers tend to appear early in the hiring funnel‚Äîtypically in recruiter screens, take-home challenges, or online assessments. While you might get sent a SQL interview questions for data analyst PDF as prep material, remember that companies are testing more than syntax memorization. They‚Äôre looking for clarity in how you approach data, how you structure logic, and how well you can generalize patterns across datasets. Each of these basic SQL interview questions for data analyst roles targets specific foundational skills‚Äîwhether it‚Äôs joining tables, applying aggregation, or extracting time-based insights. Mastering these builds a strong core for more advanced questions later in the process. What query returns the largest salary in each department? This exercise checks whether you can aggregate data and apply group-level filters. You need to GROUP BY department_id and use MAX(salary) to capture the highest value per group, then join to a dimension (or add a window function) if the interviewer also wants employee names. It reinforces the idea that every SELECT with a grouped aggregate must include only grouping columns or aggregates. Interviewers listen for discussion of NULL salaries and why casting to DECIMAL might be required when a table mixes currencies. Clear communication of these edge cases shows you understand how basic aggregation supports compensation dashboards. How would you find the 2nd-highest salary in the engineering department? A classic ranking problem that proves you can work with ordering and limits. Common answers use DENSE_RANK() or ROW_NUMBER() partitioned by department, filter on =2, and add WHERE dept_name='engineering'. Candidates should point out that ties at the top push the ‚Äútrue‚Äù second value down, making DENSE_RANK() the safer choice. Interviewers like to hear how you‚Äôd handle departments with fewer than two employees, perhaps returning NULL or excluding them entirely. Knowing when to use a window function versus a correlated subquery highlights core SQL literacy. Which neighborhoods have zero registered users? This anti-join problem tests understanding of NULL handling and set logic. A straightforward LEFT JOIN users u ON n.neighborhood_id = u.neighborhood_id WHERE u.user_id IS NULL surfaces empty areas. Explaining why NOT IN or NOT EXISTS could behave differently when NULLs appear shows grasp of three-valued logic. The query is common in churn or vacancy analyses where managers need to see untouched market segments. Interviewers may ask how adding an index on neighborhood_id speeds results on large city-wide datasets. How can you return one random car manufacturer with equal probability? Selecting a uniform random row validates awareness of database-specific random functions (ORDER BY RANDOM() in Postgres, TABLESAMPLE in BigQuery, etc.). Candidates should mention why adding LIMIT 1 is critical and discuss performance implications when the table grows‚Äîe.g., why full sorts can be expensive and how to use a precomputed sampling column. This maps to real features like ‚Äúpick a random promo‚Äù or A/B bucket assignment. Good answers show you can translate business requests into performant SQL rather than relying on na√Øve approaches. How much did 2022 sign-ups spend on every product? Here you join users (filtered on registration_year = 2022) to purchases, then sum price * quantity per product_id. It reinforces join direction, date filtering, and grouped aggregation‚Äîbread-and-butter skills for any analyst. Explaining why you use an INNER JOIN versus LEFT JOIN (to exclude users with no purchases) demonstrates awareness of how join semantics affect totals. You might also discuss rounding currency and indexing on (user_id, product_id) to keep the query responsive. How do you calculate the daily average downloads for free vs. paying accounts? This question couples conditional aggregation with date grouping. You join accounts to downloads, apply COUNT(DISTINCT download_id) or simple COUNT(*), and divide by distinct account count per plan to get averages‚Äîrounding to two decimals. Interviewers expect mention of grouping by download_date and plan_type and why accounts with zero downloads should be excluded per spec. It mirrors real SaaS KPIs like DAU/MAU or usage per subscription tier. What query returns the maximum quantity bought for every product each year? The task blends date extraction (EXTRACT(YEAR FROM order_date)) with per-product aggregation. You need to group by year and product_id, selecting MAX(quantity) as max_quantity, then order by those keys. Bringing up indexing on (product_id, order_date) and partitioning large fact tables on year helps show you think about scale even for basic metrics. Such year-over-year comparisons are staple requests in retail analytics. How many days separate each user‚Äôs first and last session in 2020? This problem evaluates use of MIN() and MAX() in one pass per user, or window functions if you prefer. You filter on YEAR(session_date)=2020, compute the difference in days, and return user_id plus the gap. Candidates should highlight that results may be negative if data quality is bad and suggest placing a composite index on (user_id, session_date) to speed scanning billions of events. It echoes churn analytics where tenure length influences retention models. How do you compute the average order value by gender? Joining customer attributes to transaction totals and then grouping by gender tests basic join logic plus conditional counting (only users who have ever placed an order). You sum order_amount per user, divide by order count, and round to two decimals. Interviewers note whether you handle NULL genders and whether you use a subquery or CTE for clarity. Such demographic breakdowns appear daily in e-commerce BI work. What share of Apple-platform actions ranked in the top-5 during November 2020? You must filter on platform, restrict to November 2020, aggregate counts, then rank with DENSE_RANK. Handling ties properly and producing an ordered output shows mastery of grouping plus ranking logic in real engagement analyses. How would you flag each purchase as either the customer‚Äôs first or a repeat in its product category? Interviewers want to see whether you can leverage window functions (ROW_NUMBER() or MIN(id) OVER (PARTITION BY user_id, category)) to mark a ‚Äúfirst‚Äù versus subsequent purchase, then cast that boolean into a tidy feature column. A good solution joins no extra tables, sorts by purchase time, and explains why session-level deduping isn‚Äôt needed. Mentioning that this repeat-purchase label later feeds retention analyses shows business awareness while keeping the SQL lightweight. Given wireless packet logs, how can you return‚Äîper SSID‚Äîthe largest number of packets any single device sent in the first ten minutes of 1 Jan 2022? The query filters on the timestamp window, groups by both ssid and device_id, counts packets, then applies MAX() (or ROW_NUMBER() with DESC ordering) per SSID. Explaining that you choose an index on (ssid, created_at) to speed the time filter demonstrates practical sense, yet the core logic remains a straightforward aggregation‚Äîsquarely entry-level. What SQL statement gives each user‚Äôs total transaction cost, sorted from highest spender to lowest? This test reinforces simple grouping (SUM(amount)) and ordering skills. Candidates should highlight that an INNER JOIN to a product table isn‚Äôt necessary unless unit prices live elsewhere, and that NULL amounts require COALESCE to keep sums correct. Such wallet-share rollups are daily fare for junior analysts in fintech or retail data teams. How would you output, in one result set, the total transaction count, the number of distinct purchasers, the count of ‚Äúpaid‚Äù transactions ‚â• $100, and the product with the highest paid revenue? Interviewers are testing whether you can combine scalar subqueries or CTEs into a single select list. A neat answer uses four subqueries‚Äîeach aggregating differently‚Äîwhile noting why unioning or multiple passes over the table would be less efficient. This ‚Äúdashboard in one row‚Äù pattern appears often in recruiter screens. Which five user actions ranked highest during Thanksgiving week 2020, and what were their ranks (ties allowed)? The task mixes filtering on a date range, aggregating counts, and ranking with DENSE_RANK(). Candidates should explain tie handling and why ORDER BY action_count DESC before ranking is crucial. The scenario mirrors common engagement reporting‚Äîperfect for junior analysts who‚Äôll build feature-usage tables. How do you calculate the overall acceptance rate of friend requests, rounded to four decimals? Solving requires counting total requests versus accepted ones‚Äîoften via a join or a request_id IN (SELECT ‚Ä¶) pattern. Key talking points include integer division pitfalls, the need to cast to DECIMAL, and whether to exclude self-friend edge cases. Simplicity keeps it entry-level, but the precision requirement checks attention to detail. After discovering duplicate rows in employee_projects, how would you still identify the five priciest projects by budget-to-employee ratio? A clean answer uses COUNT(DISTINCT employee_id) in the denominator, guarding against duplicates, then orders by the computed ratio and limits to five. The exercise spotlights practical data-quality thinking (deduping) without venturing into advanced optimization, making it a solid capstone basic query for new analysts. SQL Interview Questions for Experienced Data Analysts Once you‚Äôve cleared the basics, most data analyst SQL interviews begin to probe deeper into query logic, edge-case reasoning, and optimization skills. For candidates with 3+ years of experience, the expectations go beyond just writing accurate queries. These are the types of SQL query interview questions for data analyst roles that assess how well you can translate business requests into accurate, testable SQL logic. Expect a mix of hands-on live coding tasks and take-home SQL challenges‚Äîespecially at companies like Meta, Amazon, or Netflix‚Äîwhere your ability to manipulate data at scale matters just as much as syntax fluency. These types of SQL interview questions for experienced data analyst roles are especially common in companies handling terabytes of data daily‚Äîlike e-commerce platforms, fintech firms, and data-driven marketplaces. If you‚Äôre looking to ace SQL interview questions for 3 years experience, focus on techniques like query planning, indexing strategy, and intelligent use of CTEs or window functions. What is the last transaction recorded on each calendar day? A banking table lists id, transaction_value, and created_at timestamps. Your goal is to pick, for every date, the single transaction with the latest timestamp and output its id, amount, and datetime. This entry-level task teaches the staple window-function pattern‚ÄîROW_NUMBER() OVER (PARTITION BY CAST(created_at AS DATE) ORDER BY created_at DESC)‚Äîand encourages candidates to consider tie-breakers when two entries share an identical timestamp. Interviewers gauge whether you can partition correctly, convert datetimes to dates, and deliver an ordered result set that business users can trust. How would you pivot exam results so each student‚Äôs four test scores appear on a single row? A table exam_scores records student-id, exam-id (1-4) and score. You‚Äôre asked to reshape the data into a wide format‚Äîone row per student, with separate columns for Exam 1 through Exam 4. The prompt reinforces essential entry-level skills: conditional aggregation (or filtered pivots) and null handling when scores are missing. Interviewers love it because it surfaces your mental model of grouping, selective aggregation with CASE, and output formatting for downstream dashboard use. Getting it right demonstrates that you can translate a reporting requirement into clean SQL without over-engineering the solution. How would you pull a truly random row from a 100-million-row table without overloading the database? A na√Øve ORDER BY RANDOM() causes full sorts, so seasoned beginners mention more efficient tricks‚Äîsampling by id range, using a random modulo predicate, or leveraging database sampling clauses like TABLESAMPLE BERNOULLI. The question pushes you to reason about performance trade-offs and estimate how long a query might lock. It also opens discussion on why approximate randomness is often ‚Äúgood enough‚Äù for dashboards or QA spot-checks. Which customers have placed more than three transactions in both 2019 and 2020? You aggregate by (user_id, year) with COUNT(*), filter on >3 using a CTE, then GROUP BY user_id HAVING COUNT(DISTINCT year)=2. The task ensures you understand grouping, HAVING filters, and how to pivot year-level conditions into a single pass. It‚Äôs the kind of simple cohort query recruiters expect juniors to nail quickly. Which shipments were delivered during a customer‚Äôs membership period, and which were not? You‚Äôre a data scientist on Amazon‚Äôs distribution team and must tag each shipment as Y (delivered while the customer was an active member) or N (delivered outside that window). The exercise checks your comfort with conditional joins and date-range logic: you‚Äôll join a customers table that stores membership start and end dates to a shipments table, compare shipment dates against those ranges, and return a tidy report. A correct answer shows you can reason about inclusive vs. exclusive boundaries (edge-case shipments sent on the exact start or end date) and format a boolean output column. It‚Äôs a classic entry-level test of CASE expressions, simple joins, and clear communication of business rules. Mastering this pattern prepares you for common ‚Äúflag-this-row‚Äù analytics tasks that pop up in day-to-day work. How would you list only the duplicate rows in a users table? Data-cleaning is core to analyst work, and this task checks your ability to spot duplicates using COUNT(*) > 1 in a grouped CTE or ROW_NUMBER() > 1 in a window. You must decide which columns define ‚Äúduplicate‚Äù‚Äîoften all columns except a surrogate key‚Äîand explain why hashing or concatenating fields can be handy. The interviewer looks for discussion of removing rather than just identifying duplicates, highlighting the importance of reproducible ETL pipelines. Mentioning how to add a composite unique index to prevent recurrence shows practical thinking. Who are the top three highest-earning employees in each department? Using employees and departments, build a ranked list of the three largest salaries per department, outputting employee full name, department name, and salary. The question probes intermediate query construction: joining reference tables, applying RANK() or DENSE_RANK(), and handling departments with fewer than three staff. A solid answer shows familiarity with window functions, tie-breaking rules, and ordering by multiple fields‚Äîskills that quickly separate candidates who only know basic aggregation from those who can craft polished reporting queries. How many customers were upsold after their initial purchase? Given a purchases table with timestamps, determine the number of users who bought additional products after their first purchase date (same-day multiple items don‚Äôt count). You‚Äôll apply MIN(purchase_date) in a CTE, join back, and filter on later dates. The scenario tests logical thinking around customer behavior funnels and event ordering, plus competence with CTEs and date comparisons. It‚Äôs a favorite mid-screen question because the correct query is short yet requires careful reasoning about ‚Äúfirst purchase‚Äù vs. ‚Äúlater purchase‚Äù semantics. Create a January-2020 histogram of comments per user, with one-comment bins. From an events table, count how many comments each user left in January 2020, then bucket those counts (0, 1, 2, ‚Ä¶) and tally users per bucket. This query forces use of subqueries or CTEs for per-user counts followed by either a GROUP BY on that derived count or a windowed approach. Interviewers want to see if you understand grouping on aggregated results, generating missing buckets (optional), and rounding percentages if requested. It‚Äôs representative of product-analytics tasks like building engagement histograms. What item did each user purchase third? A transactions table records every order with user_id, item, timestamp, and id. You must return, for every user, the item (or full row) corresponding to their third chronological purchase, breaking timestamp ties with the lower id. The exercise highlights ranking functions (ROW_NUMBER()) and tie-handling logic‚Äîcore abilities for analysts who work with event streams. It also demonstrates your understanding of why deterministic ordering matters when timestamps collide. How would HR total regular pay, overtime, and overall compensation per role? Group the payroll table by role_title, SUM(regular_salary) AS reg_pay, SUM(overtime_pay) AS ot_pay, and compute total_comp = reg_pay + ot_pay. Presenting both component and aggregated figures helps budget planning, and comparing each role‚Äôs share to company averages can reveal inequities. The paragraph stresses validating that overtime isn‚Äôt double-counted and explains how currency conversions or multi-country payrolls complicate roll-ups. What query totals IT, HR, Marketing, and Other departmental spend by 2023 fiscal quarter? Create fiscal_qtr = DATE_TRUNC('quarter', txn_date) (or custom fiscal logic), then sum amounts with conditional aggregation: SUM(CASE WHEN dept='IT' THEN amt END) AS it_spend, and group by fiscal_qtr. An ‚ÄúOther‚Äù column sums any department not explicitly listed. Finance uses this snapshot to spot over-budget units quickly. Including a quarter index or partition improves performance, and noting how fiscal calendars can differ from calendar quarters shows analyst diligence. How do you compute a three-day rolling average of steps per user, excluding the first two days? Partition by user_id, order by step_date, then AVG(steps) OVER (PARTITION BY user_id ORDER BY step_date ROWS BETWEEN 2 PRECEDING AND CURRENT ROW) gives the moving average. Filter out rows where ROW_NUMBER() ‚â§ 2. Rounding the result matches dashboard display needs. The explanation cautions about missing dates: if gaps exist, analysts might need a calendar table to fill them before windowing. Which query extracts every user‚Äôs third purchase, breaking timestamp ties by the lower transaction ID? Apply ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY purchase_ts, id) and filter for row_number = 3. Sorting by (user_id, id) afterwards yields a tidy list. Merchandisers watch this milestone because the third order often signals long-term retention. Highlight that users with fewer than three purchases won‚Äôt appear, and note that composite indexing on (user_id, purchase_ts, id) optimizes the window function. How can you pivot worldwide branch sales so each year is a column? Start by unifying all yearly branch tables‚Äîeither with UNION ALL into a common-table expression or by querying a single long-format table if one already exists‚Äîso every row holds branch_id, year, total_sales. Apply a conditional aggregation: SUM(CASE WHEN year = 2021 THEN total_sales END) AS sales_2021, repeating for each year you need, and group by branch_id. This returns one row per branch with sales split across columns, letting executives compare multi-year performance at a glance. Including a fallback ‚Äúother_year‚Äù column or dynamically generating the year list future-proofs the report. A composite index on (branch_id, year) keeps scans fast even with millions of rows. What query finds the median household income for every city? Use a window function: partition incomes by city, order by income, then assign row numbers from both the top and bottom (ROW_NUMBER() and COUNT(*) OVER). For each city keep rows where the two row numbers meet in the middle; average them when the count is even. This calculation handles any sample size and avoids subqueries that scan the same city repeatedly. Presenting the median rather than the mean gives a better sense of typical earnings when outliers skew the data. Be sure to cast incomes to a numeric type with the right precision to avoid truncation. How do you compute a 3-day weighted moving average of product sales (0.5, 0.3, 0.2)? Partition rows by product_id, order by sale_date, and grab the three-day window with LAG(); then calculate 0.5*curr + 0.3*prev1 + 0.2*prev2 only when both previous rows exist. Filtering with WHERE prev1 IS NOT NULL AND prev2 IS NOT NULL ensures you output dates that have two predecessors. This weighted view smooths volatility while still reacting quickly to recent shifts, which is why analysts prefer it for trend dashboards. Indexes on (product_id, sale_date) guarantee sequential access, and adding ROUND(value, 2) readies the figure for stakeholder slide decks. How can you classify 2023 sales as Standard, Premium, or Promotional and sum them by region? A CASE statement encodes the hierarchy: July overrides all as Promotional; East overrides the amount cut-off except in July; otherwise the 2 000 threshold splits Premium and Standard. Sum amount and COUNT(*) by region and the derived sale_type to build the report. Management uses these figures to tune pricing and seasonal promotions. Clearly documenting rule priority prevents logic drift, and partitioning by sale date enables parallel scans for year-long tables. How would you calculate the number of unpurchased seats on every flight? Joining flights, planes, and flight_purchases demands careful use of LEFT JOIN and COALESCE() to treat ‚Äúno purchases‚Äù as zeros. Advanced candidates point out that a SKU-like key combining flight date, flight number, and seat number prevents double counting, and they‚Äôll propose materialized views or incremental aggregation to keep the query sub-second for operations teams. Explaining how this metric feeds yield-management optimizations demonstrates business impact awareness. What query reports 2022 total expenses and the company-wide average per department? Senior analysts must aggregate at two levels in one result: per-department totals and an overall benchmark. A clean answer uses a window function (AVG(total_expense) OVER ()) or a cross-join to a sub-aggregate, and discusses why aligning fiscal vs. calendar years matters. Performance commentary‚Äîsuch as partitioning the fact table on expense_date and compressing low-cardinality dept_id‚Äîsignals experience with real finance datasets. Which cities have the lowest-quality search results (all ratings < 3)? The challenge blends grouping with Boolean tests across result sets: you must confirm that all rows per query meet a condition, not just the average. A typical pattern uses MIN(rating) and checks if it‚Äôs >=3, then flips the logic. Interviewers expect discussion of the anti-join alternative and of clustering the table by (query, rating) so that the engine can skip irrelevant blocks‚Äîcrucial for terabyte-scale search logs. How many confirmation SMS responses do we receive by carrier and country on 28-Feb-2020? Real-time marketing teams rely on this metric to detect deliverability issues, so latency and accuracy both matter. You join the latest ‚Äúconfirmation‚Äù message per phone number to the confirmations table, group by carrier, country, and count responses. Senior-level answers mention windowing to select ‚Äúlatest‚Äù per number, advocate a filtered index on type='confirmation', and discuss why time-zone normalization is vital when messages span regions. What share of comments on each ad occurs in the feed versus the ‚Äúmoments‚Äù surface? Solving this requires UNIONing two comment tables, tagging the source, grouping by ad_id, and computing percentages. Advanced interviewees justify using COUNT(DISTINCT comment_id) to avoid duplicates, suggest bitmap indexes on ad_id, and highlight the importance of consistent UTC timestamps when ads run in multiple regions. They may even propose pre-aggregating hourly to power real-time advertiser dashboards. How do you retrieve each employee‚Äôs current salary after an ETL bug inserted yearly updates as new rows? The fix leverages ROW_NUMBER() over (employee_id ORDER BY salary_effective_date DESC) to isolate the latest row. You then join this CTE back to employees for a clean, deduplicated view. Experienced analysts discuss adding a surrogate key plus ON CONFLICT handling to prevent future drift and consider a covering index (employee_id, salary_effective_date DESC) to support both the query and payroll reports. How would you build a monthly customer KPI report for 2020 showing user count, transactions, and GMV? The query aggregates different measures from separate tables, aligns them on a generated date spine, and outputs tidy month-level rows suited for dashboards. Senior answers cover why using a calendar table avoids missing-month gaps, how to handle late-arriving transactions via incremental backfills, and ways to index on (order_date) + (user_signup_date) to keep nightly ETL light. Which users performed ATM withdrawals exactly 10 seconds apart‚Äîindicating possible fraud? You use LAG() over (user_id ORDER BY created_at) to compute time deltas, then confirm that all consecutive gaps equal 10 seconds. Edge-case handling (single-transaction users) and ordering in the final result (ORDER BY user_id) show professionalism. Discussing a composite index (user_id, created_at) and partitioning on created_at to shorten forensic look-backs moves the answer into staff-level territory. Rank departments with ‚â•10 employees by percent earning > 100 K, keep top 3. The query mixes conditional aggregation, filtering on department size, and percentage calculation. Interviewers check numeric precision, use of window functions for ranking, and thoughtful exclusion of small departments‚Äîcommon executive-level reporting nuances. Find the three lowest-paid employees who have finished ‚â•2 projects. The answer requires joining employee, project, and assignment tables, filtering completed projects, and ranking salaries. Interviewers judge your join ordering and ability to eliminate duplicates that inflate project counts. Fix an ETL bug: retrieve each employee‚Äôs latest salary despite duplicate rows. Seasoned analysts must deploy ROW_NUMBER() OVER (PARTITION BY employee_id ORDER BY salary_date DESC) or a MAX-by-GROUP approach, then discuss auditing steps to prevent future duplication. It tests data-quality instincts alongside SQL chops. Which users post the same job repeatedly vs. only once? Counting per-user per-job occurrences, then pivoting into single vs. multiple posters, forces nuanced grouping and CASE aggregation. Senior roles often own marketplace anti-spam metrics like this. Who are the daily top-3 downloaders, using window RANK? Large download_fact tables demand efficient partitioning and thoughtful ordering; follow-ups often cover index or cluster key choices. Experienced analysts should anticipate scale-related pitfalls. How would you integrate payment, behavior, and fraud logs to improve the system? The prompt is open-ended: discuss data cleansing, schema unification, entity resolution, and choosing the right join keys. Interviewers want narrative structure‚Äîingestion ‚Üí validation ‚Üí feature engineering ‚Üí insight generation‚Äîillustrating that you can plan end-to-end analytics projects beyond a single SQL script. Compute a weighted campaign score using 0.3 √ó open rate and 0.7 √ó click rate. Beyond writing the SQL, strong candidates justify why click-heavy weighting matters, mention confidence intervals on small sends, and flag bias if opens are auto-filtered by email clients. It marries arithmetic SQL with marketing-domain reasoning. Describe the data-model migration from a document DB to relational tables. The scenario expects an architectural narrative: identifying entities (users, friendships, interactions), defining PK/FK constraints, planning backfill ETLs, and outlining read-pattern performance. It evaluates system-thinking more than pure query writing. What insights and distribution metrics would you build on daily conversation counts? After outlining potential KPIs (median conversations per user, power-law tails, churn predictors), you must deliver a SQL query producing the per-user daily conversation histogram. The question blends exploratory analytics reasoning with concrete querying‚Äîperfect for analysts who straddle data discovery and SQL execution How would you calculate the total salary paid to employees who never finished a single assigned project ? You must join employees to projects, flag unfinished work where end_dt IS NULL, and identify staff whose entire project set is unfinished. A CTE that counts finished projects per employee (COUNT(end_dt) FILTER (WHERE end_dt IS NOT NULL)) and filters on = 0 is a clean pattern. Summing their salaries shows the true cost of ‚Äúslackers‚Äù and is often used in cost-reduction audits. Good answers also mention excluding employees with no projects and adding an index on (employee_id, end_dt) for speed. What query returns the running (cumulative) sales total for every product, ordered by product and date? This task highlights window functions: SUM(price) OVER (PARTITION BY product_id ORDER BY date ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) produces the cumulative field. Grouping isn‚Äôt needed‚Äîwindowing keeps each purchase row intact‚Äîso analysts can trend the metric day by day. Discussing how to partition large sales tables (e.g., by month) shows scale awareness. Rounding and casting are minor but necessary finishing touches for reporting. How many rows would each join type (INNER, LEFT, RIGHT, CROSS) return when you join all ads to the top-3 ads subquery? You first build a CTE top_ads using ORDER BY popularity LIMIT 3, then create four separate SELECT COUNT(*) blocks labeled by join type. The puzzle forces you to reason about join mechanics‚ÄîINNER should give 3, LEFT gives N, RIGHT gives 3, and CROSS gives 3 √ó N‚Äîrather than just write syntax. Seasoned answers mention why RIGHT joins aren‚Äôt supported in some systems and how nulls affect counts. It doubles as a quick sanity-check of a candidate‚Äôs join intuition. Which user has the highest average number of unique item categories per order? You‚Äôll need a two-stage aggregate: first count distinct categories inside each order, then average that count per user. Ordering the result and limiting to 1 returns the winning user. The question checks comfort with nested aggregation, COUNT(DISTINCT ‚Ä¶), and the difference between order-level and user-level granularity. Mentioning tie-handling and potential use of WITH TIES shows polish. Which two students scored closest to each other on the SAT, and what was the score gap? A neat approach self-joins the table on score differences or uses window functions with LAG() after ordering by score. You then pick the minimum absolute difference and, if ties remain, return the alphabetically higher pair. This tests ranking logic, tie-breaking, and string comparison. Explaining why an index on score speeds the inner difference scan gets bonus points. What percentage of users held ‚ÄúData Analyst‚Äù immediately before ‚ÄúData Scientist‚Äù? Using ROW_NUMBER() or LEAD() over each user‚Äôs job-history ordered by start date lets you compare adjacent titles. Count matches where the earlier row is ‚ÄúData Analyst‚Äù and the next row is ‚ÄúData Scientist,‚Äù divide by total distinct users, and round. The prompt tests your ability to work with ordered event data and compute conditional ratios. Call out pitfalls like overlapping date ranges or simultaneous titles. On what earliest date did each user listen to their third unique song, and what was that song? You partition by user_id, rank distinct song_id by first-play date, and filter for rank 3, leaving nulls for users below the threshold. Handling distinctness inside the window (ROW_NUMBER() OVER ‚Ä¶ PARTITION BY user_id ORDER BY MIN(play_dt)) shows finesse. Interviewers like hearing about edge cases‚Äîrepeated plays of the same song‚Äîand why a surrogate key on (user_id, song_id) accelerates the query. What fraction of 12/31/2019 active accounts closed on 1/1/2020? You identify the active cohort on December 31, join to January 1 statuses, count those whose status changed to ‚Äúclosed,‚Äù and divide by the cohort total. Rounding to two decimals matches finance reporting standards. Discussing how to index (account_id, ds) for daily status snapshots demonstrates practical performance thinking. It also surfaces the need to guard against duplicate daily rows. How would you label each user‚Äôs attribution as ‚Äúpaid‚Äù or ‚Äúorganic‚Äù based on prior Facebook or Google visits? A subquery that checks EXISTS (SELECT 1 FROM visits WHERE user_id=‚Ä¶ AND source IN ('facebook','google')) feeds a simple CASE statement. The exercise is tiny but reveals your clarity on boolean logic and set membership. Advanced candidates bring up deduplicating multi-channel visits and the importance of visit timing relative to conversion. It‚Äôs foundational for marketing analytics pipelines. How do you assign session numbers to events when a session is ‚â§ 60 minutes of inactivity? Use LAG(event_ts) per user to compute minute gaps, flag starts where gap > 60, then apply a running SUM() of those flags to generate session_id. This classic pattern tests mastery of window functions for stateful labeling. Mentioning timezone normalization and indexing (user_id, event_ts) shows real-world savvy. Edge-case awareness‚Äîlike back-to-back identical timestamps‚Äîalso impresses. Which ongoing projects are forecast to go ‚Äúover-budget‚Äù versus ‚Äúwithin budget‚Äù? You prorate each employee‚Äôs salary to project duration, sum per project, and compare to the budget. A CASE label outputs the status, making it useful for dashboards. The math forces candidates to convert annual salaries into daily costs and handle half-year examples correctly. Seasoned answers discuss assuming a 365-day divisor and suggest materializing salary snapshots for long projects. What was the month-over-month revenue change for every month in 2019? Aggregate revenue by month, then apply LAG(total_rev) to compute the change and ROUND(‚Ä¶,2) for presentation. Candidates must filter to 2019, handle January‚Äôs null prior month, and decide between absolute or percentage change. Performance-minded folks note that partitioning the transactions table by date keeps annual scans light. Which products cost more than their own average transaction total? A per-product CTE calculates AVG(price*quantity) as avg_total; the outer query joins to products and filters on product_price > avg_total. Rounding both numeric columns to two decimals matches stakeholder expectations. The problem checks understanding of self-referential filters and grouped aggregates. Bringing up indexed materialized views for large SKU catalogs adds senior-level depth. If you‚Äôre preparing offline, you can also use a downloadable SQL practice questions for data analyst interview PDF or worksheet. The best prep resources go beyond copy-paste queries‚Äîthey explain why each query matters in a business context. Let these questions guide your prep, but make sure to actually write and run them in a real SQL editor. Practice under realistic constraints is what separates candidates who pass from those who almost do. Scenario-Based and Advanced SQL Questions As you move into mid-level and senior data analyst roles, SQL interviews go beyond basic queries. Companies expect you to handle multi-table joins, create optimized CTEs, work with window functions, and debug slow queries in production. These advanced SQL interview questions for data analysts reflect business-critical scenarios where precision, scalability, and business logic all matter. Many SQL scenario-based interview questions for data analyst roles also test your ability to reason about trade-offs‚Äîe.g., filtering before or after joins, dealing with nulls, or ensuring referential integrity. Below are examples that simulate these real-world demands. How many minutes did each plane spend in the air on every calendar day? This problem forces you to convert departure and arrival timestamps into minute-level duration, group by both plane_id and flight date, and round down fractional minutes. It rewards analysts who can spot hidden pitfalls‚Äîovernight flights that straddle dates, missing data, or daylight-saving jumps‚Äîand who suggest placing a composite index on (plane_id, departure_ts) to avoid full table scans during daily ETL. Interviewers also look for discussion of window vs. aggregation trade-offs when the same table powers multiple metrics. Which SQL pulls the 2nd-longest flight for every city pair? Normalize routes by sorting the two city names and storing them as city_a, city_b so A-B equals B-A, then compute duration_minutes. Apply ROW_NUMBER() OVER (PARTITION BY city_a, city_b ORDER BY duration_minutes DESC) and filter for rank = 2; if a pair lacks two flights no row returns. Sorting the final output by flight_id meets the spec. Airlines inspect this list to schedule backup aircraft for long hauls, so accuracy matters. A multi-column index on normalized cities plus duration speeds the ranking even in decade-long flight logs. How would you calculate first-touch attribution for each converting shopper? Join attribution to user_sessions, filter to rows where conversion = TRUE, and for every user_id pick the earliest session (MIN(session_ts)) then capture its channel with FIRST_VALUE(channel) over an ORDER BY session_ts. This isolates the discovery channel that led to the eventual purchase, informing marketing spend. Mention deduplicating multiple same-timestamp sessions and handling users who clear cookies. Partitioning by user_id and indexing on (user_id, session_ts) make the scan feasible when logs exceed a billion rows. How do you calculate a three-day rolling average of deposits in a bank-transactions table? You first filter to positive transaction_values, group them by txn_date, then use AVG(daily_total) OVER (ORDER BY txn_date ROWS BETWEEN 2 PRECEDING AND CURRENT ROW) to smooth volatility in inflows. The explanation should mention why withdrawals are excluded, how to handle holidays that skip dates, and how indexing on txn_date keeps the query scalable for real-time dashboards. How can you surface the five product pairs most frequently purchased together? The technique explodes each transaction into product pairs via a self-join (enforcing p1 < p2 to avoid duplicates), counts occurrences, and orders by that count. The query illustrates market-basket analysis at scale‚Äîimportant for recommendation engines‚Äîso candidates should comment on deduplicating large intermediate joins (e.g., using sessionization or probabilistic sketches). Deterministic alphabetical ordering (p2) ensures tie-breaking for reproducible BI dashboards. Calculate a 3-day rolling average of step counts per user. The query uses AVG() OVER(ORDER BY date ROWS BETWEEN 2 PRECEDING AND CURRENT ROW) while filtering out rows lacking two predecessors. It gauges ability to apply window frames, convert floating output to whole numbers, and think through the first-two-days exclusion. Such rolling metrics surface constantly in health-tech dashboards, making this a practical advanced exercise. How many right-swipes does each feed-ranking variant average among users with ‚â• 10, 50 and 100 total swipes? You‚Äôll join the swipes log to the variants table, bucket users by total-swipe count (‚â•10, ‚â•50, ‚â•100), and for each cohort compute the mean of is_right_swipe separately for variants A and B. The challenge mixes conditional aggregation with a HAVING filter on swipe thresholds and showcases why integer division of right/total swipes yields a clearer metric than simply averaging booleans. Good answers also explain how excluding users below each threshold avoids small-sample noise and why indexing (user_id, variant) keeps the query performant on billions of swipes. Interviewers listen for discussion of statistical significance and whether further stratification (e.g., by geography) might alter conclusions. What cumulative distribution (CDF) of comment counts per user can you build, using one-comment buckets? First, aggregate the comments table to get each user‚Äôs total comment count; then group these counts into integer buckets and apply a running SUM() window to produce the cumulative percentage. This pattern teaches how to turn raw frequency data into a CDF that product managers can read at a glance (e.g., ‚Äú90 % of users leave ‚â§ 3 comments‚Äù). Candidates should mention handling sparse tails, ensuring the bucket list is complete, and ordering the window correctly so cumulative values stay monotonic. Indexing on user_id and pre-materialising daily comment tallies are good scale optimisations to note. How many ‚Äúlikers‚Äô likers‚Äù does each user have on a dating platform? The task requires a self-join: first find everyone who liked you, then count how many people liked them in turn. Using DISTINCT in the inner set avoids double-counting duplicates, and grouping by the original user_id produces a tidy fan-out metric. The exercise checks fluency with aliasing, multi-layer joins, and reasoning about graph-like relationships in SQL. Interviewers value explanations of edge cases (users with no inbound likes) and performance tips such as indexing (liker_id) to accelerate the second-level lookup. What annual-cohort retention does an annually-billed SaaS achieve? In annual_payments each row marks a yearly renewal; cohort users by their first payment_year, then compute the share who renew in year +1 and year +2. You‚Äôll pivot counts into retention percentages and order by cohort year for an executive-friendly table. The query demonstrates date extraction, cohort labelling, and conditional aggregation‚Äîall staples of subscription analytics. Strong answers discuss missing renewals (NULL pay dates), churn bias, and how to handle users who upgrade mid-cycle. How many push notifications does a user receive before converting, segmented across the user base? Join notification_deliveries to the users table, cap each user‚Äôs timeline at their conversion_date, and count notifications sent before that moment (or to today if they never convert). Aggregating these counts into a histogram‚Äîe.g., 0-3, 4-7, 8+‚Äîreveals whether over-messaging hurts conversions. The prompt tests temporal joins, NULL handling for non-converters, and the ability to craft business-ready distribution outputs. Savvy candidates will discuss window functions to pick ‚Äúlast pre-purchase notification‚Äù and the impact of time-zone normalisation. What is the three-month cohort retention for each subscription plan? Using subscriptions, derive the signup month, then for months +1, +2, +3 flag whether the user remains active (end_date IS NULL or after the window). A UNION or conditional aggregation can roll these flags into retention rates per (start_month, plan_id, num_month). The problem blends date math, cohort framing, and ratio calculation, mirroring dashboards built for product-led-growth teams. Interviewers look for clear ordering, thoughtful null checks, and commentary on why 3-month retention predicts lifetime value. Does click-through rate rise with higher human-rated relevance in Facebook search results? Combine search_results with search_events, group by discrete rating bands, and compute both impressions and clicks to output CTR per rating. A subsequent regression or chi-square test (outside SQL) can confirm significance, but the query itself must deliver clean aggregates: total rows, clicked rows, and CTR rounded to two decimals. The exercise checks ability to join fact tables correctly, avoid double counting when multiple results share a query, and reason about causality versus correlation in product metrics. Mentioning confidence intervals and exposure thresholds shows senior-level insight. MySQL and Tool-Specific SQL Questions If you‚Äôre preparing for a role that specifically uses MySQL, expect questions on syntax, functions, and performance nuances unique to this platform. Many MySQL data analyst interview questions focus on functions like STR_TO_DATE, DATEDIFF, GROUP_CONCAT, and window functions such as ROW_NUMBER()‚Äîall critical for date parsing, ranking, and summarizing large datasets. What are common MySQL functions used in analytics? In data analyst interviews focused on MySQL, you‚Äôll often be asked to demonstrate fluency with built-in functions that are essential for performing analytical tasks. These types of MySQL interview questions for data analyst roles are especially common at smaller startups and SaaS companies that rely on MySQL for powering dashboards and reporting pipelines. You may also be asked to debug queries involving MySQL-specific behaviors, such as how NULL values are sorted or how execution plans are generated. To stand out, go beyond just syntax‚Äîbe ready to explain how MySQL handles indexing, temporary tables, and query optimization under the hood. What does GROUP_CONCAT() do in MySQL, and when would you use it? The GROUP_CONCAT() function in MySQL combines multiple values from grouped rows into a single comma-separated string. It‚Äôs especially useful in data analyst tasks when summarizing categories or labels into one field, such as combining all product names per customer. This function isn‚Äôt supported natively in all databases, making it a frequent question in MySQL data analyst interview questions. You may also be asked to handle truncation or ordering issues with this function. How does MySQL handle NULL values when using ORDER BY? Unlike some databases that treat NULL as the lowest value, MySQL orders NULLs first in ascending order and last in descending order by default. This behavior can affect analytic reports or dashboards when sorting is involved, especially in rankings or priority queues. It‚Äôs a subtle point but commonly tested in MySQL interview questions for data analyst candidates who are expected to understand default behaviors and how to override them with IS NULL, IFNULL(), or COALESCE(). Explain the difference between LIMIT in MySQL and TOP in SQL Server. MySQL uses LIMIT to restrict the number of rows returned, while SQL Server uses TOP. For example, SELECT * FROM users LIMIT 10 is equivalent to SELECT TOP 10 * FROM users in SQL Server. Understanding this difference is crucial for analysts who switch between platforms or work with ETL pipelines spanning multiple systems. It‚Äôs also a common question in MySQL-focused interviews, testing adaptability across SQL dialects. How would you use DATE_FORMAT() to bucket a timestamp column into calendar months while preserving the sort order? Candidates should explain that DATE_FORMAT(ts,'%Y-%m') converts a timestamp to a year-month string that still sorts chronologically, enabling straightforward GROUP BY or ORDER BY without additional casts. A strong answer mentions edge cases such as time-zone inconsistencies, how %b %Y would break lexical ordering, and why using DATE_TRUNC() equivalents (available only in other SQL dialects) isn‚Äôt an option in pre-8.0 MySQL. Interviewers also appreciate discussion of indexing on the raw timestamp versus the formatted string. When aggregating revenue, why might you choose COALESCE(col,0) over IFNULL(col,0)? Both functions replace NULL, but COALESCE is ANSI-standard and accepts more than two arguments, making queries portable and expressive. Analysts should note that in MySQL they perform identically on performance, yet COALESCE works inside window frames, nested selects, and casts without surprises. Highlighting subtle precedence rules and null-propagation pitfalls shows deeper fluency. Explain how GROUP_CONCAT() can be used to create a ‚Äútop products per user‚Äù string, and list two limitations of the function. A complete answer covers concatenating sorted product names within a GROUP BY user_id, optionally controlling order with ORDER BY price DESC inside the function. Limitations include the default group_concat_max_len (often 1,024 bytes) and the inability to store more than one value per delimiter safely when downstream tools expect atomic columns. Mentioning a fallback to sub-queries or reporting tables demonstrates real-world experience. Write a query that compares two dates in different time zones using CONVERT_TZ() and TIMESTAMPDIFF(). What could go wrong around daylight-saving changes? Interviewers want to see CONVERT_TZ(order_ts,'UTC','America/New_York') followed by a TIMESTAMPDIFF(day, signup_ts, ‚Ä¶) clause. A strong explanation calls out that DST gaps/overlaps may yield nulls if MySQL‚Äôs time-zone tables are stale, and that TIMESTAMPDIFF truncates toward zero. Acknowledging the need to refresh or mount mysql_tzinfo_to_sql shows operational maturity. How can JSON_EXTRACT() (or >) be leveraged to filter events stored in a JSON column, and why is a virtual column sometimes preferable? Good answers demonstrate WHERE JSON_EXTRACT(meta,'$.event') = 'click', discuss generated virtual columns for indexing, and note that MySQL cannot index deep keys directly without exposing them. They might also mention cost trade-offs of storing semi-structured data in JSON versus normalizing into relational tables. Describe a scenario where LAG() combined with IFNULL() solves an analytics problem in MySQL 8.0. Typical use-case: computing session gaps or day-over-day user metrics. The analyst must show LAG(val) OVER (PARTITION BY user ORDER BY ts) to fetch the prior value, then wrap in IFNULL() to set a default for the first row. Highlighting memory usage and the implications of window size indicates deeper expertise. Why might SUBSTRING_INDEX() be safer than SUBSTRING() for parsing URLs into domain buckets? SUBSTRING_INDEX(url,'/',3) grabs everything up to the third slash without relying on hard-coded positions, handling variable lengths robustly. Interviewers value commentary on search-engine tracking parameters, how leading ‚Äúhttps://‚Äù changes offsets, and why pre-cleaning with LOWER() prevents case-sensitive mismatches. Show how DENSE_RANK() differs from ROW_NUMBER() when extracting top-selling SKUs per month. Candidates must articulate that DENSE_RANK preserves shared ranks for ties, whereas ROW_NUMBER forces uniqueness. Illustrating with revenue ties and explaining downstream dashboard impact (e.g., ‚Äútop 3‚Äù may yield more than three rows) proves practical understanding. What is the purpose of the CAST() function when joining a numeric user ID stored as a string to another table storing it as INT? Beyond syntax, answers should discuss index usage: casting the smaller side (or using generated columns) maintains performance, whereas casting a bigint column in the WHERE clause negates indexes. Mentioning data-quality initiatives to align types highlights broader thinking. How does MySQL sort NULL values by default, and what expression forces explicit ordering? By default, ORDER BY col ASC places NULL first; adding ORDER BY col IS NULL, col pushes them last. A seasoned analyst notes MySQL 8.0‚Äôs How to Prepare for a SQL Interview as a Data Analyst Cracking the SQL portion of a data analyst interview requires more than just memorizing syntax‚Äîyou need to solve business problems using structured logic, write efficient queries, and explain your reasoning clearly. Whether you‚Äôre prepping for your first job or have years of experience, most data analyst SQL interviews will test your grasp of real-world query writing, data interpretation, and optimization techniques. The good news? There‚Äôs a predictable structure to how these interviews are built‚Äîand with the right study plan, you can master it. Study Topics to Master If you‚Äôre preparing for a SQL test for data analyst roles, your first step is to build a strong foundation in the following areas: Joins (inner, left, self joins) and understanding data relationships Aggregations with GROUP BY, COUNT(), SUM(), AVG() Filtering using WHERE, HAVING, and subconditions Window functions like RANK(), ROW_NUMBER(), LAG() and LEAD() Subqueries and CTEs, especially for nested logic or transformations Indexes and performance optimization, especially on large datasets For advanced roles, you‚Äôll also be tested on query optimization, data modeling concepts, and the ability to break down business KPIs using SQL logic. Want structure? Start with the SQL Learning Path on Interview Query‚Äîit guides you from basic queries to complex window functions and optimization.

---

#### SELECT pc.product_id,pc.quantity,pc.quantity*pd.price AS price

FROM purchases_2362 pc INNER JOIN products_2362 pd ON pc.product_id = pd.product_id WHERE invoice_id = (SELECT pc.invoice_id FROM purchases_2362 pc INNER JOIN products_2362 pd ON pc.product_id = pd.product_id GROUP BY pc.invoice_id ORDER BY SUM(quantity*price) DESC,pc.invoice_id ASC LIMIT 1);

---

#### Listing conversion rate percentile among listings.

Presto: WITH v AS ( SELECT listing_id, COUNT(*) AS views FROM events WHERE event_name='view_listing' GROUP BY 1 ), b AS ( SELECT listing_id, COUNT(*) AS conf FROM bookings WHERE status='confirmed' GROUP BY 1 ), cr AS ( SELECT v.listing_id, CASE WHEN v.views>0 THEN COALESCE(b.conf,0)*1.0/v.views ELSE 0 END cr FROM v LEFT JOIN b ON v.listing_id=b.listing_id ) SELECT listing_id, cr, cume_dist() OVER (ORDER BY cr) AS cr_percentile FROM cr ORDER BY cr DESC;

---

#### Small tables as inline views vs CTE: show both patterns.

(Conceptual) Use CTEs for readability & reuse. Inline views fine for one-off short logic; prefer CTEs when referenced multiple times to avoid duplication.

---

#### Extract search query & guests from event properties JSON.

Presto: SELECT session_id, event_ts, json_extract_scalar(properties,'$.q')      AS query, CAST(json_extract_scalar(properties,'$.guests') AS INTEGER) AS guests FROM events WHERE event_name='search';

---

#### Parse UTM-like source/medium into a normalized channel.

(Example of CASE normalization) SELECT session_id, CASE WHEN source='google' AND medium='cpc' THEN 'SEM' WHEN source='facebook' AND medium='cpc' THEN 'Facebook' WHEN source='email'   THEN 'Email' WHEN medium='organic' THEN 'SEO' ELSE 'Direct/Other' END AS channel_norm FROM sessions;

---

#### 4-step funnel (page_view ‚Üí search ‚Üí view_listing ‚Üí start_booking) by day.

Presto: WITH steps AS ( SELECT DATE(e.event_ts) AS day, e.session_id, e.user_id, MAX(CASE WHEN event_name='page_view'     THEN 1 END) AS s1, MAX(CASE WHEN event_name='search'        THEN 1 END) AS s2, MAX(CASE WHEN event_name='view_listing'  THEN 1 END) AS s3, MAX(CASE WHEN event_name='start_booking' THEN 1 END) AS s4 FROM events e GROUP BY 1,2,3 ) SELECT day, COUNT(*)                                   AS sessions, SUM(CASE WHEN s1=1 THEN 1 ELSE 0 END)      AS step1, SUM(CASE WHEN s2=1 THEN 1 ELSE 0 END)      AS step2, SUM(CASE WHEN s3=1 THEN 1 ELSE 0 END)      AS step3, SUM(CASE WHEN s4=1 THEN 1 ELSE 0 END)      AS step4, step4*1.0/NULLIF(step1,0)                  AS funnel_conv FROM steps GROUP BY day ORDER BY day;

---

#### Monthly signup cohorts and D30 retention (had any session by D30).

Presto: WITH cohorts AS ( SELECT user_id, date_trunc('month', signup_date) AS cohort FROM users ), ret AS ( SELECT u.user_id, MIN(DATE(s.session_start)) AS first_seen FROM users u JOIN sessions s ON u.user_id=s.user_id GROUP BY u.user_id ) SELECT c.cohort, COUNT(*) AS users, SUM(CASE WHEN date_diff('day', c.cohort, r.first_seen) <= 30 THEN 1 ELSE 0 END) AS d30_retained FROM cohorts c LEFT JOIN ret r ON c.user_id=r.user_id GROUP BY c.cohort ORDER BY c.cohort;

---

#### Biggest drop-off step between S1‚ÜíS4 (same steps as Q34).

Use Q34 CTE and compute rates step(k+1)/step(k); smallest rate = largest drop.

---

#### Path length distribution (unique event names per session).

SELECT COUNT(DISTINCT event_name) AS uniq_events, COUNT(DISTINCT session_id) AS sessions FROM events GROUP BY uniq_events ORDER BY uniq_events;

---

#### New vs repeat bookers by normalized channel.

WITH first_book AS ( SELECT user_id, MIN(booking_ts) AS first_bkg_ts FROM bookings WHERE status='confirmed' GROUP BY 1 ), sess AS ( SELECT b.user_id, b.booking_ts, c.channel FROM bookings b JOIN sessions s ON b.user_id=s.user_id LEFT JOIN campaigns c ON s.campaign_id=c.campaign_id WHERE b.status='confirmed' ) SELECT COALESCE(channel,'Organic/Direct') AS channel, SUM(CASE WHEN b.booking_ts = fb.first_bkg_ts THEN 1 ELSE 0 END) AS new, SUM(CASE WHEN b.booking_ts <> fb.first_bkg_ts THEN 1 ELSE 0 END) AS repeat FROM sess b JOIN first_book fb ON b.user_id=fb.user_id GROUP BY 1 ORDER BY 1;

---

#### 7-day last-click attribution from click ‚Üí booking.

Presto: WITH lc AS ( SELECT user_id, campaign_id, click_ts, ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY click_ts DESC) rn FROM ad_clicks ), b AS ( SELECT booking_id, user_id, booking_ts, price_usd FROM bookings WHERE status='confirmed' ) SELECT b.booking_id, b.user_id, b.price_usd, lc.campaign_id FROM b JOIN lc ON b.user_id=lc.user_id AND lc.rn=1 WHERE date_diff('day', DATE(lc.click_ts), DATE(b.booking_ts)) BETWEEN 0 AND 7;

---

#### Simple position-based attribution (40-20-40) in-session paths.

(Interview-style sketch; actual calc requires ordered path of touches. Explain you‚Äôd explode an ordered array of touches per user, use positions to weight: first=0.4, last=0.4, mids share 0.2. Sum weights per campaign, then multiply by booking revenue. Provide steps; exact code omitted for brevity in live round.)

---

#### ROAS by campaign (confirmed bookings / spend).

(Combine revenue by campaign from sessions‚Üíbookings with spend_daily as in Q10.)

---

#### Incrementality outline (geo holdout or time-based DiD).

(Conceptual) Form matched geo pairs or date windows; compute (treat_post - treat_pre) - (ctrl_post - ctrl_pre) on bookings/revenue per capita; validate pre-period balance.

---

#### A/B revenue per assigned user; diff and lift.

WITH agg AS ( SELECT ea.variant, AVG(em.metric_value) AS avg_rev_per_user FROM experiment_assignment ea LEFT JOIN experiment_metrics em ON ea.user_id=em.user_id AND ea.exp_name=em.exp_name AND em.metric_name='gross_revenue' WHERE ea.exp_name='NewCheckout' GROUP BY ea.variant ) SELECT MAX(CASE WHEN variant='treatment' THEN avg_rev_per_user END) AS trt, MAX(CASE WHEN variant='control'   THEN avg_rev_per_user END) AS ctl, (MAX(CASE WHEN variant='treatment' THEN avg_rev_per_user END) - MAX(CASE WHEN variant='control'   THEN avg_rev_per_user END)) AS abs_diff, CASE WHEN MAX(CASE WHEN variant='control' THEN avg_rev_per_user END) > 0 THEN (MAX(CASE WHEN variant='treatment' THEN avg_rev_per_user END) / MAX(CASE WHEN variant='control'   THEN avg_rev_per_user END) - 1) END AS rel_lift FROM agg;

---

#### CUPED (conceptual with SQL hint).

Compute pre-period covariate X (e.g., prior spend/sessions) per user and treatment indicator T. Estimate theta = cov(Y,X)/var(X) (via a small SQL aggregation over both arms). Then adjust Y* = Y - theta*(X - mean(X)). Compare means of Y* across variants. (Note: run regressions outside SQL or via Presto functions if allowed).

---

#### Guardrail: CTR difference across variants.

WITH a AS ( SELECT ea.variant, COUNT(DISTINCT i.user_id) AS imps_users, COUNT(DISTINCT c.user_id) AS click_users FROM experiment_assignment ea LEFT JOIN ad_impressions i ON ea.user_id=i.user_id LEFT JOIN ad_clicks c ON ea.user_id=c.user_id WHERE ea.exp_name='NewCheckout' GROUP BY ea.variant ) SELECT variant, click_users*1.0/NULLIF(imps_users,0) AS user_ctr FROM a; (Discuss statistical test done outside SQL or via UDFs.)

---

#### SRM check (Sample Ratio Mismatch).

SELECT variant, COUNT(DISTINCT user_id) AS n FROM experiment_assignment WHERE exp_name='NewCheckout' GROUP BY variant; (Compare to planned split 50/50; flag if chi-square p-value small.)

---

#### WHERE vs HAVING.

Use WHERE to filter rows before aggregation (faster, less data). Use HAVING to filter after GROUP BY on aggregated results. Prefer partition pruning (e.g., WHERE day BETWEEN ...) when tables are partitioned.

---

#### Join null-safe + defaulting channels.

In paid/organic mixes, campaign_id may be NULL. Use LEFT JOIN and COALESCE(channel,'Organic/Direct'). Avoid inner joins that drop organic.

---

#### Data skew mitigation.

Skewed keys (e.g., campaign_id = 201 huge) cause reducers to overload.

---

#### Safe casting & dates.

Avoid implicit casts; use CAST explicitly. Standardize to DATE(...) and TIMESTAMP consistently. For timezones, normalize to UTC on write; convert on read for reporting. Quick sanity checks you can run now Who booked? SELECT user_id, price_usd FROM bookings WHERE status='confirmed'; Channel normalized path (sessions): SELECT session_id, source, medium, CASE WHEN source='google' AND medium='cpc' THEN 'SEM' WHEN source='facebook' AND medium='cpc' THEN 'Facebook' WHEN source='email'   THEN 'Email' WHEN medium='organic' THEN 'SEO' ELSE 'Direct/Other' END AS channel_norm FROM sessions ORDER BY session_id; How to practice effectively (Airbnb-aligned) Emphasize window functions (ranking, dedupe, funnels), anti-joins, sessionization, cohorts/retention, and paid vs organic blending with campaign lookups. Be ready to: Build a day-level funnel and identify the drop-off step (Q34, Q36). Attribute bookings to last click within a window (Q39). Compute DAU/WAU/MAU and MoM growth (Q11, Q24). Normalize channels robustly (Q33, Q26). Summarize experiment outcome & articulate validity checks (Q43‚ÄìQ46).

---

#### SELECT s.id,s.name

FROM students_1350 s LEFT JOIN departments_1350 d ON s.department_id = d.id WHERE d.id IS NULL;

---

#### WITH common_followers AS (

SELECT r1.user_id AS user1,r2.user_id AS user2, COUNT(r1.follower_id) AS cmn_fwlr FROM relations_1951 r1 INNER JOIN relations_1951 r2 ON r1.user_id < r2.user_id AND r1.follower_id = r2.follower_id GROUP BY r1.user_id,r2.user_id ), max_common_followers AS ( SELECT user1,user2,cmn_fwlr, MAX(cmn_fwlr) OVER () mx_cmn_fwlr FROM common_followers ) SELECT user1,user2 FROM max_common_followers WHERE mx_cmn_fwlr = cmn_fwlr;

---

#### SELECT DISTINCT session_id

FROM playback_1809 pb LEFT JOIN ads_1809 ad ON pb.customer_id = ad.customer_id AND ad.timestamp BETWEEN start_time AND end_time WHERE ad_id IS NULL;

---

#### WITH ranked AS (

SELECT log_id, log_id-ROW_NUMBER() OVER (ORDER BY log_id) AS diff FROM logs_1285 ) SELECT MIN(log_id) AS start_id,MAX(log_id) AS end_id FROM ranked GROUP BY diff ORDER BY start_id;

---

#### -- Question 47

-- Table: Employee -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | employee_id   | int     | -- | team_id       | int     | -- +---------------+---------+ -- employee_id is the primary key for this table. -- Each row of this table contains the ID of each employee and their respective team. -- Write an SQL query to find the team size of each of the employees. -- Return result table in any order. -- The query result format is in the following example: -- Employee Table: -- +-------------+------------+ -- | employee_id | team_id    | -- +-------------+------------+ -- |     1       |     8      | -- |     2       |     8      | -- |     3       |     8      | -- |     4       |     7      | -- |     5       |     9      | -- |     6       |     9      | -- +-------------+------------+ -- Result table: -- +-------------+------------+ -- | employee_id | team_size  | -- +-------------+------------+ -- |     1       |     3      | -- |     2       |     3      | -- |     3       |     3      | -- |     4       |     1      | -- |     5       |     2      | -- |     6       |     2      | -- +-------------+------------+ -- Employees with Id 1,2,3 are part of a team with team_id = 8. -- Employees with Id 4 is part of a team with team_id = 7. -- Employees with Id 5,6 are part of a team with team_id = 9. -- Solution Select employee_id, b.team_size from employee e join ( Select team_id, count(team_id) as team_size from employee group by team_id) b on e.team_id = b.team_id

---

#### WITH users AS (

SELECT user_id, ROUND(COUNT(CASE WHEN action = 'confirmed' THEN 1 ELSE NULL END)::NUMERIC/ COUNT(1),2) AS confirmation_rate FROM confirmations_1934 GROUP BY user_id ) SELECT s.user_id,COALESCE(u.confirmation_rate,0.00) FROM signups_1934 s LEFT JOIN users u ON s.user_id = u.user_id;

---

#### WITH all_contacts AS(

SELECT user_id,COUNT(contact_name) AS a_contacts FROM contacts_1364 GROUP BY user_id ), trusted_contacts AS( SELECT user_id,COUNT(contact_name) AS t_contacts FROM contacts_1364 ct INNER JOIN customers_1364 cs ON ct.contact_name = cs.customer_name GROUP BY user_id ) SELECT i.*,COALESCE(a_contacts,0) all_contacts,COALESCE(t_contacts,0) trusted_contacts FROM invoices_1364 i LEFT JOIN all_contacts ac ON i.user_id = ac.user_id LEFT JOIN trusted_contacts tc ON i.user_id = tc.user_id ORDER BY 1;

---

#### SELECT e.name as Employee

FROM employee_181 e JOIN employee_181 m ON e.manager_id = m.id AND e.salary>m.salary;

---

#### -- Question 104

-- Table: Failed -- +--------------+---------+ -- | Column Name  | Type    | -- +--------------+---------+ -- | fail_date    | date    | -- +--------------+---------+ -- Primary key for this table is fail_date. -- Failed table contains the days of failed tasks. -- Table: Succeeded -- +--------------+---------+ -- | Column Name  | Type    | -- +--------------+---------+ -- | success_date | date    | -- +--------------+---------+ -- Primary key for this table is success_date. -- Succeeded table contains the days of succeeded tasks. -- A system is running one task every day. Every task is independent of the previous tasks. The tasks can fail or succeed. -- Write an SQL query to generate a report of period_state for each continuous interval of days in the period from 2019-01-01 to 2019-12-31. -- period_state is 'failed' if tasks in this interval failed or 'succeeded' if tasks in this interval succeeded. Interval of days are retrieved as start_date and end_date. -- Order result by start_date. -- The query result format is in the following example: -- Failed table: -- +-------------------+ -- | fail_date         | -- +-------------------+ -- | 2018-12-28        | -- | 2018-12-29        | -- | 2019-01-04        | -- | 2019-01-05        | -- +-------------------+ -- Succeeded table: -- +-------------------+ -- | success_date      | -- +-------------------+ -- | 2018-12-30        | -- | 2018-12-31        | -- | 2019-01-01        | -- | 2019-01-02        | -- | 2019-01-03        | -- | 2019-01-06        | -- +-------------------+ -- Result table: -- +--------------+--------------+--------------+ -- | period_state | start_date   | end_date     | -- +--------------+--------------+--------------+ -- | succeeded    | 2019-01-01   | 2019-01-03   | -- | failed       | 2019-01-04   | 2019-01-05   | -- | succeeded    | 2019-01-06   | 2019-01-06   | -- +--------------+--------------+--------------+ -- The report ignored the system state in 2018 as we care about the system in the period 2019-01-01 to 2019-12-31. -- From 2019-01-01 to 2019-01-03 all tasks succeeded and the system state was "succeeded". -- From 2019-01-04 to 2019-01-05 all tasks failed and system state was "failed". -- From 2019-01-06 to 2019-01-06 all tasks succeeded and system state was "succeeded". -- Solution with t1 as( select min(success_date) as start_date, max(success_date) as end_date, state from( select *, date_sub(success_date, interval row_number() over(order by success_date) day) as diff, 1 as state from succeeded where success_date between "2019-01-01" and "2019-12-31") a group by diff), t2 as( select min(fail_date) as start_date, max(fail_date) as end_date, state from( select *, date_sub(fail_date, interval row_number() over(order by fail_date) day) as diff, 0 as state from failed where fail_date between "2019-01-01" and "2019-12-31") b group by diff) select case when c.state = 1 then "succeeded" else "failed" end as period_state,start_date, end_date from( select * from t1 union all select * from t2) c order by start_date

---

#### WITH calls AS (

SELECT from_id,to_id,duration FROM calls_1699 UNION ALL SELECT to_id,from_id,duration FROM calls_1699 ) SELECT from_id,to_id,COUNT(*) AS call_count,SUM(duration) AS total_duration FROM calls WHERE from_id<to_id GROUP BY from_id,to_id;

---

#### WITH grouped AS(

SELECT visited_on,SUM(amount) AS amount FROM customer_1321 GROUP BY visited_on ), cte AS ( SELECT *,ROW_NUMBER() OVER (ORDER BY visited_on) AS num FROM grouped ), cte2 AS( SELECT *, SUM(amount) OVER (ORDER BY visited_on ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) AS sum_amount, ROUND(AVG(amount) OVER (ORDER BY visited_on ROWS BETWEEN 6 PRECEDING AND CURRENT ROW),2) AS average_amount FROM cte ) SELECT visited_on,sum_amount,average_amount FROM cte2 WHERE num>=7; --------------------------------------------------------------------------------------------------------------------------------- WITH daily_spent AS ( SELECT visited_on,SUM(amount) AS amount, ROW_NUMBER() OVER (ORDER BY visited_on) AS rn FROM customer_1321 GROUP BY visited_on ), moving_averages AS ( SELECT visited_on,rn, ROUND((AVG(amount) OVER (ORDER BY visited_on ROWS BETWEEN 6 PRECEDING AND CURRENT ROW)),2) AS running_avg FROM daily_spent ORDER BY visited_on ) SELECT * FROM moving_averages WHERE rn >= 7; -- Window functions are evaluated after group by clause got executed, and window functions are applied to the result of group by clause.

---

#### SELECT card_name, MAX(issued_amount) - MIN(issued_amount) AS difference

FROM monthly_cards_issued GROUP BY card_name ORDER BY difference DESC;

---

#### SELECT p.product_name,s.year,s.price

FROM sales_1068 s JOIN product_1068 p ON s.product_id = p.product_id;

---

#### (SELECT u.name

FROM movie_rating_1341 mr INNER JOIN users_1341 u ON mr.user_id = u.user_id GROUP BY u.name ORDER BY COUNT(mr.rating) DESC,u.name LIMIT 1) UNION (SELECT m.title FROM movie_rating_1341 mr INNER JOIN movies_1341 m ON mr.movie_id = m.movie_id WHERE EXTRACT(MONTH FROM created_at)=2 GROUP BY m.title ORDER BY AVG(mr.rating) DESC,m.title LIMIT 1);

---

#### -- Question 22

-- Given a table salary, such as the one below, that has m=male and f=female values. -- Swap all f and m values (i.e., change all f values to m and vice versa) with -- a single update statement and no intermediate temp table. -- Note that you must write a single update statement, DO NOT write any select statement for this problem. -- Example: -- | id | name | sex | salary | -- |----|------|-----|--------| -- | 1  | A    | m   | 2500   | -- | 2  | B    | f   | 1500   | -- | 3  | C    | m   | 5500   | -- | 4  | D    | f   | 500    | -- After running your update statement, the above salary table should have the following rows: -- | id | name | sex | salary | -- |----|------|-----|--------| -- | 1  | A    | f   | 2500   | -- | 2  | B    | m   | 1500   | -- | 3  | C    | f   | 5500   | -- | 4  | D    | m   | 500    | -- Solution Update salary set sex = Case when sex = 'm' then 'f' when sex = 'f' then 'm' end;

---

#### SELECT DISTINCT author_id

FROM views_1148 WHERE viewer_id = author_id;

---

#### -- Question 85

-- Table: Project -- +-------------+---------+ -- | Column Name | Type    | -- +-------------+---------+ -- | project_id  | int     | -- | employee_id | int     | -- +-------------+---------+ -- (project_id, employee_id) is the primary key of this table. -- employee_id is a foreign key to Employee table. -- Table: Employee -- +------------------+---------+ -- | Column Name      | Type    | -- +------------------+---------+ -- | employee_id      | int     | -- | name             | varchar | -- | experience_years | int     | -- +------------------+---------+ -- employee_id is the primary key of this table. -- Write an SQL query that reports the most experienced employees in each project. -- In case of a tie, report all employees with the maximum number of experience years. -- The query result format is in the following example: -- Project table: -- +-------------+-------------+ -- | project_id  | employee_id | -- +-------------+-------------+ -- | 1           | 1           | -- | 1           | 2           | -- | 1           | 3           | -- | 2           | 1           | -- | 2           | 4           | -- +-------------+-------------+ -- Employee table: -- +-------------+--------+------------------+ -- | employee_id | name   | experience_years | -- +-------------+--------+------------------+ -- | 1           | Khaled | 3                | -- | 2           | Ali    | 2                | -- | 3           | John   | 3                | -- | 4           | Doe    | 2                | -- +-------------+--------+------------------+ -- Result table: -- +-------------+---------------+ -- | project_id  | employee_id   | -- +-------------+---------------+ -- | 1           | 1             | -- | 1           | 3             | -- | 2           | 1             | -- +-------------+---------------+ -- Both employees with id 1 and 3 have the -- most experience among the employees of the first project. For the second project, the employee with id 1 has the most experience. -- Solution with t1 as( select p.project_id, p.employee_id, e.experience_years, rank() over(partition by project_id order by experience_years desc) as rk from project p join employee e on p.employee_id = e.employee_id) select t1.project_id, t1.employee_id from t1 where t1.rk = 1

---

#### -- Question 93

-- Table: Customer -- +-------------+---------+ -- | Column Name | Type    | -- +-------------+---------+ -- | customer_id | int     | -- | product_key | int     | -- +-------------+---------+ -- product_key is a foreign key to Product table. -- Table: Product -- +-------------+---------+ -- | Column Name | Type    | -- +-------------+---------+ -- | product_key | int     | -- +-------------+---------+ -- product_key is the primary key column for this table. -- Write an SQL query for a report that provides the customer ids from the Customer table that bought all the products in the Product table. -- For example: -- Customer table: -- +-------------+-------------+ -- | customer_id | product_key | -- +-------------+-------------+ -- | 1           | 5           | -- | 2           | 6           | -- | 3           | 5           | -- | 3           | 6           | -- | 1           | 6           | -- +-------------+-------------+ -- Product table: -- +-------------+ -- | product_key | -- +-------------+ -- | 5           | -- | 6           | -- +-------------+ -- Result table: -- +-------------+ -- | customer_id | -- +-------------+ -- | 1           | -- | 3           | -- +-------------+ -- The customers who bought all the products (5 and 6) are customers with id 1 and 3. -- Solution select customer_id from customer group by customer_id having count(distinct product_key) = (select COUNT(distinct product_key) from product)

---

#### WITH CTE AS

( SELECT artist_name, COUNT(GSR.song_id) AS count_songs FROM global_song_rank AS GSR INNER JOIN songs ON songs.song_id = GSR.song_id INNER JOIN artists ON songs.artist_id = artists.artist_id WHERE rank <= 10 GROUP BY artist_name ) SELECT * FROM ( SELECT artist_name, DENSE_RANK() OVER(ORDER BY count_songs DESC) AS artist_rank FROM CTE ) AS TP WHERE artist_rank <= 5

---

#### SELECT manufacturer,

COUNT(drug) AS drug_count, ABS(SUM(total_sales - cogs)) AS total_loss FROM pharmacy_sales WHERE total_sales <= cogs GROUP BY manufacturer ORDER BY total_loss DESC

---

#### SELECT DISTINCT p.product_id,p.product_name

FROM product_1082 p INNER JOIN sales_1082 s ON p.product_id = s.product_id AND (s.sale_date BETWEEN '2019-01-01' AND '2019-03-31') EXCEPT SELECT DISTINCT p.product_id,p.product_name FROM product_1082 p INNER JOIN sales_1082 s ON p.product_id = s.product_id AND (s.sale_date < '2019-01-01' OR s.sale_date > '2019-03-31');

---

#### WITH cancelled AS(

SELECT t.request_at,COUNT(*) AS cancelled_count FROM trips_262 t JOIN users_262 c ON t.client_id = c.user_id AND c.banned like 'No' JOIN users_262 d ON t.driver_id = d.user_id AND d.banned like 'No' WHERE t.status LIKE 'cancelled_by_client' OR t.status LIKE 'cancelled_by_driver' GROUP BY t.request_at), total AS( SELECT t.request_at,COUNT(*) AS total_count FROM trips_262 t JOIN users_262 c ON t.client_id = c.user_id AND c.banned like 'No' JOIN users_262 d ON t.driver_id = d.user_id AND d.banned like 'No' GROUP BY t.request_at) SELECT t.request_at,(COALESCE(c.cancelled_count::FLOAT,0.0)/t.total_count::FLOAT) FROM cancelled c RIGHT JOIN total t ON c.request_at = t.request_at; (OR) SELECT request_at,ROUND(COUNT(CASE WHEN status <> 'completed' THEN 1 ELSE NULL END)::NUMERIC/COUNT(*),2) AS cancellation_rate FROM trips_262 WHERE request_at BETWEEN '2013-10-01' AND '2013-10-03' AND client_id NOT IN (SELECT user_id FROM users_262 WHERE banned LIKE 'Yes' AND role LIKE 'client') AND driver_id NOT IN (SELECT user_id FROM users_262 WHERE banned LIKE 'Yes' AND role LIKE 'driver') GROUP BY request_at;

---

#### -- Question 36

-- Table: Departments -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | id            | int     | -- | name          | varchar | -- +---------------+---------+ -- id is the primary key of this table. -- The table has information about the id of each department of a university. -- Table: Students -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | id            | int     | -- | name          | varchar | -- | department_id | int     | -- +---------------+---------+ -- id is the primary key of this table. -- The table has information about the id of each student at a university and the id of the department he/she studies at. -- Write an SQL query to find the id and the name of all students who are enrolled in departments that no longer exists. -- Return the result table in any order. -- The query result format is in the following example: -- Departments table: -- +------+--------------------------+ -- | id   | name                     | -- +------+--------------------------+ -- | 1    | Electrical Engineering   | -- | 7    | Computer Engineering     | -- | 13   | Bussiness Administration | -- +------+--------------------------+ -- Students table: -- +------+----------+---------------+ -- | id   | name     | department_id | -- +------+----------+---------------+ -- | 23   | Alice    | 1             | -- | 1    | Bob      | 7             | -- | 5    | Jennifer | 13            | -- | 2    | John     | 14            | -- | 4    | Jasmine  | 77            | -- | 3    | Steve    | 74            | -- | 6    | Luis     | 1             | -- | 8    | Jonathan | 7             | -- | 7    | Daiana   | 33            | -- | 11   | Madelynn | 1             | -- +------+----------+---------------+ -- Result table: -- +------+----------+ -- | id   | name     | -- +------+----------+ -- | 2    | John     | -- | 7    | Daiana   | -- | 4    | Jasmine  | -- | 3    | Steve    | -- +------+----------+ -- John, Daiana, Steve and Jasmine are enrolled in departments 14, 33, 74 and 77 respectively. -- department 14, 33, 74 and 77 doesn't exist in the Departments table. -- Solution Select s.id, s.name from students s left join departments d on s.department_id = d.id where d.name is null

---

#### -- Question 15

-- The Employee table holds all employees including their managers. -- Every employee has an Id, and there is also a column for the manager Id. -- +----+-------+--------+-----------+ -- | Id | Name  | Salary | ManagerId | -- +----+-------+--------+-----------+ -- | 1  | Joe   | 70000  | 3         | -- | 2  | Henry | 80000  | 4         | -- | 3  | Sam   | 60000  | NULL      | -- | 4  | Max   | 90000  | NULL      | -- +----+-------+--------+-----------+ -- Given the Employee table, write a SQL query that finds out employees who earn more than their managers. -- For the above table, Joe is the only employee who earns more than his manager. -- +----------+ -- | Employee | -- +----------+ -- | Joe      | -- +----------+ -- Solution select a.Name as Employee from employee a, employee b where a.salary>b.salary and a.managerid=b.id

---

#### SELECT date_id,make_name,COUNT(DISTINCT lead_id) AS unique_leads,COUNT(DISTINCT partner_id) AS unique_partners

FROM daily_sales_1693 GROUP BY date_id,make_name;

---

#### SELECT a.student_name,b.student_name,c.student_name

FROM school_a_1623 a CROSS JOIN school_b_1623 b CROSS JOIN school_c_1623 c WHERE a.student_id <> b.student_id AND a.student_id <> c.student_id AND b.student_id <> c.student_id AND a.student_name <> b.student_name AND a.student_name <> c.student_name AND b.student_name <> c.student_name;

---

#### Advanced SQL

Leveling up SQL Data Types SQL Date Format Data Wrangling with SQL Using SQL String Functions to Clean Data Writing Subqueries in SQL SQL Window Functions Performance Tuning SQL Queries Pivoting Data in SQL Intermediate SQL Putting it together SQL Aggregate Functions SQL COUNT SQL SUM SQL MIN/MAX SQL AVG SQL GROUP BY SQL HAVING SQL CASE SQL DISTINCT SQL Joins SQL INNER JOIN SQL Outer Joins SQL LEFT JOIN SQL RIGHT JOIN SQL Joins Using WHERE or ON SQL FULL OUTER JOIN SQL UNION SQL Joins with Comparison Operators SQL Joins on Multiple Keys SQL Self Joins

---

#### -- (Using MAX() function)

WITH updated_transactions AS ( SELECT *, MAX(amount) OVER (PARTITION BY DATE_TRUNC('DAY',day)) as max_amount FROM transactions_1831 ) SELECT transactions_id FROM updated_transactions WHERE amount = max_amount ORDER BY transactions_id; --OR (Without using MAX() function) WITH updated_transactions AS ( SELECT *, RANK() OVER (PARTITION BY DATE_TRUNC('DAY',day) ORDER BY amount DESC) as rn FROM transactions_1831 ) SELECT transactions_id FROM updated_transactions WHERE rn= 1 ORDER BY transactions_id; --OR (Without using window functions) WITH max_amounts AS ( SELECT DISTINCT t1.day,t1.amount AS max_amt FROM transactions_1831 t1 LEFT JOIN transactions_1831 t2 ON DATE_TRUNC('DAY',t1.day)=DATE_TRUNC('DAY',t2.day) AND t2.amount>t1.amount WHERE t2.transactions_id IS NULL ) SELECT transactions_id FROM transactions_1831 WHERE (day,amount) IN (SELECT * FROM max_amounts) ORDER BY transactions_id;

---

#### -- Question 99

-- X city built a new stadium, each day many people visit it and the stats are saved as these columns: id, visit_date, people -- Please write a query to display the records which have 3 or more consecutive rows and the amount of people more than 100(inclusive). -- For example, the table stadium: -- +------+------------+-----------+ -- | id   | visit_date | people    | -- +------+------------+-----------+ -- | 1    | 2017-01-01 | 10        | -- | 2    | 2017-01-02 | 109       | -- | 3    | 2017-01-03 | 150       | -- | 4    | 2017-01-04 | 99        | -- | 5    | 2017-01-05 | 145       | -- | 6    | 2017-01-06 | 1455      | -- | 7    | 2017-01-07 | 199       | -- | 8    | 2017-01-08 | 188       | -- +------+------------+-----------+ -- For the sample data above, the output is: -- +------+------------+-----------+ -- | id   | visit_date | people    | -- +------+------------+-----------+ -- | 5    | 2017-01-05 | 145       | -- | 6    | 2017-01-06 | 1455      | -- | 7    | 2017-01-07 | 199       | -- | 8    | 2017-01-08 | 188       | -- +------+------------+-----------+ -- Note: -- Each day only have one row record, and the dates are increasing with id increasing. -- Solution WITH t1 AS ( SELECT id, visit_date, people, id - ROW_NUMBER() OVER(ORDER BY visit_date) AS dates FROM stadium WHERE people >= 100) SELECT t1.id, t1.visit_date, t1people FROM t1 LEFT JOIN ( SELECT dates, COUNT(*) as total FROM t1 GROUP BY dates) AS b USING (dates) WHERE b.total > 2

---

#### -- Question 21

-- Table: ActorDirector -- +-------------+---------+ -- | Column Name | Type    | -- +-------------+---------+ -- | actor_id    | int     | -- | director_id | int     | -- | timestamp   | int     | -- +-------------+---------+ -- timestamp is the primary key column for this table. -- Write a SQL query for a report that provides the pairs (actor_id, director_id) where the actor have cooperated with the director at least 3 times. -- Example: -- ActorDirector table: -- +-------------+-------------+-------------+ -- | actor_id    | director_id | timestamp   | -- +-------------+-------------+-------------+ -- | 1           | 1           | 0           | -- | 1           | 1           | 1           | -- | 1           | 1           | 2           | -- | 1           | 2           | 3           | -- | 1           | 2           | 4           | -- | 2           | 1           | 5           | -- | 2           | 1           | 6           | -- +-------------+-------------+-------------+ -- Result table: -- +-------------+-------------+ -- | actor_id    | director_id | -- +-------------+-------------+ -- | 1           | 1           | -- +-------------+-------------+ -- The only pair is (1, 1) where they cooperated exactly 3 times. -- Solution Select actor_id, director_id from actordirector group by actor_id, director_id having count(*)>=3

---

#### -- Question 102

-- The Employee table holds the salary information in a year. -- Write a SQL to get the cumulative sum of an employee's salary over a period of 3 months but exclude the most recent month. -- The result should be displayed by 'Id' ascending, and then by 'Month' descending. -- Example -- Input -- | Id | Month | Salary | -- |----|-------|--------| -- | 1  | 1     | 20     | -- | 2  | 1     | 20     | -- | 1  | 2     | 30     | -- | 2  | 2     | 30     | -- | 3  | 2     | 40     | -- | 1  | 3     | 40     | -- | 3  | 3     | 60     | -- | 1  | 4     | 60     | -- | 3  | 4     | 70     | -- Output -- | Id | Month | Salary | -- |----|-------|--------| -- | 1  | 3     | 90     | -- | 1  | 2     | 50     | -- | 1  | 1     | 20     | -- | 2  | 1     | 20     | -- | 3  | 3     | 100    | -- | 3  | 2     | 40     | -- Explanation -- Employee '1' has 3 salary records for the following 3 months except the most recent month '4': salary 40 for month '3', 30 for month '2' and 20 for month '1' -- So the cumulative sum of salary of this employee over 3 months is 90(40+30+20), 50(30+20) and 20 respectively. -- | Id | Month | Salary | -- |----|-------|--------| -- | 1  | 3     | 90     | -- | 1  | 2     | 50     | -- | 1  | 1     | 20     | -- Employee '2' only has one salary record (month '1') except its most recent month '2'. -- | Id | Month | Salary | -- |----|-------|--------| -- | 2  | 1     | 20     | -- Employ '3' has two salary records except its most recent pay month '4': month '3' with 60 and month '2' with 40. So the cumulative salary is as following. -- | Id | Month | Salary | -- |----|-------|--------| -- | 3  | 3     | 100    | -- | 3  | 2     | 40     | -- Solution with t1 as( select *, max(month) over(partition by id) as recent_month from employee) select id, month, sum(salary) over(partition by id order by month rows between 2 preceding and current row) as salary from t1 where month<recent_month order by 1, 2 desc

---

#### -- Question 3

-- Table: Activity -- +--------------+---------+ -- | Column Name  | Type    | -- +--------------+---------+ -- | player_id    | int     | -- | device_id    | int     | -- | event_date   | date    | -- | games_played | int     | -- +--------------+---------+ -- (player_id, event_date) is the primary key of this table. -- This table shows the activity of players of some game. -- Each row is a record of a player who logged in and played a number of games (possibly 0) before logging out on some day using some device. -- Write an SQL query that reports the first login date for each player. -- The query result format is in the following example: -- Activity table: -- +-----------+-----------+------------+--------------+ -- | player_id | device_id | event_date | games_played | -- +-----------+-----------+------------+--------------+ -- | 1         | 2         | 2016-03-01 | 5            | -- | 1         | 2         | 2016-05-02 | 6            | -- | 2         | 3         | 2017-06-25 | 1            | -- | 3         | 1         | 2016-03-02 | 0            | -- | 3         | 4         | 2018-07-03 | 5            | -- +-----------+-----------+------------+--------------+ -- Result table: -- +-----------+-------------+ -- | player_id | first_login | -- +-----------+-------------+ -- | 1         | 2016-03-01  | -- | 2         | 2017-06-25  | -- | 3         | 2016-03-02  | -- +-----------+-------------+ -- Solution Select player_id, min(event_date) as first_login from Activity Group by player_id

---

#### WITH cte AS(

SELECT s.sales_id FROM orders_607 o JOIN company_607 c ON o.com_id = c.com_id JOIN salesperson_607 s ON o.sales_id = s.sales_id WHERE c.name like 'RED' ) SELECT DISTINCT name FROM salesperson_607 WHERE sales_id NOT IN (SELECT * FROM cte);

---

#### What is the difference between SQL and MySQL?

SQL vs MySQL SQL	MySQL SQL is a standard language which stands for Structured Query Language based on the English language	MySQL is a database management system. SQL is the core of the relational database which is used for accessing and managing database MySQL is an RDMS (Relational Database Management System) such as SQL Server, Informix etc.

---

#### What are the different subsets of SQL?

Data Definition Language (DDL) ‚Äì It allows you to perform various operations on the database such as CREATE, ALTER, and DELETE objects. Data Manipulation Language(DML) ‚Äì It allows you to access and manipulate data. It helps you to insert, update, delete and retrieve data from the database. Data Control Language(DCL) ‚Äì It allows you to control access to the database. Example ‚Äì Grant and Revoke access permissions.

---

#### What do you mean by DBMS? What are its different types?

Database - SQL Interview Questions - EdurekaA Database Management System (DBMS) is a software application that interacts with the user, applications, and the database itself to capture and analyze data. A database is a structured collection of data. A DBMS allows a user to interact with the database. The data stored in the database can be modified, retrieved and deleted and can be of any type like strings, numbers, images, etc. There are two types of DBMS: Relational Database Management System: The data is stored in relations (tables). Example ‚Äì MySQL. Non-Relational Database Management System: There is no concept of relations, tuples and attributes.  Example ‚Äì MongoDB Let‚Äôs move to the next question in this SQL Interview Questions.

---

#### What is RDBMS? How is it different from DBMS?

A relational database management system (RDBMS) is a set of applications and features that allow IT professionals and others to develop, edit, administer, and interact with relational databases. Most commercial relational database management systems use Structured Query Language (SQL) to access the database, which is stored in the form of tables. RDBMS is the most widely used database system in businesses all over the world. It offers a stable means of storing and retrieving massive amounts of data. Databases, in general, hold collections of data that may be accessed and used in other applications. The development, administration, and use of database platforms are all supported by a database management system. A relational database management system (RDBMS) is a type of database management system (DBMS) that stores data in a row-based table structure that links related data components. An RDBMS contains functions that ensure the data‚Äôs security, accuracy, integrity, and consistency. This is not the same as the file storage utilized by a database management system. The following are some further distinctions between database management systems and relational database management systems: Number of users who are permitted to utilise the system DBMS can only handle one user at a time, whereas an RDBMS can handle numerous users. Hardware and software specifications In comparison to an RDBMS, a DBMS requires less software and hardware. Amount of information RDBMSes can handle any quantity of data, from tiny to enormous, whereas DBMSes are limited to small amounts. The structure of the database Data is stored in a hierarchical format in a DBMS, whereas an RDBMS uses a table with headers that serve as column names and rows that hold the associated values. Implementation of the ACID principle The atomicity, consistency, isolation, and durability (ACID) concept is not used by DBMSs for data storage. RDBMSes, on the other hand, use the ACID model to organize their data and ensure consistency. Databases that are distributed DBMS will not provide complete support for distributed databases, whereas RDBMS will. Programs that are managed DBMS focuses on keeping databases that are present within the computer network and system hard discs, whereas an RDBMS helps manage relationships between its incorporated tables of data. Normalization of databases is supported RDBMS can be normalized , but a DBMS cannot be normalized.

---

#### What is a Self-Join?

Self-join is a type of join that can be used to connect two tables. As a result, it is a unary relationship. Each row of the table is attached to itself and all other rows of the same table in a self-join. As a result, self-joining is mostly used to combine and compare rows from the same database table.

---

#### What is the SELECT statement?

The SELECT command gets zero or more rows from one or more database tables or views. SELECT the most frequent data manipulation language (DML) command in most applications. SELECT queries define a result set, but not how to calculate it, because SQL is a declarative programming language.

---

#### What are some common clauses used with SELECT query in SQL?

The following are some frequent SQL clauses used in conjunction with a SELECT query: WHERE clause: In SQL, the WHERE clause is used to filter records that are required depending on certain criteria. ORDER BY clause: The ORDER BY clause in SQL is used to sort data in ascending (ASC) or descending (DESC) order depending on specified field(s) (DESC). GROUP BY clause: GROUP BY clause in SQL is used to group entries with identical data and may be used with aggregation methods to obtain summarised database results. HAVING clause in SQL is used to filter records in combination with the GROUP BY clause. It is different from WHERE, since the WHERE clause cannot filter aggregated records.

---

#### What are UNION, MINUS and INTERSECT commands?

The UNION operator is used to combine the results of two tables while also removing duplicate entries. The MINUS operator is used to return rows from the first query but not from the second query. The INTERSECT operator is used to combine the results of both queries into a single row. Before running either of the above SQL statements, certain requirements must be satisfied ‚Äì Within the clause, each SELECT query must have the same number of columns. The data types in the columns must also be comparable. In each SELECT statement, the columns must be in the same order.

---

#### What is Cursor? How to use a Cursor?

After any variable declaration, DECLARE a cursor. A SELECT Statement must always be coupled with the cursor definition. To start the result set, move the cursor over it. Before obtaining rows from the result set, the OPEN statement must be executed. To retrieve it and go to the next row in the result set, use the FETCH command. To disable the cursor, use the CLOSE command. Finally, use the DEALLOCATE command to remove the cursor definition and free up the resources connected to it.

---

#### List the different types of relationships in SQL.

There are different types of relations in the database: One-to-One ‚Äì This is a connection between two tables in which each record in one table corresponds to the maximum of one record in the other. One-to-Many and Many-to-One ‚Äì This is the most frequent connection, in which a record in one table is linked to several records in another. Many-to-Many ‚Äì This is used when defining a relationship that requires several instances on each side. Self-Referencing Relationships ‚Äì When a table has to declare a connection with itself, this is the method to employ.

---

#### What is OLTP?

OLTP, or online transactional processing, allows huge groups of people to execute massive amounts of database transactions in real time, usually via the internet. A database transaction occurs when data in a database is changed, inserted, deleted, or queried.

---

#### What are the differences between OLTP and OLAP?

OLTP stands for online transaction processing, whereas OLAP stands for online analytical processing. OLTP is an online database modification system, whereas OLAP is an online database query response system.

---

#### How do I create empty tables with the same structure as another table?

To create empty tables: Using the INTO operator to fetch the records of one table into a new table while setting a WHERE clause to false for all entries, it is possible to create empty tables with the same structure. As a result, SQL creates a new table with a duplicate structure to accept the fetched entries, but nothing is stored into the new table since the WHERE clause is active.

---

#### What is PostgreSQL?

In 1986, a team lead by Computer Science Professor Michael Stonebraker created PostgreSQL under the name Postgres. It was created to aid developers in the development of enterprise-level applications by ensuring data integrity and fault tolerance in systems. PostgreSQL is an enterprise-level, versatile, resilient, open-source, object-relational database management system that supports variable workloads and concurrent users. The international developer community has constantly backed it. PostgreSQL has achieved significant appeal among developers because to its fault-tolerant characteristics. It‚Äôs a very reliable database management system, with more than two decades of community work to thank for its high levels of resiliency, integrity, and accuracy. Many online, mobile, geospatial, and analytics applications utilise PostgreSQL as their primary data storage or data warehouse. SQL Interview Questions and Answers for Freshers

---

#### What are SQL comments?

SQL Comments are used to clarify portions of SQL statements and to prevent SQL statements from being executed. Comments are quite important in many programming languages. The comments are not supported by a Microsoft Access database. As a result, the Microsoft Access database is used in the examples in Mozilla Firefox and Microsoft Edge. Single Line Comments: It starts with two consecutive hyphens (‚Äì). Multi-line Comments: It starts with /* and ends with */.

---

#### What is the usage of the NVL() function?

You may use the NVL function to replace null values with a default value. The function returns the value of the second parameter if the first parameter is null. If the first parameter is anything other than null, it is left alone. This function is used in Oracle, not in SQL and MySQL. Instead of NVL() function, MySQL have IFNULL() and SQL Server have ISNULL() function. Let‚Äôs move to the next question in this SQL Interview Questions.

---

#### Explain character-manipulation functions? Explains its different types in SQL.

Change, extract, and edit the character string using character manipulation routines. The function will do its action on the input strings and return the result when one or more characters and words are supplied into it. The character manipulation functions in SQL are as follows: A) CONCAT (joining two or more values): This function is used to join two or more values together. The second string is always appended to the end of the first string. B) SUBSTR: This function returns a segment of a string from a given start point to a given endpoint. C) LENGTH: This function returns the length of the string in numerical form, including blank spaces. D) INSTR: This function calculates the precise numeric location of a character or word in a string. E) LPAD: For right-justified values, it returns the padding of the left-side character value. F) RPAD: For a left-justified value, it returns the padding of the right-side character value. G) TRIM: This function removes all defined characters from the beginning, end, or both ends of a string. It also reduced the amount of wasted space. H) REPLACE: This function replaces all instances of a word or a section of a string (substring) with the other string value specified.

---

#### Write the SQL query to get the third maximum salary of an employee from a table named employees.

Employee table employee_name	salary A	24000 C	34000 D	55000 E	75000 F	21000 G	40000 H	50000 SELECT * FROM( SELECT employee_name, salary, DENSE_RANK() OVER(ORDER BY salary DESC)r FROM Employee) WHERE r=&n; To find 3rd highest salary set n = 3

---

#### What is the difference between the RANK() and DENSE_RANK() functions?

The RANK() function in the result set defines the rank of each row within your ordered partition. If both rows have the same rank, the next number in the ranking will be the previous rank plus a number of duplicates. If we have three records at rank 4, for example, the next level indicated is 7. The DENSE_RANK() function assigns a distinct rank to each row within a partition based on the provided column value, with no gaps. It always indicates a ranking in order of precedence. This function will assign the same rank to the two rows if they have the same rank, with the next rank being the next consecutive number. If we have three records at rank 4, for example, the next level indicated is 5.

---

#### What are Tables and Fields?

A table is a collection of data components organized in rows and columns in a relational database. A table can also be thought of as a useful representation of relationships. The most basic form of data storage is the table. An example of an Employee table is shown below. ID	Name	Department	Salary 1	Rahul	Sales	24000 2	Rohini	Marketing	34000 3	Shylesh	Sales	24000 4	Tarun	Analytics	30000 A Record or Row is a single entry in a table. In a table, a record represents a collection of connected data. The Employee table, for example, has four records. A table is made up of numerous records (rows), each of which can be split down into smaller units called Fields(columns). ID, Name, Department, and Salary are the four fields in the Employee table above.

---

#### What is a UNIQUE constraint?

The UNIQUE Constraint prevents identical values in a column from appearing in two records. The UNIQUE constraint guarantees that every value in a column is unique.

---

#### What is a Self-Join?

Self-join is a type of join that can be used to connect two tables. As a result, it is a unary relationship. Each row of the table is attached to itself and all other rows of the same table in a self-join. As a result, a self-join is mostly used to combine and compare rows from the same database table.

---

#### What is the SELECT statement?

A SELECT command gets zero or more rows from one or more database tables or views. SELECT the most frequent data manipulation language (DML) command is SELECT in most applications. SELECT queries define a result set, but not how to calculate it, because SQL is a declarative programming language.

---

#### What are some common clauses used with SELECT query in SQL?

The following are some frequent SQL clauses used in conjunction with a SELECT query: WHERE clause: In SQL, the WHERE clause is used to filter records that are required depending on certain criteria. ORDER BY clause: The ORDER BY clause in SQL is used to sort data in ascending (ASC) or descending (DESC) order depending on specified field(s) (DESC). GROUP BY clause: GROUP BY clause in SQL is used to group entries with identical data and may be used with aggregation methods to obtain summarised database results. HAVING clause in SQL is used to filter records in combination with the GROUP BY clause. It is different from WHERE, since the WHERE clause cannot filter aggregated records.

---

#### What are UNION, MINUS and INTERSECT commands?

The UNION operator is used to combine the results of two tables while also removing duplicate entries. The MINUS operator is used to return rows from the first query but not from the second query. The INTERSECT operator is used to combine the results of both queries into a single row. Before running either of the above SQL statements, certain requirements must be satisfied ‚Äì Within the clause, each SELECT query must have the same amount of columns. The data types in the columns must also be comparable. In each SELECT statement, the columns must be in the same order. Let‚Äôs move to the next question in this SQL Interview Questions.

---

#### What is Cursor? How to use a Cursor?

After any variable declaration, DECLARE a cursor. A SELECT Statement must always be coupled with the cursor definition. To start the result set, move the cursor over it. Before obtaining rows from the result set, the OPEN statement must be executed. To retrieve and go to the next row in the result set, use the FETCH command. To disable the cursor, use the CLOSE command. Finally, use the DEALLOCATE command to remove the cursor definition and free up the resources connected with it.

---

#### List the different types of relationships in SQL.

There are different types of relations in the database: One-to-One ‚Äì This is a connection between two tables in which each record in one table corresponds to the maximum of one record in the other. One-to-Many and Many-to-One ‚Äì This is the most frequent connection, in which a record in one table is linked to several records in another. Many-to-Many ‚Äì This is used when defining a relationship that requires several instances on each sides. Self-Referencing Relationships ‚Äì When a table has to declare a connection with itself, this is the method to employ.

---

#### What is SQL example?

SQL is a database query language that allows you to edit, remove, and request data from databases. The following statements are a few examples of SQL statements: SELECT INSERT UPDATE DELETE CREATE DATABASE ALTER DATABASE

---

#### What are basic SQL skills?

SQL skills aid data analysts in the creation, maintenance, and retrieval of data from relational databases, which divide data into columns and rows. It also enables users to efficiently retrieve, update, manipulate, insert, and alter data. The most fundamental abilities that a SQL expert should possess are: Database Management Structuring a Database Creating SQL clauses and statements SQL System SKills like MYSQL, PostgreSQL PHP expertise is useful. Analyze SQL data Using WAMP with SQL to create a database OLAP Skills

---

#### What is schema in SQL Server?

A schema is a visual representation of the database that is logical. It builds and specifies the relationships among the database‚Äôs numerous entities. It refers to the several kinds of constraints that may be applied to a database. It also describes the various data kinds. It may also be used on Tables and Views. Schemas come in a variety of shapes and sizes. Star schema and Snowflake schema are two of the most popular. The entities in a star schema are represented in a star form, whereas those in a snowflake schema are shown in a snowflake shape. Any database architecture is built on the foundation of schemas.

---

#### How to create a temp table in SQL Server?

Temporary tables are created in TempDB and are erased automatically after the last connection is closed. We may use Temporary Tables to store and process interim results. When we need to store temporary data, temporary tables come in handy. The following is the syntax for creating a Temporary Table: CREATE TABLE #Employee (id INT, name VARCHAR(25)) INSERT INTO #Employee VALUES (01, ‚ÄòAshish‚Äô), (02, ‚ÄòAtul‚Äô) Let‚Äôs move to the next question in this SQL Interview Questions.

---

#### How to install SQL Server in Windows 11?

Install SQL Server Management Studio In Windows 11 Step 1: Click on SSMS, which will take you to the SQL Server Management Studio page. Step 2: Moreover, click on the SQL Server Management Studio link and tap on Save File. Step 3: Save this file to your local drive and go to the folder. Step 4: The setup window will appear, and here you can choose the location where you want to save the file. Step 5: Click on Install. Step 6: Close the window after the installation is complete. Step 7: Furthermore, go back to your Start Menu and search for SQL server management studio. Step 8: Furthermore, double-click on it, and the login page will appear once it shows up. Step 9: You should be able to see your server name. However, if that‚Äôs not visible, click on the drop-down arrow on the server and tap on Browse. Step 10: Choose your SQL server and click on Connect. After that, the SQL server will connect, and Windows 11 will run well.

---

#### What is the case when in SQL Server?

The CASE statement is used to construct logic in which one column‚Äôs value is determined by the values of other columns. At least one set of WHEN and THEN commands makes up the SQL Server CASE Statement. The condition to be tested is specified by the WHEN statement. If the WHEN the condition returns TRUE, the THEN sentence explains what to do. When none of the WHEN conditions return true, the ELSE statement is executed. The END keyword brings the CASE statement to a close. CASE WHEN condition1 THEN result1 WHEN condition2 THEN result2 WHEN conditionN THEN resultN ELSE results END;

---

#### NoSQL vs SQL

In summary, the following are the five major distinctions between SQL and NoSQL: Relational databases are SQL, while non-relational databases are NoSQL. SQL databases have a specified schema and employ structured query language. For unstructured data, NoSQL databases use dynamic schemas. SQL databases scale vertically, but NoSQL databases scale horizontally. NoSQL databases are document, key-value, graph, or wide-column stores, whereas SQL databases are table-based. SQL databases excel in multi-row transactions, while NoSQL excels at unstructured data such as documents and JSON.

---

#### What is the difference between NOW() and CURRENT_DATE()?

NOW() returns a constant time that indicates the time at which the statement began to execute. (Within a stored function or trigger, NOW() returns the time at which the function or triggering statement began to execute. The simple difference between NOW() and CURRENT_DATE() is that NOW() will fetch the current date and time both in format ‚ÄòYYYY-MM_DD HH:MM:SS‚Äô while CURRENT_DATE() will fetch the date of the current day ‚ÄòYYYY-MM_DD‚Äô. Let‚Äôs move to the next question in this SQL Interview Questions.

---

#### What is BLOB and TEXT in MySQL?

BLOB stands for Binary Huge Objects and can be used to store binary data, whereas TEXT may be used to store a large number of strings. BLOB may be used to store binary data, which includes images, movies, audio, and applications. BLOB values function similarly to byte strings, and they lack a character set. As a result, bytes‚Äô numeric values are completely dependent on comparison and sorting. TEXT values behave similarly to a character string or a non-binary string. The comparison/sorting of TEXT is completely dependent on the character set collection. SQL Interview Questions and Answers for Experienced

---

#### How to remove duplicate rows in SQL?

If the SQL table has duplicate rows, the duplicate rows must be removed. Let‚Äôs assume the following table for our dataset: ID	Name	Age 1	A	21 2	B	23 2	B	23 4	D	22 5	E	25 6	G	26 5	E	25 The following SQL query removes the duplicate ids from the table: DELETE FROM table WHERE ID IN ( SELECT ID, COUNT(ID) FROM   table GROUP BY  ID HAVING COUNT (ID) > 1);

---

#### How to create a stored procedure using SQL Server?

A stored procedure is a piece of prepared SQL code that you can save and reuse again and over. So, if you have a SQL query that you create frequently, save it as a stored procedure and then call it to run it. You may also supply parameters to a stored procedure so that it can act based on the value(s) of the parameter(s) given. Stored Procedure Syntax CREATE PROCEDURE procedure_name AS sql_statement GO; Execute a Stored Procedure EXEC procedure_name;

---

#### What is Database Black Box Testing?

Black Box Testing is a software testing approach that involves testing the functions of software applications without knowing the internal code structure, implementation details, or internal routes. Black Box Testing is a type of software testing that focuses on the input and output of software applications and is totally driven by software requirements and specifications. Behavioral testing is another name for it.

---

#### What are the different types of SQL sandbox?

SQL Sandbox is a secure environment within SQL Server where untrusted programmes can be run. There are three different types of SQL sandboxes: Safe Access Sandbox: In this environment, a user may execute SQL activities like as building stored procedures, triggers, and so on, but they can‚Äôt access the memory or create files. Sandbox for External Access: Users can access files without having the ability to alter memory allocation. Unsafe Access Sandbox: This contains untrustworthy code that allows a user to access memory. Let‚Äôs move to the next question in this SQL Interview Questions.

---

#### Where MyISAM table is stored?

Prior to the introduction of MySQL 5.5 in December 2009, MyISAM was the default storage engine for MySQL relational database management system versions.  It‚Äôs based on the older ISAM code, but it comes with a lot of extra features. Each MyISAM table is split into three files on disc (if it is not partitioned). The file names start with the table name and end with an extension that indicates the file type. The table definition is stored in a.frm file, however this file is not part of the MyISAM engine; instead, it is part of the server. The data file suffix is.MYD (MYData). The index file extension is.MYI (MYIndex). If you lose your index file, you may always restore it by recreating indexes.

---

#### How to find the nth highest salary in SQL?

The most typical interview question is to find the Nth highest pay in a table. This work can be accomplished using the dense rank() function. Employee table employee_name	salary A	24000 C	34000 D	55000 E	75000 F	21000 G	40000 H	50000 SELECT * FROM( SELECT employee_name, salary, DENSE_RANK() OVER(ORDER BY salary DESC)r FROM Employee) WHERE r=&n; To find to the 2nd highest salary set n = 2 To find 3rd highest salary set n = 3 and so on.

---

#### What do you mean by table and field in SQL?

A table refers to a collection of data in an organised manner in form of rows and columns. A field refers to the number of columns in a table. For example: Table: StudentInformation Field: Stu Id, Stu Name, Stu Marks

---

#### What are joins in SQL?

A JOIN clause is used to combine rows from two or more tables, based on a related column between them. It is used to merge two tables or retrieve data from there. There are 4 types of joins, as you can refer to below: Inner join: Inner Join in SQL is the most common type of join. It is used to return all the rows from multiple tables where the join condition is satisfied. Left Join: Left Join in SQL is used to return all the rows from the left table but only the matching rows from the right table where the join condition is fulfilled. Right Join: Right Join in SQL is used to return all the rows from the right table but only the matching rows from the left table where the join condition is fulfilled. Full Join: Full join returns all the records when there is a match in any of the tables. Therefore, it returns all the rows from the left-hand side table and all the rows from the right-hand side table. Let‚Äôs move to the next question in this SQL Interview Questions.

---

#### What is the difference between CHAR and VARCHAR2 datatype in SQL?

Both Char and Varchar2 are used for character datatype but varchar2 is used for character strings of variable length whereas Char is used for strings of fixed length. For example, char(10) can only store 10 characters and will not be able to store a string of any other length whereas varchar2(10) can store any length i.e 6,8,2 in this variable.

---

#### What is a Primary key?

A Primary key in SQL is a column (or collection of columns) or a set of columns that uniquely identifies each row in the table. Uniquely identifies a single row in the table Null values not allowed Example- In the Student table, Stu_ID is the primary key.

---

#### What are Constraints?

Constraints in SQL are used to specify the limit on the data type of the table. It can be specified while creating or altering the table statement. The sample of constraints are: NOT NULL CHECK DEFAULT UNIQUE PRIMARY KEY FOREIGN KEY

---

#### What is the difference between DELETE and TRUNCATE statements?

DELETE vs TRUNCATE DELETE	TRUNCATE Delete command is used to delete a row in a table.	Truncate is used to delete all the rows from a table. You can rollback data after using delete statement.	You cannot rollback data. It is a DML command.	It is a DDL command. It is slower than truncate statement.	It is faster.

---

#### What is a Unique key?

Uniquely identifies a single row in the table. Multiple values allowed per table. Null values allowed. Apart from this SQL Interview Questions blog, if you want to get trained by professionals on this technology, you can opt for structured training from edureka!

---

#### What is a Foreign key in SQL?

Foreign key maintains referential integrity by enforcing a link between the data in two tables. The foreign key in the child table references the primary key in the parent table. The foreign key constraint prevents actions that would destroy links between the child and parent tables.

---

#### What do you mean by data integrity?

Data Integrity defines the accuracy as well as the consistency of the data stored in a database. It also defines integrity constraints to enforce business rules on the data when it is entered into an application or a database.

---

#### What is the difference between clustered and non-clustered index in SQL?

The differences between the clustered and non clustered index in SQL are : Clustered index is used for easy retrieval of data from the database and its faster whereas reading from non clustered index is relatively slower. Clustered index alters the way records are stored in a database as it sorts out rows by the column which is set to be clustered index whereas in a non clustered index, it does not alter the way it was stored but it creates a separate object within a table which points back to the original table rows after searching. One table can only have one clustered index whereas it can have many non clustered indexes.

---

#### Write a SQL query to display the current date?

In SQL, there is a built-in function called GetDate() which helps to return the current timestamp/date.

---

#### What do you understand from query optimization?

The phase that identifies a plan for the evaluation query with the least estimated cost is known as query optimization. The advantages of query optimization are as follows: The output is provided faster A larger number of queries can be executed in less time Reduces time and space complexity Denormalization refers to a technique which is used to access data from higher to lower forms of a database. It helps database managers to increase the performance of the entire infrastructure as it introduces redundancy into a table. It adds the redundant data into a table by incorporating database queries that combine data from various tables into a single table.

---

#### What are Entities and Relationships?

Entities:  A person, place, or thing in the real world about which data can be stored in a database. Tables store data that represents one type of entity. For example ‚Äì A bank database has a customer table to store customer information. The customer table stores this information as a set of attributes (columns within the table) for each customer. Relationships: Relation or links between entities that have something to do with each other. For example ‚Äì The customer‚Äôs name is related to the customer account number and contact information, which might be in the same table. There can also be relationships between separate tables (for example, customer to accounts). Let‚Äôs move to the next question in this SQL Interview Questions.

---

#### What is an Index?

An index refers to a performance tuning method of allowing faster retrieval of records from the table. An index creates an entry for each value and hence it will be faster to retrieve data.

---

#### Explain different types of index in SQL.

There are three types of index in SQL namely: Unique Index: This index does not allow the field to have duplicate values if the column is unique indexed. If a primary key is defined, a unique index can be applied automatically. Clustered Index: This index reorders the physical order of the table and searches based on the basis of key values. Each table can only have one clustered index. Non-Clustered Index: Non-Clustered Index does not alter the physical order of the table and maintains a logical order of the data. Each table can have many nonclustered indexes. SQL Interview Questions for Data Analyst

---

#### What is Normalization and what are the advantages of it?

Normalization in SQL is the process of organizing data to avoid duplication and redundancy. Some of the advantages are: Better Database organization More Tables with smaller rows Efficient data access Greater Flexibility for Queries Quickly find the information Easier to implement Security Allows easy modification Reduction of redundant and duplicate data More Compact Database Ensure Consistent data after modification Apart from this SQL Interview Questions Blog, if you want to get trained by professionals on this technology, you can opt for structured training from edureka!

---

#### What is the difference between DROP and TRUNCATE commands?

DROP command removes a table and it cannot be rolled back from the database whereas TRUNCATE command removes all the rows from the table.

---

#### Explain the different types of Normalization.

There are many successive levels of normalization. These are called normal forms. Each consecutive normal form depends on the previous one.The first three normal forms are usually adequate. Normal Forms are used in database tables to remove or decrease duplication. The following are the many forms: First Normal Form: When every attribute in a relationship is a single-valued attribute, it is said to be in the first normal form. The first normal form is broken when a relation has a composite or multi-valued property. Second Normal Form: A relationship is in a second normal form if it meets the first normal form‚Äôs requirements and does not contain any partial dependencies. In 2NF, a relation has no partial dependence, which means it has no non-prime attribute that is dependent on any suitable subset of any table candidate key. Often, the problem may be solved by setting a single column Primary Key. Third Normal Form: If a relation meets the requirements for the second normal form and there is no transitive dependency, it is said to be in the third normal form.

---

#### What is OLTP?

OLTP, or online transactional processing, allows huge groups of people to execute massive amounts of database transactions in real time, usually via the internet. A database transaction occurs when data in a database is changed, inserted, deleted, or queried. What are the differences between OLTP and OLAP? OLTP stands for online transaction processing, whereas OLAP stands for online analytical processing. OLTP is an online database modification system, whereas OLAP is an online database query response system.

---

#### How to create empty tables with the same structure as another table?

To create empty tables: Using the INTO operator to fetch the records of one table into a new table while setting a WHERE clause to false for all entries, it is possible to create empty tables with the same structure. As a result, SQL creates a new table with a duplicate structure to accept the fetched entries, but nothing is stored into the new table since the WHERE clause is active.

---

#### What is PostgreSQL?

In 1986, a team lead by Computer Science Professor Michael Stonebraker created PostgreSQL under the name Postgres. It was created to aid developers in the development of enterprise-level applications by ensuring data integrity and fault tolerance in systems. PostgreSQL is an enterprise-level, versatile, resilient, open-source, object-relational database management system that supports variable workloads and concurrent users. The international developer community has consistently backed it. PostgreSQL has achieved significant appeal among developers because of its fault-tolerant characteristics. It‚Äôs a very reliable database management system, with more than two decades of community work to thank for its high levels of resiliency, integrity, and accuracy. Many online, mobile, geospatial, and analytics applications utilise PostgreSQL as their primary data storage or data warehouse.

---

#### What are SQL comments?

SQL Comments are used to clarify portions of SQL statements and to prevent SQL statements from being executed. Comments are quite important in many programming languages. These comments are not supported by the Microsoft Access database. As a result, the Microsoft Access database is used in the examples in Mozilla Firefox and Microsoft Edge. Single Line Comments: It starts with two consecutive hyphens (‚Äì). Multi-line Comments: It starts with /* and ends with */. Let‚Äôs move to the next question in this SQL Interview Questions.

---

#### What is the difference between the RANK() and DENSE_RANK() functions?

The RANK() function in the result set defines the rank of each row within your ordered partition. If both rows have the same rank, the next number in the ranking will be the previous rank plus a number of duplicates. If we have three records at rank 4, for example, the next level indicated is 7. The DENSE_RANK() function assigns a distinct rank to each row within a partition based on the provided column value, with no gaps. It always indicates a ranking in order of precedence. This function will assign the same rank to the two rows if they have the same rank, with the next rank being the next consecutive number. If we have three records at rank 4, for example, the next level indicated is 5.

---

#### What is SQL Injection?

SQL injection is a sort of flaw in website and web app code that allows attackers to take control of back-end processes and access, retrieve, and delete sensitive data stored in databases. In this approach, malicious SQL statements are entered into a database entry field, and the database becomes exposed to an attacker once they are executed. By utilising data-driven apps, this strategy is widely utilised to get access to sensitive data and execute administrative tasks on databases. SQLi attack is another name for it. The following are some examples of SQL injection: Getting access to secret data in order to change a SQL query to acquire the desired results. UNION attacks are designed to steal data from several database tables. Examine the database to get information about the database‚Äôs version and structure

---

#### How many Aggregate functions are available in SQL?

SQL aggregate functions provide information about a database‚Äôs data. AVG, for example, returns the average of a database column‚Äôs values. SQL provides seven (7) aggregate functions, which are given below: AVG(): returns the average value from the specified columns. COUNT(): returns the number of table rows, including rows with null values. MAX(): returns the largest value among the group. MIN(): returns the smallest value among the group. SUM(): returns the total summed values(non-null) of the specified column. FIRST(): returns the first value of an expression. LAST(): returns the last value of an expression.

---

#### What is the default ordering of data using the ORDER BY clause? How could it be changed?

The ORDER BY clause in MySQL can be used without the ASC or DESC modifiers. The sort order is preset to ASC or ascending order when this attribute is absent from the ORDER BY clause.

---

#### How do we use the DISTINCT statement? What is its use?

The SQL DISTINCT keyword is combined with the SELECT query to remove all duplicate records and return only unique records. There may be times when a table has several duplicate records. The DISTINCT clause in SQL is used to eliminate duplicates from a SELECT statement‚Äôs result set.

---

#### What are the syntax and use of the COALESCE function?

From a succession of expressions, the COALESCE function returns the first non-NULL value. The expressions are evaluated in the order that they are supplied, and the function‚Äôs result is the first non-null value. Only if all of the inputs are null does the COALESCE method return NULL. The syntax of COALESCE function is COALESCE (exp1, exp2, ‚Ä¶. expn)

---

#### What is the ACID property in a database?

ACID stands for Atomicity, Consistency, Isolation, Durability. It is used to ensure that the data transactions are processed reliably in a database system. Atomicity: Atomicity refers to the transactions that are completely done or failed where transaction refers to a single logical operation of a data. It means if one part of any transaction fails, the entire transaction fails and the database state is left unchanged. Consistency: Consistency ensures that the data must meet all the validation rules. In simple words, you can say that your transaction never leaves the database without completing its state. Isolation: The main goal of isolation is concurrency control. Durability: Durability means that if a transaction has been committed, it will occur whatever may come in between such as power loss, crash or any sort of error. Top 10 Trending Technologies to Learn in 2025 | Edureka This video talks about the Top 10 Trending Technologies in 2025 that you must learn.

---

#### What do you mean by ‚ÄúTrigger‚Äù in SQL?

Trigger in SQL is are a special type of stored procedures that are defined to execute automatically in place or after data modifications. It allows you to execute a batch of code when an insert, update or any other query is executed against a specific table.

---

#### What are the different operators available in SQL?

There are three operators available in SQL, namely: Arithmetic Operators Logical Operators Comparison Operators Apart from this SQL Interview Questions blog, if you want to get trained by professionals on this technology, you can opt for structured training from Edureka!

---

#### Are NULL values the same as that of zero or a blank space?

A NULL value is not at all the same as that of zero or a blank space. NULL values represent a value that is unavailable, unknown, assigned or not applicable whereas a zero is a number and a blank space is a character.

---

#### What is the difference between cross join and natural join?

The cross join produces the cross product or Cartesian product of two tables whereas the natural join is based on all the columns having the same name and data types in both the tables.

---

#### What is subquery in SQL?

A subquery is a query inside another query where a query is defined to retrieve data or information back from the database. In a subquery, the outer query is called as the main query whereas the inner query is called subquery. Subqueries are always executed first and the result of the subquery is passed on to the main query. It can be nested inside a SELECT, UPDATE or any other query. A subquery can also use any comparison operators such as >,< or =.

---

#### What are the different types of a subquery?

There are two types of subquery namely, Correlated and Non-Correlated. Correlated subquery: These are queries which select the data from a table referenced in the outer query. This is not considered an independent query as it refers to another table and refers to the column in a table. Non-Correlated subquery: This query is an independent query where the output of subquery is substituted in the main query. Let‚Äôs move to the next question in this SQL Interview Questions.

---

#### List the ways to get the count of records in a table?

To count the number of records in a table in SQL, you can use the below commands: SELECT * FROM table1 SELECT COUNT(*) FROM table1 SELECT rows FROM sysindexes WHERE id = OBJECT_ID(table1) AND indid < 2 Apart from this SQL Interview Questions Blog, if you want to get trained by professionals on this technology, you can opt for structured training from edureka! Interview Questions for SQL Developer

---

#### Write a SQL query to find the names of employees that begin with ‚ÄòA‚Äô?

To display name of the employees that begin with ‚ÄòA‚Äô, type in the below command: SELECT * FROM Table_name WHERE EmpName like 'A%'

---

#### Write a SQL query to get the third-highest salary of an employee from employee_table?

SELECT TOP 1 salary FROM( SELECT TOP 3 salary FROM employee_table ORDER BY salary DESC) AS emp ORDER BY salary ASC;

---

#### What is the need for group functions in SQL?

Group functions work on the set of rows and return one result per group. Some of the commonly used group functions are: AVG, COUNT, MAX, MIN, SUM, VARIANCE.

---

#### What is a Relationship and what are they?

Relation or links are between entities that have something to do with each other. Relationships are defined as the connection between the tables in a database. There are various relationships, namely: One to One Relationship. One to Many Relationship. Many to One Relationship. Self-Referencing Relationship.

---

#### How can you insert NULL values in a column while inserting the data?

NULL values in SQL can be inserted in the following ways: Implicitly by omitting column from column list. Explicitly by specifying NULL keyword in the VALUES clause

---

#### What is the main difference between ‚ÄòBETWEEN‚Äô and ‚ÄòIN‚Äô condition operators?

BETWEEN operator is used to display rows based on a range of values in a row whereas the IN condition operator is used to check for values contained in a specific set of values. Example of BETWEEN: SELECT * FROM Students where ROLL_NO BETWEEN 10 AND 50; Example of IN: SELECT * FROM students where ROLL_NO IN (8,15,25); Get More SQL query interview questions

---

#### Why are SQL functions used?

SQL functions are used for the following purposes: To perform some calculations on the data To modify individual data items To manipulate the output To format dates and numbers To convert the data types

---

#### What is the need for MERGE statement?

This statement allows conditional update or insertion of data into a table. It performs an UPDATE if a row exists, or an INSERT if the row does not exist.

---

#### What do you mean by recursive stored procedure?

Recursive stored procedure refers to a stored procedure which calls by itself until it reaches some boundary condition. This recursive function or procedure helps the programmers to use the same set of code n number of times.

---

#### What is CLAUSE in SQL?

SQL clause helps to limit the result set by providing a condition to the query. A clause helps to filter the rows from the entire set of records. For example ‚Äì WHERE, HAVING clause. Apart from this SQL Interview Questions Blog, if you want to get trained by professionals on this technology, you can opt for a structured training from edureka! Click below to learn more.

---

#### What is the difference between ‚ÄòHAVING‚Äô CLAUSE and a ‚Äúwhere‚Äù clause?

HAVING clause can only be used only with SELECT statement. It is usually used in a GROUP BY clause and whenever GROUP BY is not used, HAVING behaves like a WHERE clause. Having Clause is only used with the GROUP BY function in a query whereas WHERE Clause is applied to each row before they are a part of the GROUP BY function in a query.

---

#### List the ways in which Dynamic SQL can be executed?

Following are the ways in which dynamic SQL can be executed: Write a query with parameters. Using EXEC. Using sp_executesql.

---

#### What are the various levels of constraints?

Constraints are the representation of a column to enforce data entity and consistency. There are two levels of a constraint, namely: column level constraint table level constraint

---

#### How can you fetch common records from two tables?

You can fetch common records from two tables using INTERSECT. For example: Select studentID from student. <strong>INTERSECT </strong> Select StudentID from Exam

---

#### List some case manipulation functions in SQL?

There are three case manipulation functions in SQL, namely: LOWER: This function returns the string in lowercase. It takes a string as an argument and returns it by converting it into lower case. Syntax: LOWER(‚Äòstring‚Äô) UPPER: This function returns the string in uppercase. It takes a string as an argument and returns it by converting it into uppercase. Syntax: UPPER(‚Äòstring‚Äô) INITCAP: This function returns the string with the first letter in uppercase and rest of the letters in lowercase. Syntax: INITCAP(‚Äòstring‚Äô) Apart from this SQL Interview Questions blog, if you want to get trained by professionals on this technology, you can opt for a structured training from edureka! Click below to learn more.

---

#### What are the different set operators available in SQL?

Some of the available set operators are ‚Äì Union, Intersect or Minus operators.

---

#### What is an ALIAS command?

ALIAS command in SQL is the name that can be given to any table or a column. The alias name can be referred in WHERE clause to identify a particular table or column. For example- Select emp.empID, dept.Result from employee emp, department as dept where emp.empID=dept.empID In the above example, emp refers to alias name for employee table and dept refers to alias name for department table. Let‚Äôs move to the next question in this SQL Interview Questions.

---

#### What are aggregate and scalar functions?

Aggregate functions are used to evaluate mathematical calculation and returns a single value. These calculations are done from the columns in a table. For example- max(),count() are calculated with respect to numeric. Scalar functions return a single value based on the input value. For example ‚Äì UCASE(), NOW() are calculated with respect to string. Let‚Äôs move to the next question in this SQL Interview Questions.

---

#### How can you fetch alternate records from a table?

You can fetch alternate records i.e both odd and even row numbers. For example- To display even numbers, use the following command: Select studentId from (Select rowno, studentId from student) where mod(rowno,2)=0 Now, to display odd numbers: Select studentId from (Select rowno, studentId from student) where mod(rowno,2)=1

---

#### Name the operator which is used in the query for pattern matching?

LIKE an operator is used for pattern matching, and it can be used as -. % ‚Äì It matches zero or more characters. For example- select * from students where studentname like ‚Äòa%‚Äô _ (Underscore) ‚Äì it matches exactly one character. For example- select * from student where studentname like ‚Äòabc_‚Äô Apart from this SQL Interview Questions Blog, if you want to get trained from professionals on this technology, you can opt for structured training from edureka!

---

#### How can you select unique records from a table?

You can select unique records from a table by using the DISTINCT keyword. Select DISTINCT studentID from Student Using this command, it will print unique student id from the table Student.

---

#### How can you fetch the first 5 characters of the string?

There are a lot of ways to fetch characters from a string. For example: Select SUBSTRING(StudentName,1,5) as studentname from student

---

#### What is the main difference between SQL and PL/SQL?

SQL is a query language that allows you to issue a single query or execute a single insert/update/delete whereas PL/SQL is Oracle‚Äôs ‚ÄúProcedural Language‚Äù SQL, which allows you to write a full program (loops, variables, etc.) to accomplish multiple operations such as selects/inserts/updates/deletes.

---

#### What is a View?

A view is a virtual table which consists of a subset of data contained in a table. Since views are not present, it takes less space to store. View can have data from one or more tables combined and it depends on the relationship. Let‚Äôs move to the next question in this SQL Interview Questions.

---

#### What are Views used for?

A view refers to a logical snapshot based on a table or another view. It is used for the following reasons: Restricting access to data. Making complex queries simple. Ensuring data independence. Providing different views of the same data.

---

#### What is a Stored Procedure?

A Stored Procedure is a function which consists of many SQL statements to access the database system. Several SQL statements are consolidated into a stored procedure and execute them whenever and wherever required which saves time and avoids writing code again and again.

---

#### List some advantages and disadvantages of Stored Procedure?

Advantages: A Stored Procedure can be used as a modular programming which means to create once, store and call several times whenever it is required. This supports faster execution. It also reduces network traffic and provides better security to the data. Disadvantage: The only disadvantage of Stored Procedure is that it can be executed only in the database and utilizes more memory in the database server.

---

#### List all the types of user-defined functions?

There are three types of user-defined functions, namely: Scalar Functions Inline Table-valued functions Multi-statement valued functions Scalar returns the unit, variant defined the return clause. Other two types of defined functions return table. Let‚Äôs move to the next question in this SQL Interview Questions.

---

#### What do you mean by Collation?

Collation is defined as a set of rules that determine how data can be sorted as well as compared. Character data is sorted using the rules that define the correct character sequence along with options for specifying case-sensitivity, character width etc. Let‚Äôs move to the next question in this SQL Interview Questions.

---

#### What are the different types of Collation Sensitivity?

Following are the different types of collation sensitivity: Case Sensitivity: A and a and B and b. Kana Sensitivity: Japanese Kana characters. Width Sensitivity: Single byte character and double-byte character. Accent Sensitivity. Apart from this SQL Interview Questions Blog, if you want to get trained by professionals on this technology, you can opt for structured training from Edureka!

---

#### What are the Local and Global variables?

Local variables: These variables can be used or exist only inside the function. These variables are not used or referred to by any other function. Global variables: These variables are the variables which can be accessed throughout the program. Global variables cannot be created whenever that function is called.

---

#### What is Auto Increment in SQL?

Autoincrement keyword allows the user to create a unique number to get generated whenever a new record is inserted into the table. This keyword is usually required whenever PRIMARY KEY in SQL is used. AUTO INCREMENT keyword can be used in Oracle and IDENTITY keyword can be used in SQL SERVER.

---

#### What is a Datawarehouse?

Datawarehouse refers to a central repository of data where the data is assembled from multiple sources of information. Those data are consolidated, transformed and made available for mining as well as online processing. Warehouse data also has a subset of data called Data Marts.

---

#### What are the different authentication modes in SQL Server? How can it be changed?

Windows mode and Mixed Mode ‚Äì SQL and Windows. You can go to the steps below to change authentication mode in SQL Server: Click Start> Programs> Microsoft SQL Server and click SQL Enterprise Manager to run SQL Enterprise Manager from the Microsoft SQL Server program group. Then select the server from the Tools menu. Select SQL Server Configuration Properties and choose the Security page.

---

#### What are STUFF and REPLACE function?

STUFF Function: This function is used to overwrite existing character or inserts a string into another string. Syntax: STUFF(string_expression,start, length, replacement_characters) where, string_expression: it is the string that will have characters substituted start: This refers to the starting position length: It refers to the number of characters in the string which are substituted. replacement_string: They are the new characters which are injected in the string. REPLACE function: This function is used to replace the existing characters of all the occurrences. Syntax: REPLACE (string_expression, search_string, replacement_string) Here every search_string in the string_expression will be replaced with the replacement_string.

---

#### How do you add email validation using only one query?

You can use a regular expression within a SQL query to validate an email format. For example, in MySQL, you can do it like this: SELECT email FROM your_table_name WHERE email REGEXP ‚Äò^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+.[a-zA-Z]{2,}$‚Äô; This query selects the email column from your_table_name where the email matches the specified regular expression pattern for a valid email format.

---

#### Write a query to get the last record from a table.

To get the last record from a table, you can use a query like this: SELECT * FROM your_table_name ORDER BY your_primary_key_column DESC LIMIT 1; Replace your_table_name with the name of your table and your_primary_key_column with the primary key column that defines the order of records. The DESC keyword sorts the records in descending order, and LIMIT 1 ensures you only get the last record. So this brings us to the end of the SQL interview questions blog. I hope this set of SQL Interview Questions will help you ace your job interview. All the best for your interview! Apart from this SQL Interview Questions Blog, if you want to get trained from professionals on SQL, you can opt for a structured training from edureka! Click below to know more.

---

#### WITH CT AS

( SELECT title, AVG(salary) av FROM employee_pay GROUP BY title ) SELECT DISTINCT ep.employee_id, salary, CASE WHEN salary >= 2 * CT.av THEN 'Overpaid' ELSE'Underpaid' END AS status FROM employee_pay ep, CT WHERE salary >= (2 * CT.av) OR salary * 2 <  CT.av AND ep.title = CT.title ORDER BY employee_id;

---

#### SELECT DISTINCT o1.customer_id,c.customer_name

FROM orders_1398 o1 LEFT JOIN orders_1398 o2 ON o1.product_name = 'A' AND o2.product_name = 'B' AND o1.customer_id = o2.customer_id LEFT JOIN orders_1398 o3 ON o1.product_name = 'A' AND o3.product_name = 'C' AND o1.customer_id = o3.customer_id INNER JOIN customers_1398 c ON o1.customer_id = c.customer_id WHERE o1.product_name IS NOT NULL AND o2.product_name IS NOT NULL AND o3.product_name IS NULL;

---

#### SELECT query_name,

ROUND(AVG(rating::NUMERIC/position),2) AS quality, ROUND((COUNT(CASE WHEN rating < 3 THEN 1 ELSE NULL END)::NUMERIC/COUNT(*))*100,2) AS poor_query_percentage FROM queries_1211 GROUP BY query_name;

---

#### -- Question 115

-- Write an SQL query to report the distinct titles of the kid-friendly movies streamed in June 2020. -- Return the result table in any order. -- The query result format is in the following example. -- TVProgram table: -- +--------------------+--------------+-------------+ -- | program_date       | content_id   | channel     | -- +--------------------+--------------+-------------+ -- | 2020-06-10 08:00   | 1            | LC-Channel  | -- | 2020-05-11 12:00   | 2            | LC-Channel  | -- | 2020-05-12 12:00   | 3            | LC-Channel  | -- | 2020-05-13 14:00   | 4            | Disney Ch   | -- | 2020-06-18 14:00   | 4            | Disney Ch   | -- | 2020-07-15 16:00   | 5            | Disney Ch   | -- +--------------------+--------------+-------------+ -- Content table: -- +------------+----------------+---------------+---------------+ -- | content_id | title          | Kids_content  | content_type  | -- +------------+----------------+---------------+---------------+ -- | 1          | Leetcode Movie | N             | Movies        | -- | 2          | Alg. for Kids  | Y             | Series        | -- | 3          | Database Sols  | N             | Series        | -- | 4          | Aladdin        | Y             | Movies        | -- | 5          | Cinderella     | Y             | Movies        | -- +------------+----------------+---------------+---------------+ -- Result table: -- +--------------+ -- | title        | -- +--------------+ -- | Aladdin      | -- +--------------+ -- "Leetcode Movie" is not a content for kids. -- "Alg. for Kids" is not a movie. -- "Database Sols" is not a movie -- "Alladin" is a movie, content for kids and was streamed in June 2020. -- "Cinderella" was not streamed in June 2020. -- Solution select distinct title from (select content_id, title from content where kids_content = 'Y' and content_type = 'Movies') a join tvprogram using (content_id) where month(program_date) = 6

---

#### -- Question 1

-- Table: Users -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | id            | int     | -- | name          | varchar | -- +---------------+---------+ -- id is the primary key for this table. -- name is the name of the user. -- Table: Rides -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | id            | int     | -- | user_id       | int     | -- | distance      | int     | -- +---------------+---------+ -- id is the primary key for this table. -- user_id is the id of the user who travelled the distance "distance". -- Write an SQL query to report the distance travelled by each user. -- Return the result table ordered by travelled_distance in descending order, -- if two or more users travelled the same distance, order them by their name in ascending order. -- The query result format is in the following example. -- Users table: -- +------+-----------+ -- | id   | name      | -- +------+-----------+ -- | 1    | Alice     | -- | 2    | Bob       | -- | 3    | Alex      | -- | 4    | Donald    | -- | 7    | Lee       | -- | 13   | Jonathan  | -- | 19   | Elvis     | -- +------+-----------+ -- Rides table: -- +------+----------+----------+ -- | id   | user_id  | distance | -- +------+----------+----------+ -- | 1    | 1        | 120      | -- | 2    | 2        | 317      | -- | 3    | 3        | 222      | -- | 4    | 7        | 100      | -- | 5    | 13       | 312      | -- | 6    | 19       | 50       | -- | 7    | 7        | 120      | -- | 8    | 19       | 400      | -- | 9    | 7        | 230      | -- +------+----------+----------+ -- Result table: -- +----------+--------------------+ -- | name     | travelled_distance | -- +----------+--------------------+ -- | Elvis    | 450                | -- | Lee      | 450                | -- | Bob      | 317                | -- | Jonathan | 312                | -- | Alex     | 222                | -- | Alice    | 120                | -- | Donald   | 0                  | -- +----------+--------------------+ -- Elvis and Lee travelled 450 miles, Elvis is the top traveller as his name is alphabetically smaller than Lee. -- Bob, Jonathan, Alex and Alice have only one ride and we just order them by the total distances of the ride. -- Donald didn't have any rides, the distance travelled by him is 0. -- Solution Select U.name as name, coalesce(sum(R.distance),0) as travelled_distance from Users U left join Rides R on R.user_id = U.id group by name Order by travelled_distance desc, name

---

#### -- Question 77

-- Table: Friends -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | id            | int     | -- | name          | varchar | -- | activity      | varchar | -- +---------------+---------+ -- id is the id of the friend and primary key for this table. -- name is the name of the friend. -- activity is the name of the activity which the friend takes part in. -- Table: Activities -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | id            | int     | -- | name          | varchar | -- +---------------+---------+ -- id is the primary key for this table. -- name is the name of the activity. -- Write an SQL query to find the names of all the activities with neither maximum, nor minimum number of participants. -- Return the result table in any order. Each activity in table Activities is performed by any person in the table Friends. -- The query result format is in the following example: -- Friends table: -- +------+--------------+---------------+ -- | id   | name         | activity      | -- +------+--------------+---------------+ -- | 1    | Jonathan D.  | Eating        | -- | 2    | Jade W.      | Singing       | -- | 3    | Victor J.    | Singing       | -- | 4    | Elvis Q.     | Eating        | -- | 5    | Daniel A.    | Eating        | -- | 6    | Bob B.       | Horse Riding  | -- +------+--------------+---------------+ -- Activities table: -- +------+--------------+ -- | id   | name         | -- +------+--------------+ -- | 1    | Eating       | -- | 2    | Singing      | -- | 3    | Horse Riding | -- +------+--------------+ -- Result table: -- +--------------+ -- | activity     | -- +--------------+ -- | Singing      | -- +--------------+ -- Eating activity is performed by 3 friends, maximum number of participants, (Jonathan D. , Elvis Q. and Daniel A.) -- Horse Riding activity is performed by 1 friend, minimum number of participants, (Bob B.) -- Singing is performed by 2 friends (Victor J. and Jade W.) -- Solution with t1 as( select max(a.total) as total from( select activity, count(*) as total from friends group by activity) a union all select min(b.total) as low from( select activity, count(*) as total from friends group by activity) b), t2 as ( select activity, count(*) as total from friends group by activity ) select activity from t1 right join t2 on t1.total = t2.total where t1.total is null

---

#### -- Question 53

-- Table: Teams -- +---------------+----------+ -- | Column Name   | Type     | -- +---------------+----------+ -- | team_id       | int      | -- | team_name     | varchar  | -- +---------------+----------+ -- team_id is the primary key of this table. -- Each row of this table represents a single football team. -- Table: Matches -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | match_id      | int     | -- | host_team     | int     | -- | guest_team    | int     | -- | host_goals    | int     | -- | guest_goals   | int     | -- +---------------+---------+ -- match_id is the primary key of this table. -- Each row is a record of a finished match between two different teams. -- Teams host_team and guest_team are represented by their IDs in the teams table (team_id) and they scored host_goals and guest_goals goals respectively. -- You would like to compute the scores of all teams after all matches. Points are awarded as follows: -- A team receives three points if they win a match (Score strictly more goals than the opponent team). -- A team receives one point if they draw a match (Same number of goals as the opponent team). -- A team receives no points if they lose a match (Score less goals than the opponent team). -- Write an SQL query that selects the team_id, team_name and num_points of each team in the tournament after all described matches. Result table should be ordered by num_points (decreasing order). In case of a tie, order the records by team_id (increasing order). -- The query result format is in the following example: -- Teams table: -- +-----------+--------------+ -- | team_id   | team_name    | -- +-----------+--------------+ -- | 10        | Leetcode FC  | -- | 20        | NewYork FC   | -- | 30        | Atlanta FC   | -- | 40        | Chicago FC   | -- | 50        | Toronto FC   | -- +-----------+--------------+ -- Matches table: -- +------------+--------------+---------------+-------------+--------------+ -- | match_id   | host_team    | guest_team    | host_goals  | guest_goals  | -- +------------+--------------+---------------+-------------+--------------+ -- | 1          | 10           | 20            | 3           | 0            | -- | 2          | 30           | 10            | 2           | 2            | -- | 3          | 10           | 50            | 5           | 1            | -- | 4          | 20           | 30            | 1           | 0            | -- | 5          | 50           | 30            | 1           | 0            | -- +------------+--------------+---------------+-------------+--------------+ -- Result table: -- +------------+--------------+---------------+ -- | team_id    | team_name    | num_points    | -- +------------+--------------+---------------+ -- | 10         | Leetcode FC  | 7             | -- | 20         | NewYork FC   | 3             | -- | 50         | Toronto FC   | 3             | -- | 30         | Atlanta FC   | 1             | -- | 40         | Chicago FC   | 0             | -- +------------+--------------+---------------+ -- Solution with t1 as( Select c.host_id, c.host_name, c.host_points from( select a.match_id, a.team_id as host_id, a.team_name as host_name, b.team_id as guest_id, b.team_name as guest_name, a.host_goals, a.guest_goals, case when a.host_goals > a.guest_goals then 3 when a.host_goals = a.guest_goals then 1 else 0 end as host_points, case when a.host_goals < a.guest_goals then 3 when a.host_goals = a.guest_goals then 1 else 0 end as guest_points from( select * from matches m join teams t on t.team_id = m.host_team) a join (select * from matches m join teams t on t.team_id = m.guest_team) b on a.match_id = b.match_id) c union all Select d.guest_id, d.guest_name, d.guest_points from( select a.match_id, a.team_id as host_id, a.team_name as host_name, b.team_id as guest_id, b.team_name as guest_name, a.host_goals, a.guest_goals, case when a.host_goals > a.guest_goals then 3 when a.host_goals = a.guest_goals then 1 else 0 end as host_points, case when a.host_goals < a.guest_goals then 3 when a.host_goals = a.guest_goals then 1 else 0 end as guest_points from( select * from matches m join teams t on t.team_id = m.host_team) a join (select * from matches m join teams t on t.team_id = m.guest_team) b on a.match_id = b.match_id) d) Select team_id, team_name, coalesce(total,0) as num_points from teams t2 left join( select host_id, host_name, sum(host_points) as total from t1 group by host_id, host_name) e on t2.team_id = e.host_id order by num_points desc, team_id

---

#### -- Question 40

-- Table: Activity -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | user_id       | int     | -- | session_id    | int     | -- | activity_date | date    | -- | activity_type | enum    | -- +---------------+---------+ -- There is no primary key for this table, it may have duplicate rows. -- The activity_type column is an ENUM of type ('open_session', 'end_session', 'scroll_down', 'send_message'). -- The table shows the user activities for a social media website. -- Note that each session belongs to exactly one user. -- Write an SQL query to find the daily active user count for a period of 30 days ending 2019-07-27 inclusively. A user was active on some day if he/she made at least one activity on that day. -- The query result format is in the following example: -- Activity table: -- +---------+------------+---------------+---------------+ -- | user_id | session_id | activity_date | activity_type | -- +---------+------------+---------------+---------------+ -- | 1       | 1          | 2019-07-20    | open_session  | -- | 1       | 1          | 2019-07-20    | scroll_down   | -- | 1       | 1          | 2019-07-20    | end_session   | -- | 2       | 4          | 2019-07-20    | open_session  | -- | 2       | 4          | 2019-07-21    | send_message  | -- | 2       | 4          | 2019-07-21    | end_session   | -- | 3       | 2          | 2019-07-21    | open_session  | -- | 3       | 2          | 2019-07-21    | send_message  | -- | 3       | 2          | 2019-07-21    | end_session   | -- | 4       | 3          | 2019-06-25    | open_session  | -- | 4       | 3          | 2019-06-25    | end_session   | -- +---------+------------+---------------+---------------+ -- Result table: -- +------------+--------------+ -- | day        | active_users | -- +------------+--------------+ -- | 2019-07-20 | 2            | -- | 2019-07-21 | 2            | -- +------------+--------------+ -- Note that we do not care about days with zero active users. -- Solution Select activity_date as day, count(distinct user_id) as active_users from activity where activity_date > '2019-06-26' and activity_date < '2019-07-27' group by activity_date

---

#### SELECT p.post_id,COALESCE(STRING_AGG(DISTINCT k.topic_id::TEXT,',' ORDER BY k.topic_id::TEXT),'Ambiguous!') AS topic

FROM posts_2199 p LEFT JOIN keywords_2199 k ON POSITION(LOWER(' '||k.word||' ') IN LOWER(' '||p.content||' '))!=0 GROUP BY p.post_id;

---

#### SELECT COUNT(DISTINCT user_id) AS user_cnt

FROM purchases_2205 WHERE (DATE_TRUNC('DAY',time_stamp) BETWEEN '2022-03-08' AND '2022-03-20') AND amount >= 1000;

---

#### -- Question 38

-- Table: Delivery -- +-----------------------------+---------+ -- | Column Name                 | Type    | -- +-----------------------------+---------+ -- | delivery_id                 | int     | -- | customer_id                 | int     | -- | order_date                  | date    | -- | customer_pref_delivery_date | date    | -- +-----------------------------+---------+ -- delivery_id is the primary key of this table. -- The table holds information about food delivery to customers that make orders at some date and specify a preferred delivery date (on the same order date or after it). -- If the preferred delivery date of the customer is the same as the order date then the order is called immediate otherwise it's called scheduled. -- Write an SQL query to find the percentage of immediate orders in the table, rounded to 2 decimal places. -- The query result format is in the following example: -- Delivery table: -- +-------------+-------------+------------+-----------------------------+ -- | delivery_id | customer_id | order_date | customer_pref_delivery_date | -- +-------------+-------------+------------+-----------------------------+ -- | 1           | 1           | 2019-08-01 | 2019-08-02                  | -- | 2           | 5           | 2019-08-02 | 2019-08-02                  | -- | 3           | 1           | 2019-08-11 | 2019-08-11                  | -- | 4           | 3           | 2019-08-24 | 2019-08-26                  | -- | 5           | 4           | 2019-08-21 | 2019-08-22                  | -- | 6           | 2           | 2019-08-11 | 2019-08-13                  | -- +-------------+-------------+------------+-----------------------------+ -- Result table: -- +----------------------+ -- | immediate_percentage | -- +----------------------+ -- | 33.33                | -- +----------------------+ -- The orders with delivery id 2 and 3 are immediate while the others are scheduled. -- Solution Select Round(avg(case when order_date=customer_pref_delivery_date then 1 else 0 end)*100,2) as immediate_percentage from delivery

---

#### -- Question 55

-- Table: Employees -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | employee_id   | int     | -- | employee_name | varchar | -- | manager_id    | int     | -- +---------------+---------+ -- employee_id is the primary key for this table. -- Each row of this table indicates that the employee with ID employee_id and name employee_name reports his -- work to his/her direct manager with manager_id -- The head of the company is the employee with employee_id = 1. -- Write an SQL query to find employee_id of all employees that directly or indirectly report their work to the head of the company. -- The indirect relation between managers will not exceed 3 managers as the company is small. -- Return result table in any order without duplicates. -- The query result format is in the following example: -- Employees table: -- +-------------+---------------+------------+ -- | employee_id | employee_name | manager_id | -- +-------------+---------------+------------+ -- | 1           | Boss          | 1          | -- | 3           | Alice         | 3          | -- | 2           | Bob           | 1          | -- | 4           | Daniel        | 2          | -- | 7           | Luis          | 4          | -- | 8           | Jhon          | 3          | -- | 9           | Angela        | 8          | -- | 77          | Robert        | 1          | -- +-------------+---------------+------------+ -- Result table: -- +-------------+ -- | employee_id | -- +-------------+ -- | 2           | -- | 77          | -- | 4           | -- | 7           | -- +-------------+ -- The head of the company is the employee with employee_id 1. -- The employees with employee_id 2 and 77 report their work directly to the head of the company. -- The employee with employee_id 4 report his work indirectly to the head of the company 4 --> 2 --> 1. -- The employee with employee_id 7 report his work indirectly to the head of the company 7 --> 4 --> 2 --> 1. -- The employees with employee_id 3, 8 and 9 don't report their work to head of company directly or indirectly. -- Solution select employee_id from employees where manager_id = 1 and employee_id != 1 union select employee_id from employees where manager_id = any (select employee_id from employees where manager_id = 1 and employee_id != 1) union select employee_id from employees where manager_id = any (select employee_id from employees where manager_id = any (select employee_id from employees where manager_id = 1 and employee_id != 1))

---

#### CREATE OR REPLACE FUNCTION pivot_products_1777()

RETURNS TEXT LANGUAGE PLPGSQL AS $$ DECLARE stores_array TEXT[]; store_name TEXT; query_text TEXT := ''; BEGIN SELECT ARRAY_AGG(DISTINCT store ORDER BY store ASC) INTO stores_array FROM products_1777; query_text := query_text || 'SELECT product_id, '; FOREACH store_name IN ARRAY stores_array LOOP query_text := query_text || 'SUM(CASE WHEN store = ''' || store_name || ''' THEN price ELSE NULL END) AS "' || store_name || '",'; END LOOP; query_text := LEFT(query_text,LENGTH(query_text)-1); query_text := query_text || ' FROM products_1777 GROUP BY product_id ORDER BY product_id;'; RETURN query_text; END $$; SELECT pivot_products_1777(); /* SELECT product_id, SUM(CASE WHEN store = 'store1' THEN price ELSE NULL END) AS "store1", SUM(CASE WHEN store = 'store2' THEN price ELSE NULL END) AS "store2", SUM(CASE WHEN store = 'store3' THEN price ELSE NULL END) AS "store3" FROM products_1777 GROUP BY product_id ORDER BY product_id; */

---

#### WITH calls AS (

SELECT caller_id,recipient_id,call_time FROM calls_1972 UNION SELECT recipient_id,caller_id,call_time FROM calls_1972 ), first_last_calls AS ( SELECT *, MIN(call_time) OVER (PARTITION BY caller_id,EXTRACT(DAY FROM call_time)) AS first_call, MAX(call_time) OVER (PARTITION BY caller_id,EXTRACT(DAY FROM call_time)) AS last_call FROM calls ) SELECT DISTINCT f.caller_id AS user_id FROM first_last_calls f INNER JOIN first_last_calls l ON f.caller_id = l.caller_id AND f.recipient_id = l.recipient_id AND f.call_time = f.first_call AND l.call_time = l.last_call;

---

#### SELECT i.item_category AS "Category",

SUM(CASE WHEN EXTRACT(ISODOW FROM o.order_date)=1 THEN o.quantity ELSE 0 END) AS "Monday", SUM(CASE WHEN EXTRACT(ISODOW FROM o.order_date)=2 THEN o.quantity ELSE 0 END) AS "Tuesday", SUM(CASE WHEN EXTRACT(ISODOW FROM o.order_date)=3 THEN o.quantity ELSE 0 END) AS "Wednesday", SUM(CASE WHEN EXTRACT(ISODOW FROM o.order_date)=4 THEN o.quantity ELSE 0 END) AS "Thursday", SUM(CASE WHEN EXTRACT(ISODOW FROM o.order_date)=5 THEN o.quantity ELSE 0 END) AS "Friday", SUM(CASE WHEN EXTRACT(ISODOW FROM o.order_date)=6 THEN o.quantity ELSE 0 END) AS "Saturday", SUM(CASE WHEN EXTRACT(ISODOW FROM o.order_date)=7 THEN o.quantity ELSE 0 END) AS "Sunday" FROM items_1479 i LEFT JOIN orders_1479 o ON o.item_id=i.item_id::INT GROUP BY i.item_category ORDER BY i.item_category;

---

#### WITH cte AS (

SELECT activity,COUNT(activity) AS cnt FROM friends_1355 GROUP BY activity ), cte1 AS ( SELECT activity,cnt, MAX(cnt) OVER () AS max_cnt, MIN(cnt) OVER () AS min_cnt FROM cte ) SELECT activity FROM cte1 WHERE cnt <> max_cnt AND cnt <> min_cnt;

---

#### WITH running_total_passengers AS (

SELECT *, COUNT(passenger_id) OVER (PARTITION BY bus_id ORDER BY b.arrival_time) AS passengers FROM buses_2142 b LEFT JOIN passengers_2142 p ON p.arrival_time <= b.arrival_time ) SELECT r1.bus_id,r1.passengers-COALESCE(r2.passengers,0) AS passengers_cnt FROM running_total_passengers r1 LEFT JOIN running_total_passengers r2 ON r1.bus_id=r2.bus_id+1 ORDER BY r1.passengers,r1.bus_id; --(Here we have made an assumption that smaller bus_id arrived first which will not be the case always) -- Better Query WITH running_total_passengers AS ( SELECT b.bus_id,b.arrival_time AS bus_arrival_time, p.passenger_id,p.arrival_time AS passenger_arrival_time, COUNT(passenger_id) OVER (PARTITION BY bus_id ORDER BY b.arrival_time) AS passengers FROM buses_2142 b LEFT JOIN passengers_2142 p ON p.arrival_time <= b.arrival_time ) SELECT DISTINCT r1.bus_id,r1.passengers-COALESCE(r2.passengers,0) AS passengers_cnt FROM running_total_passengers r1 LEFT JOIN running_total_passengers r2 ON r1.bus_arrival_time > r2.bus_arrival_time AND r1.bus_id=r2.bus_id+1

---

#### SELECT question_id

FROM surveylog_578 GROUP BY question_id ORDER BY COUNT(CASE WHEN action='answer' THEN question_id ELSE NULL END)/COUNT(CASE WHEN action='show' THEN question_id ELSE NULL END) DESC LIMIT 1;

---

#### SELECT customer_id

FROM customers_1821 WHERE year = 2021 AND revenue > 0;

---

#### SELECT DISTINCT s.buyer_id

FROM sales_1082 s LEFT JOIN product_1082 p ON s.product_id = p.product_id WHERE p.product_name = 'S8' AND s.buyer_id NOT IN (SELECT s.buyer_id FROM sales_1082 s LEFT JOIN product_1082 p ON s.product_id = p.product_id WHERE p.product_name = 'iPhone');

---

#### -- Question 105

-- A U.S graduate school has students from Asia, Europe and America. The students' location information are stored in table student as below. -- | name   | continent | -- |--------|-----------| -- | Jack   | America   | -- | Pascal | Europe    | -- | Xi     | Asia      | -- | Jane   | America   | -- Pivot the continent column in this table so that each name is sorted alphabetically and displayed underneath its corresponding continent. The output headers should be America, Asia and Europe respectively. It is guaranteed that the student number from America is no less than either Asia or Europe. -- For the sample input, the output is: -- | America | Asia | Europe | -- |---------|------|--------| -- | Jack    | Xi   | Pascal | -- | Jane    |      |        | -- Solution select min(case when continent = 'America' then name end) as America, min(case when continent = 'Asia' then name end) as Asia, min(case when continent = 'Europe' then name end) as Europe from (select *, row_number() over(partition by continent order by name) as rn from student) a group by rn

---

#### -- Question 82

-- Table: Delivery -- +-----------------------------+---------+ -- | Column Name                 | Type    | -- +-----------------------------+---------+ -- | delivery_id                 | int     | -- | customer_id                 | int     | -- | order_date                  | date    | -- | customer_pref_delivery_date | date    | -- +-----------------------------+---------+ -- delivery_id is the primary key of this table. -- The table holds information about food delivery to customers that make orders at some date and specify a preferred delivery date (on the same order date or after it). -- If the preferred delivery date of the customer is the same as the order date then the order is called immediate otherwise it's called scheduled. -- The first order of a customer is the order with the earliest order date that customer made. It is guaranteed that a customer has exactly one first order. -- Write an SQL query to find the percentage of immediate orders in the first orders of all customers, rounded to 2 decimal places. -- The query result format is in the following example: -- Delivery table: -- +-------------+-------------+------------+-----------------------------+ -- | delivery_id | customer_id | order_date | customer_pref_delivery_date | -- +-------------+-------------+------------+-----------------------------+ -- | 1           | 1           | 2019-08-01 | 2019-08-02                  | -- | 2           | 2           | 2019-08-02 | 2019-08-02                  | -- | 3           | 1           | 2019-08-11 | 2019-08-12                  | -- | 4           | 3           | 2019-08-24 | 2019-08-24                  | -- | 5           | 3           | 2019-08-21 | 2019-08-22                  | -- | 6           | 2           | 2019-08-11 | 2019-08-13                  | -- | 7           | 4           | 2019-08-09 | 2019-08-09                  | -- +-------------+-------------+------------+-----------------------------+ -- Result table: -- +----------------------+ -- | immediate_percentage | -- +----------------------+ -- | 50.00                | -- +----------------------+ -- The customer id 1 has a first order with delivery id 1 and it is scheduled. -- The customer id 2 has a first order with delivery id 2 and it is immediate. -- The customer id 3 has a first order with delivery id 5 and it is scheduled. -- The customer id 4 has a first order with delivery id 7 and it is immediate. -- Hence, half the customers have immediate first orders. -- Solution select round(avg(case when order_date = customer_pref_delivery_date then 1 else 0 end)*100,2) as immediate_percentage from (select *, rank() over(partition by customer_id order by order_date) as rk from delivery) a where a.rk=1

---

#### SELECT stock_name,

SUM(CASE WHEN operation = 'Buy' THEN price * -1 ELSE price END) AS capital_gain_loss FROM stocks_1393 GROUP BY stock_name ORDER BY capital_gain_loss DESC;

---

#### WITH CT AS

( SELECT category, product, SUM(spend) AS total_spend, ROW_NUMBER() OVER(PARTITION BY category ORDER BY SUM(spend) DESC) AS RN FROM product_spend WHERE DATE_PART('year', transaction_date) = 2022 GROUP BY category, product ) SELECT category, product, total_spend FROM CT WHERE RN IN(1, 2)

---

#### -- Question 98

-- The Trips table holds all taxi trips. Each trip has a unique Id, while Client_Id and Driver_Id are both foreign keys to the Users_Id at the Users table. Status is an ENUM type of (‚Äòcompleted‚Äô, ‚Äòcancelled_by_driver‚Äô, ‚Äòcancelled_by_client‚Äô). -- +----+-----------+-----------+---------+--------------------+----------+ -- | Id | Client_Id | Driver_Id | City_Id |        Status      |Request_at| -- +----+-----------+-----------+---------+--------------------+----------+ -- | 1  |     1     |    10     |    1    |     completed      |2013-10-01| -- | 2  |     2     |    11     |    1    | cancelled_by_driver|2013-10-01| -- | 3  |     3     |    12     |    6    |     completed      |2013-10-01| -- | 4  |     4     |    13     |    6    | cancelled_by_client|2013-10-01| -- | 5  |     1     |    10     |    1    |     completed      |2013-10-02| -- | 6  |     2     |    11     |    6    |     completed      |2013-10-02| -- | 7  |     3     |    12     |    6    |     completed      |2013-10-02| -- | 8  |     2     |    12     |    12   |     completed      |2013-10-03| -- | 9  |     3     |    10     |    12   |     completed      |2013-10-03| -- | 10 |     4     |    13     |    12   | cancelled_by_driver|2013-10-03| -- +----+-----------+-----------+---------+--------------------+----------+ -- The Users table holds all users. Each user has an unique Users_Id, and Role is an ENUM type of (‚Äòclient‚Äô, ‚Äòdriver‚Äô, ‚Äòpartner‚Äô). -- +----------+--------+--------+ -- | Users_Id | Banned |  Role  | -- +----------+--------+--------+ -- |    1     |   No   | client | -- |    2     |   Yes  | client | -- |    3     |   No   | client | -- |    4     |   No   | client | -- |    10    |   No   | driver | -- |    11    |   No   | driver | -- |    12    |   No   | driver | -- |    13    |   No   | driver | -- +----------+--------+--------+ -- Write a SQL query to find the cancellation rate of requests made by unbanned users (both client and driver must be unbanned) between Oct 1, 2013 and Oct 3, 2013. The cancellation rate is computed by dividing the number of canceled (by client or driver) requests made by unbanned users by the total number of requests made by unbanned users. -- For the above tables, your SQL query should return the following rows with the cancellation rate being rounded to two decimal places. -- +------------+-------------------+ -- |     Day    | Cancellation Rate | -- +------------+-------------------+ -- | 2013-10-01 |       0.33        | -- | 2013-10-02 |       0.00        | -- | 2013-10-03 |       0.50        | -- +------------+-------------------+ -- Credits: -- Special thanks to @cak1erlizhou for contributing this question, writing the problem description and adding part of the test cases. -- Solution with t1 as( select request_at, count(status) as total from trips where client_id = any(select users_id from users where banned != 'Yes') and driver_id = any(select users_id from users where banned != 'Yes') and request_at between '2013-10-01' and '2013-10-03' group by request_at), t2 as ( select request_at, count(status) as cancel from trips where client_id = any(select users_id from users where banned != 'Yes') and driver_id = any(select users_id from users where banned != 'Yes') and request_at between '2013-10-01' and '2013-10-03' and status != 'completed' group by request_at ) select request_at as Day, coalesce(round((cancel+0.00)/(total+0.00),2),0) as "Cancellation Rate" from t1 left join t2 using(request_at)

---

#### Combine Two Tables | Easy | LeetCode

Table: Person +-------------+---------+ | Column Name | Type    | +-------------+---------+ | PersonId    | int     | | FirstName   | varchar | | LastName    | varchar | +-------------+---------+ PersonId is the primary key column for this table. Table: Address +-------------+---------+ | Column Name | Type    | +-------------+---------+ | AddressId   | int     | | PersonId    | int     | | City        | varchar | | State       | varchar | +-------------+---------+ AddressId is the primary key column for this table. Write a SQL query for a report that provides the following information for each person in the Person table, regardless if there is an address for each of those people: FirstName, LastName, City, State Solution sql SELECT p.FirstName, p.LastName, a.City, a.State FROM Person p LEFT JOIN Address a ON p.PersonId = a.PersonId;

---

#### Second Highest Salary | Easy | LeetCode

Write a SQL query to get the second highest salary from the Employee table. +----+--------+ | Id | Salary | +----+--------+ | 1  | 100    | | 2  | 200    | | 3  | 300    | +----+--------+ For example, given the above Employee table, the query should return 200 as the second highest salary. If there is no second highest salary, then the query should return null. +---------------------+ | SecondHighestSalary | +---------------------+ | 200                 | +---------------------+ Solution sql #Solution 1: SELECT Max(Salary) SecondHighestSalary FROM Employee WHERE Salary < (SELECT MAX(Salary) FROM Employee) #Solution 2: WITH CTE AS (SELECT DISTINCT Salary FROM Employee ORDER BY Salary DESC LIMIT 2) SELECT Salary as SecondHighestSalary FROM CTE ORDER BY Salary Asc LIMIT 1; #Solution 3: WITH CTE AS ( SELECT Salary, DENSE_RANK() OVER (ORDER BY Salary DESC) AS DENSERANK FROM Employee ) SELECT Salary SecondHighestSalary FROM CTE WHERE DENSERANK = 2;

---

#### Nth Highest Salary | Medium | LeetCode

Write a SQL query to get the nth highest salary from the Employee table. +----+--------+ | Id | Salary | +----+--------+ | 1  | 100    | | 2  | 200    | | 3  | 300    | +----+--------+ For example, given the above Employee table, the nth highest salary where n = 2 is 200. If there is no nth highest salary, then the query should return null. +------------------------+ | getNthHighestSalary(2) | +------------------------+ | 200                    | +------------------------+ Solution sql CREATE FUNCTION getNthHighestSalary(N INT) RETURNS INT BEGIN SET N = N-1; RETURN( SELECT DISTINCT Salary FROM Employee ORDER BY Salary DESC LIMIT 1 OFFSET N ); END

---

#### Rank Scores | Medium | LeetCode

Write a SQL query to rank scores. If there is a tie between two scores, both should have the same ranking. Note that after a tie, the next ranking number should be the next consecutive integer value. In other words, there should be no "holes" between ranks. +----+-------+ | Id | Score | +----+-------+ | 1  | 3.50  | | 2  | 3.65  | | 3  | 4.00  | | 4  | 3.85  | | 5  | 4.00  | | 6  | 3.65  | +----+-------+ For example, given the above Scores table, your query should generate the following report (order by highest score): +-------+---------+ | score | Rank    | +-------+---------+ | 4.00  | 1       | | 4.00  | 1       | | 3.85  | 2       | | 3.65  | 3       | | 3.65  | 3       | | 3.50  | 4       | +-------+---------+ Important Note: For MySQL solutions, to escape reserved words used as column names, you can use an apostrophe before and after the keyword. For example Rank. Solution sql SELECT score, DENSE_RANK() OVER (ORDER By Score DESC) AS "Rank" FROM Scores;

---

#### Consecutive Numbers | Medium | LeetCode

Table: Logs +-------------+---------+ | Column Name | Type    | +-------------+---------+ | id          | int     | | num         | varchar | +-------------+---------+ id is the primary key for this table. Write an SQL query to find all numbers that appear at least three times consecutively. Return the result table in any order. The query result format is in the following example: Logs table: +----+-----+ | Id | Num | +----+-----+ | 1  | 1   | | 2  | 1   | | 3  | 1   | | 4  | 2   | | 5  | 1   | | 6  | 2   | | 7  | 2   | +----+-----+ Result table: +-----------------+ | ConsecutiveNums | +-----------------+ | 1               | +-----------------+ 1 is the only number that appears consecutively for at least three times. Solution sql SELECT a.Num as ConsecutiveNums FROM Logs a JOIN Logs b ON a.id = b.id+1 AND a.num = b.num JOIN Logs c ON a.id = c.id+2 AND a.num = c.num;

---

#### Employees Earning More Than Their Managers | Easy | LeetCode

The Employee table holds all employees including their managers. Every employee has an Id, and there is also a column for the manager Id. +----+-------+--------+-----------+ | Id | Name  | Salary | ManagerId | +----+-------+--------+-----------+ | 1  | Joe   | 70000  | 3         | | 2  | Henry | 80000  | 4         | | 3  | Sam   | 60000  | NULL      | | 4  | Max   | 90000  | NULL      | +----+-------+--------+-----------+ Given the Employee table, write a SQL query that finds out employees who earn more than their managers. For the above table, Joe is the only employee who earns more than his manager. +----------+ | Employee | +----------+ | Joe      | +----------+ Solution sql SELECT E.Name as "Employee" FROM Employee E JOIN Employee M ON E.ManagerId = M.Id AND E.Salary > M.Salary;

---

#### Duplicate Emails | Easy | LeetCode

Write a SQL query to find all duplicate emails in a table named Person. +----+---------+ | Id | Email   | +----+---------+ | 1  | a@b.com | | 2  | c@d.com | | 3  | a@b.com | +----+---------+ For example, your query should return the following for the above table: +---------+ | Email   | +---------+ | a@b.com | +---------+ Note: All emails are in lowercase. Solution sql #Solution- 1: SELECT Email FROM Person GROUP BY Email HAVING count(*) > 1 #Solution- 2: WITH CTE AS( SELECT Email, ROW_NUMBER() OVER(PARTITION BY Email ORDER BY Email) AS RN FROM Person ) SELECT Email FROM CTE WHERE RN > 1;

---

#### Customers Who Never Order | Easy | LeetCode

Suppose that a website contains two tables, the Customers table and the Orders table. Write a SQL query to find all customers who never order anything. Table: Customers. +----+-------+ | Id | Name  | +----+-------+ | 1  | Joe   | | 2  | Henry | | 3  | Sam   | | 4  | Max   | +----+-------+ Table: Orders. +----+------------+ | Id | CustomerId | +----+------------+ | 1  | 3          | | 2  | 1          | +----+------------+ Using the above tables as example, return the following: +-----------+ | Customers | +-----------+ | Henry     | | Max       | +-----------+ Solution sql #Solution- 1: SELECT Name AS Customers FROM Customers LEFT JOIN Orders ON Customers.Id = Orders.CustomerId WHERE CustomerId IS NULL; #Solution- 2: SELECT Name as Customers FROM Customers WHERE Id NOT IN( SELECT CustomerId FROM Orders )

---

#### Department Highest Salary | Medium | LeetCode

The Employee table holds all employees. Every employee has an Id, a salary, and there is also a column for the department Id. +----+-------+--------+--------------+ | Id | Name  | Salary | DepartmentId | +----+-------+--------+--------------+ | 1  | Joe   | 70000  | 1            | | 2  | Jim   | 90000  | 1            | | 3  | Henry | 80000  | 2            | | 4  | Sam   | 60000  | 2            | | 5  | Max   | 90000  | 1            | +----+-------+--------+--------------+ The Department table holds all departments of the company. +----+----------+ | Id | Name     | +----+----------+ | 1  | IT       | | 2  | Sales    | +----+----------+ Write a SQL query to find employees who have the highest salary in each of the departments. For the above tables, your SQL query should return the following rows (order of rows does not matter). +------------+----------+--------+ | Department | Employee | Salary | +------------+----------+--------+ | IT         | Max      | 90000  | | IT         | Jim      | 90000  | | Sales      | Henry    | 80000  | +------------+----------+--------+ Explanation: Max and Jim both have the highest salary in the IT department and Henry has the highest salary in the Sales department. Solution sql SELECT Department.Name AS Department, Employee.Name AS Employee, Salary FROM Employee JOIN Department ON Employee.DepartmentId = Department.Id WHERE (DepartmentId, Salary) IN( SELECT  DepartmentId, MAX(Salary) AS Salary FROM Employee GROUP BY DepartmentId );

---

#### Department Top Three Salaries | Hard | LeetCode

The Employee table holds all employees. Every employee has an Id, and there is also a column for the department Id. +----+-------+--------+--------------+ | Id | Name` | Salary | DepartmentId | +----+-------+--------+--------------+ | 1  | Joe   | 85000  | 1            | | 2  | Henry | 80000  | 2            | | 3  | Sam   | 60000  | 2            | | 4  | Max   | 90000  | 1            | | 5  | Janet | 69000  | 1            | | 6  | Randy | 85000  | 1            | | 7  | Will  | 70000  | 1            | +----+-------+--------+--------------+ The Department table holds all departments of the company. +----+----------+ | Id | Name     | +----+----------+ | 1  | IT       | | 2  | Sales    | +----+----------+ Write a SQL query to find employees who earn the top three salaries in each of the department. For the above tables, your SQL query should return the following rows (order of rows does not matter). +------------+----------+--------+ | Department | Employee | Salary | +------------+----------+--------+ | IT         | Max      | 90000  | | IT         | Randy    | 85000  | | IT         | Joe      | 85000  | | IT         | Will     | 70000  | | Sales      | Henry    | 80000  | | Sales      | Sam      | 60000  | +------------+----------+--------+ Explanation: In IT department, Max earns the highest salary, both Randy and Joe earn the second highest salary, and Will earns the third highest salary. There are only two employees in the Sales department, Henry earns the highest salary while Sam earns the second highest salary. Solution sql WITH department_ranking AS ( SELECT Name AS Employee, Salary ,DepartmentId ,DENSE_RANK() OVER (PARTITION BY DepartmentId ORDER BY Salary DESC) AS rnk FROM Employee ) SELECT d.Name AS Department, r.Employee, r.Salary FROM department_ranking AS r JOIN Department AS d ON r.DepartmentId = d.Id WHERE r.rnk <= 3 ORDER BY d.Name ASC, r.Salary DESC;

---

#### Delete Duplicate Emails | Easy | LeetCode

Write a SQL query to delete all duplicate email entries in a table named Person, keeping only unique emails based on its smallest Id. +----+------------------+ | Id | Email            | +----+------------------+ | 1  | john@example.com | | 2  | bob@example.com  | | 3  | john@example.com | +----+------------------+ Id is the primary key column for this table. For example, after running your query, the above Person table should have the following rows: +----+------------------+ | Id | Email            | +----+------------------+ | 1  | john@example.com | | 2  | bob@example.com  | +----+------------------+ Note: Your output is the whole Person table after executing your sql. Use delete statement. Solution sql DELETE p2 FROM Person p1 JOIN Person p2 ON p1.Email = p2.Email AND p1.id < p2.id

---

#### Rising Temperature | Easy | LeetCode

Table: Weather +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | id            | int     | | recordDate    | date    | | temperature   | int     | +---------------+---------+ id is the primary key for this table. This table contains information about the temperature in a certain day. Write an SQL query to find all dates' id with higher temperature compared to its previous dates (yesterday). Return the result table in any order. The query result format is in the following example: Weather +----+------------+-------------+ | id | recordDate | Temperature | +----+------------+-------------+ | 1  | 2015-01-01 | 10          | | 2  | 2015-01-02 | 25          | | 3  | 2015-01-03 | 20          | | 4  | 2015-01-04 | 30          | +----+------------+-------------+ Result table: +----+ | id | +----+ | 2  | | 4  | +----+ In 2015-01-02, temperature was higher than the previous day (10 -> 25). In 2015-01-04, temperature was higher than the previous day (20 -> 30). Solution sql #Solution- 1: SELECT t.Id FROM Weather AS t, Weather AS y WHERE DATEDIFF(t.RecordDate, y.RecordDate) = 1 AND t.Temperature > y.Temperature; #Solution- 2: SELECT t.Id FROM Weather t JOIN Weather y ON DATEDIFF(t.recordDate, y.recordDate) = 1 AND t.temperature > y.temperature;

---

#### Trips and Users | Hard | LeetCode

Table: Trips +-------------+----------+ | Column Name | Type     | +-------------+----------+ | Id          | int      | | Client_Id   | int      | | Driver_Id   | int      | | City_Id     | int      | | Status      | enum     | | Request_at  | date     | +-------------+----------+ Id is the primary key for this table. The table holds all taxi trips. Each trip has a unique Id, while Client_Id and Driver_Id are foreign keys to the Users_Id at the Users table. Status is an ENUM type of (‚Äòcompleted‚Äô, ‚Äòcancelled_by_driver‚Äô, ‚Äòcancelled_by_client‚Äô). Table: Users +-------------+----------+ | Column Name | Type     | +-------------+----------+ | Users_Id    | int      | | Banned      | enum     | | Role        | enum     | +-------------+----------+ Users_Id is the primary key for this table. The table holds all users. Each user has a unique Users_Id, and Role is an ENUM type of (‚Äòclient‚Äô, ‚Äòdriver‚Äô, ‚Äòpartner‚Äô). Status is an ENUM type of (‚ÄòYes‚Äô, ‚ÄòNo‚Äô). Write a SQL query to find the cancellation rate of requests with unbanned users (both client and driver must not be banned) each day between "2013-10-01" and "2013-10-03". The cancellation rate is computed by dividing the number of canceled (by client or driver) requests with unbanned users by the total number of requests with unbanned users on that day. Return the result table in any order. Round Cancellation Rate to two decimal points. The query result format is in the following example: Trips table: +----+-----------+-----------+---------+---------------------+------------+ | Id | Client_Id | Driver_Id | City_Id | Status              | Request_at | +----+-----------+-----------+---------+---------------------+------------+ | 1  | 1         | 10        | 1       | completed           | 2013-10-01 | | 2  | 2         | 11        | 1       | cancelled_by_driver | 2013-10-01 | | 3  | 3         | 12        | 6       | completed           | 2013-10-01 | | 4  | 4         | 13        | 6       | cancelled_by_client | 2013-10-01 | | 5  | 1         | 10        | 1       | completed           | 2013-10-02 | | 6  | 2         | 11        | 6       | completed           | 2013-10-02 | | 7  | 3         | 12        | 6       | completed           | 2013-10-02 | | 8  | 2         | 12        | 12      | completed           | 2013-10-03 | | 9  | 3         | 10        | 12      | completed           | 2013-10-03 | | 10 | 4         | 13        | 12      | cancelled_by_driver | 2013-10-03 | +----+-----------+-----------+---------+---------------------+------------+ Users table: +----------+--------+--------+ | Users_Id | Banned | Role   | +----------+--------+--------+ | 1        | No     | client | | 2        | Yes    | client | | 3        | No     | client | | 4        | No     | client | | 10       | No     | driver | | 11       | No     | driver | | 12       | No     | driver | | 13       | No     | driver | +----------+--------+--------+ Result table: +------------+-------------------+ | Day        | Cancellation Rate | +------------+-------------------+ | 2013-10-01 | 0.33              | | 2013-10-02 | 0.00              | | 2013-10-03 | 0.50              | +------------+-------------------+ On 2013-10-01: - There were 4 requests in total, 2 of which were canceled. - However, the request with Id=2 was made by a banned client (User_Id=2), so it is ignored in the calculation. - Hence there are 3 unbanned requests in total, 1 of which was canceled. - The Cancellation Rate is (1 / 3) = 0.33 On 2013-10-02: - There were 3 requests in total, 0 of which were canceled. - The request with Id=6 was made by a banned client, so it is ignored. - Hence there are 2 unbanned requests in total, 0 of which were canceled. - The Cancellation Rate is (0 / 2) = 0.00 On 2013-10-03: - There were 3 requests in total, 1 of which was canceled. - The request with Id=8 was made by a banned client, so it is ignored. - Hence there are 2 unbanned request in total, 1 of which were canceled. - The Cancellation Rate is (1 / 2) = 0.50 Solution sql SELECT Request_at AS Day, ROUND(SUM(IF(Status<>"completed", 1, 0))/COUNT(Status),2) AS "Cancellation Rate" FROM Trips WHERE Request_at BETWEEN "2013-10-01" AND "2013-10-03" AND Client_Id NOT IN (SELECT Users_Id FROM Users WHERE Banned = 'Yes') AND Driver_Id NOT IN (SELECT Users_Id FROM Users WHERE Banned = 'Yes') GROUP BY Request_at;

---

#### Game Play Analysis I | Easy | üîí LeetCode

Table: Activity +--------------+---------+ | Column Name  | Type    | +--------------+---------+ | player_id    | int     | | device_id    | int     | | event_date   | date    | | games_played | int     | +--------------+---------+ (player_id, event_date) is the primary key of this table. This table shows the activity of players of some game. Each row is a record of a player who logged in and played a number of games (possibly 0) before logging out on some day using some device. Write an SQL query that reports the first login date for each player. The query result format is in the following example: Activity table: +-----------+-----------+------------+--------------+ | player_id | device_id | event_date | games_played | +-----------+-----------+------------+--------------+ | 1         | 2         | 2016-03-01 | 5            | | 1         | 2         | 2016-05-02 | 6            | | 2         | 3         | 2017-06-25 | 1            | | 3         | 1         | 2016-03-02 | 0            | | 3         | 4         | 2018-07-03 | 5            | +-----------+-----------+------------+--------------+ Result table: +-----------+-------------+ | player_id | first_login | +-----------+-------------+ | 1         | 2016-03-01  | | 2         | 2017-06-25  | | 3         | 2016-03-02  | +-----------+-------------+ Solution sql SELECT player_id, MIN(event_date) as first_login FROM Activity GROUP BY player_id

---

#### Game Play Analysis II | Easy | üîí LeetCode

Table: Activity +--------------+---------+ | Column Name  | Type    | +--------------+---------+ | player_id    | int     | | device_id    | int     | | event_date   | date    | | games_played | int     | +--------------+---------+ (player_id, event_date) is the primary key of this table. This table shows the activity of players of some game. Each row is a record of a player who logged in and played a number of games (possibly 0) before logging out on some day using some device. Write a SQL query that reports the device that is first logged in for each player. The query result format is in the following example: Activity table: +-----------+-----------+------------+--------------+ | player_id | device_id | event_date | games_played | +-----------+-----------+------------+--------------+ | 1         | 2         | 2016-03-01 | 5            | | 1         | 2         | 2016-05-02 | 6            | | 2         | 3         | 2017-06-25 | 1            | | 3         | 1         | 2016-03-02 | 0            | | 3         | 4         | 2018-07-03 | 5            | +-----------+-----------+------------+--------------+ Result table: +-----------+-----------+ | player_id | device_id | +-----------+-----------+ | 1         | 2         | | 2         | 3         | | 3         | 1         | +-----------+-----------+ Solution sql #Solution- 1: SELECT DISTINCT player_id, device_id FROM Activity WHERE (player_id, event_date) in ( SELECT player_id, min(event_date) FROM Activity GROUP BY player_id) #Solution- 2: SELECT a.player_id, b.device_id FROM (SELECT player_id, MIN(event_date) AS event_date FROM Activity GROUP BY player_id) a JOIN Activity b ON a.player_id = b.player_id AND a.event_date = b.event_date; #Solution- 3: SELECT player_id, device_id FROM (SELECT player_id, device_id, event_date, ROW_NUMBER() OVER (PARTITION BY player_id ORDER BY event_date) AS r FROM Activity) lookup WHERE r = 1;

---

#### Game Play Analysis III | Medium | üîí LeetCode

Table: Activity +--------------+---------+ | Column Name  | Type    | +--------------+---------+ | player_id    | int     | | device_id    | int     | | event_date   | date    | | games_played | int     | +--------------+---------+ (player_id, event_date) is the primary key of this table. This table shows the activity of players of some game. Each row is a record of a player who logged in and played a number of games (possibly 0) before logging out on some day using some device. Write an SQL query that reports for each player and date, how many games played so far by the player. That is, the total number of games played by the player until that date. Check the example for clarity. The query result format is in the following example: Activity table: +-----------+-----------+------------+--------------+ | player_id | device_id | event_date | games_played | +-----------+-----------+------------+--------------+ | 1         | 2         | 2016-03-01 | 5            | | 1         | 2         | 2016-05-02 | 6            | | 1         | 3         | 2017-06-25 | 1            | | 3         | 1         | 2016-03-02 | 0            | | 3         | 4         | 2018-07-03 | 5            | +-----------+-----------+------------+--------------+ Result table: +-----------+------------+---------------------+ | player_id | event_date | games_played_so_far | +-----------+------------+---------------------+ | 1         | 2016-03-01 | 5                   | | 1         | 2016-05-02 | 11                  | | 1         | 2017-06-25 | 12                  | | 3         | 2016-03-02 | 0                   | | 3         | 2018-07-03 | 5                   | +-----------+------------+---------------------+ For the player with id 1, 5 + 6 = 11 games played by 2016-05-02, and 5 + 6 + 1 = 12 games played by 2017-06-25. For the player with id 3, 0 + 5 = 5 games played by 2018-07-03. Note that for each player we only care about the days when the player logged in. Solution sql #Solution- 1: SELECT t1.player_id, t1.event_date, SUM(t2.games_played) as games_played_so_far FROM Activity t1 JOIN Activity t2 ON t1.player_id = t2.player_id WHERE t1.event_date >= t2.event_date GROUP BY t1.player_id, t1.event_date; #Solution- 2: SELECT player_id, event_date, SUM(games_played) OVER (PARTITION BY player_id ORDER BY event_date) AS games_played_so_far FROM Activity;

---

#### Game Play Analysis IV | Medium | üîí LeetCode

Table: Activity +--------------+---------+ | Column Name  | Type    | +--------------+---------+ | player_id    | int     | | device_id    | int     | | event_date   | date    | | games_played | int     | +--------------+---------+ (player_id, event_date) is the primary key of this table. This table shows the activity of players of some game. Each row is a record of a player who logged in and played a number of games (possibly 0) before logging out on some day using some device. Write an SQL query that reports the fraction of players that logged in again on the day after the day they first logged in, rounded to 2 decimal places. In other words, you need to count the number of players that logged in for at least two consecutive days starting from their first login date, then divide that number by the total number of players. The query result format is in the following example: Activity table: +-----------+-----------+------------+--------------+ | player_id | device_id | event_date | games_played | +-----------+-----------+------------+--------------+ | 1         | 2         | 2016-03-01 | 5            | | 1         | 2         | 2016-03-02 | 6            | | 2         | 3         | 2017-06-25 | 1            | | 3         | 1         | 2016-03-02 | 0            | | 3         | 4         | 2018-07-03 | 5            | +-----------+-----------+------------+--------------+ Result table: +-----------+ | fraction  | +-----------+ | 0.33      | +-----------+ Only the player with id 1 logged back in after the first day he had logged in so the answer is 1/3 = 0.33 Solution sql #Solution- 1: SELECT ROUND(sum(CASE WHEN t1.event_date = t2.first_event+1 THEN 1 ELSE 0 END)/COUNT(DISTINCT t1.player_id), 2) AS fraction FROM Activity t1 JOIN (SELECT player_id, MIN(event_date) AS first_event FROM Activity GROUP BY player_id) t2 ON t1.player_id = t2.player_id; #Solution- 2: SELECT ROUND(COUNT(DISTINCT b.player_id)/COUNT(DISTINCT a.player_id),2) AS fraction FROM (SELECT player_id, MIN(event_date) AS event_date FROM Activity GROUP BY player_id) a LEFT JOIN Activity b ON a.player_id = b.player_id AND a.event_date+1 = b.event_date;

---

#### Median Employee Salary | Hard | üîí LeetCode

The Employee table holds all employees. The employee table has three columns: Employee Id, Company Name, and Salary. +-----+------------+--------+ |Id   | Company    | Salary | +-----+------------+--------+ |1    | A          | 2341   | |2    | A          | 341    | |3    | A          | 15     | |4    | A          | 15314  | |5    | A          | 451    | |6    | A          | 513    | |7    | B          | 15     | |8    | B          | 13     | |9    | B          | 1154   | |10   | B          | 1345   | |11   | B          | 1221   | |12   | B          | 234    | |13   | C          | 2345   | |14   | C          | 2645   | |15   | C          | 2645   | |16   | C          | 2652   | |17   | C          | 65     | +-----+------------+--------+ Write a SQL query to find the median salary of each company. Bonus points if you can solve it without using any built-in SQL functions. +-----+------------+--------+ |Id   | Company    | Salary | +-----+------------+--------+ |5    | A          | 451    | |6    | A          | 513    | |12   | B          | 234    | |9    | B          | 1154   | |14   | C          | 2645   | +-----+------------+--------+ Solution sql SELECT t1.Id AS Id, t1.Company, t1.Salary FROM Employee AS t1 JOIN Employee AS t2 ON t1.Company = t2.Company GROUP BY t1.Id HAVING abs(sum(CASE WHEN t2.Salary<t1.Salary THEN 1 WHEN t2.Salary>t1.Salary THEN -1 WHEN t2.Salary=t1.Salary AND t2.Id<t1.Id THEN 1 WHEN t2.Salary=t1.Salary AND t2.Id>t1.Id THEN -1 ELSE 0 END)) <= 1 ORDER BY t1.Company, t1.Salary, t1.Id

---

#### Managers with at Least 5 Direct Reports | Medium | üîí LeetCode

The Employee table holds all employees including their managers. Every employee has an Id, and there is also a column for the manager Id. +------+----------+-----------+----------+ |Id    |Name 	    |Department |ManagerId | +------+----------+-----------+----------+ |101   |John 	    |A 	        |null      | |102   |Dan 	    |A 	        |101       | |103   |James 	  |A 	        |101       | |104   |Amy 	    |A 	        |101       | |105   |Anne 	    |A 	        |101       | |106   |Ron 	    |B 	        |101       | +------+----------+-----------+----------+ Given the Employee table, write a SQL query that finds out managers with at least 5 direct report. For the above table, your SQL query should return: +-------+ | Name  | +-------+ | John  | +-------+ Note: No one would report to himself. Solution sql SELECT Name FROM Employee WHERE id IN (SELECT ManagerId FROM Employee GROUP BY ManagerId HAVING COUNT(DISTINCT Id) >= 5)

---

#### Find Median Given Frequency of Numbers | üîí LeetCode

The Numbers table keeps the value of number and its frequency. +----------+-------------+ |  Number  |  Frequency  | +----------+-------------| |  0       |  7          | |  1       |  1          | |  2       |  3          | |  3       |  1          | +----------+-------------+ In this table, the numbers are 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 3, so the median is (0 + 0) / 2 = 0. +--------+ | median | +--------| | 0.0000 | +--------+ Write a query to find the median of all numbers and name the result as median. Solution sql SELECT avg(t3.Number) as median FROM Numbers as t3 JOIN (SELECT t1.Number, abs(SUM(CASE WHEN t1.Number>t2.Number THEN t2.Frequency ELSE 0 END) - SUM(CASE WHEN t1.Number<t2.Number THEN t2.Frequency ELSE 0 END)) AS count_diff FROM numbers AS t1, numbers AS t2 GROUP BY t1.Number) AS t4 ON t3.Number = t4.Number WHERE t3.Frequency>=t4.count_diff

---

#### Winning Candidate | Medium | üîí LeetCode

Table: Candidate +-----+---------+ | id  | Name    | +-----+---------+ | 1   | A       | | 2   | B       | | 3   | C       | | 4   | D       | | 5   | E       | +-----+---------+ Table: Vote +-----+--------------+ | id  | CandidateId  | +-----+--------------+ | 1   |     2        | | 2   |     4        | | 3   |     3        | | 4   |     2        | | 5   |     5        | +-----+--------------+ id is the auto-increment primary key, CandidateId is the id appeared in Candidate table. Write a sql to find the name of the winning candidate, the above example will return the winner B. +------+ | Name | +------+ | B    | +------+ Notes: You may assume there is no tie, in other words there will be at most one winning candidate. Solution sql SELECT Name FROM Candidate WHERE id = (SELECT CandidateId FROM Vote GROUP BY CandidateId ORDER BY COUNT(1) desc LIMIT 1) ## Assumption: if we have two candidates with the same votes, we choose the one who get the first vote # SELECT Name # FROM Candidate JOIN #     (SELECT CandidateId #     FROM Vote #     GROUP BY CandidateId #     ORDER BY count(1) DESC #     LIMIT 1) AS t # ON Candidate.id = t.CandidateId

---

#### Employee Bonus | Easy | üîí LeetCode

Select all employee‚Äôs name and bonus whose bonus is < 1000. Table:Employee +-------+--------+-----------+--------+ | empId |  name  | supervisor| salary | +-------+--------+-----------+--------+ |   1   | John   |  3        | 1000   | |   2   | Dan    |  3        | 2000   | |   3   | Brad   |  null     | 4000   | |   4   | Thomas |  3        | 4000   | +-------+--------+-----------+--------+ empId is the primary key column for this table. Table: Bonus +-------+-------+ | empId | bonus | +-------+-------+ | 2     | 500   | | 4     | 2000  | +-------+-------+ empId is the primary key column for this table. Example ouput: +-------+-------+ | name  | bonus | +-------+-------+ | John  | null  | | Dan   | 500   | | Brad  | null  | +-------+-------+ Solution sql SELECT name, bonus FROM Employee LEFT JOIN Bonus ON Employee.empId = Bonus.empId WHERE bonus<1000 OR bonus IS NULL;

---

#### Get Highest Answer Rate Question | Medium | üîí LeetCode

Get the highest answer rate question from a table survey_log with these columns: uid, action, question_id, answer_id, q_num, timestamp. uid means user id; action has these kind of values: ‚Äúshow‚Äù, ‚Äúanswer‚Äù, ‚Äúskip‚Äù; answer_id is not null when action column is ‚Äúanswer‚Äù, while is null for ‚Äúshow‚Äù and ‚Äúskip‚Äù; q_num is the numeral order of the question in current session. Write a sql query to identify the question which has the highest answer rate. Example: Input: +------+-----------+--------------+------------+-----------+------------+ | uid  | action    | question_id  | answer_id  | q_num     | timestamp  | +------+-----------+--------------+------------+-----------+------------+ | 5    | show      | 285          | null       | 1         | 123        | | 5    | answer    | 285          | 124124     | 1         | 124        | | 5    | show      | 369          | null       | 2         | 125        | | 5    | skip      | 369          | null       | 2         | 126        | +------+-----------+--------------+------------+-----------+------------+ Output: +-------------+ | survey_log  | +-------------+ |    285      | +-------------+ Explanation: question 285 has answer rate 1/1, while question 369 has 0/1 answer rate, so output 285. Note: The highest answer rate meaning is: answer number‚Äôs ratio in show number in the same question. Solution sql #Solution- 1:: SELECT question_id AS survey_log FROM (SELECT question_id, SUM(IF(action='show', 1, 0)) AS num_show, SUM(IF(action='answer', 1, 0)) AS num_answer FROM survey_log GROUP BY question_id) AS t ORDER BY (num_answer/num_show) DESC LIMIT 1; #Solution- 2: SELECT question_id AS survey_log FROM (SELECT question_id, sum(CASE WHEN  action='show' THEN 1 ELSE 0 END) AS show_count, sum(CASE WHEN  action='answer' THEN 1 ELSE 0 END) AS answer_count FROM survey_log GROUP BY question_id) AS t ORDER BY answer_count/show_count DESC LIMIT 1;

---

#### Find Cumulative Salary of an Employee | Hard | üîí LeetCode

The Employee table holds the salary information in a year. Write a SQL to get the cumulative sum of an employee‚Äôs salary over a period of 3 months but exclude the most recent month. The result should be displayed by ‚ÄòId‚Äô ascending, and then by ‚ÄòMonth‚Äô descending. Example Input | Id | Month | Salary | |----|-------|--------| | 1  | 1     | 20     | | 2  | 1     | 20     | | 1  | 2     | 30     | | 2  | 2     | 30     | | 3  | 2     | 40     | | 1  | 3     | 40     | | 3  | 3     | 60     | | 1  | 4     | 60     | | 3  | 4     | 70     | Output | Id | Month | Salary | |----|-------|--------| | 1  | 3     | 90     | | 1  | 2     | 50     | | 1  | 1     | 20     | | 2  | 1     | 20     | | 3  | 3     | 100    | | 3  | 2     | 40     | Explanation Employee ‚Äò1‚Äô has 3 salary records for the following 3 months except the most recent month ‚Äò4‚Äô: salary 40 for month ‚Äò3‚Äô, 30 for month ‚Äò2‚Äô and 20 for month ‚Äò1‚Äô So the cumulative sum of salary of this employee over 3 months is 90(40+30+20), 50(30+20) and 20 respectively. | Id | Month | Salary | |----|-------|--------| | 1  | 3     | 90     | | 1  | 2     | 50     | | 1  | 1     | 20     | Employee ‚Äò2‚Äô only has one salary record (month ‚Äò1‚Äô) except its most recent month ‚Äò2‚Äô. | Id | Month | Salary | |----|-------|--------| | 2  | 1     | 20     | Employ ‚Äò3‚Äô has two salary records except its most recent pay month ‚Äò4‚Äô: month ‚Äò3‚Äô with 60 and month ‚Äò2‚Äô with 40. So the cumulative salary is as following. | Id | Month | Salary | |----|-------|--------| | 3  | 3     | 100    | | 3  | 2     | 40     | Solution sql SELECT id, month, SUM(b.salary) Salary FROM Employee a JOIN Employee b ON id = b.id AND month - b.month >= 0 AND month - b.month < 3 GROUP BY id, a.month HAVING (a.id, a.month) NOT IN (SELECT id, MAX(month) FROM Employee GROUP BY id) ORDER BY id, a.month DESC

---

#### Count Student Number in Departments | Medium | üîí LeetCode

A university uses 2 data tables, student and department, to store data about its students and the departments associated with each major. Write a query to print the respective department name and number of students majoring in each department for all departments in the department table (even ones with no current students). Sort your results by descending number of students; if two or more departments have the same number of students, then sort those departments alphabetically by department name. The student is described as follow: | Column Name  | Type      | |--------------|-----------| | student_id   | Integer   | | student_name | String    | | gender       | Character | | dept_id      | Integer   | where student_id is the student‚Äôs ID number, student_name is the student‚Äôs name, gender is their gender, and dept_id is the department ID associated with their declared major. And the department table is described as below: | Column Name | Type    | |-------------|---------| | dept_id     | Integer | | dept_name   | String  | where dept_id is the department‚Äôs ID number and dept_name is the department name. Here is an example input: student table: | student_id | student_name | gender | dept_id | |------------|--------------|--------|---------| | 1          | Jack         | M      | 1       | | 2          | Jane         | F      | 1       | | 3          | Mark         | M      | 2       | department table: | dept_id | dept_name   | |---------|-------------| | 1       | Engineering | | 2       | Science     | | 3       | Law         | The Output should be: | dept_name   | student_number | |-------------|----------------| | Engineering | 2              | | Science     | 1              | | Law         | 0              | Solution sql SELECT dept_name, SUM(CASE WHEN student_id IS NULL THEN 0 ELSE 1 END) AS student_number FROM department LEFT JOIN student ON department.dept_id = student.dept_id GROUP BY department.dept_id ORDER BY student_number DESC, dept_name

---

#### Find Customer Referee | Easy | üîí LeetCode

Given a table customer holding customers information and the referee. +------+------+-----------+ | id   | name | referee_id| +------+------+-----------+ |    1 | Will |      NULL | |    2 | Jane |      NULL | |    3 | Alex |         2 | |    4 | Bill |      NULL | |    5 | Zack |         1 | |    6 | Mark |         2 | +------+------+-----------+ Write a query to return the list of customers NOT referred by the person with id ‚Äò2‚Äô. For the sample data above, the result is: +------+ | name | +------+ | Will | | Jane | | Bill | | Zack | +------+ Solution sql SELECT name FROM customer WHERE referee_id != '2' OR referee_id IS NULL;

---

#### Investments in 2016 | Medium | üîí LeetCode

Write a query to print the sum of all total investment values in 2016 (TIV_2016), to a scale of 2 decimal places, for all policy holders who meet the following criteria: Have the same TIV_2015 value as one or more other policyholders. Are not located in the same city as any other policyholder (i.e.: the (latitude, longitude) attribute pairs must be unique). Input Format: The insurance table is described as follows: | Column Name | Type          | |-------------|---------------| | PID         | INTEGER(11)   | | TIV_2015    | NUMERIC(15,2) | | TIV_2016    | NUMERIC(15,2) | | LAT         | NUMERIC(5,2)  | | LON         | NUMERIC(5,2)  | where PID is the policyholder‚Äôs policy ID, TIV_2015 is the total investment value in 2015, TIV_2016 is the total investment value in 2016, LAT is the latitude of the policy holder‚Äôs city, and LON is the longitude of the policy holder‚Äôs city. Sample Input | PID | TIV_2015 | TIV_2016 | LAT | LON | |-----|----------|----------|-----|-----| | 1   | 10       | 5        | 10  | 10  | | 2   | 20       | 20       | 20  | 20  | | 3   | 10       | 30       | 20  | 20  | | 4   | 10       | 40       | 40  | 40  | Sample Output | TIV_2016 | |----------| | 45.00    | Explanation The first record in the table, like the last record, meets both of the two criteria. The TIV_2015 value '10' is as the same as the third and forth record, and its location unique. The second record does not meet any of the two criteria. Its TIV_2015 is not like any other policyholders. And its location is the same with the third record, which makes the third record fail, too. So, the result is the sum of TIV_2016 of the first and last record, which is 45. Solution sql SELECT SUM(TIV_2016) AS TIV_2016 FROM insurance WHERE CONCAT(LAT, ',', LON) IN (SELECT CONCAT(LAT, ',', LON) FROM insurance GROUP BY LAT, LON HAVING COUNT(1) = 1) AND TIV_2015 in (SELECT TIV_2015 FROM insurance GROUP BY TIV_2015 HAVING COUNT(1)>1)

---

#### Customer Placing the Largest Number of Orders | Easy | üîí LeetCode

Query the customer_number from the orders table for the customer who has placed the largest number of orders. It is guaranteed that exactly one customer will have placed more orders than any other customer. The orders table is defined as follows: | Column            | Type      | |-------------------|-----------| | order_number (PK) | int       | | customer_number   | int       | | order_date        | date      | | required_date     | date      | | shipped_date      | date      | | status            | char(15)  | | comment           | char(200) | Sample Input | order_number | customer_number | order_date | required_date | shipped_date | status | comment | |--------------|-----------------|------------|---------------|--------------|--------|---------| | 1            | 1               | 2017-04-09 | 2017-04-13    | 2017-04-12   | Closed |         | | 2            | 2               | 2017-04-15 | 2017-04-20    | 2017-04-18   | Closed |         | | 3            | 3               | 2017-04-16 | 2017-04-25    | 2017-04-20   | Closed |         | | 4            | 3               | 2017-04-18 | 2017-04-28    | 2017-04-25   | Closed |         | Sample Output | customer_number | |-----------------| | 3               | Explanation The customer with number '3' has two orders, which is greater than either customer '1' or '2' because each of them  only has one order. So the result is customer_number '3'. Solution sql # assume: only one match SELECT customer_number FROM orders GROUP BY customer_number ORDER BY COUNT(1) DESC LIMIT 1 ## assume: multiple matches ##  1 1 ##  2 1 ##  3 1 ## ##  1 1 1 1 ##  1 1 2 1 ##  1 1 3 1 ## ##  SELECT t1.customer_number ##  FROM (SELECT customer_number, COUNT(1) AS count ##        FROM orders GROUP BY customer_number) AS t1, ##        (SELECT customer_number, COUNT(1) AS count ##        FROM orders GROUP BY customer_number) AS t2 ##  GROUP BY t1.customer_number ##  HAVING max(t1.count) = max(t2.count)

---

#### Big Countries | Easy | LeetCode

There is a table World +-----------------+------------+------------+--------------+---------------+ | name            | continent  | area       | population   | gdp           | +-----------------+------------+------------+--------------+---------------+ | Afghanistan     | Asia       | 652230     | 25500100     | 20343000      | | Albania         | Europe     | 28748      | 2831741      | 12960000      | | Algeria         | Africa     | 2381741    | 37100000     | 188681000     | | Andorra         | Europe     | 468        | 78115        | 3712000       | | Angola          | Africa     | 1246700    | 20609294     | 100990000     | +-----------------+------------+------------+--------------+---------------+ A country is big if it has an area of bigger than 3 million square km or a population of more than 25 million. Write a SQL solution to output big countries' name, population and area. For example, according to the above table, we should output: +--------------+-------------+--------------+ | name         | population  | area         | +--------------+-------------+--------------+ | Afghanistan  | 25500100    | 652230       | | Algeria      | 37100000    | 2381741      | +--------------+-------------+--------------+ Solution sql SELECT name, population, area FROM World WHERE area >= 3000000 OR population > 25000000;

---

#### Classes More Than 5 Students | Easy | LeetCode

There is a table courses with columns: student and class Please list out all classes which have more than or equal to 5 students. For example, the table: +---------+------------+ | student | class      | +---------+------------+ | A       | Math       | | B       | English    | | C       | Math       | | D       | Biology    | | E       | Math       | | F       | Computer   | | G       | Math       | | H       | Math       | | I       | Math       | +---------+------------+ Should output: +---------+ | class   | +---------+ | Math    | +---------+ Solution sql SELECT class FROM courses GROUP BY class HAVING count(DISTINCT Student)>=5;

---

#### Friend Requests I: Overall Acceptance Rate | Easy | üîí LeetCode

In social network like Facebook or Twitter, people send friend requests and accept others‚Äô requests as well. Now given two tables as below: Table: friend_request | sender_id | send_to_id |request_date| |-----------|------------|------------| | 1         | 2          | 2016_06-01 | | 1         | 3          | 2016_06-01 | | 1         | 4          | 2016_06-01 | | 2         | 3          | 2016_06-02 | | 3         | 4          | 2016-06-09 | Table: request_accepted | requester_id | accepter_id |accept_date | |--------------|-------------|------------| | 1            | 2           | 2016_06-03 | | 1            | 3           | 2016-06-08 | | 2            | 3           | 2016-06-08 | | 3            | 4           | 2016-06-09 | | 3            | 4           | 2016-06-10 | Write a query to find the overall acceptance rate of requests rounded to 2 decimals, which is the number of acceptance divide the number of requests. For the sample data above, your query should return the following result. |accept_rate| |-----------| |       0.80| Note: The accepted requests are not necessarily from the table friend_request. In this case, you just need to simply count the total accepted requests (no matter whether they are in the original requests), and divide it by the number of requests to get the acceptance rate. It is possible that a sender sends multiple requests to the same receiver, and a request could be accepted more than once. In this case, the ‚Äòduplicated‚Äô requests or acceptances are only counted once. If there is no requests at all, you should return 0.00 as the accept_rate. Explanation: There are 4 unique accepted requests, and there are 5 requests in total. So the rate is 0.80. Follow-up: Can you write a query to return the accept rate but for every month? How about the cumulative accept rate for every day? Solution sql SELECT IFNULL((round(accepts/requests, 2)), 0.0) AS accept_rate FROM (SELECT count(DISTINCT sender_id, send_to_id) AS requests FROM friend_request) AS t1, (SELECT count(DISTINCT requester_id, accepter_id) AS accepts FROM request_accepted) AS t2

---

#### Human Traffic of Stadium | Hard | LeetCode

Table: Stadium +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | id            | int     | | visit_date    | date    | | people        | int     | +---------------+---------+ visit_date is the primary key for this table. Each row of this table contains the visit date and visit id to the stadium with the number of people during the visit. No two rows will have the same visit_date, and as the id increases, the dates increase as well. Write an SQL query to display the records with three or more rows with consecutive id's, and the number of people is greater than or equal to 100 for each. Return the result table ordered by visit_date in ascending order. The query result format is in the following example. Stadium table: +------+------------+-----------+ | id   | visit_date | people    | +------+------------+-----------+ | 1    | 2017-01-01 | 10        | | 2    | 2017-01-02 | 109       | | 3    | 2017-01-03 | 150       | | 4    | 2017-01-04 | 99        | | 5    | 2017-01-05 | 145       | | 6    | 2017-01-06 | 1455      | | 7    | 2017-01-07 | 199       | | 8    | 2017-01-09 | 188       | +------+------------+-----------+ Result table: +------+------------+-----------+ | id   | visit_date | people    | +------+------------+-----------+ | 5    | 2017-01-05 | 145       | | 6    | 2017-01-06 | 1455      | | 7    | 2017-01-07 | 199       | | 8    | 2017-01-09 | 188       | +------+------------+-----------+ The four rows with ids 5, 6, 7, and 8 have consecutive ids and each of them has >= 100 people attended. Note that row 8 was included even though the visit_date was not the next day after row 7. The rows with ids 2 and 3 are not included because we need at least three consecutive ids. Solution sql SELECT DISTINCT s1.* FROM Stadium s1 JOIN Stadium s2 JOIN Stadium s3 ON (s1.id = s2.id-1 AND s1.id = s3.id-2) OR (s1.id = s2.id+1 AND s1.id = s3.id-1) OR (s1.id = s2.id+1 AND s1.id = s3.id+2) WHERE s1.people >= 100 AND s2.people >= 100 AND s3.people>=100 ORDER BY visit_date

---

#### Friend Requests II: Who Has the Most Friends | Medium | üîí LeetCode

In social network like Facebook or Twitter, people send friend requests and accept others‚Äô requests as well. Table request_accepted holds the data of friend acceptance, while requester_id and accepter_id both are the id of a person. | requester_id | accepter_id | accept_date| |--------------|-------------|------------| | 1            | 2           | 2016_06-03 | | 1            | 3           | 2016-06-08 | | 2            | 3           | 2016-06-08 | | 3            | 4           | 2016-06-09 | Write a query to find the the people who has most friends and the most friends number. For the sample data above, the result is: | id | num | |----|-----| | 3  | 3   | Note: It is guaranteed there is only 1 people having the most friends. The friend request could only been accepted once, which mean there is no multiple records with the same requester_id and accepter_id value. Explanation: The person with id ‚Äò3‚Äô is a friend of people ‚Äò1‚Äô, ‚Äò2‚Äô and ‚Äò4‚Äô, so he has 3 friends in total, which is the most number than any others. Follow-up: In the real world, multiple people could have the same most number of friends, can you find all these people in this case? sql SELECT t.id, sum(t.num) AS num FROM ( (SELECT requester_id AS id, COUNT(1) AS num FROM request_accepted GROUP BY requester_id) union all (SELECT accepter_id AS id, COUNT(1) AS num FROM request_accepted GROUP BY accepter_id)) AS t GROUP BY t.id ORDER BY num DESC LIMIT 1;

---

#### Consecutive Available Seats | Easy | üîí LeetCode

Several friends at a cinema ticket office would like to reserve consecutive available seats. Can you help to query all the consecutive available seats order by the seat_id using the following cinema table? | seat_id | free | |---------|------| | 1       | 1    | | 2       | 0    | | 3       | 1    | | 4       | 1    | | 5       | 1    | Your query should return the following result for the sample case above. | seat_id | |---------| | 3       | | 4       | | 5       | Note: The seat_id is an auto increment int, and free is bool (‚Äò1‚Äô means free, and ‚Äò0‚Äô means occupied.). Consecutive available seats are more than 2(inclusive) seats consecutively available. Solution sql SELECT DISTINCT t1.seat_id FROM cinema AS t1 JOIN cinema AS t2 ON abs(t1.seat_id-t2.seat_id)=1 WHERE t1.free='1' AND t2.free='1' ORDER BY t1.seat_id

---

#### Sales Person | Easy | üîí LeetCode

Description Given three tables: salesperson, company, orders. Output all the names in the table salesperson, who didn‚Äôt have sales to company ‚ÄòRED‚Äô. Example Input Table: salesperson +----------+------+--------+-----------------+-----------+ | sales_id | name | salary | commission_rate | hire_date | +----------+------+--------+-----------------+-----------+ |   1      | John | 100000 |     6           | 4/1/2006  | |   2      | Amy  | 120000 |     5           | 5/1/2010  | |   3      | Mark | 65000  |     12          | 12/25/2008| |   4      | Pam  | 25000  |     25          | 1/1/2005  | |   5      | Alex | 50000  |     10          | 2/3/2007  | +----------+------+--------+-----------------+-----------+ The table salesperson holds the salesperson information. Every salesperson has a sales_id and a name. Table: company +---------+--------+------------+ | com_id  |  name  |    city    | +---------+--------+------------+ |   1     |  RED   |   Boston   | |   2     | ORANGE |   New York | |   3     | YELLOW |   Boston   | |   4     | GREEN  |   Austin   | +---------+--------+------------+ The table company holds the company information. Every company has a com_id and a name. Table: orders +----------+----------+---------+----------+--------+ | order_id |  date    | com_id  | sales_id | amount | +----------+----------+---------+----------+--------+ | 1        | 1/1/2014 |    3    |    4     | 100000 | | 2        | 2/1/2014 |    4    |    5     | 5000   | | 3        | 3/1/2014 |    1    |    1     | 50000  | | 4        | 4/1/2014 |    1    |    4     | 25000  | +----------+----------+---------+----------+--------+ The table orders holds the sales record information, salesperson and customer company are represented by sales_id and com_id. output +------+ | name | +------+ | Amy  | | Mark | | Alex | +------+ Explanation According to order ‚Äò3‚Äô and ‚Äò4‚Äô in table orders, it is easy to tell only salesperson ‚ÄòJohn‚Äô and ‚ÄòAlex‚Äô have sales to company ‚ÄòRED‚Äô, so we need to output all the other names in table salesperson. Solution sql SELECT name FROM salesperson WHERE name NOT IN (SELECT DISTINCT salesperson.name FROM salesperson, orders, company WHERE company.name = 'RED' AND salesperson.sales_id = orders.sales_id AND orders.com_id = company.com_id)

---

#### Tree Node | Medium | üîí LeetCode

Given a table tree, id is identifier of the tree node and p_id is its parent node‚Äôs id. +----+------+ | id | p_id | +----+------+ | 1  | null | | 2  | 1    | | 3  | 1    | | 4  | 2    | | 5  | 2    | +----+------+ Each node in the tree can be one of three types: Leaf: if the node is a leaf node. Root: if the node is the root of the tree. Inner: If the node is neither a leaf node nor a root node. Write a query to print the node id and the type of the node. Sort your output by the node id. The result for the above sample is: +----+------+ | id | Type | +----+------+ | 1  | Root | | 2  | Inner| | 3  | Leaf | | 4  | Leaf | | 5  | Leaf | +----+------+ Explanation Node ‚Äò1‚Äô is root node, because its parent node is NULL and it has child node ‚Äò2‚Äô and ‚Äò3‚Äô. Node ‚Äò2‚Äô is inner node, because it has parent node ‚Äò1‚Äô and child node ‚Äò4‚Äô and ‚Äò5‚Äô. Node ‚Äò3‚Äô, ‚Äò4‚Äô and ‚Äò5‚Äô is Leaf node, because they have parent node and they don‚Äôt have child node. And here is the image of the sample tree as below: 1 /   \ 2       3 /   \ 4       5 Note If there is only one node on the tree, you only need to output its root attributes. Solution sql ## Basic Ideas: LEFT JOIN # In tree, each node can only one parent or no parent ## | id | p_id | id (child) | ## |----+------+------------| ## |  1 | null |          1 | ## |  1 | null |          2 | ## |  2 |    1 |          4 | ## |  2 |    1 |          5 | ## |  3 |    1 |       null | ## |  4 |    2 |       null | ## |  5 |    2 |       null | SELECT t1.id, CASE WHEN ISNULL(t1.p_id) THEN 'Root' WHEN ISNULL(MAX(t2.id)) THEN 'Leaf' ELSE 'Inner' END AS Type FROM tree AS t1 LEFT JOIN tree AS t2 ON t1.id = t2.p_id GROUP BY t1.id, t1.p_id

---

#### Triangle Judgement | Easy | üîí LeetCode

A pupil Tim gets homework to identify whether three line segments could possibly form a triangle. However, this assignment is very heavy because there are hundreds of records to calculate. Could you help Tim by writing a query to judge whether these three sides can form a triangle, assuming table triangle holds the length of the three sides x, y and z. | x  | y  | z  | |----|----|----| | 13 | 15 | 30 | | 10 | 20 | 15 | For the sample data above, your query should return the follow result: | x  | y  | z  | triangle | |----|----|----|----------| | 13 | 15 | 30 | No       | | 10 | 20 | 15 | Yes      | Solution sql SELECT x, y, z, CASE WHEN x+y>z AND y+z>x AND x+z>y THEN 'Yes' ELSE 'No' END AS triangle FROM triangle

---

#### Shortest Distance in a Plane | Medium | üîí LeetCode

Table point_2d holds the coordinates (x,y) of some unique points (more than two) in a plane. Write a query to find the shortest distance between these points rounded to 2 decimals. | x  | y  | |----|----| | -1 | -1 | | 0  | 0  | | -1 | -2 | The shortest distance is 1.00 from point (-1,-1) to (-1,2). So the output should be: | shortest | |----------| | 1.00     | Note: The longest distance among all the points are less than 10000. Solution sql SELECT ROUND(MIN(SQRT((t1.x-t2.x)*(t1.x-t2.x) + (t1.y-t2.y)*(t1.y-t2.y))), 2) as shortest FROM point_2d AS t1, point_2d AS t2 WHERE t1.x!=t2.x OR t1.y!=t2.y # SELECT ROUND(SQRT((t1.x-t2.x)*(t1.x-t2.x) + (t1.y-t2.y)*(t1.y-t2.y)), 2) AS shortest # FROM point_2d AS t1, point_2d AS t2 # WHERE t1.x!=t2.x OR t1.y!=t2.y # ORDER BY shortest ASC # LIMIT 1

---

#### Shortest Distance in a Line | Easy | üîí LeetCode

Table point holds the x coordinate of some points on x-axis in a plane, which are all integers. Write a query to find the shortest distance between two points in these points. | x   | |-----| | -1  | | 0   | | 2   | The shortest distance is ‚Äò1‚Äô obviously, which is from point ‚Äò-1‚Äô to ‚Äò0‚Äô. So the output is as below: | shortest| |---------| | 1       | Note: Every point is unique, which means there is no duplicates in table point. Follow-up: What if all these points have an id and are arranged from the left most to the right most of x axis? Solution sql SELECT t1.x-t2.x AS shortest FROM point AS t1 JOIN point AS t2 WHERE t1.x>t2.x ORDER BY (t1.x-t2.x) ASC LIMIT 1

---

#### Second Degree Follower | Medium | üîí LeetCode

In facebook, there is a follow table with two columns: followee, follower. Please write a sql query to get the amount of each follower‚Äôs follower if he/she has one. For example: +-------------+------------+ | followee    | follower   | +-------------+------------+ |     A       |     B      | |     B       |     C      | |     B       |     D      | |     D       |     E      | +-------------+------------+ should output: +-------------+------------+ | follower    | num        | +-------------+------------+ |     B       |  2         | |     D       |  1         | +-------------+------------+ Explanation: Both B and D exist in the follower list, when as a followee, B‚Äôs follower is C and D, and D‚Äôs follower is E. A does not exist in follower list. Note: Followee would not follow himself/herself in all cases. Please display the result in follower‚Äôs alphabet order. Solution sql ## Explain the business logic ##   A follows B. Then A is follwer, B is followee ## What are second degree followers? ##   A follows B, and B follows C. ##   Then A is the second degree followers of C SELECT f1.follower, COUNT(DISTINCT f2.follower) AS num FROM follow AS f1 JOIN follow AS f2 ON f1.follower = f2.followee GROUP BY f1.follower;

---

#### Average Salary: Departments VS Company | Hard | üîí LeetCode

Given two tables as below, write a query to display the comparison result (higher/lower/same) of the average salary of employees in a department to the company‚Äôs average salary. Table: salary | id | employee_id | amount | pay_date   | |----|-------------|--------|------------| | 1  | 1           | 9000   | 2017-03-31 | | 2  | 2           | 6000   | 2017-03-31 | | 3  | 3           | 10000  | 2017-03-31 | | 4  | 1           | 7000   | 2017-02-28 | | 5  | 2           | 6000   | 2017-02-28 | | 6  | 3           | 8000   | 2017-02-28 | The employee_id column refers to the employee_id in the following table employee. | employee_id | department_id | |-------------|---------------| | 1           | 1             | | 2           | 2             | | 3           | 2             | So for the sample data above, the result is: | pay_month | department_id | comparison  | |-----------|---------------|-------------| | 2017-03   | 1             | higher      | | 2017-03   | 2             | lower       | | 2017-02   | 1             | same        | | 2017-02   | 2             | same        | Explanation In March, the company‚Äôs average salary is (9000+6000+10000)/3 = 8333.33‚Ä¶ The average salary for department ‚Äò1‚Äô is 9000, which is the salary of employee_id ‚Äò1‚Äô since there is only one employee in this department. So the comparison result is ‚Äòhigher‚Äô since 9000 > 8333.33 obviously. The average salary of department ‚Äò2‚Äô is (6000 + 10000)/2 = 8000, which is the average of employee_id ‚Äò2‚Äô and ‚Äò3‚Äô. So the comparison result is ‚Äòlower‚Äô since 8000 < 8333.33. With he same formula for the average salary comparison in February, the result is ‚Äòsame‚Äô since both the department ‚Äò1‚Äô and ‚Äò2‚Äô have the same average salary with the company, which is 7000. Solution sql SELECT t1.pay_month, t1.department_id, (CASE WHEN t1.amount = t2.amount THEN 'same' WHEN t1.amount > t2.amount THEN 'higher' WHEN t1.amount < t2.amount THEN 'lower' END) AS comparison FROM (SELECT left(pay_date, 7) AS pay_month, department_id, avg(amount) AS amount FROM salary JOIN employee ON salary.employee_id = employee.employee_id GROUP BY pay_month, department_id ORDER BY pay_month DESC, department_id) AS t1 JOIN (SELECT left(pay_date, 7) AS pay_month, avg(amount) AS amount FROM salary JOIN employee ON salary.employee_id = employee.employee_id GROUP BY pay_month) AS t2 ON t1.pay_month = t2.pay_month

---

#### Students Report By Geography | Hard | üîí LeetCode

A U.S graduate school has students from Asia, Europe and America. The students‚Äô location information are stored in table student as below. | name   | continent | |--------|-----------| | Jack   | America   | | Pascal | Europe    | | Xi     | Asia      | | Jane   | America   | Pivot the continent column in this table so that each name is sorted alphabetically and displayed underneath its corresponding continent. The output headers should be America, Asia and Europe respectively. It is guaranteed that the student number from America is no less than either Asia or Europe. For the sample input, the output is: | America | Asia | Europe | |---------|------|--------| | Jack    | Xi   | Pascal | | Jane    |      |        | Follow-up: If it is unknown which continent has the most students, can you write a query to generate the student report? Solution sql SELECT t1.name AS America, t2.name AS Asia, t3.name AS Europe FROM (SELECT (@cnt1 := @cnt1 + 1) AS id, name FROM student CROSS JOIN (SELECT @cnt1 := 0) AS dummy WHERE continent='America' ORDER BY name) AS t1 LEFT JOIN (SELECT (@cnt2 := @cnt2 + 1) AS id, name FROM student CROSS JOIN (SELECT @cnt2 := 0) AS dummy WHERE continent='Asia' ORDER BY name) AS t2 ON t1.id = t2.id LEFT JOIN (SELECT (@cnt3 := @cnt3 + 1) AS id, name FROM student CROSS JOIN (SELECT @cnt3 := 0) AS dummy WHERE continent='Europe' ORDER BY name) AS t3 ON t1.id = t3.id

---

#### Biggest Single Number | Easy | üîí LeetCode

Table number contains many numbers in column num including duplicated ones. Can you write a SQL query to find the biggest number, which only appears once. +---+ |num| +---+ | 8 | | 8 | | 3 | | 3 | | 1 | | 4 | | 5 | | 6 | For the sample data above, your query should return the following result: +---+ |num| +---+ | 6 | Note: If there is no such number, just output null. Solution sql SELECT IFNULL(( SELECT num FROM number GROUP BY num HAVING count(1) = 1 ORDER BY num DESC LIMIT 0, 1), NULL) AS num

---

#### Not Boring Movies | Easy | LeetCode

X city opened a new cinema, many people would like to go to this cinema. The cinema also gives out a poster indicating the movies‚Äô ratings and descriptions. Please write a SQL query to output movies with an odd numbered ID and a description that is not 'boring'. Order the result by rating. For example, table cinema: +---------+-----------+--------------+-----------+ |   id    | movie     |  description |  rating   | +---------+-----------+--------------+-----------+ |   1     | War       |   great 3D   |   8.9     | |   2     | Science   |   fiction    |   8.5     | |   3     | irish     |   boring     |   6.2     | |   4     | Ice song  |   Fantacy    |   8.6     | |   5     | House card|   Interesting|   9.1     | +---------+-----------+--------------+-----------+ For the example above, the output should be: +---------+-----------+--------------+-----------+ |   id    | movie     |  description |  rating   | +---------+-----------+--------------+-----------+ |   5     | House card|   Interesting|   9.1     | |   1     | War       |   great 3D   |   8.9     | +---------+-----------+--------------+-----------+ Solution sql SELECT * FROM Cinema WHERE description <> 'boring' AND ID % 2 = 1 ORDER BY rating DESC;

---

#### Exchange Seats | Medium | LeetCode

Mary is a teacher in a middle school and she has a table seat storing students' names and their corresponding seat ids. The column id is continuous increment. Mary wants to change seats for the adjacent students. Can you write a SQL query to output the result for Mary? +---------+---------+ |    id   | student | +---------+---------+ |    1    | Abbot   | |    2    | Doris   | |    3    | Emerson | |    4    | Green   | |    5    | Jeames  | +---------+---------+ For the sample input, the output is: +---------+---------+ |    id   | student | +---------+---------+ |    1    | Doris   | |    2    | Abbot   | |    3    | Green   | |    4    | Emerson | |    5    | Jeames  | +---------+---------+ Note: If the number of students is odd, there is no need to change the last one's seat. Solution sql SELECT IF(id<(SELECT MAX(id) FROM seat),IF(id%2=0,id-1, id+1),IF(id%2=0, id-1, id)) AS id, student FROM seat ORDER BY id;

---

#### Swap Salary | LeetCode

Table: Salary +-------------+----------+ | Column Name | Type     | +-------------+----------+ | id          | int      | | name        | varchar  | | sex         | ENUM     | | salary      | int      | +-------------+----------+ id is the primary key for this table. The sex column is ENUM value of type ('m', 'f'). The table contains information about an employee. Write an SQL query to swap all 'f' and 'm' values (i.e., change all 'f' values to 'm' and vice versa) with a single update statement and no intermediate temp table(s). Note that you must write a single update statement, DO NOT write any select statement for this problem. The query result format is in the following example: Salary table: +----+------+-----+--------+ | id | name | sex | salary | +----+------+-----+--------+ | 1  | A    | m   | 2500   | | 2  | B    | f   | 1500   | | 3  | C    | m   | 5500   | | 4  | D    | f   | 500    | +----+------+-----+--------+ Result table: +----+------+-----+--------+ | id | name | sex | salary | +----+------+-----+--------+ | 1  | A    | f   | 2500   | | 2  | B    | m   | 1500   | | 3  | C    | f   | 5500   | | 4  | D    | m   | 500    | +----+------+-----+--------+ (1, A) and (2, C) were changed from 'm' to 'f'. (2, B) and (4, D) were changed from 'f' to 'm'. Solution sql # With IF UPDATE Salary SET sex = IF(sex='m', 'f', 'm') # With CASE UPDATE Salary SET sex = CASE WHEN sex='m' THEN 'f' ELSE 'm' END

---

#### Customers Who Bought All Products | Medium | üîí LeetCode

Table: Customer +-------------+---------+ | Column Name | Type    | +-------------+---------+ | customer_id | int     | | product_key | int     | +-------------+---------+ product_key is a foreign key to Product table. Table: Product +-------------+---------+ | Column Name | Type    | +-------------+---------+ | product_key | int     | +-------------+---------+ product_key is the primary key column for this table. Write an SQL query for a report that provides the customer ids from the Customer table that bought all the products in the Product table. For example: Customer table: +-------------+-------------+ | customer_id | product_key | +-------------+-------------+ | 1           | 5           | | 2           | 6           | | 3           | 5           | | 3           | 6           | | 1           | 6           | +-------------+-------------+ Product table: +-------------+ | product_key | +-------------+ | 5           | | 6           | +-------------+ Result table: +-------------+ | customer_id | +-------------+ | 1           | | 3           | +-------------+ The customers who bought all the products (5 and 6) are customers with id 1 and 3. Solution sql SELECT customer_id FROM Customer GROUP NY customer_id HAVING count(DISTINCT product_key) = ( SELECT count(1) FROM Product)

---

#### Actors and Directors Who Cooperated At Least Three Times | Easy | üîí LeetCode

Table: ActorDirector +-------------+---------+ | Column Name | Type    | +-------------+---------+ | actor_id    | int     | | director_id | int     | | timestamp   | int     | +-------------+---------+ timestamp is the primary key column for this table. Write a SQL query for a report that provides the pairs (actor_id, director_id) where the actor have cooperated with the director at least 3 times. Example: ActorDirector table: +-------------+-------------+-------------+ | actor_id    | director_id | timestamp   | +-------------+-------------+-------------+ | 1           | 1           | 0           | | 1           | 1           | 1           | | 1           | 1           | 2           | | 1           | 2           | 3           | | 1           | 2           | 4           | | 2           | 1           | 5           | | 2           | 1           | 6           | +-------------+-------------+-------------+ Result table: +-------------+-------------+ | actor_id    | director_id | +-------------+-------------+ | 1           | 1           | +-------------+-------------+ The only pair is (1, 1) where they cooperated exactly 3 times. Solution sql SELECT actor_id, director_id FROM ActorDirector GROUP BY actor_id, director_id HAVING COUNT(1)>=3

---

#### Product Sales Analysis I | Easy | üîí LeetCode

Table: Sales +-------------+-------+ | Column Name | Type  | +-------------+-------+ | sale_id     | int   | | product_id  | int   | | year        | int   | | quantity    | int   | | price       | int   | +-------------+-------+ (sale_id, year) is the primary key of this table. product_id is a foreign key to Product table. Note that the price is per unit. Table: Product +--------------+---------+ | Column Name  | Type    | +--------------+---------+ | product_id   | int     | | product_name | varchar | +--------------+---------+ product_id is the primary key of this table. Write an SQL query that reports all product names of the products in the Sales table along with their selling year and price. For example: Sales table: +---------+------------+------+----------+-------+ | sale_id | product_id | year | quantity | price | +---------+------------+------+----------+-------+ | 1       | 100        | 2008 | 10       | 5000  | | 2       | 100        | 2009 | 12       | 5000  | | 7       | 200        | 2011 | 15       | 9000  | +---------+------------+------+----------+-------+ Product table: +------------+--------------+ | product_id | product_name | +------------+--------------+ | 100        | Nokia        | | 200        | Apple        | | 300        | Samsung      | +------------+--------------+ Result table: +--------------+-------+-------+ | product_name | year  | price | +--------------+-------+-------+ | Nokia        | 2008  | 5000  | | Nokia        | 2009  | 5000  | | Apple        | 2011  | 9000  | +--------------+-------+-------+ Solution sql SELECT product_name, year, price FROM Sales JOIN Product ON Product.product_id = Sales.product_id

---

#### Product Sales Analysis II | Easy | üîí LeetCode

Table: Sales +-------------+-------+ | Column Name | Type  | +-------------+-------+ | sale_id     | int   | | product_id  | int   | | year        | int   | | quantity    | int   | | price       | int   | +-------------+-------+ sale_id is the primary key of this table. product_id is a foreign key to Product table. Note that the price is per unit. Table: Product +--------------+---------+ | Column Name  | Type    | +--------------+---------+ | product_id   | int     | | product_name | varchar | +--------------+---------+ product_id is the primary key of this table. Write an SQL query that reports the total quantity sold for every product id. The query result format is in the following example: Sales table: +---------+------------+------+----------+-------+ | sale_id | product_id | year | quantity | price | +---------+------------+------+----------+-------+ | 1       | 100        | 2008 | 10       | 5000  | | 2       | 100        | 2009 | 12       | 5000  | | 7       | 200        | 2011 | 15       | 9000  | +---------+------------+------+----------+-------+ Product table: +------------+--------------+ | product_id | product_name | +------------+--------------+ | 100        | Nokia        | | 200        | Apple        | | 300        | Samsung      | +------------+--------------+ Result table: +--------------+----------------+ | product_id   | total_quantity | +--------------+----------------+ | 100          | 22             | | 200          | 15             | +--------------+----------------+ Solution sql SELECT product_id, sum(quantity) AS total_quantity FROM Sales GROUP BY product_id;

---

#### Product Sales Analysis III | Medium | üîí LeetCode

Table: Sales +-------------+-------+ | Column Name | Type  | +-------------+-------+ | sale_id     | int   | | product_id  | int   | | year        | int   | | quantity    | int   | | price       | int   | +-------------+-------+ sale_id is the primary key of this table. product_id is a foreign key to Product table. Note that the price is per unit. Table: Product +--------------+---------+ | Column Name  | Type    | +--------------+---------+ | product_id   | int     | | product_name | varchar | +--------------+---------+ product_id is the primary key of this table. Write an SQL query that selects the product id, year, quantity, and price for the first year of every product sold. The query result format is in the following example: Sales table: +---------+------------+------+----------+-------+ | sale_id | product_id | year | quantity | price | +---------+------------+------+----------+-------+ | 1       | 100        | 2008 | 10       | 5000  | | 2       | 100        | 2009 | 12       | 5000  | | 7       | 200        | 2011 | 15       | 9000  | +---------+------------+------+----------+-------+ Product table: +------------+--------------+ | product_id | product_name | +------------+--------------+ | 100        | Nokia        | | 200        | Apple        | | 300        | Samsung      | +------------+--------------+ Result table: +------------+------------+----------+-------+ | product_id | first_year | quantity | price | +------------+------------+----------+-------+ | 100        | 2008       | 10       | 5000  | | 200        | 2011       | 15       | 9000  | +------------+------------+----------+-------+ Solution sql SELECT product_id, year first_year, quantity, price FROM Sales WHERE (product_id, year) IN (SELECT product_id, MIN(year) FROM Sales GROUP BY product_id)

---

#### Project Employees I | Easy | üîí LeetCode

Table: Project +-------------+---------+ | Column Name | Type    | +-------------+---------+ | project_id  | int     | | employee_id | int     | +-------------+---------+ (project_id, employee_id) is the primary key of this table. employee_id is a foreign key to Employee table. Table: Employee +------------------+---------+ | Column Name      | Type    | +------------------+---------+ | employee_id      | int     | | name             | varchar | | experience_years | int     | +------------------+---------+ employee_id is the primary key of this table. Write an SQL query that reports the average experience years of all the employees for each project, rounded to 2 digits. The query result format is in the following example: Project table: +-------------+-------------+ | project_id  | employee_id | +-------------+-------------+ | 1           | 1           | | 1           | 2           | | 1           | 3           | | 2           | 1           | | 2           | 4           | +-------------+-------------+ Employee table: +-------------+--------+------------------+ | employee_id | name   | experience_years | +-------------+--------+------------------+ | 1           | Khaled | 3                | | 2           | Ali    | 2                | | 3           | John   | 1                | | 4           | Doe    | 2                | +-------------+--------+------------------+ Result table: +-------------+---------------+ | project_id  | average_years | +-------------+---------------+ | 1           | 2.00          | | 2           | 2.50          | +-------------+---------------+ The average experience years for the first project is (3 + 2 + 1) / 3 = 2.00 and for the second project is (3 + 2) / 2 = 2.50 Solution sql SELECT p.project_id, ROUND(AVG(e.experience_years),2) average_years FROM Project p JOIN Employee e ON p.employee_id = e.employee_id GROUP BY p.project_id

---

#### Project Employees II | Easy | üîí LeetCode

Table: Project +-------------+---------+ | Column Name | Type    | +-------------+---------+ | project_id  | int     | | employee_id | int     | +-------------+---------+ (project_id, employee_id) is the primary key of this table. employee_id is a foreign key to Employee table. Table: Employee +------------------+---------+ | Column Name      | Type    | +------------------+---------+ | employee_id      | int     | | name             | varchar | | experience_years | int     | +------------------+---------+ employee_id is the primary key of this table. Write an SQL query that reports all the projects that have the most employees. The query result format is in the following example: Project table: +-------------+-------------+ | project_id  | employee_id | +-------------+-------------+ | 1           | 1           | | 1           | 2           | | 1           | 3           | | 2           | 1           | | 2           | 4           | +-------------+-------------+ Employee table: +-------------+--------+------------------+ | employee_id | name   | experience_years | +-------------+--------+------------------+ | 1           | Khaled | 3                | | 2           | Ali    | 2                | | 3           | John   | 1                | | 4           | Doe    | 2                | +-------------+--------+------------------+ Result table: +-------------+ | project_id  | +-------------+ | 1           | +-------------+ The first project has 3 employees while the second one has 2. sql SELECT project_id FROM Project GROUP BY project_id HAVING COUNT(employee_id) = (SELECT COUNT(employee_id) FROM Project GROUP BY project_id ORDER BY COUNT(employee_id) DESC LIMIT 1)

---

#### Project Employees III | Medium | üîí LeetCode

Table: Project +-------------+---------+ | Column Name | Type    | +-------------+---------+ | project_id  | int     | | employee_id | int     | +-------------+---------+ (project_id, employee_id) is the primary key of this table. employee_id is a foreign key to Employee table. Table: Employee +------------------+---------+ | Column Name      | Type    | +------------------+---------+ | employee_id      | int     | | name             | varchar | | experience_years | int     | +------------------+---------+ employee_id is the primary key of this table. Write an SQL query that reports the most experienced employees in each project. In case of a tie, report all employees with the maximum number of experience years. The query result format is in the following example: Project table: +-------------+-------------+ | project_id  | employee_id | +-------------+-------------+ | 1           | 1           | | 1           | 2           | | 1           | 3           | | 2           | 1           | | 2           | 4           | +-------------+-------------+ Employee table: +-------------+--------+------------------+ | employee_id | name   | experience_years | +-------------+--------+------------------+ | 1           | Khaled | 3                | | 2           | Ali    | 2                | | 3           | John   | 3                | | 4           | Doe    | 2                | +-------------+--------+------------------+ Result table: +-------------+---------------+ | project_id  | employee_id   | +-------------+---------------+ | 1           | 1             | | 1           | 3             | | 2           | 1             | +-------------+---------------+ Both employees with id 1 and 3 have the most experience among the employees of the first project. For the second project, the employee with id 1 has the most experience. Solution sql SELECT p.project_id, e.employee_id FROM Project p LEFT JOIN Employee e ON p.employee_id = e.employee_id WHERE (p.project_id, e.experience_years) IN (SELECT p.project_id, MAX(e.experience_years) FROM Project p JOIN Employee e ON p.employee_id = e.employee_id GROUP BY p.project_id)

---

#### Sales Analysis I | Easy | üîí LeetCode

Table: Product +--------------+---------+ | Column Name  | Type    | +--------------+---------+ | product_id   | int     | | product_name | varchar | | unit_price   | int     | +--------------+---------+ product_id is the primary key of this table. Table: Sales +-------------+---------+ | Column Name | Type    | +-------------+---------+ | seller_id   | int     | | product_id  | int     | | buyer_id    | int     | | sale_date   | date    | | quantity    | int     | | price       | int     | +------ ------+---------+ This table has no primary key, it can have repeated rows. product_id is a foreign key to Product table. Write an SQL query that reports the best seller by total sales price, If there is a tie, report them all. The query result format is in the following example: Product table: +------------+--------------+------------+ | product_id | product_name | unit_price | +------------+--------------+------------+ | 1          | S8           | 1000       | | 2          | G4           | 800        | | 3          | iPhone       | 1400       | +------------+--------------+------------+ Sales table: +-----------+------------+----------+------------+----------+-------+ | seller_id | product_id | buyer_id | sale_date  | quantity | price | +-----------+------------+----------+------------+----------+-------+ | 1         | 1          | 1        | 2019-01-21 | 2        | 2000  | | 1         | 2          | 2        | 2019-02-17 | 1        | 800   | | 2         | 2          | 3        | 2019-06-02 | 1        | 800   | | 3         | 3          | 4        | 2019-05-13 | 2        | 2800  | +-----------+------------+----------+------------+----------+-------+ Result table: +-------------+ | seller_id   | +-------------+ | 1           | | 3           | +-------------+ Both sellers with id 1 and 3 sold products with the most total price of 2800. Solution sql SELECT seller_id FROM Sales GROUP BY seller_id HAVING SUM(price) = (SELECT SUM(price) FROM Sales GROUP BY seller_id ORDER BY SUM(price) DESC LIMIT 1)

---

#### Sales Analysis II | Easy | üîí LeetCode

Table: Product +--------------+---------+ | Column Name  | Type    | +--------------+---------+ | product_id   | int     | | product_name | varchar | | unit_price   | int     | +--------------+---------+ product_id is the primary key of this table. Table: Sales +-------------+---------+ | Column Name | Type    | +-------------+---------+ | seller_id   | int     | | product_id  | int     | | buyer_id    | int     | | sale_date   | date    | | quantity    | int     | | price       | int     | +------ ------+---------+ This table has no primary key, it can have repeated rows. product_id is a foreign key to Product table. Write an SQL query that reports the buyers who have bought S8 but not iPhone. Note that S8 and iPhone are products present in the Product table. The query result format is in the following example: Product table: +------------+--------------+------------+ | product_id | product_name | unit_price | +------------+--------------+------------+ | 1          | S8           | 1000       | | 2          | G4           | 800        | | 3          | iPhone       | 1400       | +------------+--------------+------------+ Sales table: +-----------+------------+----------+------------+----------+-------+ | seller_id | product_id | buyer_id | sale_date  | quantity | price | +-----------+------------+----------+------------+----------+-------+ | 1         | 1          | 1        | 2019-01-21 | 2        | 2000  | | 1         | 2          | 2        | 2019-02-17 | 1        | 800   | | 2         | 1          | 3        | 2019-06-02 | 1        | 800   | | 3         | 3          | 3        | 2019-05-13 | 2        | 2800  | +-----------+------------+----------+------------+----------+-------+ Result table: +-------------+ | buyer_id    | +-------------+ | 1           | +-------------+ The buyer with id 1 bought an S8 but didn't buy an iPhone. The buyer with id 3 bought both. Solution sql SELECT DISTINCT s.buyer_id FROM Sales s LEFT JOIN Product p ON s.product_id = p.product_id WHERE p.product_name = 'S8' AND s.buyer_id NOT IN (SELECT s.buyer_id FROM Sales s LEFT JOIN Product p ON s.product_id = p.product_id WHERE p.product_name = 'iPhone')

---

#### Sales Analysis III | Easy | üîí LeetCode

Reports the products that were only sold in spring 2019. That is, between 2019-01-01 and 2019-03-31 inclusive. Select the product that were only sold in spring 2019. Product table: +------------+--------------+------------+ | product_id | product_name | unit_price | +------------+--------------+------------+ | 1          | S8           | 1000       | | 2          | G4           | 800        | | 3          | iPhone       | 1400       | +------------+--------------+------------+ Sales table: +-----------+------------+----------+------------+----------+-------+ | seller_id | product_id | buyer_id | sale_date  | quantity | price | +-----------+------------+----------+------------+----------+-------+ | 1         | 1          | 1        | 2019-01-21 | 2        | 2000  | | 1         | 2          | 2        | 2019-02-17 | 1        | 800   | | 2         | 2          | 3        | 2019-06-02 | 1        | 800   | | 3         | 3          | 4        | 2019-05-13 | 2        | 2800  | +-----------+------------+----------+------------+----------+-------+ Result table: +-------------+--------------+ | product_id  | product_name | +-------------+--------------+ | 1           | S8           | +-------------+--------------+ The product with id 1 was only sold in spring 2019 while the other two were sold after. Solution sql (SELECT DISTINCT s.product_id, p.product_name FROM Sales s LEFT JOIN Product p ON s.product_id = p.product_id WHERE s.sale_date >= '2019-01-01' AND s.sale_date <= '2019-03-31') EXCEPT -- MINUS if Oracle (SELECT DISTINCT s.product_id, p.product_name FROM Sales s LEFT JOIN Product p ON s.product_id = p.product_id WHERE s.sale_date < '2019-01-01' OR s.sale_date > '2019-03-31')

---

#### Game Play Analysis V | Hard | üîí LeetCode

We define the install date of a player to be the first login day of that player. We also define day 1 retention of some date X to be the number of players whose install date is X and they logged back in on the day right after X , divided by the number of players whose install date is X, rounded to 2 decimal places. Write an SQL query that reports for each install date, the number of players that installed the game on that day and the day 1 retention. The query result format is in the following example: Activity table: +-----------+-----------+------------+--------------+ | player_id | device_id | event_date | games_played | +-----------+-----------+------------+--------------+ | 1         | 2         | 2016-03-01 | 5            | | 1         | 2         | 2016-03-02 | 6            | | 2         | 3         | 2017-06-25 | 1            | | 3         | 1         | 2016-03-01 | 0            | | 3         | 4         | 2016-07-03 | 5            | +-----------+-----------+------------+--------------+ Result table: +------------+----------+----------------+ | install_dt | installs | Day1_retention | +------------+----------+----------------+ | 2016-03-01 | 2        | 0.50           | | 2017-06-25 | 1        | 0.00           | +------------+----------+----------------+ Player 1 and 3 installed the game on 2016-03-01 but only player 1 logged back in on 2016-03-02 so the day 1 retention of 2016-03-01 is 1/2 = 0.50 Player 2 installed the game on 2017 -06-25 but didn't log back in on 2017-06-26 so the day 1 retention of 2017-06-25 is 0/1 = 0.00 Solution sql SELECT install_dt, COUNT(player_id) installs, ROUND(COUNT(retention)/COUNT(player_id),2) Day1_retention  --the number of record on the next day / the total number of id on the day = retention rate FROM ( SELECT a.player_id, a.install_dt, b.event_date retention -- id, the record of the first installation day and next day FROM (SELECT player_id, MIN(event_date) install_dt   --subquery 1 take the first installation of date of each id FROM Activity GROUP BY player_id) a LEFT JOIN Activity b ON   --sq1 left join the original table, find the login status the next day after the first installation player_id = b.player_id AND install_dt + 1=b.event_date ) AS tmp GROUP BY install_dt

---

#### Unpopular Books | Medium | üîí LeetCode

Table: Books +----------------+---------+ | Column Name    | Type    | +----------------+---------+ | book_id        | int     | | name           | varchar | | available_from | date    | +----------------+---------+ book_id is the primary key of this table. Table: Orders +----------------+---------+ | Column Name    | Type    | +----------------+---------+ | order_id       | int     | | book_id        | int     | | quantity       | int     | | dispatch_date  | date    | +----------------+---------+ order_id is the primary key of this table. book_id is a foreign key to the Books table. Write an SQL query that reports the books that have sold less than 10 copies in the last year, excluding books that have been available for less than 1 month from today. Assume today is 2019-06-23. The query result format is in the following example: Books table: +---------+--------------------+----------------+ | book_id | name               | available_from | +---------+--------------------+----------------+ | 1       | "Kalila And Demna" | 2010-01-01     | | 2       | "28 Letters"       | 2012-05-12     | | 3       | "The Hobbit"       | 2019-06-10     | | 4       | "13 Reasons Why"   | 2019-06-01     | | 5       | "The Hunger Games" | 2008-09-21     | +---------+--------------------+----------------+ Orders table: +----------+---------+----------+---------------+ | order_id | book_id | quantity | dispatch_date | +----------+---------+----------+---------------+ | 1        | 1       | 2        | 2018-07-26    | | 2        | 1       | 1        | 2018-11-05    | | 3        | 3       | 8        | 2019-06-11    | | 4        | 4       | 6        | 2019-06-05    | | 5        | 4       | 5        | 2019-06-20    | | 6        | 5       | 9        | 2009-02-02    | | 7        | 5       | 8        | 2010-04-13    | +----------+---------+----------+---------------+ Result table: +-----------+--------------------+ | book_id   | name               | +-----------+--------------------+ | 1         | "Kalila And Demna" | | 2         | "28 Letters"       | | 5         | "The Hunger Games" | +-----------+--------------------+ Solution sql SELECT b.book_id, b.name FROM Books b LEFT JOIN (                    -- subquery calculates last year's sales SELECT book_id, SUM(quantity) nsold FROM Orders WHERE dispatch_date BETWEEN '2018-06-23' AND '2019-06-23' GROUP BY book_id ) o ON b.book_id = o.book_id WHERE (o.nsold < 10 OR o.nsold IS NULL) AND           -- Sales less than 10 or no sales DATEDIFF('2019-06-23', b.available_from) > 30   -- Not a new book within 1 month

---

#### New Users Daily Count | Medium | üîí LeetCode

Table: Traffic +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | user_id       | int     | | activity      | enum    | | activity_date | date    | +---------------+---------+ There is no primary key for this table, it may have duplicate rows. The activity column is an ENUM type of ('login', 'logout', 'jobs', 'groups', 'homepage'). Write an SQL query that reports for every date within at most 90 days from today, the number of users that logged in for the first time on that date. Assume today is 2019-06-30. The query result format is in the following example: Traffic table: +---------+----------+---------------+ | user_id | activity | activity_date | +---------+----------+---------------+ | 1       | login    | 2019-05-01    | | 1       | homepage | 2019-05-01    | | 1       | logout   | 2019-05-01    | | 2       | login    | 2019-06-21    | | 2       | logout   | 2019-06-21    | | 3       | login    | 2019-01-01    | | 3       | jobs     | 2019-01-01    | | 3       | logout   | 2019-01-01    | | 4       | login    | 2019-06-21    | | 4       | groups   | 2019-06-21    | | 4       | logout   | 2019-06-21    | | 5       | login    | 2019-03-01    | | 5       | logout   | 2019-03-01    | | 5       | login    | 2019-06-21    | | 5       | logout   | 2019-06-21    | +---------+----------+---------------+ Result table: +------------+-------------+ | login_date | user_count  | +------------+-------------+ | 2019-05-01 | 1           | | 2019-06-21 | 2           | +------------+-------------+ Note that we only care about dates with non zero user count. The user with id 5 first logged in on 2019-03-01 so he's not counted on 2019-06-21. Solution sql #Solution- 1: SELECT login_date, COUNT(user_id) AS user_count FROM (SELECT user_id, MIN(activity_date) AS login_date FROM Traffic WHERE activity = 'login' GROUP BY user_id) AS t WHERE login_date >= DATE_ADD('2019-06-30', INTERVAL -90 DAY) AND login_date <= '2019-06-30' GROUP BY login_date #Solution- 2: SELECT login_date, COUNT(user_id) user_count FROM (SELECT user_id, MIN(activity_date) as login_date FROM Traffic WHERE activity='login' GROUP BY user_id) as t WHERE DATEDIFF('2019-06-30', login_date) <= 90 GROUP BY login_date

---

#### Highest Grade For Each Student | Medium | üîí LeetCode

Table: Enrollments +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | student_id    | int     | | course_id     | int     | | grade         | int     | +---------------+---------+ (student_id, course_id) is the primary key of this table. Write a SQL query to find the highest grade with its corresponding course for each student. In case of a tie, you should find the course with the smallest course_id. The output must be sorted by increasing student_id. The query result format is in the following example: Enrollments table: +------------+-------------------+ | student_id | course_id | grade | +------------+-----------+-------+ | 2          | 2         | 95    | | 2          | 3         | 95    | | 1          | 1         | 90    | | 1          | 2         | 99    | | 3          | 1         | 80    | | 3          | 2         | 75    | | 3          | 3         | 82    | +------------+-----------+-------+ Result table: +------------+-------------------+ | student_id | course_id | grade | +------------+-----------+-------+ | 1          | 2         | 99    | | 2          | 2         | 95    | | 3          | 3         | 82    | +------------+-----------+-------+ Solution sql SELECT student_id, MIN(course_id) course_id, grade FROM Enrollments WHERE (student_id, grade) IN (SELECT student_id, MAX(grade) FROM Enrollments GROUP BY student_id) GROUP BY student_id ORDER BY student_id;

---

#### Reported Posts | Easy | üîí LeetCode

Table: Actions +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | user_id       | int     | | post_id       | int     | | action_date   | date    | | action        | enum    | | extra         | varchar | +---------------+---------+ There is no primary key for this table, it may have duplicate rows. The action column is an ENUM type of ('view', 'like', 'reaction', 'comment', 'report', 'share'). The extra column has optional information about the action such as a reason for report or a type of reaction. Write an SQL query that reports the number of posts reported yesterday for each report reason. Assume today is 2019-07-05. The query result format is in the following example: Actions table: +---------+---------+-------------+--------+--------+ | user_id | post_id | action_date | action | extra  | +---------+---------+-------------+--------+--------+ | 1       | 1       | 2019-07-01  | view   | null   | | 1       | 1       | 2019-07-01  | like   | null   | | 1       | 1       | 2019-07-01  | share  | null   | | 2       | 4       | 2019-07-04  | view   | null   | | 2       | 4       | 2019-07-04  | report | spam   | | 3       | 4       | 2019-07-04  | view   | null   | | 3       | 4       | 2019-07-04  | report | spam   | | 4       | 3       | 2019-07-02  | view   | null   | | 4       | 3       | 2019-07-02  | report | spam   | | 5       | 2       | 2019-07-04  | view   | null   | | 5       | 2       | 2019-07-04  | report | racism | | 5       | 5       | 2019-07-04  | view   | null   | | 5       | 5       | 2019-07-04  | report | racism | +---------+---------+-------------+--------+--------+ Result table: +---------------+--------------+ | report_reason | report_count | +---------------+--------------+ | spam          | 1            | | racism        | 2            | +---------------+--------------+ Note that we only care about report reasons with non zero number of reports. Solution sql SELECT extra report_reason, COUNT(DISTINCT post_id) report_count FROM (SELECT post_id, extra FROM Actions WHERE action_date = DATE_SUB('2019-07-05', INTERVAL 1 DAY) AND action = 'report') AS tmp GROUP BY extra

---

#### Active Businesses | Medium | üîí LeetCode

Table: Events +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | business_id   | int     | | event_type    | varchar | | occurences    | int     | +---------------+---------+ (business_id, event_type) is the primary key of this table. Each row in the table logs the info that an event of some type occured at some business for a number of times. Write an SQL query to find all active businesses. An active business is a business that has more than one event type with occurences greater than the average occurences of that event type among all businesses. The query result format is in the following example: Events table: +-------------+------------+------------+ | business_id | event_type | occurences | +-------------+------------+------------+ | 1           | reviews    | 7          | | 3           | reviews    | 3          | | 1           | ads        | 11         | | 2           | ads        | 7          | | 3           | ads        | 6          | | 1           | page views | 3          | | 2           | page views | 12         | +-------------+------------+------------+ Result table: +-------------+ | business_id | +-------------+ | 1           | +-------------+ Average for 'reviews', 'ads' and 'page views' are (7+3)/2=5, (11+7+6)/3=8, (3+12)/2=7.5 respectively. Business with id 1 has 7 'reviews' events (more than 5) and 11 'ads' events (more than 8) so it is an active business. Solution sql SELECT business_id FROM (SELECT a.business_id, a.event_type, a.occurences, b.event_avg  -- sub 2 FROM Events a LEFT JOIN (SELECT event_type, AVG(occurences) event_avg   -- sub 1 FROM Events GROUP BY event_type) b ON event_type = b.event_type) tmp WHERE occurences > event_avg GROUP BY business_id HAVING COUNT(event_type) > 1

---

#### User Purchase Platform | Hard | üîí LeetCode

Table: Spending +-------------+---------+ | Column Name | Type    | +-------------+---------+ | user_id     | int     | | spend_date  | date    | | platform    | enum    | | amount      | int     | +-------------+---------+ The table logs the spendings history of users that make purchases from an online shopping website which has a desktop and a mobile application. (user_id, spend_date, platform) is the primary key of this table. The platform column is an ENUM type of ('desktop', 'mobile'). Write an SQL query to find the total number of users and the total amount spent using mobile only, desktop only and both mobile and desktop together for each date. The query result format is in the following example: Spending table: +---------+------------+----------+--------+ | user_id | spend_date | platform | amount | +---------+------------+----------+--------+ | 1       | 2019-07-01 | mobile   | 100    | | 1       | 2019-07-01 | desktop  | 100    | | 2       | 2019-07-01 | mobile   | 100    | | 2       | 2019-07-02 | mobile   | 100    | | 3       | 2019-07-01 | desktop  | 100    | | 3       | 2019-07-02 | desktop  | 100    | +---------+------------+----------+--------+ Result table: +------------+----------+--------------+-------------+ | spend_date | platform | total_amount | total_users | +------------+----------+--------------+-------------+ | 2019-07-01 | desktop  | 100          | 1           | | 2019-07-01 | mobile   | 100          | 1           | | 2019-07-01 | both     | 200          | 1           | | 2019-07-02 | desktop  | 100          | 1           | | 2019-07-02 | mobile   | 100          | 1           | | 2019-07-02 | both     | 0            | 0           | +------------+----------+--------------+-------------+ On 2019-07-01, user 1 purchased using both desktop and mobile, user 2 purchased using mobile only and user 3 purchased using desktop only. On 2019-07-02, user 2 purchased using mobile only, user 3 purchased using desktop only and no one purchased using both platforms. Solution sql SELECT aa.spend_date, aa.platform, COALESCE(bb.total_amount, 0) total_amount, COALESCE(bb.total_users,0) total_users FROM (SELECT DISTINCT(spend_date), a.platform   -- table aa FROM Spending JOIN (SELECT 'desktop' AS platform UNION SELECT 'mobile' AS platform UNION SELECT 'both' AS platform ) a ) aa LEFT JOIN (SELECT spend_date,                      -- table bb platform, SUM(amount) total_amount, COUNT(user_id) total_users FROM (SELECT spend_date, user_id, (CASE COUNT(DISTINCT platform) WHEN 1 THEN platform WHEN 2 THEN 'both' END) platform, SUM(amount) amount FROM Spending GROUP BY spend_date, user_id ) b GROUP BY spend_date, platform ) bb ON aa.platform = bb.platform AND aa.spend_date = bb.spend_date

---

#### Reported Posts II | Medium | üîí LeetCode

Table: Actions +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | user_id       | int     | | post_id       | int     | | action_date   | date    | | action        | enum    | | extra         | varchar | +---------------+---------+ There is no primary key for this table, it may have duplicate rows. The action column is an ENUM type of ('view', 'like', 'reaction', 'comment', 'report', 'share'). The extra column has optional information about the action such as a reason for report or a type of reaction. Table: Removals +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | post_id       | int     | | remove_date   | date    | +---------------+---------+ post_id is the primary key of this table. Each row in this table indicates that some post was removed as a result of being reported or as a result of an admin review. Write an SQL query to find the average for daily percentage of posts that got removed after being reported as spam, rounded to 2 decimal places. The query result format is in the following example: Actions table: +---------+---------+-------------+--------+--------+ | user_id | post_id | action_date | action | extra  | +---------+---------+-------------+--------+--------+ | 1       | 1       | 2019-07-01  | view   | null   | | 1       | 1       | 2019-07-01  | like   | null   | | 1       | 1       | 2019-07-01  | share  | null   | | 2       | 2       | 2019-07-04  | view   | null   | | 2       | 2       | 2019-07-04  | report | spam   | | 3       | 4       | 2019-07-04  | view   | null   | | 3       | 4       | 2019-07-04  | report | spam   | | 4       | 3       | 2019-07-02  | view   | null   | | 4       | 3       | 2019-07-02  | report | spam   | | 5       | 2       | 2019-07-03  | view   | null   | | 5       | 2       | 2019-07-03  | report | racism | | 5       | 5       | 2019-07-03  | view   | null   | | 5       | 5       | 2019-07-03  | report | racism | +---------+---------+-------------+--------+--------+ Removals table: +---------+-------------+ | post_id | remove_date | +---------+-------------+ | 2       | 2019-07-20  | | 3       | 2019-07-18  | +---------+-------------+ Result table: +-----------------------+ | average_daily_percent | +-----------------------+ | 75.00                 | +-----------------------+ The percentage for 2019-07-04 is 50% because only one post of two spam reported posts was removed. The percentage for 2019-07-02 is 100% because one post was reported as spam and it was removed. The other days had no spam reports so the average is (50 + 100) / 2 = 75% Note that the output is only one number and that we do not care about the remove dates. Solution sql WITH t1 AS( SELECT a.action_date, (COUNT(DISTINCT r.post_id))/(COUNT(DISTINCT a.post_id)) AS result FROM (SELECT action_date, post_id FROM actions WHERE extra = 'spam' AND action = 'report') a LEFT JOIN removals r ON a.post_id = r.post_id GROUP BY a.action_date) SELECT ROUND(AVG(t1.result)*100,2) AS  average_daily_percent FROM t1

---

#### User Activity for the Past 30 Days I | Easy | üîí LeetCode

Table: Activity +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | user_id       | int     | | session_id    | int     | | activity_date | date    | | activity_type | enum    | +---------------+---------+ There is no primary key for this table, it may have duplicate rows. The activity_type column is an ENUM of type ('open_session', 'end_session', 'scroll_down', 'send_message'). The table shows the user activities for a social media website. Note that each session belongs to exactly one user. Write an SQL query to find the daily active user count for a period of 30 days ending 2019-07-27 inclusively. A user was active on some day if he/she made at least one activity on that day. The query result format is in the following example: Activity table: +---------+------------+---------------+---------------+ | user_id | session_id | activity_date | activity_type | +---------+------------+---------------+---------------+ | 1       | 1          | 2019-07-20    | open_session  | | 1       | 1          | 2019-07-20    | scroll_down   | | 1       | 1          | 2019-07-20    | end_session   | | 2       | 4          | 2019-07-20    | open_session  | | 2       | 4          | 2019-07-21    | send_message  | | 2       | 4          | 2019-07-21    | end_session   | | 3       | 2          | 2019-07-21    | open_session  | | 3       | 2          | 2019-07-21    | send_message  | | 3       | 2          | 2019-07-21    | end_session   | | 4       | 3          | 2019-06-25    | open_session  | | 4       | 3          | 2019-06-25    | end_session   | +---------+------------+---------------+---------------+ Result table: +------------+--------------+ | day        | active_users | +------------+--------------+ | 2019-07-20 | 2            | | 2019-07-21 | 2            | +------------+--------------+ Note that we do not care about days with zero active users. Solution sql SELECT activity_date AS day, COUNT(DISTINCT user_id) AS active_users FROM activity WHERE activity_date > '2019-06-26' AND activity_date < '2019-07-27' GROUP BY activity_date

---

#### User Activity for the Past 30 Days II | Easy | üîí LeetCode

Table: Activity +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | user_id       | int     | | session_id    | int     | | activity_date | date    | | activity_type | enum    | +---------------+---------+ There is no primary key for this table, it may have duplicate rows. The activity_type column is an ENUM of type ('open_session', 'end_session', 'scroll_down', 'send_message'). The table shows the user activities for a social media website. Note that each session belongs to exactly one user. Write an SQL query to find the average number of sessions per user for a period of 30 days ending 2019-07-27 inclusively, rounded to 2 decimal places. The sessions we want to count for a user are those with at least one activity in that time period. The query result format is in the following example: Activity table: +---------+------------+---------------+---------------+ | user_id | session_id | activity_date | activity_type | +---------+------------+---------------+---------------+ | 1       | 1          | 2019-07-20    | open_session  | | 1       | 1          | 2019-07-20    | scroll_down   | | 1       | 1          | 2019-07-20    | end_session   | | 2       | 4          | 2019-07-20    | open_session  | | 2       | 4          | 2019-07-21    | send_message  | | 2       | 4          | 2019-07-21    | end_session   | | 3       | 2          | 2019-07-21    | open_session  | | 3       | 2          | 2019-07-21    | send_message  | | 3       | 2          | 2019-07-21    | end_session   | | 3       | 5          | 2019-07-21    | open_session  | | 3       | 5          | 2019-07-21    | scroll_down   | | 3       | 5          | 2019-07-21    | end_session   | | 4       | 3          | 2019-06-25    | open_session  | | 4       | 3          | 2019-06-25    | end_session   | +---------+------------+---------------+---------------+ Result table: +---------------------------+ | average_sessions_per_user | +---------------------------+ | 1.33                      | +---------------------------+ User 1 and 2 each had 1 session in the past 30 days while user 3 had 2 sessions so the average is (1 + 1 + 2) / 3 = 1.33. Solution sql SELECT IFNULL(ROUND(AVG(a.num),2),0) AS average_sessions_per_user FROM ( SELECT COUNT(DISTINCT session_id) AS num FROM activity WHERE activity_date BETWEEN '2019-06-28' AND '2019-07-27' GROUP BY user_id) a

---

#### Article Views I | Easy | üîí LeetCode

Table: Views +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | article_id    | int     | | author_id     | int     | | viewer_id     | int     | | view_date     | date    | +---------------+---------+ There is no primary key for this table, it may have duplicate rows. Each row of this table indicates that some viewer viewed an article (written by some author) on some date. Note that equal author_id and viewer_id indicate the same person. Write an SQL query to find all the authors that viewed at least one of their own articles, sorted in ascending order by their id. The query result format is in the following example: Views table: +------------+-----------+-----------+------------+ | article_id | author_id | viewer_id | view_date  | +------------+-----------+-----------+------------+ | 1          | 3         | 5         | 2019-08-01 | | 1          | 3         | 6         | 2019-08-02 | | 2          | 7         | 7         | 2019-08-01 | | 2          | 7         | 6         | 2019-08-02 | | 4          | 7         | 1         | 2019-07-22 | | 3          | 4         | 4         | 2019-07-21 | | 3          | 4         | 4         | 2019-07-21 | +------------+-----------+-----------+------------+ Result table: +------+ | id   | +------+ | 4    | | 7    | +------+ Solution sql SELECT DISTINCT author_id AS id FROM Views WHERE author_id = viewer_id ORDER BY author_id

---

#### Article Views II | Medium | üîí LeetCode

Table: Views +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | article_id    | int     | | author_id     | int     | | viewer_id     | int     | | view_date     | date    | +---------------+---------+ There is no primary key for this table, it may have duplicate rows. Each row of this table indicates that some viewer viewed an article (written by some author) on some date. Note that equal author_id and viewer_id indicate the same person. Write an SQL query to find all the people who viewed more than one article on the same date, sorted in ascending order by their id. The query result format is in the following example: Views table: +------------+-----------+-----------+------------+ | article_id | author_id | viewer_id | view_date  | +------------+-----------+-----------+------------+ | 1          | 3         | 5         | 2019-08-01 | | 3          | 4         | 5         | 2019-08-01 | | 1          | 3         | 6         | 2019-08-02 | | 2          | 7         | 7         | 2019-08-01 | | 2          | 7         | 6         | 2019-08-02 | | 4          | 7         | 1         | 2019-07-22 | | 3          | 4         | 4         | 2019-07-21 | | 3          | 4         | 4         | 2019-07-21 | +------------+-----------+-----------+------------+ Result table: +------+ | id   | +------+ | 5    | | 6    | +------+ Solution sql SELECT DISTINCT viewer_id AS id#, COUNT(DISTINCT article_id) AS total FROM views GROUP BY viewer_id, view_date HAVING count(DISTINCT article_id)>1 ORDER BY 1

---

#### Market Analysis I | Medium | üîí LeetCode

Table: Users +----------------+---------+ | Column Name    | Type    | +----------------+---------+ | user_id        | int     | | join_date      | date    | | favorite_brand | varchar | +----------------+---------+ user_id is the primary key of this table. This table has the info of the users of an online shopping website where users can sell and buy items. Table: Orders +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | order_id      | int     | | order_date    | date    | | item_id       | int     | | buyer_id      | int     | | seller_id     | int     | +---------------+---------+ order_id is the primary key of this table. item_id is a foreign key to the Items table. buyer_id and seller_id are foreign keys to the Users table. Table: Items +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | item_id       | int     | | item_brand    | varchar | +---------------+---------+ item_id is the primary key of this table. Write an SQL query to find for each user, the join date and the number of orders they made as a buyer in 2019. The query result format is in the following example: Users table: +---------+------------+----------------+ | user_id | join_date  | favorite_brand | +---------+------------+----------------+ | 1       | 2018-01-01 | Lenovo         | | 2       | 2018-02-09 | Samsung        | | 3       | 2018-01-19 | LG             | | 4       | 2018-05-21 | HP             | +---------+------------+----------------+ Orders table: +----------+------------+---------+----------+-----------+ | order_id | order_date | item_id | buyer_id | seller_id | +----------+------------+---------+----------+-----------+ | 1        | 2019-08-01 | 4       | 1        | 2         | | 2        | 2018-08-02 | 2       | 1        | 3         | | 3        | 2019-08-03 | 3       | 2        | 3         | | 4        | 2018-08-04 | 1       | 4        | 2         | | 5        | 2018-08-04 | 1       | 3        | 4         | | 6        | 2019-08-05 | 2       | 2        | 4         | +----------+------------+---------+----------+-----------+ Items table: +---------+------------+ | item_id | item_brand | +---------+------------+ | 1       | Samsung    | | 2       | Lenovo     | | 3       | LG         | | 4       | HP         | +---------+------------+ Result table: +-----------+------------+----------------+ | buyer_id  | join_date  | orders_in_2019 | +-----------+------------+----------------+ | 1         | 2018-01-01 | 1              | | 2         | 2018-02-09 | 2              | | 3         | 2018-01-19 | 0              | | 4         | 2018-05-21 | 0              | +-----------+------------+----------------+ Solution sql SELECT user_id AS buyer_id, join_date, coalesce(a.orders_in_2019,0) FROM users LEFT JOIN ( SELECT buyer_id, coalesce(count(*), 0) AS orders_in_2019 FROM orders o JOIN users u ON u.user_id = o.buyer_id WHERE extract('year' FROM order_date) = 2019 GROUP BY buyer_id) a ON users.user_id = a.buyer_id

---

#### Market Analysis II | Hard | üîí LeetCode

Table: Users +----------------+---------+ | Column Name    | Type    | +----------------+---------+ | user_id        | int     | | join_date      | date    | | favorite_brand | varchar | +----------------+---------+ user_id is the primary key of this table. This table has the info of the users of an online shopping website where users can sell and buy items. Table: Orders +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | order_id      | int     | | order_date    | date    | | item_id       | int     | | buyer_id      | int     | | seller_id     | int     | +---------------+---------+ order_id is the primary key of this table. item_id is a foreign key to the Items table. buyer_id and seller_id are foreign keys to the Users table. Table: Items +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | item_id       | int     | | item_brand    | varchar | +---------------+---------+ item_id is the primary key of this table. Write an SQL query to find for each user, whether the brand of the second item (by date) they sold is their favorite brand. If a user sold less than two items, report the answer for that user as no. It is guaranteed that no seller sold more than one item on a day. The query result format is in the following example: Users table: +---------+------------+----------------+ | user_id | join_date  | favorite_brand | +---------+------------+----------------+ | 1       | 2019-01-01 | Lenovo         | | 2       | 2019-02-09 | Samsung        | | 3       | 2019-01-19 | LG             | | 4       | 2019-05-21 | HP             | +---------+------------+----------------+ Orders table: +----------+------------+---------+----------+-----------+ | order_id | order_date | item_id | buyer_id | seller_id | +----------+------------+---------+----------+-----------+ | 1        | 2019-08-01 | 4       | 1        | 2         | | 2        | 2019-08-02 | 2       | 1        | 3         | | 3        | 2019-08-03 | 3       | 2        | 3         | | 4        | 2019-08-04 | 1       | 4        | 2         | | 5        | 2019-08-04 | 1       | 3        | 4         | | 6        | 2019-08-05 | 2       | 2        | 4         | +----------+------------+---------+----------+-----------+ Items table: +---------+------------+ | item_id | item_brand | +---------+------------+ | 1       | Samsung    | | 2       | Lenovo     | | 3       | LG         | | 4       | HP         | +---------+------------+ Result table: +-----------+--------------------+ | seller_id | 2nd_item_fav_brand | +-----------+--------------------+ | 1         | no                 | | 2         | yes                | | 3         | yes                | | 4         | no                 | +-----------+--------------------+ The answer for the user with id 1 is no because they sold nothing. The answer for the users with id 2 and 3 is yes because the brands of their second sold items are their favorite brands. The answer for the user with id 4 is no because the brand of their second sold item is not their favorite brand. Solution sql #Solution- 1: SELECT user_id AS seller_id, IF(ISNULL(item_brand), "no", "yes") AS 2nd_item_fav_brand FROM Users LEFT JOIN (SELECT seller_id, item_brand FROM Orders INNER JOIN Items ON Orders.item_id = Items.item_id WHERE (seller_id, order_date) IN (SELECT seller_id, MIN(order_date) AS order_date FROM Orders WHERE (seller_id, order_date) NOT IN (SELECT seller_id, MIN(order_date) FROM Orders GROUP BY seller_id) GROUP BY seller_id) ) AS t ON Users.user_id = t.seller_id and favorite_brand = item_brand #Solution- 2: WITH t1 AS( SELECT user_id, CASE WHEN favorite_brand = item_brand THEN "yes" ELSE "no" END AS 2nd_item_fav_brand FROM users u LEFT JOIN (SELECT o.item_id, seller_id, item_brand, RANK() OVER(PARTITION BY seller_id ORDER BY order_date) AS rk FROM orders o join items i USING (item_id)) a ON u.user_id = a.seller_id WHERE a.rk = 2) SELECT u.user_id AS seller_id, COALESCE(2nd_item_fav_brand,"no") AS 2nd_item_fav_brand FROM users u LEFT JOIN t1 USING(user_id)

---

#### Product Price at a Given Date | Medium | üîí LeetCode

Table: Products +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | product_id    | int     | | new_price     | int     | | change_date   | date    | +---------------+---------+ (product_id, change_date) is the primary key of this table. Each row of this table indicates that the price of some product was changed to a new price at some date. Write an SQL query to find the prices of all products on 2019-08-16. Assume the price of all products before any change is 10. The query result format is in the following example: Products table: +------------+-----------+-------------+ | product_id | new_price | change_date | +------------+-----------+-------------+ | 1          | 20        | 2019-08-14  | | 2          | 50        | 2019-08-14  | | 1          | 30        | 2019-08-15  | | 1          | 35        | 2019-08-16  | | 2          | 65        | 2019-08-17  | | 3          | 20        | 2019-08-18  | +------------+-----------+-------------+ Result table: +------------+-------+ | product_id | price | +------------+-------+ | 2          | 50    | | 1          | 35    | | 3          | 10    | +------------+-------+ Solution sql #Solution- 1: WITH t1 AS ( SELECT a.product_id, new_price FROM( SELECT product_id, max(change_date) AS date FROM products WHERE change_date<='2019-08-16' GROUP BY product_id) a JOIN products p ON a.product_id = p.product_id AND a.date = p.change_date), t2 AS ( SELECT distinct product_id FROM products) SELECT t2.product_id, coalesce(new_price,10) AS price FROM t2 LEFT JOIN t1 ON t2.product_id = t1.product_id ORDER BY price DESC #Solution- 2: SELECT t1.product_id AS product_id, IF(ISNULL(t2.price), 10, t2.price) AS price FROM (SELECT distinct product_id FROM Products) AS t1 LEFT JOIN (SELECT product_id, new_price AS price FROM Products WHERE (product_id, change_date) in (SELECT product_id, max(change_date) FROM Products WHERE change_date <='2019-08-16' GROUP BY product_id)) AS t2 ON t1.product_id = t2.product_id

---

#### Immediate Food Delivery I | Easy | üîí LeetCode

Table: Delivery +-----------------------------+---------+ | Column Name                 | Type    | +-----------------------------+---------+ | delivery_id                 | int     | | customer_id                 | int     | | order_date                  | date    | | customer_pref_delivery_date | date    | +-----------------------------+---------+ delivery_id is the primary key of this table. The table holds information about food delivery to customers that make orders at some date and specify a preferred delivery date (on the same order date or after it). If the preferred delivery date of the customer is the same as the order date then the order is called immediate otherwise it's called scheduled. Write an SQL query to find the percentage of immediate orders in the table, rounded to 2 decimal places. The query result format is in the following example: Delivery table: +-------------+-------------+------------+-----------------------------+ | delivery_id | customer_id | order_date | customer_pref_delivery_date | +-------------+-------------+------------+-----------------------------+ | 1           | 1           | 2019-08-01 | 2019-08-02                  | | 2           | 5           | 2019-08-02 | 2019-08-02                  | | 3           | 1           | 2019-08-11 | 2019-08-11                  | | 4           | 3           | 2019-08-24 | 2019-08-26                  | | 5           | 4           | 2019-08-21 | 2019-08-22                  | | 6           | 2           | 2019-08-11 | 2019-08-13                  | +-------------+-------------+------------+-----------------------------+ Result table: +----------------------+ | immediate_percentage | +----------------------+ | 33.33                | +----------------------+ The orders with delivery id 2 and 3 are immediate while the others are scheduled. Solution sql #Solution- 1: SELECT ROUND(SUM(CASE WHEN order_date=customer_pref_delivery_date THEN 1 ELSE 0 END)/count(1)*100, 2) immediate_percentage FROM Delivery; #Solution- 2: SELECT ROUND(avg(CASE WHEN order_date=customer_pref_delivery_date THEN 1 ELSE 0 END)*100,2) AS immediate_percentage FROM delivery

---

#### Immediate Food Delivery II | Medium | üîí LeetCode

Table: Delivery +-----------------------------+---------+ | Column Name                 | Type    | +-----------------------------+---------+ | delivery_id                 | int     | | customer_id                 | int     | | order_date                  | date    | | customer_pref_delivery_date | date    | +-----------------------------+---------+ delivery_id is the primary key of this table. The table holds information about food delivery to customers that make orders at some date and specify a preferred delivery date (on the same order date or after it). If the preferred delivery date of the customer is the same as the order date then the order is called immediate otherwise it's called scheduled. The first order of a customer is the order with the earliest order date that customer made. It is guaranteed that a customer has exactly one first order. Write an SQL query to find the percentage of immediate orders in the first orders of all customers, rounded to 2 decimal places. The query result format is in the following example: Delivery table: +-------------+-------------+------------+-----------------------------+ | delivery_id | customer_id | order_date | customer_pref_delivery_date | +-------------+-------------+------------+-----------------------------+ | 1           | 1           | 2019-08-01 | 2019-08-02                  | | 2           | 2           | 2019-08-02 | 2019-08-02                  | | 3           | 1           | 2019-08-11 | 2019-08-12                  | | 4           | 3           | 2019-08-24 | 2019-08-24                  | | 5           | 3           | 2019-08-21 | 2019-08-22                  | | 6           | 2           | 2019-08-11 | 2019-08-13                  | | 7           | 4           | 2019-08-09 | 2019-08-09                  | +-------------+-------------+------------+-----------------------------+ Result table: +----------------------+ | immediate_percentage | +----------------------+ | 50.00                | +----------------------+ The customer id 1 has a first order with delivery id 1 and it is scheduled. The customer id 2 has a first order with delivery id 2 and it is immediate. The customer id 3 has a first order with delivery id 5 and it is scheduled. The customer id 4 has a first order with delivery id 7 and it is immediate. Hence, half the customers have immediate first orders. Solution sql #Solution- 1: SELECT ROUND(SUM(CASE WHEN order_date=customer_pref_delivery_date THEN 1 ELSE 0 END)/count(DISTINCT customer_id)*100, 2) immediate_percentage FROM Delivery WHERE (customer_id, order_date) IN (SELECT customer_id, MIN(order_date) FROM Delivery GROUP BY customer_id) #Solution- 2: SELECT ROUND(AVG(CASE WHEN order_date = customer_pref_delivery_date THEN 1 ELSE 0 END)*100,2) as immediate_percentage FROM (SELECT *, RANK() OVER(PARTITION BY customer_id ORDER BY order_date) AS rk FROM delivery) a WHERE a.rk=1

---

#### Reformat Department Table | Easy | LeetCode

Table: Department +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | id            | int     | | revenue       | int     | | month         | varchar | +---------------+---------+ (id, month) is the primary key of this table. The table has information about the revenue of each department per month. The month has values in ["Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"]. Write an SQL query to reformat the table such that there is a department id column and a revenue column for each month. The query result format is in the following example: Department table: +------+---------+-------+ | id   | revenue | month | +------+---------+-------+ | 1    | 8000    | Jan   | | 2    | 9000    | Jan   | | 3    | 10000   | Feb   | | 1    | 7000    | Feb   | | 1    | 6000    | Mar   | +------+---------+-------+ Result table: +------+-------------+-------------+-------------+-----+-------------+ | id   | Jan_Revenue | Feb_Revenue | Mar_Revenue | ... | Dec_Revenue | +------+-------------+-------------+-------------+-----+-------------+ | 1    | 8000        | 7000        | 6000        | ... | null        | | 2    | 9000        | null        | null        | ... | null        | | 3    | null        | 10000       | null        | ... | null        | +------+-------------+-------------+-------------+-----+-------------+ Note that the result table has 13 columns (1 for the department id + 12 for the months). Solution sql SELECT id, SUM(IF(month='Jan', revenue, NULL)) AS Jan_Revenue, SUM(IF(month='Feb', revenue, NULL)) AS Feb_Revenue, SUM(IF(month='Mar', revenue, NULL)) AS Mar_Revenue, SUM(IF(month='Apr', revenue, NULL)) AS Apr_Revenue, SUM(IF(month='May', revenue, NULL)) AS May_Revenue, SUM(IF(month='Jun', revenue, NULL)) AS Jun_Revenue, SUM(IF(month='Jul', revenue, NULL)) AS Jul_Revenue, SUM(IF(month='Aug', revenue, NULL)) AS Aug_Revenue, SUM(IF(month='Sep', revenue, NULL)) AS Sep_Revenue, SUM(IF(month='Oct', revenue, NULL)) AS Oct_Revenue, SUM(IF(month='Nov', revenue, NULL)) AS Nov_Revenue, SUM(IF(month='Dec', revenue, NULL)) AS Dec_Revenue FROM Department Group BY id;

---

#### Monthly Transactions I | Medium | üîí LeetCode

Table: Transactions +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | id            | int     | | country       | varchar | | state         | enum    | | amount        | int     | | trans_date    | date    | +---------------+---------+ id is the primary key of this table. The table has information about incoming transactions. The state column is an enum of type ["approved", "declined"]. Write an SQL query to find for each month and country, the number of transactions and their total amount, the number of approved transactions and their total amount. The query result format is in the following example: Transactions table: +------+---------+----------+--------+------------+ | id   | country | state    | amount | trans_date | +------+---------+----------+--------+------------+ | 121  | US      | approved | 1000   | 2018-12-18 | | 122  | US      | declined | 2000   | 2018-12-19 | | 123  | US      | approved | 2000   | 2019-01-01 | | 124  | DE      | approved | 2000   | 2019-01-07 | +------+---------+----------+--------+------------+ Result table: +----------+---------+-------------+----------------+--------------------+-----------------------+ | month    | country | trans_count | approved_count | trans_total_amount | approved_total_amount | +----------+---------+-------------+----------------+--------------------+-----------------------+ | 2018-12  | US      | 2           | 1              | 3000               | 1000                  | | 2019-01  | US      | 1           | 1              | 2000               | 2000                  | | 2019-01  | DE      | 1           | 1              | 2000               | 2000                  | +----------+---------+-------------+----------------+--------------------+-----------------------+ Solution sql WITH t1 AS( SELECT DATE_FORMAT(trans_date,'%Y-%m') AS month, country, COUNT(state) AS trans_count, sum(amount) AS trans_total_amount FROM transactions GROUP BY country, month(trans_date)), t2 AS ( SELECT DATE_FORMAT(trans_date,'%Y-%m') AS month, country, COUNT(state) AS approved_count, sum(amount) AS approved_total_amount FROM transactions WHERE state = 'approved' GROUP BY country, month(trans_date)) SELECT t1.month, t1.country, COALESCE(t1.trans_count,0) AS trans_count, COALESCE(t2.approved_count,0) AS approved_count, COALESCE(t1.trans_total_amount,0) AS trans_total_amount, COALESCE(t2.approved_total_amount,0) AS approved_total_amount FROM t1 LEFT JOIN t2 ON t1.country = t2.country and t1.month = t2.month

---

#### Tournament Winners | Hard | üîí LeetCode

Table: Players +-------------+-------+ | Column Name | Type  | +-------------+-------+ | player_id   | int   | | group_id    | int   | +-------------+-------+ player_id is the primary key of this table. Each row of this table indicates the group of each player. Table: Matches +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | match_id      | int     | | first_player  | int     | | second_player | int     | | first_score   | int     | | second_score  | int     | +---------------+---------+ match_id is the primary key of this table. Each row is a record of a match, first_player and second_player contain the player_id of each match. first_score and second_score contain the number of points of the first_player and second_player respectively. You may assume that, in each match, players belongs to the same group. The winner in each group is the player who scored the maximum total points within the group. In the case of a tie, the lowest player_id wins. Write an SQL query to find the winner in each group. The query result format is in the following example: Players table: +-----------+------------+ | player_id | group_id   | +-----------+------------+ | 15        | 1          | | 25        | 1          | | 30        | 1          | | 45        | 1          | | 10        | 2          | | 35        | 2          | | 50        | 2          | | 20        | 3          | | 40        | 3          | +-----------+------------+ Matches table: +------------+--------------+---------------+-------------+--------------+ | match_id   | first_player | second_player | first_score | second_score | +------------+--------------+---------------+-------------+--------------+ | 1          | 15           | 45            | 3           | 0            | | 2          | 30           | 25            | 1           | 2            | | 3          | 30           | 15            | 2           | 0            | | 4          | 40           | 20            | 5           | 2            | | 5          | 35           | 50            | 1           | 1            | +------------+--------------+---------------+-------------+--------------+ Result table: +-----------+------------+ | group_id  | player_id  | +-----------+------------+ | 1         | 15         | | 2         | 35         | | 3         | 40         | +-----------+------------+ Solution sql WITH t1 AS( SELECT first_player, SUM(first_score) AS total FROM (SELECT first_player, first_score FROM matches UNION ALL SELECT second_player, second_score FROM matches) a GROUP BY 1), t2 AS( SELECT *, COALESCE(total,0) AS score FROM players p LEFT JOIN t1 ON p.player_id = t1.first_player) SELECT group_id, player_id FROM (SELECT *, ROW_NUMBER() OVER(PARTITION BY group_id ORDER BY group_id, score DESC) AS rn FROM t2) b WHERE b.rn = 1

---

#### Last Person to Fit in the Elevator | Medium | üîí LeetCode

Table: Queue +-------------+---------+ | Column Name | Type    | +-------------+---------+ | person_id   | int     | | person_name | varchar | | weight      | int     | | turn        | int     | +-------------+---------+ person_id is the primary key column for this table. This table has the information about all people waiting for an elevator. The person_id and turn columns will contain all numbers from 1 to n, where n is the number of rows in the table. The maximum weight the elevator can hold is 1000. Write an SQL query to find the person_name of the last person who will fit in the elevator without exceeding the weight limit. It is guaranteed that the person who is first in the queue can fit in the elevator. The query result format is in the following example: Queue table +-----------+-------------------+--------+------+ | person_id | person_name       | weight | turn | +-----------+-------------------+--------+------+ | 5         | George Washington | 250    | 1    | | 3         | John Adams        | 350    | 2    | | 6         | Thomas Jefferson  | 400    | 3    | | 2         | Will Johnliams    | 200    | 4    | | 4         | Thomas Jefferson  | 175    | 5    | | 1         | James Elephant    | 500    | 6    | +-----------+-------------------+--------+------+ Result table +-------------------+ | person_name       | +-------------------+ | Thomas Jefferson  | +-------------------+ Queue table is ordered by turn in the example for simplicity. In the example George Washington(id 5), John Adams(id 3) and Thomas Jefferson(id 6) will enter the elevator as their weight sum is 250 + 350 + 400 = 1000. Thomas Jefferson(id 6) is the last person to fit in the elevator because he has the last turn in these three people. Solution sql WITH t1 AS ( SELECT *, SUM(weight) OVER(ORDER BY turn) AS cum_weight FROM queue ORDER BY turn) SELECT t1.person_name FROM t1 WHERE turn = (SELECT MAX(turn) FROM t1 WHERE t1.cum_weight<=1000)

---

#### Monthly Transactions II | Medium | üîí LeetCode

Table: Transactions +----------------+---------+ | Column Name    | Type    | +----------------+---------+ | id             | int     | | country        | varchar | | state          | enum    | | amount         | int     | | trans_date     | date    | +----------------+---------+ id is the primary key of this table. The table has information about incoming transactions. The state column is an enum of type ["approved", "declined"]. Table: Chargebacks +----------------+---------+ | Column Name    | Type    | +----------------+---------+ | trans_id       | int     | | charge_date    | date    | +----------------+---------+ Chargebacks contains basic information regarding incoming chargebacks from some transactions placed in Transactions table. trans_id is a foreign key to the id column of Transactions table. Each chargeback corresponds to a transaction made previously even if they were not approved. Write an SQL query to find for each month and country, the number of approved transactions and their total amount, the number of chargebacks and their total amount. Note: In your query, given the month and country, ignore rows with all zeros. The query result format is in the following example: Transactions table: +------+---------+----------+--------+------------+ | id   | country | state    | amount | trans_date | +------+---------+----------+--------+------------+ | 101  | US      | approved | 1000   | 2019-05-18 | | 102  | US      | declined | 2000   | 2019-05-19 | | 103  | US      | approved | 3000   | 2019-06-10 | | 104  | US      | approved | 4000   | 2019-06-13 | | 105  | US      | approved | 5000   | 2019-06-15 | +------+---------+----------+--------+------------+ Chargebacks table: +------------+------------+ | trans_id   | trans_date | +------------+------------+ | 102        | 2019-05-29 | | 101        | 2019-06-30 | | 105        | 2019-09-18 | +------------+------------+ Result table: +----------+---------+----------------+-----------------+-------------------+--------------------+ | month    | country | approved_count | approved_amount | chargeback_count  | chargeback_amount  | +----------+`---------+----------------+-----------------+-------------------+--------------------+ | 2019-05  | US      | 1              | 1000            | 1                 | 2000               | | 2019-06  | US      | 3              | 12000           | 1                 | 1000               | | 2019-09  | US      | 0              | 0               | 1                 | 5000               | +----------+---------+----------------+-----------------+-------------------+--------------------+ Solution sql #Solution 1: WITH t1 AS (SELECT country, extract('month' FROM trans_date), state, COUNT(*) AS approved_count, SUM(amount) AS approved_amount FROM transactions WHERE state = 'approved' GROUP BY 1, 2, 3), t2 AS( SELECT t.country, extract('month' FROM c.trans_date), SUM(amount) AS chargeback_amount, COUNT(*) AS chargeback_count FROM chargebacks c LEFT JOIN transactions t ON trans_id = id GROUP BY t.country, extract('month' FROM c.trans_date)), t3 AS( SELECT t2.date_part, t2.country, COALESCE(approved_count,0) AS approved_count, COALESCE(approved_amount,0) AS approved_amount, COALESCE(chargeback_count,0) AS chargeback_count, COALESCE(chargeback_amount,0) AS chargeback_amount FROM t2 LEFT JOIN t1 ON t2.date_part = t1.date_part AND t2.country = t1.country), t4 AS( SELECT t1.date_part, t1.country, COALESCE(approved_count,0) AS approved_count, COALESCE(approved_amount,0) AS approved_amount, COALESCE(chargeback_count,0) AS chargeback_count, COALESCE(chargeback_amount,0) AS chargeback_amount FROM t2 RIGHT JOIN t1 ON t2.date_part = t1.date_part AND t2.country = t1.country) SELECT * FROM t3 UNION SELECT * FROM t4 #Solution 2: SELECT month, country, SUM(CASE WHEN type='approved' THEN 1 ELSE 0 END) AS approved_count, SUM(CASE WHEN type='approved' THEN amount ELSE 0 END) AS approved_amount, SUM(CASE WHEN type='chargeback' THEN 1 ELSE 0 END) AS chargeback_count, SUM(CASE WHEN type='chargeback' THEN amount ELSE 0 END) AS chargeback_amount FROM ( ( SELECT left(t.trans_date, 7) AS month, t.country, amount,'approved' AS type FROM Transactions AS t WHERE state='approved' ) UNION ALL ( SELECT left(c.trans_date, 7) AS month, t.country, amount,'chargeback' AS type FROM Transactions AS t JOIN Chargebacks AS c ON t.id = c.trans_id ) ) AS tt GROUP BY tt.month, tt.country #Solution 3: SELECT month, country, SUM(CASE WHEN type='approved' THEN count ELSE 0 END) AS approved_count, SUM(CASE WHEN type='approved' THEN amount ELSE 0 END) AS approved_amount, SUM(CASE WHEN type='chargeback' THEN count ELSE 0 END) AS chargeback_count, SUM(CASE WHEN type='chargeback' THEN amount ELSE 0 END) AS chargeback_amount FROM ( ( SELECT LEFT(t.trans_date, 7) AS month, t.country, COUNT(1) AS count, SUM(amount) AS amount,'approved' AS type FROM Transactions AS t LEFT JOIN Chargebacks AS c ON t.id = c.trans_id WHERE state='approved' GROUP BY LEFT(t.trans_date, 7), t.country ) union ( SELECT LEFT(c.trans_date, 7) AS month, t.country, COUNT(1) AS count, SUM(amount) AS amount,'chargeback' AS type FROM Transactions AS t JOIN Chargebacks AS c ON t.id = c.trans_id GROUP BY LEFT(c.trans_date, 7), t.country ) ) AS tt GROUP BY tt.month, tt.country

---

#### Queries Quality and Percentage | Easy | üîí LeetCode

Table: Queries +-------------+---------+ | Column Name | Type    | +-------------+---------+ | query_name  | varchar | | result      | varchar | | position    | int     | | rating      | int     | +-------------+---------+ There is no primary key for this table, it may have duplicate rows. This table contains information collected from some queries on a database. The position column has a value from 1 to 500. The rating column has a value from 1 to 5. Query with rating less than 3 is a poor query. We define query quality as: The average of the ratio between query rating and its position. We also define poor query percentage as: The percentage of all queries with rating less than 3. Write an SQL query to find each query_name, the quality and poor_query_percentage. Both quality and poor_query_percentage should be rounded to 2 decimal places. The query result format is in the following example: Queries table: +------------+-------------------+----------+--------+ | query_name | result            | position | rating | +------------+-------------------+----------+--------+ | Dog        | Golden Retriever  | 1        | 5      | | Dog        | German Shepherd   | 2        | 5      | | Dog        | Mule              | 200      | 1      | | Cat        | Shirazi           | 5        | 2      | | Cat        | Siamese           | 3        | 3      | | Cat        | Sphynx            | 7        | 4      | +------------+-------------------+----------+--------+ Result table: +------------+---------+-----------------------+ | query_name | quality | poor_query_percentage | +------------+---------+-----------------------+ | Dog        | 2.50    | 33.33                 | | Cat        | 0.66    | 33.33                 | +------------+---------+-----------------------+ Dog queries quality is ((5 / 1) + (5 / 2) + (1 / 200)) / 3 = 2.50 Dog queries poor_ query_percentage is (1 / 3) * 100 = 33.33 Cat queries quality equals ((2 / 5) + (3 / 3) + (4 / 7)) / 3 = 0.66 Cat queries poor_ query_percentage is (1 / 3) * 100 = 33.33 Solution sql #Solution 1: SELECT query_name, ROUND(SUM(rating/position)/COUNT(*),2) AS quality, ROUND(AVG(CASE WHEN rating<3 THEN 1 ELSE 0 END)*100,2) AS poor_query_percentage FROM queries GROUP BY query_name #Solution 2: SELECT query_name, ROUND(AVG(rating/position), 2) AS quality, ROUND(100*SUM(CASE WHEN rating<3 THEN 1 ELSE 0 END)/COUNT(1), 2) AS poor_query_percentage FROM Queries GROUP BY query_name

---

#### Team Scores in Football Tournament | Medium | üîí LeetCode

Table: Teams +---------------+----------+ | Column Name   | Type     | +---------------+----------+ | team_id       | int      | | team_name     | varchar  | +---------------+----------+ team_id is the primary key of this table. Each row of this table represents a single football team. Table: Matches +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | match_id      | int     | | host_team     | int     | | guest_team    | int     | | host_goals    | int     | | guest_goals   | int     | +---------------+---------+ match_id is the primary key of this table. Each row is a record of a finished match between two different teams. Teams host_team and guest_team are represented by their IDs in the teams table (team_id) and they scored host_goals and guest_goals goals respectively. You would like to compute the scores of all teams after all matches. Points are awarded as follows: A team receives three points if they win a match (Score strictly more goals than the opponent team). A team receives one point if they draw a match (Same number of goals as the opponent team). A team receives no points if they lose a match (Score less goals than the opponent team). Write an SQL query that selects the team_id, team_name and num_points of each team in the tournament after all described matches. Result table should be ordered by num_points (decreasing order). In case of a tie, order the records by team_id (increasing order). The query result format is in the following example: Teams table: +-----------+--------------+ | team_id   | team_name    | +-----------+--------------+ | 10        | Leetcode FC  | | 20        | NewYork FC   | | 30        | Atlanta FC   | | 40        | Chicago FC   | | 50        | Toronto FC   | +-----------+--------------+ Matches table: +------------+--------------+---------------+-------------+--------------+ | match_id   | host_team    | guest_team    | host_goals  | guest_goals  | +------------+--------------+---------------+-------------+--------------+ | 1          | 10           | 20            | 3           | 0            | | 2          | 30           | 10            | 2           | 2            | | 3          | 10           | 50            | 5           | 1            | | 4          | 20           | 30            | 1           | 0            | | 5          | 50           | 30            | 1           | 0            | +------------+--------------+---------------+-------------+--------------+ Result table: +------------+--------------+---------------+ | team_id    | team_name    | num_points    | +------------+--------------+---------------+ | 10         | Leetcode FC  | 7             | | 20         | NewYork FC   | 3             | | 50         | Toronto FC   | 3             | | 30         | Atlanta FC   | 1             | | 40         | Chicago FC   | 0             | +------------+--------------+---------------+ Solution sql #Solution 1: SELECT Teams.team_id, Teams.team_name, SUM(CASE WHEN team_id=host_team AND host_goals>guest_goals THEN 3 ELSE 0 END) + SUM(CASE WHEN team_id=host_team AND host_goals=guest_goals THEN 1 ELSE 0 END) + SUM(CASE WHEN team_id=guest_team AND host_goals<guest_goals THEN 3 ELSE 0 END) + SUM(CASE WHEN team_id=guest_team AND host_goals=guest_goals THEN 1 ELSE 0 END) AS num_points FROM Teams LEFT JOIN Matches ON Teams.team_id = Matches.host_team OR Teams.team_id = Matches.guest_team GROUP BY Teams.team_id ORDER BY num_points DESC, Teams.team_id ASC #Solution 2: SELECT Teams.team_id, Teams.team_name, SUM(if(isnull(num_points), 0, num_points)) AS num_points FROM Teams LEFT JOIN ( SELECT host_team AS team_id, SUM(CASE WHEN host_goals>guest_goals THEN 3 WHEN host_goals=guest_goals THEN 1 ELSE 0 END) AS num_points FROM Matches GROUP BY host_team UNION ALL SELECT guest_team AS team_id, SUM(CASE WHEN host_goals<guest_goals THEN 3 WHEN host_goals=guest_goals THEN 1 ELSE 0 END) AS num_points FROM Matches GROUP BY guest_team ) AS tt ON Teams.team_id = tt.team_id GROUP BY Teams.team_id ORDER BY num_points DESC, Teams.team_id ASC #Solution 3: SELECT Teams.team_id, Teams.team_name, IFNULL(SUM(num_points), 0) AS num_points FROM Teams LEFT JOIN ( SELECT host_team AS team_id, SUM(CASE WHEN host_goals>guest_goals THEN 3 WHEN host_goals=guest_goals THEN 1 ELSE 0 END) AS num_points FROM Matches GROUP BY host_team UNION ALL SELECT guest_team AS team_id, SUM(CASE WHEN host_goals<guest_goals THEN 3 WHEN host_goals=guest_goals THEN 1 ELSE 0 END) AS num_points FROM Matches GROUP BY guest_team ) AS tt ON Teams.team_id = tt.team_id GROUP BY Teams.team_id ORDER BY num_points DESC, Teams.team_id ASC #Solution 4: WITH t1 AS( SELECT c.host_id, c.host_name, c.host_points FROM( SELECT a.match_id, a.team_id AS host_id, a.team_name AS host_name, b.team_id AS guest_id, b.team_name AS guest_name, a.host_goals, a.guest_goals, CASE WHEN a.host_goals > a.guest_goals THEN 3 WHEN a.host_goals = a.guest_goals THEN 1 ELSE 0 END AS host_points, CASE WHEN a.host_goals < a.guest_goals THEN 3 WHEN a.host_goals = a.guest_goals THEN 1 ELSE 0 END AS guest_points FROM( SELECT * FROM matches m JOIN teams t ON t.team_id = m.host_team) a JOIN (SELECT * FROM matches m JOIN teams t ON t.team_id = m.guest_team) b ON a.match_id = b.match_id) c UNION ALL SELECT d.guest_id, d.guest_name, d.guest_points FROM( SELECT a.match_id, a.team_id AS host_id, a.team_name AS host_name, b.team_id AS guest_id, b.team_name AS guest_name, a.host_goals, a.guest_goals, CASE WHEN a.host_goals > a.guest_goals THEN 3 WHEN a.host_goals = a.guest_goals THEN 1 ELSE 0 END AS host_points, CASE WHEN a.host_goals < a.guest_goals THEN 3 WHEN a.host_goals = a.guest_goals THEN 1 ELSE 0 END AS guest_points FROM( SELECT * FROM matches m JOIN teams t ON t.team_id = m.host_team) a JOIN (SELECT * FROM matches m JOIN teams t ON t.team_id = m.guest_team) b ON a.match_id = b.match_id) d) SELECT team_id, team_name, coalesce(total,0) AS num_points FROM teams t2 LEFT JOIN( SELECT host_id, host_name, SUM(host_points) AS total FROM t1 GROUP BY host_id, host_name) e ON t2.team_id = e.host_id ORDER BY num_points DESC, team_id

---

#### Report Contiguous Dates | Hard | üîí LeetCode

Table: Failed +--------------+---------+ | Column Name  | Type    | +--------------+---------+ | fail_date    | date    | +--------------+---------+ Primary key for this table is fail_date. Failed table contains the days of failed tasks. Table: Succeeded +--------------+---------+ | Column Name  | Type    | +--------------+---------+ | success_date | date    | +--------------+---------+ Primary key for this table is success_date. Succeeded table contains the days of succeeded tasks. A system is running one task every day. Every task is independent of the previous tasks. The tasks can fail or succeed. Write an SQL query to generate a report of period_state for each continuous interval of days in the period from 2019-01-01 to 2019-12-31. period_state is 'failed' if tasks in this interval failed or 'succeeded' if tasks in this interval succeeded. Interval of days are retrieved as start_date and end_date. Order result by start_date. The query result format is in the following example: Failed table: +-------------------+ | fail_date         | +-------------------+ | 2018-12-28        | | 2018-12-29        | | 2019-01-04        | | 2019-01-05        | +-------------------+ Succeeded table: +-------------------+ | success_date      | +-------------------+ | 2018-12-30        | | 2018-12-31        | | 2019-01-01        | | 2019-01-02        | | 2019-01-03        | | 2019-01-06        | +-------------------+ Result table: +--------------+--------------+--------------+ | period_state | start_date   | end_date     | +--------------+--------------+--------------+ | succeeded    | 2019-01-01   | 2019-01-03   | | failed       | 2019-01-04   | 2019-01-05   | | succeeded    | 2019-01-06   | 2019-01-06   | +--------------+--------------+--------------+ The report ignored the system state in 2018 as we care about the system in the period 2019-01-01 to 2019-12-31. From 2019-01-01 to 2019-01-03 all tasks succeeded and the system state was "succeeded". From 2019-01-04 to 2019-01-05 all tasks failed and system state was "failed". From 2019-01-06 to 2019-01-06 all tasks succeeded and system state was "succeeded". Solution sql #Solution 1: WITH t1 AS( SELECT MIN(success_date) AS start_date, MAX(success_date) AS end_date, state FROM( SELECT *, date_sub(success_date, interval ROW_NUMBER() OVER(ORDER BY success_date) day) AS diff, 1 AS state FROM succeeded WHERE success_date BETWEEN "2019-01-01" AND "2019-12-31") a GROUP BY diff), t2 AS( SELECT MIN(fail_date) AS start_date, MAX(fail_date) AS end_date, state FROM( SELECT *, date_sub(fail_date, interval ROW_NUMBER() OVER(ORDER BY fail_date) day) AS diff, 0 AS state FROM failed WHERE fail_date BETWEEN "2019-01-01" AND "2019-12-31") b GROUP BY diff) SELECT CASE WHEN c.state = 1 THEN "succeeded" ELSE "failed" END AS period_state,start_date, end_date FROM( SELECT * FROM t1 UNION ALL SELECT * FROM t2) c ORDER BY start_date #Solution 2: ## First generate a list of dates ##   succeeded 2019-01-01 ##   succeeded 2019-01-02 ##   ... ##   failed 2019-01-04 ##   ... ## Add group id for contiguous ranges ## Notice: dates themselves are contiguous ## SELECT period_state, MIN(date) AS start_date, MAX(date) AS end_date FROM ( SELECT period_state, date, @rank := CASE WHEN @prev = period_state THEN @rank ELSE @rank+1 END AS rank, @prev := period_state AS prev FROM ( SELECT 'failed' AS period_state, fail_date AS date FROM Failed WHERE fail_date BETWEEN '2019-01-01' AND '2019-12-31' UNION SELECT 'succeeded' AS period_state, success_date AS date FROM Succeeded WHERE success_date BETWEEN '2019-01-01' AND '2019-12-31') AS t, (SELECT @rank:=0, @prev:='') AS rows ORDER BY date ASC) AS tt GROUP BY rank ORDER BY rank

---

#### Number of Comments per Post | Easy | üîí LeetCode

Table: Submissions +---------------+----------+ | Column Name   | Type     | +---------------+----------+ | sub_id        | int      | | parent_id     | int      | +---------------+----------+ There is no primary key for this table, it may have duplicate rows. Each row can be a post or comment on the post. parent_id is null for posts. parent_id for comments is sub_id for another post in the table. Write an SQL query to find number of comments per each post. Result table should contain post_id and its corresponding number_of_comments, and must be sorted by post_id in ascending order. Submissions may contain duplicate comments. You should count the number of unique comments per post. Submissions may contain duplicate posts. You should treat them as one post. The query result format is in the following example: Submissions table: +---------+------------+ | sub_id  | parent_id  | +---------+------------+ | 1       | Null       | | 2       | Null       | | 1       | Null       | | 12      | Null       | | 3       | 1          | | 5       | 2          | | 3       | 1          | | 4       | 1          | | 9       | 1          | | 10      | 2          | | 6       | 7          | +---------+------------+ Result table: +---------+--------------------+ | post_id | number_of_comments | +---------+--------------------+ | 1       | 3                  | | 2       | 2                  | | 12      | 0                  | +---------+--------------------+ The post with id 1 has three comments in the table with id 3, 4 and 9. The comment with id 3 is repeated in the table, we counted it only once. The post with id 2 has two comments in the table with id 5 and 10. The post with id 12 has no comments in the table. The comment with id 6 is a comment on a deleted post with id 7 so we ignored it. Solution sql SELECT a.sub_id AS post_id, coalesce(b.number_of_comments,0) AS number_of_comments FROM( SELECT DISTINCT sub_id FROM submissions WHERE parent_id IS NULL) a LEFT JOIN( SELECT parent_id, count(DISTINCT(sub_id)) AS number_of_comments FROM submissions GROUP BY parent_id HAVING parent_id = any(SELECT sub_id from submissions WHERE parent_id IS NULL)) b ON a.sub_id = b.parent_id ORDER BY post_id

---

#### Average Selling Price | Easy | üîí LeetCode

Table: Prices +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | product_id    | int     | | start_date    | date    | | end_date      | date    | | price         | int     | +---------------+---------+ (product_id, start_date, end_date) is the primary key for this table. Each row of this table indicates the price of the product_id in the period from start_date to end_date. For each product_id there will be no two overlapping periods. That means there will be no two intersecting periods for the same product_id. Table: UnitsSold +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | product_id    | int     | | purchase_date | date    | | units         | int     | +---------------+---------+ There is no primary key for this table, it may contain duplicates. Each row of this table indicates the date, units and product_id of each product sold. Write an SQL query to find the average selling price for each product. average_price should be rounded to 2 decimal places. The query result format is in the following example: Prices table: +------------+------------+------------+--------+ | product_id | start_date | end_date   | price  | +------------+------------+------------+--------+ | 1          | 2019-02-17 | 2019-02-28 | 5      | | 1          | 2019-03-01 | 2019-03-22 | 20     | | 2          | 2019-02-01 | 2019-02-20 | 15     | | 2          | 2019-02-21 | 2019-03-31 | 30     | +------------+------------+------------+--------+ UnitsSold table: +------------+---------------+-------+ | product_id | purchase_date | units | +------------+---------------+-------+ | 1          | 2019-02-25    | 100   | | 1          | 2019-03-01    | 15    | | 2          | 2019-02-10    | 200   | | 2          | 2019-03-22    | 30    | +------------+---------------+-------+ Result table: +------------+---------------+ | product_id | average_price | +------------+---------------+ | 1          | 6.96          | | 2          | 16.96         | +------------+---------------+ Average selling price = Total Price of Product / Number of products sold. Average selling price for product 1 = ((100 * 5) + (15 * 20)) / 115 = 6.96 Average selling price for product 2 = ((200 * 15) + (30 * 30)) / 230 = 16.96 Solution sql SELECT UnitsSold.product_id, ROUND(SUM(units*price)/SUM(units), 2) AS average_price FROM UnitsSold INNER JOIN Prices ON UnitsSold.product_id = Prices.product_id AND UnitsSold.purchase_date BETWEEN Prices.start_date AND Prices.end_date GROUP BY UnitsSold.product_id

---

#### Page Recommendations | Medium | üîí LeetCode

Table: Friendship +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | user1_id      | int     | | user2_id      | int     | +---------------+---------+ (user1_id, user2_id) is the primary key for this table. Each row of this table indicates that there is a friendship relation between user1_id and user2_id. Table: Likes +-------------+---------+ | Column Name | Type    | +-------------+---------+ | user_id     | int     | | page_id     | int     | +-------------+---------+ (user_id, page_id) is the primary key for this table. Each row of this table indicates that user_id likes page_id. Write an SQL query to recommend pages to the user with user_id = 1 using the pages that your friends liked. It should not recommend pages you already liked. Return result table in any order without duplicates. The query result format is in the following example: Friendship table: +----------+----------+ | user1_id | user2_id | +----------+----------+ | 1        | 2        | | 1        | 3        | | 1        | 4        | | 2        | 3        | | 2        | 4        | | 2        | 5        | | 6        | 1        | +----------+----------+ Likes table: +---------+---------+ | user_id | page_id | +---------+---------+ | 1       | 88      | | 2       | 23      | | 3       | 24      | | 4       | 56      | | 5       | 11      | | 6       | 33      | | 2       | 77      | | 3       | 77      | | 6       | 88      | +---------+---------+ Result table: +------------------+ | recommended_page | +------------------+ | 23               | | 24               | | 56               | | 33               | | 77               | +------------------+ User one is friend with users 2, 3, 4 and 6. Suggested pages are 23 from user 2, 24 from user 3, 56 from user 3 and 33 from user 6. Page 77 is suggested from both user 2 and user 3. Page 88 is not suggested because user 1 already likes it. Solution sql SELECT DISTINCT page_id AS recommended_page FROM Likes WHERE user_id IN (SELECT user2_id FROM Friendship WHERE user1_id=1 UNION SELECT user1_id FROM Friendship WHERE user2_id=1) AND page_id NOT IN (SELECT page_id FROM Likes WHERE user_id=1)

---

#### All People Report to the Given Manager | Medium | üîí LeetCode

Table: Employees +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | employee_id   | int     | | employee_name | varchar | | manager_id    | int     | +---------------+---------+ employee_id is the primary key for this table. Each row of this table indicates that the employee with ID employee_id and name employee_name reports his work to his/her direct manager with manager_id The head of the company is the employee with employee_id = 1. Write an SQL query to find employee_id of all employees that directly or indirectly report their work to the head of the company. The indirect relation between managers will not exceed 3 managers as the company is small. Return result table in any order without duplicates. The query result format is in the following example: Employees table: +-------------+---------------+------------+ | employee_id | employee_name | manager_id | +-------------+---------------+------------+ | 1           | Boss          | 1          | | 3           | Alice         | 3          | | 2           | Bob           | 1          | | 4           | Daniel        | 2          | | 7           | Luis          | 4          | | 8           | Jhon          | 3          | | 9           | Angela        | 8          | | 77          | Robert        | 1          | +-------------+---------------+------------+ Result table: +-------------+ | employee_id | +-------------+ | 2           | | 77          | | 4           | | 7           | +-------------+ The head of the company is the employee with employee_id 1. The employees with employee_id 2 and 77 report their work directly to the head of the company. The employee with employee_id 4 report his work indirectly to the head of the company 4 --> 2 --> 1. The employee with employee_id 7 report his work indirectly to the head of the company 7 --> 4 --> 2 --> 1. The employees with employee_id 3, 8 and 9 don't report their work to head of company directly or indirectly. Solution sql #Solution 1: ## t3: directly report to employee_id 1 ## t2: directly report to t3 ## t1: directly report to t2 SELECT t1.employee_id FROM Employees AS t1 INNER JOIN Employees AS t2 ON t1.manager_id = t2.employee_id JOIN Employees AS t3 ON t2.manager_id = t3.employee_id WHERE t3.manager_id = 1 AND t1.employee_id != 1 #Solution 2: SELECT distinct employee_id FROM ( SELECT employee_id FROM Employees WHERE manager_id IN (SELECT employee_id FROM Employees WHERE manager_id IN (SELECT employee_id FROM Employees WHERE manager_id = 1)) UNION SELECT employee_id FROM Employees WHERE manager_id IN (SELECT employee_id FROM Employees WHERE manager_id = 1) UNION SELECT employee_id FROM Employees WHERE manager_id = 1) AS t WHERE employee_id != 1 #Solution 3: SELECT employee_id FROM employees WHERE manager_id = 1 AND employee_id != 1 UNION SELECT employee_id FROM employees WHERE manager_id = any (SELECT employee_id FROM employees WHERE manager_id = 1 AND employee_id != 1) UNION SELECT employee_id FROM employees WHERE manager_id = any (SELECT employee_id FROM employees WHERE manager_id = any (SELECT employee_id FROM employees WHERE manager_id = 1 AND employee_id != 1))

---

#### Students and Examinations| Easy | üîí LeetCode

Table: Students +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | student_id    | int     | | student_name  | varchar | +---------------+---------+ student_id is the primary key for this table. Each row of this table contains the ID and the name of one student in the school. Table: Subjects +--------------+---------+ | Column Name  | Type    | +--------------+---------+ | subject_name | varchar | +--------------+---------+ subject_name is the primary key for this table. Each row of this table contains a name of one subject in the school. Table: Examinations +--------------+---------+ | Column Name  | Type    | +--------------+---------+ | student_id   | int     | | subject_name | varchar | +--------------+---------+ There is no primary key for this table. It may contain duplicates. Each student from Students table takes every course from Subjects table. Each row of this table indicates that a student with ID student_id attended the exam of subject_name. Write an SQL query to find the number of times each student attended each exam. Order the result table by student_id and subject_name. The query result format is in the following example: Students table: +------------+--------------+ | student_id | student_name | +------------+--------------+ | 1          | Alice        | | 2          | Bob          | | 13         | John         | | 6          | Alex         | +------------+--------------+ Subjects table: +--------------+ | subject_name | +--------------+ | Math         | | Physics      | | Programming  | +--------------+ Examinations table: +------------+--------------+ | student_id | subject_name | +------------+--------------+ | 1          | Math         | | 1          | Physics      | | 1          | Programming  | | 2          | Programming  | | 1          | Physics      | | 1          | Math         | | 13         | Math         | | 13         | Programming  | | 13         | Physics      | | 2          | Math         | | 1          | Math         | +------------+--------------+ Result table: +------------+--------------+--------------+----------------+ | student_id | student_name | subject_name | attended_exams | +------------+--------------+--------------+----------------+ | 1          | Alice        | Math         | 3              | | 1          | Alice        | Physics      | 2              | | 1          | Alice        | Programming  | 1              | | 2          | Bob          | Math         | 1              | | 2          | Bob          | Physics      | 0              | | 2          | Bob          | Programming  | 1              | | 6          | Alex         | Math         | 0              | | 6          | Alex         | Physics      | 0              | | 6          | Alex         | Programming  | 0              | | 13         | John         | Math         | 1              | | 13         | John         | Physics      | 1              | | 13         | John         | Programming  | 1              | +------------+--------------+--------------+----------------+ The result table should contain all students and all subjects. Alice attended Math exam 3 times, Physics exam 2 times and Programming exam 1 time. Bob attended Math exam 1 time, Programming exam 1 time and didn't attend the Physics exam. Alex didn't attend any exam. John attended Math exam 1 time, Physics exam 1 time and Programming exam 1 time. Solution sql #Solution 1: count with null SELECT Students.student_id, student_name, Subjects.subject_name, COUNT(Examinations.student_id) AS attended_exams FROM Students JOIN Subjects LEFT JOIN Examinations ON Students.student_id = Examinations.student_id AND Subjects.subject_name = Examinations.subject_name GROUP BY Students.student_id, subject_name #Solution 2: using ISNULL SELECT Students.student_id, student_name, Subjects.subject_name, SUM(IF(ISNULL(Examinations.student_id), 0, 1)) AS attended_exams FROM Students JOIN Subjects LEFT JOIN Examinations ON Students.student_id = Examinations.student_id AND Subjects.subject_name = Examinations.subject_name GROUP BY Students.student_id, subject_name #Solution 3: coalesce SELECT a.student_id AS student_id, a.student_name AS student_name, a.subject_name AS subject_name, coalesce(attended_exams,0) AS attended_exams FROM( SELECT * FROM students CROSS JOIN subjects GROUP BY student_id, student_name, subject_name) a LEFT JOIN (SELECT e.student_id, student_name, subject_name, COUNT(*) AS attended_exams FROM examinations e JOIN students s ON e.student_id = s.student_id GROUP BY e.student_id, student_name, subject_name) b ON a.student_id = b.student_id AND a.subject_name =b.subject_name ORDER BY a.student_id ASC, a.subject_name ASC

---

#### Find the Start and End Number of Continuous Ranges | Medium | üîí LeetCode

Table: Logs +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | log_id        | int     | +---------------+---------+ id is the primary key for this table. Each row of this table contains the ID in a log Table. Since some IDs have been removed from Logs. Write an SQL query to find the start and end number of continuous ranges in table Logs. Order the result table by start_id. The query result format is in the following example: Logs table: +------------+ | log_id     | +------------+ | 1          | | 2          | | 3          | | 7          | | 8          | | 10         | +------------+ Result table: +------------+--------------+ | start_id   | end_id       | +------------+--------------+ | 1          | 3            | | 7          | 8            | | 10         | 10           | +------------+--------------+ The result table should contain all ranges in table Logs. From 1 to 3 is contained in the table. From 4 to 6 is missing in the table From 7 to 8 is contained in the table. Number 9 is missing in the table. Number 10 is contained in the table. Solution sql #Solution 1: SELECT MIN(log_id) AS start_id, MAX(log_id) AS end_id FROM( SELECT log_id, log_id-ROW_NUMBER() OVER (ORDER BY log_id) AS rk FROM logs) a GROUP BY rk #Solution 2: Add temporary columns of rank and prev SELECT MIN(log_id) AS START_ID, MAX(log_id) AS END_ID FROM (SELECT log_id, @rank := CASE WHEN @prev = log_id-1 THEN @rank ELSE @rank+1 END AS rank, @prev := log_id AS prev FROM Logs, (SELECT @rank:=0, @prev:=-1) AS rows) AS tt GROUP BY rank ORDER BY START_ID # Solution 3: Find the starting and ending sequences, then merge two AS one table ## find the starting sequence: 1, 7, 10 ## find the ending sequence: 3, 8, 10 ## merge them AS one table SELECT start_id, MIN(end_id) AS end_id FROM (SELECT t1.log_id AS start_id FROM logs AS t1 LEFT JOIN logs AS t2 ON t1.log_id-1 = t2.log_id WHERE t2.log_id IS NULL) tt_start join (SELECT t1.log_id AS end_id FROM logs AS t1 LEFT JOIN logs AS t2 ON t1.log_id+1 = t2.log_id WHERE t2.log_id IS NULL) tt_end WHERE start_id<=end_id GROUP BY start_id

---

#### Weather Type in Each Country | Easy | üîí LeetCode

Table: Countries +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | country_id    | int     | | country_name  | varchar | +---------------+---------+ country_id is the primary key for this table. Each row of this table contains the ID and the name of one country. Table: Weather +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | country_id    | int     | | weather_state | varchar | | day           | date    | +---------------+---------+ (country_id, day) is the primary key for this table. Each row of this table indicates the weather state in a country for one day. Write an SQL query to find the type of weather in each country for November 2019. The type of weather is Cold if the average weather_state is less than or equal 15, Hot if the average weather_state is greater than or equal 25 and Warm otherwise. Return result table in any order. The query result format is in the following example: Countries table: +------------+--------------+ | country_id | country_name | +------------+--------------+ | 2          | USA          | | 3          | Australia    | | 7          | Peru         | | 5          | China        | | 8          | Morocco      | | 9          | Spain        | +------------+--------------+ Weather table: +------------+---------------+------------+ | country_id | weather_state | day        | +------------+---------------+------------+ | 2          | 15            | 2019-11-01 | | 2          | 12            | 2019-10-28 | | 2          | 12            | 2019-10-27 | | 3          | -2            | 2019-11-10 | | 3          | 0             | 2019-11-11 | | 3          | 3             | 2019-11-12 | | 5          | 16            | 2019-11-07 | | 5          | 18            | 2019-11-09 | | 5          | 21            | 2019-11-23 | | 7          | 25            | 2019-11-28 | | 7          | 22            | 2019-12-01 | | 7          | 20            | 2019-12-02 | | 8          | 25            | 2019-11-05 | | 8          | 27            | 2019-11-15 | | 8          | 31            | 2019-11-25 | | 9          | 7             | 2019-10-23 | | 9          | 3             | 2019-12-23 | +------------+---------------+------------+ Result table: +--------------+--------------+ | country_name | weather_type | +--------------+--------------+ | USA          | Cold         | | Austraila    | Cold         | | Peru         | Hot          | | China        | Warm         | | Morocco      | Hot          | +--------------+--------------+ Average weather_state in USA in November is (15) / 1 = 15 so weather type is Cold. Average weather_state in Austraila in November is (-2 + 0 + 3) / 3 = 0.333 so weather type is Cold. Average weather_state in Peru in November is (25) / 1 = 25 so weather type is Hot. Average weather_state in China in November is (16 + 18 + 21) / 3 = 18.333 so weather type is Warm. Average weather_state in Morocco in November is (25 + 27 + 31) / 3 = 27.667 so weather type is Hot. We know nothing about average weather_state in Spain in November so we don't include it in the result table. Solution sql SELECT country_name, CASE WHEN AVG(weather_state) <= 15 THEN "Cold" WHEN AVG(weather_state) >= 25 THEN "Hot" ELSE "Warm" END AS weather_type FROM Countries INNER JOIN Weather ON Countries.country_id = Weather.country_id WHERE MONTH(day) = 11 GORUP BY country_name

---

#### Find the Team Size | Easy | üîí LeetCode

Table: Employee +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | employee_id   | int     | | team_id       | int     | +---------------+---------+ employee_id is the primary key for this table. Each row of this table contains the ID of each employee and their respective team. Write an SQL query to find the team size of each of the employees. Return result table in any order. The query result format is in the following example: Employee Table: +-------------+------------+ | employee_id | team_id    | +-------------+------------+ |     1       |     8      | |     2       |     8      | |     3       |     8      | |     4       |     7      | |     5       |     9      | |     6       |     9      | +-------------+------------+ Result table: +-------------+------------+ | employee_id | team_size  | +-------------+------------+ |     1       |     3      | |     2       |     3      | |     3       |     3      | |     4       |     1      | |     5       |     2      | |     6       |     2      | +-------------+------------+ Employees with Id 1,2,3 are part of a team with team_id = 8. Employees with Id 4 is part of a team with team_id = 7. Employees with Id 5,6 are part of a team with team_id = 9. Solution sql SELECT employee_id, b.team_size FROM employee e JOIN ( SELECT team_id, count(team_id) AS team_size FROM employee GROUP BY team_id) b ON e.team_id = b.team_id

---

#### Running Total for Different Genders | Medium | üîí LeetCode

Table: Scores +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | player_name   | varchar | | gender        | varchar | | day           | date    | | score_points  | int     | +---------------+---------+ (gender, day) is the primary key for this table. A competition is held between females team and males team. Each row of this table indicates that a player_name and with gender has scored score_point in someday. Gender is 'F' if the player is in females team and 'M' if the player is in males team. Write an SQL query to find the total score for each gender at each day. Order the result table by gender and day The query result format is in the following example: Scores table: +-------------+--------+------------+--------------+ | player_name | gender | day        | score_points | +-------------+--------+------------+--------------+ | Aron        | F      | 2020-01-01 | 17           | | Alice       | F      | 2020-01-07 | 23           | | Bajrang     | M      | 2020-01-07 | 7            | | Khali       | M      | 2019-12-25 | 11           | | Slaman      | M      | 2019-12-30 | 13           | | Joe         | M      | 2019-12-31 | 3            | | Jose        | M      | 2019-12-18 | 2            | | Priya       | F      | 2019-12-31 | 23           | | Priyanka    | F      | 2019-12-30 | 17           | +-------------+--------+------------+--------------+ Result table: +--------+------------+-------+ | gender | day        | total | +--------+------------+-------+ | F      | 2019-12-30 | 17    | | F      | 2019-12-31 | 40    | | F      | 2020-01-01 | 57    | | F      | 2020-01-07 | 80    | | M      | 2019-12-18 | 2     | | M      | 2019-12-25 | 13    | | M      | 2019-12-30 | 26    | | M      | 2019-12-31 | 29    | | M      | 2020-01-07 | 36    | +--------+------------+-------+ For females team: First day is 2019-12-30, Priyanka scored 17 points and the total score for the team is 17. Second day is 2019-12-31, Priya scored 23 points and the total score for the team is 40. Third day is 2020-01-01, Aron scored 17 points and the total score for the team is 57. Fourth day is 2020-01-07, Alice scored 23 points and the total score for the team is 80. For males team: First day is 2019-12-18, Jose scored 2 points and the total score for the team is 2. Second day is 2019-12-25, Khali scored 11 points and the total score for the team is 13. Third day is 2019-12-30, Slaman scored 13 points and the total score for the team is 26. Fourth day is 2019-12-31, Joe scored 3 points and the total score for the team is 29. Fifth day is 2020-01-07, Bajrang scored 7 points and the total score for the team is 36. Solution sql #Solution 1: SELECT gender, day, SUM(score_points) OVER(PARTITION BY gender ORDER BY day) AS total FROM scores GROUP BY 1,2 ORDER BY 1,2 #Solution 2: SELECT t1.gender, t1.day, SUM(t2.score_points) AS total FROM Scores AS t1 JOIN Scores AS t2 ON t1.gender = t2.gender AND t1.day>=t2.day GROUP BY t1.gender, t1.day

---

#### Restaurant Growth | Medium | üîí LeetCode

Table: Customer +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | customer_id   | int     | | name          | varchar | | visited_on    | date    | | amount        | int     | +---------------+---------+ (customer_id, visited_on) is the primary key for this table. This table contains data about customer transactions in a restaurant. visited_on is the date on which the customer with ID (customer_id) have visited the restaurant. amount is the total paid by a customer. You are the restaurant owner and you want to analyze a possible expansion (there will be at least one customer every day). Write an SQL query to compute moving average of how much customer paid in a 7 days window (current day + 6 days before) . The query result format is in the following example: Return result table ordered by visited_on. average_amount should be rounded to 2 decimal places, all dates are in the format ('YYYY-MM-DD'). Customer table: +-------------+--------------+--------------+-------------+ | customer_id | name         | visited_on   | amount      | +-------------+--------------+--------------+-------------+ | 1           | Jhon         | 2019-01-01   | 100         | | 2           | Daniel       | 2019-01-02   | 110         | | 3           | Jade         | 2019-01-03   | 120         | | 4           | Khaled       | 2019-01-04   | 130         | | 5           | Winston      | 2019-01-05   | 110         | | 6           | Elvis        | 2019-01-06   | 140         | | 7           | Anna         | 2019-01-07   | 150         | | 8           | Maria        | 2019-01-08   | 80          | | 9           | Jaze         | 2019-01-09   | 110         | | 1           | Jhon         | 2019-01-10   | 130         | | 3           | Jade         | 2019-01-10   | 150         | +-------------+--------------+--------------+-------------+ Result table: +--------------+--------------+----------------+ | visited_on   | amount       | average_amount | +--------------+--------------+----------------+ | 2019-01-07   | 860          | 122.86         | | 2019-01-08   | 840          | 120            | | 2019-01-09   | 840          | 120            | | 2019-01-10   | 1000         | 142.86         | +--------------+--------------+----------------+ 1st moving average from 2019-01-01 to 2019-01-07 has an average_amount of (100 + 110 + 120 + 130 + 110 + 140 + 150)/7 = 122.86 2nd moving average from 2019-01-02 to 2019-01-08 has an average_amount of (110 + 120 + 130 + 110 + 140 + 150 + 80)/7 = 120 3rd moving average from 2019-01-03 to 2019-01-09 has an average_amount of (120 + 130 + 110 + 140 + 150 + 80 + 110)/7 = 120 4th moving average from 2019-01-04 to 2019-01-10 has an average_amount of (130 + 110 + 140 + 150 + 80 + 110 + 130 + 150)/7 = 142.86 Solution sql #Solution 1: SELECT visited_on, SUM(amount) OVER(ORDER BY visited_on ROWS 6 PRECEDING), round(avg(amount) OVER(ORDER BY visited_on ROWS 6 PRECEDING),2) FROM ( SELECT visited_on, SUM(amount) AS amount FROM customer GROUP BY visited_on ORDER BY visited_on ) a ORDER BY visited_on offset 6 ROWS #Solution 2: SELECT t1.visited_on, SUM(t2.amount) AS amount, round(avg(t2.amount), 2) AS average_amount FROM ( SELECT visited_on, SUM(amount) AS amount FROM Customer GROUP BY visited_on) AS t1 inner join ( SELECT visited_on, SUM(amount) AS amount FROM Customer GROUP BY visited_on) AS t2 ON t2.visited_on BETWEEN DATE_SUB(t1.visited_on, INTERVAL 6 DAY) and t1.visited_on GROUP BY t1.visited_on HAVING COUNT(1)=7

---

#### Ads Performance | Easy | üîí LeetCode

Table: Ads +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | ad_id         | int     | | user_id       | int     | | action        | enum    | +---------------+---------+ (ad_id, user_id) is the primary key for this table. Each row of this table contains the ID of an Ad, the ID of a user and the action taken by this user regarding this Ad. The action column is an ENUM type of ('Clicked', 'Viewed', 'Ignored'). A company is running Ads and wants to calculate the performance of each Ad. Round ctr to 2 decimal points. Order the result table by ctr in descending order and by ad_id in ascending order in case of a tie. The query result format is in the following example: Ads table: +-------+---------+---------+ | ad_id | user_id | action  | +-------+---------+---------+ | 1     | 1       | Clicked | | 2     | 2       | Clicked | | 3     | 3       | Viewed  | | 5     | 5       | Ignored | | 1     | 7       | Ignored | | 2     | 7       | Viewed  | | 3     | 5       | Clicked | | 1     | 4       | Viewed  | | 2     | 11      | Viewed  | | 1     | 2       | Clicked | +-------+---------+---------+ Result table: +-------+-------+ | ad_id | ctr   | +-------+-------+ | 1     | 66.67 | | 3     | 50.00 | | 2     | 33.33 | | 5     | 0.00  | +-------+-------+ for ad_id = 1, ctr = (2/(2+1)) * 100 = 66.67 for ad_id = 2, ctr = (1/(1+2)) * 100 = 33.33 for ad_id = 3, ctr = (1/(1+1)) * 100 = 50.00 for ad_id = 5, ctr = 0.00, Note that ad_id = 5 has no clicks or views. Note that we don't care about Ignored Ads. Result table is ordered by the ctr. in case of a tie we order them by ad_id Solution sql #Solution 1: SELECT ad_id, (CASE WHEN clicks+views = 0 THEN 0 ELSE ROUND(clicks/(clicks+views)*100, 2) END) AS ctr FROM (SELECT ad_id, SUM(CASE WHEN action='Clicked' THEN 1 ELSE 0 END) AS clicks, SUM(CASE WHEN action='Viewed' THEN 1 ELSE 0 END) AS views FROM Ads GROUP BY ad_id) AS t ORDER BY ctr DESC, ad_id ASC #Solution 2: WITH t1 AS( SELECT ad_id, SUM(CASE WHEN action in ('Clicked') THEN 1 ELSE 0 END) AS clicked FROM ads GROUP BY ad_id ) , t2 AS ( SELECT ad_id AS ad, SUM(CASE WHEN action in ('Clicked','Viewed') THEN 1 ELSE 0 END) AS total FROM ads GROUP BY ad_id ) SELECT a.ad_id, coalesce(round((clicked +0.0)/nullif((total +0.0),0)*100,2),0) AS ctr FROM ( select * FROM t1 JOIN t2 ON t1.ad_id = t2.ad) a ORDER BY ctr DESC, ad_id

---

#### List the Products Ordered in a Period | Easy | üîí LeetCode

Table: Products +------------------+---------+ | Column Name      | Type    | +------------------+---------+ | product_id       | int     | | product_name     | varchar | | product_category | varchar | +------------------+---------+ product_id is the primary key for this table. This table contains data about the company's products. Table: Orders +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | product_id    | int     | | order_date    | date    | | unit          | int     | +---------------+---------+ There is no primary key for this table. It may have duplicate rows. product_id is a foreign key to Products table. unit is the number of products ordered in order_date. Write an SQL query to get the names of products with greater than or equal to 100 units ordered in February 2020 and their amount. Return result table in any order. The query result format is in the following example: Products table: +-------------+-----------------------+------------------+ | product_id  | product_name          | product_category | +-------------+-----------------------+------------------+ | 1           | Leetcode Solutions    | Book             | | 2           | Jewels of Stringology | Book             | | 3           | HP                    | Laptop           | | 4           | Lenovo                | Laptop           | | 5           | Leetcode Kit          | T-shirt          | +-------------+-----------------------+------------------+ Orders table: +--------------+--------------+----------+ | product_id   | order_date   | unit     | +--------------+--------------+----------+ | 1            | 2020-02-05   | 60       | | 1            | 2020-02-10   | 70       | | 2            | 2020-01-18   | 30       | | 2            | 2020-02-11   | 80       | | 3            | 2020-02-17   | 2        | | 3            | 2020-02-24   | 3        | | 4            | 2020-03-01   | 20       | | 4            | 2020-03-04   | 30       | | 4            | 2020-03-04   | 60       | | 5            | 2020-02-25   | 50       | | 5            | 2020-02-27   | 50       | | 5            | 2020-03-01   | 50       | +--------------+--------------+----------+ Result table: +--------------------+---------+ | product_name       | unit    | +--------------------+---------+ | Leetcode Solutions | 130     | | Leetcode Kit       | 100     | +--------------------+---------+ Products with product_id = 1 is ordered in February a total of (60 + 70) = 130. Products with product_id = 2 is ordered in February a total of 80. Products with product_id = 3 is ordered in February a total of (2 + 3) = 5. Products with product_id = 4 was not ordered in February 2020. Products with product_id = 5 is ordered in February a total of (50 + 50) = 100. Solution sql #Solution 1: SELECT a.product_name, a.unit FROM (SELECT p.product_name, SUM(unit) AS unit FROM orders o JOIN products p ON o.product_id = p.product_id WHERE MONTH(order_date)=2 and YEAR(order_date) = 2020 GROUP BY o.product_id) a WHERE a.unit>=100 #Solution 2: SELECT product_name, SUM(unit) AS unit FROM Products JOIN Orders ON Products.product_id = Orders.product_id WHERE left(order_date, 7) = "2020-02" GROUP BY Products.product_id HAVING SUM(unit)>=100

---

#### Number of Transactions per Visit | Hard | üîí LeetCode

Table: Visits +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | user_id       | int     | | visit_date    | date    | +---------------+---------+ (user_id, visit_date) is the primary key for this table. Each row of this table indicates that user_id has visited the bank in visit_date. Table: Transactions +------------------+---------+ | Column Name      | Type    | +------------------+---------+ | user_id          | int     | | transaction_date | date    | | amount           | int     | +------------------+---------+ There is no primary key for this table, it may contain duplicates. Each row of this table indicates that user_id has done a transaction of amount in transaction_date. It is guaranteed that the user has visited the bank in the transaction_date.(i.e The Visits table contains (user_id, transaction_date) in one row) A bank wants to draw a chart of the number of transactions bank visitors did in one visit to the bank and the corresponding number of visitors who have done this number of transaction in one visit. Write an SQL query to find how many users visited the bank and didn't do any transactions, how many visited the bank and did one transaction and so on. The result table will contain two columns: transactions_count which is the number of transactions done in one visit. visits_count which is the corresponding number of users who did transactions_count in one visit to the bank. transactions_count should take all values from 0 to max(transactions_count) done by one or more users. Order the result table by transactions_count. The query result format is in the following example: Visits table: +---------+------------+ | user_id | visit_date | +---------+------------+ | 1       | 2020-01-01 | | 2       | 2020-01-02 | | 12      | 2020-01-01 | | 19      | 2020-01-03 | | 1       | 2020-01-02 | | 2       | 2020-01-03 | | 1       | 2020-01-04 | | 7       | 2020-01-11 | | 9       | 2020-01-25 | | 8       | 2020-01-28 | +---------+------------+ Transactions table: +---------+------------------+--------+ | user_id | transaction_date | amount | +---------+------------------+--------+ | 1       | 2020-01-02       | 120    | | 2       | 2020-01-03       | 22     | | 7       | 2020-01-11       | 232    | | 1       | 2020-01-04       | 7      | | 9       | 2020-01-25       | 33     | | 9       | 2020-01-25       | 66     | | 8       | 2020-01-28       | 1      | | 9       | 2020-01-25       | 99     | +---------+------------------+--------+ Result table: +--------------------+--------------+ | transactions_count | visits_count | +--------------------+--------------+ | 0                  | 4            | | 1                  | 5            | | 2                  | 0            | | 3                  | 1            | +--------------------+--------------+ * For transactions_count = 0, The visits (1, "2020-01-01"), (2, "2020-01-02"), (12, "2020-01-01") and (19, "2020-01-03") did no transactions so visits_count = 4. * For transactions_count = 1, The visits (2, "2020-01-03"), (7, "2020-01-11"), (8, "2020-01-28"), (1, "2020-01-02") and (1, "2020-01-04") did one transaction so visits_count = 5. * For transactions_count = 2, No customers visited the bank and did two transactions so visits_count = 0. * For transactions_count = 3, The visit (9, "2020-01-25") did three transactions so visits_count = 1. * For transactions_count >= 4, No customers visited the bank and did more than three transactions so we will stop at transactions_count = 3 The chart drawn for this example is as follows: Solution sql WITH RECURSIVE t1 AS( SELECT visit_date, COALESCE(num_visits,0) as num_visits, COALESCE(num_trans,0) as num_trans FROM (( SELECT visit_date, user_id, COUNT(*) as num_visits FROM visits GROUP BY 1, 2) AS a LEFT JOIN ( SELECT transaction_date, user_id, count(*) as num_trans FROM transactions GROUP BY 1, 2) AS b ON a.visit_date = b.transaction_date and a.user_id = b.user_id) ), t2 AS ( SELECT MAX(num_trans) as trans FROM t1 UNION ALL SELECT trans-1 FROM t2 WHERE trans >= 1) SELECT trans as transactions_count, COALESCE(visits_count,0) as visits_count FROM t2 LEFT JOIN ( SELECT num_trans as transactions_count, COALESCE(COUNT(*),0) as visits_count FROM t1 GROUP BY 1 ORDER BY 1) AS a ON a.transactions_count = t2.trans ORDER BY 1

---

#### Movie Rating | Medium | üîí LeetCode

Table: Movies +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | movie_id      | int     | | title         | varchar | +---------------+---------+ movie_id is the primary key for this table. title is the name of the movie. Table: Users +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | user_id       | int     | | name          | varchar | +---------------+---------+ user_id is the primary key for this table. Table: Movie_Rating +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | movie_id      | int     | | user_id       | int     | | rating        | int     | | created_at    | date    | +---------------+---------+ (movie_id, user_id) is the primary key for this table. This table contains the rating of a movie by a user in their review. created_at is the user's review date. Write the following SQL query: Find the name of the user who has rated the greatest number of the movies. In case of a tie, return lexicographically smaller user name. Find the movie name with the highest average rating in February 2020. In case of a tie, return lexicographically smaller movie name.. Query is returned in 2 rows, the query result format is in the following example: Movies table: +-------------+--------------+ | movie_id    |  title       | +-------------+--------------+ | 1           | Avengers     | | 2           | Frozen 2     | | 3           | Joker        | +-------------+--------------+ Users table: +-------------+--------------+ | user_id     |  name        | +-------------+--------------+ | 1           | Daniel       | | 2           | Monica       | | 3           | Maria        | | 4           | James        | +-------------+--------------+ Movie_Rating table: +-------------+--------------+--------------+-------------+ | movie_id    | user_id      | rating       | created_at  | +-------------+--------------+--------------+-------------+ | 1           | 1            | 3            | 2020-01-12  | | 1           | 2            | 4            | 2020-02-11  | | 1           | 3            | 2            | 2020-02-12  | | 1           | 4            | 1            | 2020-01-01  | | 2           | 1            | 5            | 2020-02-17  | | 2           | 2            | 2            | 2020-02-01  | | 2           | 3            | 2            | 2020-03-01  | | 3           | 1            | 3            | 2020-02-22  | | 3           | 2            | 4            | 2020-02-25  | +-------------+--------------+--------------+-------------+ Result table: +--------------+ | results      | +--------------+ | Daniel       | | Frozen 2     | +--------------+ Daniel and Maria have rated 3 movies ("Avengers", "Frozen 2" and "Joker") but Daniel is smaller lexicographically. Frozen 2 and Joker have a rating average of 3.5 in February but Frozen 2 is smaller lexicographically. Solution sql #Solution 1: (SELECT name AS results FROM Movie_Rating JOIN Users ON Movie_Rating.user_id = Users.user_id GROUP BY Movie_Rating.user_id ORDER BY count(1) DESC, name LIMIT 1) UNION ALL (SELECT title AS results FROM Movie_Rating JOIN Movies ON Movie_Rating.movie_id = Movies.movie_id WHERE left(created_at, 7) = "2020-02" GROUP BY Movie_Rating.movie_id ORDER BY avg(rating) DESC, title LIMIT 1 ) #Solution 2: SELECT name AS results FROM( (SELECT a.name FROM( SELECT name, count(*), rank() OVER(ORDER BY count(*) DESC) AS rk FROM movie_rating m JOIN users u ON m.user_id = u.user_id GROUP BY name, m.user_id ORDER BY rk, name) a LIMIT 1) UNION (SELECT title FROM( SELECT title, round(avg(rating),1) AS rnd FROM movie_rating m JOIN movies u on m.movie_id = u.movie_id WHERE month(created_at) = 2 GROUP BY title ORDER BY rnd DESC, title) b LIMIT 1)) AS d

---

#### Students With Invalid Departments | Easy | üîí LeetCode

Table: Departments +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | id            | int     | | name          | varchar | +---------------+---------+ id is the primary key of this table. The table has information about the id of each department of a university. Table: Students +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | id            | int     | | name          | varchar | | department_id | int     | +---------------+---------+ id is the primary key of this table. The table has information about the id of each student at a university and the id of the department he/she studies at. Write an SQL query to find the id and the name of all students who are enrolled in departments that no longer exists. Return the result table in any order. The query result format is in the following example: Departments table: +------+--------------------------+ | id   | name                     | +------+--------------------------+ | 1    | Electrical Engineering   | | 7    | Computer Engineering     | | 13   | Bussiness Administration | +------+--------------------------+ Students table: +------+----------+---------------+ | id   | name     | department_id | +------+----------+---------------+ | 23   | Alice    | 1             | | 1    | Bob      | 7             | | 5    | Jennifer | 13            | | 2    | John     | 14            | | 4    | Jasmine  | 77            | | 3    | Steve    | 74            | | 6    | Luis     | 1             | | 8    | Jonathan | 7             | | 7    | Daiana   | 33            | | 11   | Madelynn | 1             | +------+----------+---------------+ Result table: +------+----------+ | id   | name     | +------+----------+ | 2    | John     | | 7    | Daiana   | | 4    | Jasmine  | | 3    | Steve    | +------+----------+ John, Daiana, Steve and Jasmine are enrolled in departments 14, 33, 74 and 77 respectively. department 14, 33, 74 and 77 doesn't exist in the Departments table. Solution sql #Solution 1: SELECT s.id, s.name FROM students s LEFT JOIN departments d ON s.department_id = d.id WHERE d.name IS NULL; #Solution 2: SELECT id, name FROM Students WHERE department_id NOT IN (SELECT id FROM Departments)

---

#### Activity Participants | Medium | üîí LeetCode

Table: Friends +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | id            | int     | | name          | varchar | | activity      | varchar | +---------------+---------+ id is the id of the friend and primary key for this table. name is the name of the friend. activity is the name of the activity which the friend takes part in. Table: Activities +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | id            | int     | | name          | varchar | +---------------+---------+ id is the primary key for this table. name is the name of the activity. Write an SQL query to find the names of all the activities with neither maximum, nor minimum number of participants. Return the result table in any order. Each activity in table Activities is performed by any person in the table Friends. The query result format is in the following example: Friends table: +------+--------------+---------------+ | id   | name         | activity      | +------+--------------+---------------+ | 1    | Jonathan D.  | Eating        | | 2    | Jade W.      | Singing       | | 3    | Victor J.    | Singing       | | 4    | Elvis Q.     | Eating        | | 5    | Daniel A.    | Eating        | | 6    | Bob B.       | Horse Riding  | +------+--------------+---------------+ Activities table: +------+--------------+ | id   | name         | +------+--------------+ | 1    | Eating       | | 2    | Singing      | | 3    | Horse Riding | +------+--------------+ Result table: +--------------+ | results      | +--------------+ | Singing      | +--------------+ Eating activity is performed by 3 friends, maximum number of participants, (Jonathan D. , Elvis Q. and Daniel A.) Horse Riding activity is performed by 1 friend, minimum number of participants, (Bob B.) Singing is performed by 2 friends (Victor J. and Jade W.) Solution sql #Solution 1: WITH CTE AS (SELECT COUNT(*) AS cnt, activity FROM Friends GROUP BY activity) SELECT activity FROM CTE WHERE cnt NOT IN (SELECT MAX(cnt) FROM CTE UNION ALL SELECT MIN(cnt) FROM CTE) #Solution 2: WITH t1 AS( SELECT MAX(a.total) AS total FROM( SELECT activity, COUNT(*) AS total FROM friends GROUP BY activity) a UNION ALL SELECT MIN(b.total) AS low FROM( SELECT activity, COUNT(*) AS total FROM friends GROUP BY activity) b), t2 AS ( SELECT activity, COUNT(*) AS total FROM friends GROUP BY activity ) SELECT activity FROM t1 RIGHT JOIN t2 ON t1.total = t2.total WHERE t1.total is null

---

#### Number of Trusted Contacts of a Customer | Medium | üîí LeetCode

Table: Customers +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | customer_id   | int     | | customer_name | varchar | | email         | varchar | +---------------+---------+ customer_id is the primary key for this table. Each row of this table contains the name and the email of a customer of an online shop. Table: Contacts +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | user_id       | id      | | contact_name  | varchar | | contact_email | varchar | +---------------+---------+ (user_id, contact_email) is the primary key for this table. Each row of this table contains the name and email of one contact of customer with user_id. This table contains information about people each customer trust. The contact may or may not exist in the Customers table. Table: Invoices +--------------+---------+ | Column Name  | Type    | +--------------+---------+ | invoice_id   | int     | | price        | int     | | user_id      | int     | +--------------+---------+ invoice_id is the primary key for this table. Each row of this table indicates that user_id has an invoice with invoice_id and a price. Write an SQL query to find the following for each invoice_id: customer_name: The name of the customer the invoice is related to. price: The price of the invoice. contacts_cnt: The number of contacts related to the customer. trusted_contacts_cnt: The number of contacts related to the customer and at the same time they are customers to the shop. (i.e His/Her email exists in the Customers table.) Order the result table by invoice_id. The query result format is in the following example: Customers table: +-------------+---------------+--------------------+ | customer_id | customer_name | email              | +-------------+---------------+--------------------+ | 1           | Alice         | alice@leetcode.com | | 2           | Bob           | bob@leetcode.com   | | 13          | John          | john@leetcode.com  | | 6           | Alex          | alex@leetcode.com  | +-------------+---------------+--------------------+ Contacts table: +-------------+--------------+--------------------+ | user_id     | contact_name | contact_email      | +-------------+--------------+--------------------+ | 1           | Bob          | bob@leetcode.com   | | 1           | John         | john@leetcode.com  | | 1           | Jal          | jal@leetcode.com   | | 2           | Omar         | omar@leetcode.com  | | 2           | Meir         | meir@leetcode.com  | | 6           | Alice        | alice@leetcode.com | +-------------+--------------+--------------------+ Invoices table: +------------+-------+---------+ | invoice_id | price | user_id | +------------+-------+---------+ | 77         | 100   | 1       | | 88         | 200   | 1       | | 99         | 300   | 2       | | 66         | 400   | 2       | | 55         | 500   | 13      | | 44         | 60    | 6       | +------------+-------+---------+ Result table: +------------+---------------+-------+--------------+----------------------+ | invoice_id | customer_name | price | contacts_cnt | trusted_contacts_cnt | +------------+---------------+-------+--------------+----------------------+ | 44         | Alex          | 60    | 1            | 1                    | | 55         | John          | 500   | 0            | 0                    | | 66         | Bob           | 400   | 2            | 0                    | | 77         | Alice         | 100   | 3            | 2                    | | 88         | Alice         | 200   | 3            | 2                    | | 99         | Bob           | 300   | 2            | 0                    | +------------+---------------+-------+--------------+----------------------+ Alice has three contacts, two of them are trusted contacts (Bob and John). Bob has two contacts, none of them is a trusted contact. Alex has one contact and it is a trusted contact (Alice). John doesn't have any contacts. Solution sql SELECT invoice_id, customer_name, price, COUNT(Contacts.user_id) AS contacts_cnt, SUM(CASE WHEN Contacts.contact_name IN (SELECT customer_name FROM Customers) THEN 1 ELSE 0 END) AS trusted_contacts_cnt FROM Invoices INNER JOIN Customers ON Invoices.user_id = Customers.customer_id LEFT JOIN Contacts ON Customers.customer_id = Contacts.user_id GROUP BY Invoices.invoice_id, customer_name ORDER BY Invoices.invoice_id

---

#### Get the Second Most Recent Activity | Hard | üîí LeetCode

Table: UserActivity +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | username      | varchar | | activity      | varchar | | startDate     | Date    | | endDate       | Date    | +---------------+---------+ This table does not contain primary key. This table contain information about the activity performed of each user in a period of time. A person with username performed a activity from startDate to endDate. Write an SQL query to show the second most recent activity of each user. If the user only has one activity, return that one. A user can't perform more than one activity at the same time. Return the result table in any order. The query result format is in the following example: UserActivity table: +------------+--------------+-------------+-------------+ | username   | activity     | startDate   | endDate     | +------------+--------------+-------------+-------------+ | Alice      | Travel       | 2020-02-12  | 2020-02-20  | | Alice      | Dancing      | 2020-02-21  | 2020-02-23  | | Alice      | Travel       | 2020-02-24  | 2020-02-28  | | Bob        | Travel       | 2020-02-11  | 2020-02-18  | +------------+--------------+-------------+-------------+ Result table: +------------+--------------+-------------+-------------+ | username   | activity     | startDate   | endDate     | +------------+--------------+-------------+-------------+ | Alice      | Dancing      | 2020-02-21  | 2020-02-23  | | Bob        | Travel       | 2020-02-11  | 2020-02-18  | +------------+--------------+-------------+-------------+ The most recent activity of Alice is Travel from 2020-02-24 to 2020-02-28, before that she was dancing from 2020-02-21 to 2020-02-23. Bob only has one record, we just take that one. Solution sql (SELECT * FROM UserActivity GROUP BY username HAVING count(1) = 1) UNION (SELECT a.* FROM UserActivity AS a LEFT JOIN UserActivity AS b on a.username = b.username AND a.endDate<b.endDate GROUP BY a.username, a.endDate HAVING count(b.endDate) = 1)

---

#### Replace Employee ID With The Unique Identifier | Easy | üîí LeetCode

Table: Employees +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | id            | int     | | name          | varchar | +---------------+---------+ id is the primary key for this table. Each row of this table contains the id and the name of an employee in a company. Table: EmployeeUNI +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | id            | int     | | unique_id     | int     | +---------------+---------+ (id, unique_id) is the primary key for this table. Each row of this table contains the id and the corresponding unique id of an employee in the company. Write an SQL query to show the unique ID of each user, If a user doesn't have a unique ID replace just show null. Return the result table in any order. The query result format is in the following example: Employees table: +----+----------+ | id | name     | +----+----------+ | 1  | Alice    | | 7  | Bob      | | 11 | Meir     | | 90 | Winston  | | 3  | Jonathan | +----+----------+ EmployeeUNI table: +----+-----------+ | id | unique_id | +----+-----------+ | 3  | 1         | | 11 | 2         | | 90 | 3         | +----+-----------+ EmployeeUNI table: +-----------+----------+ | unique_id | name     | +-----------+----------+ | null      | Alice    | | null      | Bob      | | 2         | Meir     | | 3         | Winston  | | 1         | Jonathan | +-----------+----------+ Alice and Bob don't have a unique ID, We will show null instead. The unique ID of Meir is 2. The unique ID of Winston is 3. The unique ID of Jonathan is 1. Solution sql SELECT unique_id, name FROM Employees LEFT JOIN EmployeeUNI ON Employees.id = EmployeeUNI.id

---

#### Total Sales Amount by Year | Hard | üîí LeetCode

Table: Product +---------------+---------+ | Column Name | Type | +---------------+---------+ | product_id | int | | product_name | varchar | +---------------+---------+ product_id is the primary key for this table. product_name is the name of the product. Table: Sales +---------------------+---------+ | Column Name         | Type    | +---------------------+---------+ | product_id          | int     | | period_start        | varchar | | period_end          | date    | | average_daily_sales | int     | +---------------------+---------+ product_id is the primary key for this table. period_start and period_end indicates the start and end date for sales period, both dates are inclusive. The average_daily_sales column holds the average daily sales amount of the items for the period. Write an SQL query to report the Total sales amount of each item for each year, with corresponding product name, product_id, product_name and report_year. Dates of the sales years are between 2018 to 2020. Return the result table ordered by product_id and report_year. The query result format is in the following example: Product table: +------------+--------------+ | product_id | product_name | +------------+--------------+ | 1          | LC Phone     | | 2          | LC T-Shirt   | | 3          | LC Keychain  | +------------+--------------+ Sales table: +------------+--------------+-------------+---------------------+ | product_id | period_start | period_end  | average_daily_sales | +------------+--------------+-------------+---------------------+ | 1          | 2019-01-25   | 2019-02-28  | 100                 | | 2          | 2018-12-01   | 2020-01-01  | 10                  | | 3          | 2019-12-01   | 2020-01-31  | 1                   | +------------+--------------+-------------+---------------------+ Result table: +------------+--------------+-------------+--------------+ | product_id | product_name | report_year | total_amount | +------------+--------------+-------------+--------------+ | 1          | LC Phone     |    2019     | 3500         | | 2          | LC T-Shirt   |    2018     | 310          | | 2          | LC T-Shirt   |    2019     | 3650         | | 2          | LC T-Shirt   |    2020     | 10           | | 3          | LC Keychain  |    2019     | 31           | | 3          | LC Keychain  |    2020     | 31           | +------------+--------------+-------------+--------------+ LC Phone was sold for the period of 2019-01-25 to 2019-02-28, and there are 35 days for this period. Total amount 35*100 = 3500. LC T-shirt was sold for the period of 2018-12-01 to 2020-01-01, and there are 31, 365, 1 days for years 2018, 2019 and 2020 respectively. LC Keychain was sold for the period of 2019-12-01 to 2020-01-31, and there are 31, 31 days for years 2019 and 2020 respectively. Solution sql SELECT b.product_id, product_name, yr AS report_year, CASE WHEN YEAR(b.period_start)=YEAR(b.period_end) AND a.yr=YEAR(b.period_start) THEN DATEDIFF(b.period_end,b.period_start)+1 WHEN a.yr=YEAR(b.period_start) THEN DATEDIFF(DATE_FORMAT(b.period_start,'%Y-12-31'),b.period_start)+1 WHEN a.yr=YEAR(b.period_end) THEN DAYOFYEAR(b.period_end) WHEN a.yr>YEAR(b.period_start) AND a.yr<YEAR(b.period_end) THEN 365 ELSE 0 END * average_daily_sales AS total_amount FROM (SELECT product_id,product_name,'2018' AS yr FROM Product UNION SELECT product_id,product_name,'2019' AS yr FROM Product UNION SELECT product_id,product_name,'2020' AS yr FROM Product) a JOIN Sales b ON a.product_id=b.product_id HAVING total_amount > 0 ORDER BY b.product_id,a.yr

---

#### Capital Gain/Loss | Medium | üîí LeetCode

Table: Stocks +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | stock_name    | varchar | | operation     | enum    | | operation_day | int     | | price         | int     | +---------------+---------+ (stock_name, day) is the primary key for this table. The operation column is an ENUM of type ('Sell', 'Buy') Each row of this table indicates that the stock which has stock_name had an operation on the day operation_day with the price. It is guaranteed that each 'Sell' operation for a stock has a corresponding 'Buy' operation in a previous day. Write an SQL query to report the Capital gain/loss for each stock. The capital gain/loss of a stock is total gain or loss after buying and selling the stock one or many times. Return the result table in any order. The query result format is in the following example: Stocks table: +---------------+-----------+---------------+--------+ | stock_name    | operation | operation_day | price  | +---------------+-----------+---------------+--------+ | Leetcode      | Buy       | 1             | 1000   | | Corona Masks  | Buy       | 2             | 10     | | Leetcode      | Sell      | 5             | 9000   | | Handbags      | Buy       | 17            | 30000  | | Corona Masks  | Sell      | 3             | 1010   | | Corona Masks  | Buy       | 4             | 1000   | | Corona Masks  | Sell      | 5             | 500    | | Corona Masks  | Buy       | 6             | 1000   | | Handbags      | Sell      | 29            | 7000   | | Corona Masks  | Sell      | 10            | 10000  | +---------------+-----------+---------------+--------+ Result table: +---------------+-------------------+ | stock_name    | capital_gain_loss | +---------------+-------------------+ | Corona Masks  | 9500              | | Leetcode      | 8000              | | Handbags      | -23000            | +---------------+-------------------+ Leetcode stock was bought at day 1 for 1000$ and was sold at day 5 for 9000$. Capital gain = 9000 - 1000 = 8000$. Handbags stock was bought at day 17 for 30000$ and was sold at day 29 for 7000$. Capital loss = 7000 - 30000 = -23000$. Corona Masks stock was bought at day 1 for 10$ and was sold at day 3 for 1010$. It was bought again at day 4 for 1000$ and was sold at day 5 for 500$. At last, it was bought at day 6 for 1000$ and was sold at day 10 for 10000$. Capital gain/loss is the sum of capital gains/losses for each ('Buy' --> 'Sell') operation = (1010 - 10) + (500 - 1000) + (10000 - 1000) = 1000 - 500 + 9000 = 9500$. Solution sql #Solution 1: SELECT stock_name, SUM(CASE WHEN operation = 'Buy' THEN -price ELSE price END) AS capital_gain_loss FROM Stocks GROUP BY stock_name; #Solution 2: SELECT stock_name, (one-two) AS capital_gain_loss FROM( (SELECT stock_name, sum(price) AS one FROM stocks WHERE operation = 'Sell' GROUP BY stock_name) b LEFT JOIN (SELECT stock_name AS name, sum(price) AS two FROM stocks WHERE operation = 'Buy' GROUP BY stock_name) c ON b.stock_name = c.name) ORDER BY capital_gain_loss DESC;

---

#### Customers Who Bought Products A and B but Not C | Medium | üîí LeetCode

Table: Customers +---------------------+---------+ | Column Name         | Type    | +---------------------+---------+ | customer_id         | int     | | customer_name       | varchar | +---------------------+---------+ customer_id is the primary key for this table. customer_name is the name of the customer. Table: Orders +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | order_id      | int     | | customer_id   | int     | | product_name  | varchar | +---------------+---------+ order_id is the primary key for this table. customer_id is the id of the customer who bought the product "product_name". Write an SQL query to report the customer_id and customer_name of customers who bought products "A", "B" but did not buy the product "C" since we want to recommend them buy this product. Return the result table ordered by customer_id. The query result format is in the following example. Customers table: +-------------+---------------+ | customer_id | customer_name | +-------------+---------------+ | 1           | Daniel        | | 2           | Diana         | | 3           | Elizabeth     | | 4           | Jhon          | +-------------+---------------+ Orders table: +------------+--------------+---------------+ | order_id   | customer_id  | product_name  | +------------+--------------+---------------+ | 10         |     1        |     A         | | 20         |     1        |     B         | | 30         |     1        |     D         | | 40         |     1        |     C         | | 50         |     2        |     A         | | 60         |     3        |     A         | | 70         |     3        |     B         | | 80         |     3        |     D         | | 90         |     4        |     C         | +------------+--------------+---------------+ Result table: +-------------+---------------+ | customer_id | customer_name | +-------------+---------------+ | 3           | Elizabeth     | +-------------+---------------+ Only the customer_id with id 3 bought the product A and B but not the product C. Solution sql #Solution 1: WITH t1 AS ( SELECT customer_id FROM orders WHERE product_name = 'B' AND customer_id IN (SELECT customer_id FROM orders WHERE product_name = 'A')) SELECT t1.customer_id, c.customer_name FROM t1 JOIN customers c ON t1.customer_id = c.customer_id WHERE t1.customer_id != all(SELECT customer_id FROM orders WHERE product_name = 'C') #Solution 2: SELECT * FROM Customers WHERE customer_id IN (SELECT DISTINCT customer_id FROM Orders WHERE product_name = 'A' ) AND customer_id IN (SELECT DISTINCT customer_id FROM Orders WHERE product_name = 'B' ) AND customer_id NOT IN (SELECT DISTINCT customer_id FROM Orders WHERE product_name = 'C' ) ORDER BY customer_id #Solution 3: SELECT Customers.* FROM ( SELECT customer_id, sum(CASE WHEN product_name = 'A' THEN 1 ELSE 0 END) AS product_a, sum(CASE WHEN product_name = 'B' THEN 1 ELSE 0 END) AS product_b FROM Orders GROUP BY customer_id) AS t JOIN Customers ON t.customer_id = Customers.customer_id WHERE t.product_a>0 AND product_b >0 AND Customers.customer_id NOT IN ( SELECT DISTINCT customer_id FROM Orders WHERE product_name = 'C') ORDER BY Customers.customer_id

---

#### Top Travellers | Easy | üîí LeetCode

Table: Users +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | id            | int     | | name          | varchar | +---------------+---------+ id is the primary key for this table. name is the name of the user. Table: Rides +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | id            | int     | | user_id       | int     | | distance      | int     | +---------------+---------+ id is the primary key for this table. city_id is the id of the city who bought the product "product_name". Write an SQL query to report the distance travelled by each user. Return the result table ordered by travelled_distance in descending order, if two or more users travelled the same distance, order them by their name in ascending order. The query result format is in the following example. Users table: +------+-----------+ | id   | name      | +------+-----------+ | 1    | Alice     | | 2    | Bob       | | 3    | Alex      | | 4    | Donald    | | 7    | Lee       | | 13   | Jonathan  | | 19   | Elvis     | +------+-----------+ Rides table: +------+----------+----------+ | id   | user_id  | distance | +------+----------+----------+ | 1    | 1        | 120      | | 2    | 2        | 317      | | 3    | 3        | 222      | | 4    | 7        | 100      | | 5    | 13       | 312      | | 6    | 19       | 50       | | 7    | 7        | 120      | | 8    | 19       | 400      | | 9    | 7        | 230      | +------+----------+----------+ Result table: +----------+--------------------+ | name     | travelled_distance | +----------+--------------------+ | Elvis    | 450                | | Lee      | 450                | | Bob      | 317                | | Jonathan | 312                | | Alex     | 222                | | Alice    | 120                | | Donald   | 0                  | +----------+--------------------+ Elvis and Lee travelled 450 miles, Elvis is the top traveller as his name is alphabetically smaller than Lee. Bob, Jonathan, Alex and Alice have only one ride and we just order them by the total distances of the ride. Donald didn't have any rides, the distance travelled by him is 0. Solution sql #Solution 1: SELECT U.name AS name, COALESCE(SUM(R.distance),0) AS travelled_distance FROM Users U LEFT JOIN Rides R ON R.user_id = U.id GROUP BY name ORDER BY travelled_distance DESC, name #Solution 2: SELECT name, IFNULL(SUM(distance), 0) AS travelled_distance FROM Users LEFT JOIN Rides ON Users.id = Rides.user_id GROUP BY Users.id ORDER BY travelled_distance DESC, name #Solution 3: SELECT name, SUM(IF(ISNULL(distance), 0, distance)) AS travelled_distance FROM Users LEFT JOIN Rides ON Users.id = Rides.user_id GROUP BY Users.id ORDER BY travelled_distance DESC, name

---

#### Find the Quiet Students in All Exams | Hard | üîí LeetCode

Table: Student +---------------------+---------+ | Column Name         | Type    | +---------------------+---------+ | student_id          | int     | | student_name        | varchar | +---------------------+---------+ student_id is the primary key for this table. student_name is the name of the student. Table: Exam +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | exam_id       | int     | | student_id    | int     | | score         | int     | +---------------+---------+ (exam_id, student_id) is the primary key for this table. Student with student_id got score points in exam with id exam_id. A "quite" student is the one who took at least one exam and didn't score neither the high score nor the low score. Write an SQL query to report the students (student_id, student_name) being "quiet" in ALL exams. Don't return the student who has never taken any exam. Return the result table ordered by student_id. The query result format is in the following example. Student table: +-------------+---------------+ | student_id  | student_name  | +-------------+---------------+ | 1           | Daniel        | | 2           | Jade          | | 3           | Stella        | | 4           | Jonathan      | | 5           | Will          | +-------------+---------------+ Exam table: +------------+--------------+-----------+ | exam_id    | student_id   | score     | +------------+--------------+-----------+ | 10         |     1        |    70     | | 10         |     2        |    80     | | 10         |     3        |    90     | | 20         |     1        |    80     | | 30         |     1        |    70     | | 30         |     3        |    80     | | 30         |     4        |    90     | | 40         |     1        |    60     | | 40         |     2        |    70     | | 40         |     4        |    80     | +------------+--------------+-----------+ Result table: +-------------+---------------+ | student_id  | student_name  | +-------------+---------------+ | 2           | Jade          | +-------------+---------------+ For exam 1: Student 1 and 3 hold the lowest and high score respectively. For exam 2: Student 1 hold both highest and lowest score. For exam 3 and 4: Studnet 1 and 4 hold the lowest and high score respectively. Student 2 and 5 have never got the highest or lowest in any of the exam. Since student 5 is not taking any exam, he is excluded from the result. So, we only return the information of Student 2. Solution sql #Solution 1: WITH t1 AS( SELECT student_id FROM (SELECT *, MIN(score) OVER(PARTITION BY exam_id) AS least, MAX(score) OVER(PARTITION BY exam_id) AS most FROM exam) a WHERE least = score OR most = score) SELECT DISTINCT student_id, student_name FROM exam JOIN student USING (student_id) WHERE student_id != all(SELECT student_id FROM t1) order by 1 #Solution 2: SELECT DISTINCT Student.* FROM Student INNER JOIN Exam ON Student.student_id = Exam.student_id WHERE student.student_id NOT IN (SELECT e1.student_id FROM Exam AS e1 INNER JOIN (SELECT exam_id, MIN(score) AS min_score, MAX(score) AS max_score FROM Exam GROUP BY exam_id) AS e2 ON e1.exam_id = e2.exam_id WHERE e1.score = e2.min_score OR e1.score = e2.max_score) ORDER BY student_id

---

#### NPV Queries | Medium | üîí LeetCode

Table: NPV +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | id            | int     | | year          | int     | | npv           | int     | +---------------+---------+ (id, year) is the primary key of this table. The table has information about the id and the year of each inventory and the corresponding net present value. Table: Queries +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | id            | int     | | year          | int     | +---------------+---------+ (id, year) is the primary key of this table. The table has information about the id and the year of each inventory query. Write an SQL query to find the npv of all each query of queries table. Return the result table in any order. The query result format is in the following example: NPV table: +------+--------+--------+ | id   | year   | npv    | +------+--------+--------+ | 1    | 2018   | 100    | | 7    | 2020   | 30     | | 13   | 2019   | 40     | | 1    | 2019   | 113    | | 2    | 2008   | 121    | | 3    | 2009   | 12     | | 11   | 2020   | 99     | | 7    | 2019   | 0      | +------+--------+--------+ Queries table: +------+--------+ | id   | year   | +------+--------+ | 1    | 2019   | | 2    | 2008   | | 3    | 2009   | | 7    | 2018   | | 7    | 2019   | | 7    | 2020   | | 13   | 2019   | +------+--------+ Result table: +------+--------+--------+ | id   | year   | npv    | +------+--------+--------+ | 1    | 2019   | 113    | | 2    | 2008   | 121    | | 3    | 2009   | 12     | | 7    | 2018   | 0      | | 7    | 2019   | 0      | | 7    | 2020   | 30     | | 13   | 2019   | 40     | +------+--------+--------+ The npv value of (7, 2018) is not present in the NPV table, we consider it 0. The npv values of all other queries can be found in the NPV table. Solution sql #Solution 1: SELECT q.id, q.year, COALESCE(n.npv,0) AS npv FROM queries q LEFT JOIN npv n ON q.id = n.id AND q.year=n.year #Solution 2: SELECT Queries.*, IF(ISNULL(npv), 0, npv) AS npv FROM Queries LEFT JOIN NPV ON Queries.id = NPV.id AND Queries.year = NPV.year

---

#### Create a Session Bar Chart | Easy | üîí LeetCode

Table: Sessions +---------------------+---------+ | Column Name         | Type    | +---------------------+---------+ | session_id          | int     | | duration            | int     | +---------------------+---------+ session_id is the primary key for this table. duration is the time in seconds that a user has visited the application. You want to know how long a user visits your application. You decided to create bins of "[0-5>", "[5-10>", "[10-15>" and "15 minutes or more" and count the number of sessions on it. Write an SQL query to report the (bin, total) in any order. The query result format is in the following example. Sessions table: +-------------+---------------+ | session_id  | duration      | +-------------+---------------+ | 1           | 30            | | 2           | 299           | | 3           | 340           | | 4           | 580           | | 5           | 1000          | +-------------+---------------+ Result table: +--------------+--------------+ | bin          | total        | +--------------+--------------+ | [0-5>        | 3            | | [5-10>       | 1            | | [10-15>      | 0            | | 15 or more   | 1            | +--------------+--------------+ For session_id 1, 2 and 3 have a duration greater or equal than 0 minutes and less than 5 minutes. For session_id 4 has a duration greater or equal than 5 minutes and less than 10 minutes. There are no session with a duration greater or equial than 10 minutes and less than 15 minutes. For session_id 5 has a duration greater or equal than 15 minutes. Solution sql #Solution 1: (SELECT '[0-5>' AS bin, SUM(CASE WHEN duration/60 < 5 THEN 1 ELSE 0 END) AS total FROM Sessions) UNION (SELECT '[5-10>' AS bin, SUM(CASE WHEN ((duration/60 >= 5) AND (duration/60 < 10)) THEN 1 ELSE 0 END) AS total FROM Sessions) UNION (SELECT '[10-15>' AS bin, SUM(CASE WHEN ((duration/60 >= 10) AND (duration/60 < 15)) THEN 1 ELSE 0 END) AS total FROM Sessions) UNION (SELECT '15 or more' AS bin, SUM(CASE WHEN duration/60 >= 15 THEN 1 ELSE 0 END) AS total FROM Sessions) #Solution 2: SELECT '[0-5>' AS bin, count(1) AS total FROM Sessions WHERE duration>=0 AND duration < 300 UNION SELECT '[5-10>' AS bin, count(1) AS total FROM Sessions WHERE duration>=300 AND duration < 600 UNION SELECT '[10-15>' AS bin, count(1) AS total FROM Sessions WHERE duration>=600 AND duration < 900 UNION SELECT '15 or more' AS bin, count(1) AS total FROM Sessions WHERE duration >= 900

---

#### Evaluate Boolean Expression | Medium | üîí LeetCode

Table Variables: +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | name          | varchar | | value         | int     | +---------------+---------+ name is the primary key for this table. This table contains the stored variables and their values. Table Expressions: +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | left_operand  | varchar | | operator      | enum    | | right_operand | varchar | +---------------+---------+ (left_operand, operator, right_operand) is the primary key for this table. This table contains a boolean expression that should be evaluated. operator is an enum that takes one of the values ('<', '>', '=') The values of left_operand and right_operand are guaranteed to be in the Variables table. Write an SQL query to evaluate the boolean expressions in Expressions table. Return the result table in any order. The query result format is in the following example. Variables table: +------+-------+ | name | value | +------+-------+ | x    | 66    | | y    | 77    | +------+-------+ Expressions table: +--------------+----------+---------------+ | left_operand | operator | right_operand | +--------------+----------+---------------+ | x            | >        | y             | | x            | <        | y             | | x            | =        | y             | | y            | >        | x             | | y            | <        | x             | | x            | =        | x             | +--------------+----------+---------------+ Result table: +--------------+----------+---------------+-------+ | left_operand | operator | right_operand | value | +--------------+----------+---------------+-------+ | x            | >        | y             | false | | x            | <        | y             | true  | | x            | =        | y             | false | | y            | >        | x             | true  | | y            | <        | x             | false | | x            | =        | x             | true  | +--------------+----------+---------------+-------+ As shown, you need find the value of each boolean exprssion in the table using the variables table. Solution sql #Solution 1: WITH t1 AS( SELECT e.left_operand, e.operator, e.right_operand, v.value AS left_val, v_1.value AS right_val FROM expressions e JOIN variables v ON v.name = e.left_operand JOIN variables v_1 ON v_1.name = e.right_operand) SELECT t1.left_operand, t1.operator, t1.right_operand, CASE WHEN t1.operator = '<' THEN (SELECT t1.left_val< t1.right_val) WHEN t1.operator = '>' THEN (SELECT t1.left_val > t1.right_val) WHEN t1.operator = '=' THEN (SELECT t1.left_val = t1.right_val) ELSE FALSE END AS VALUE FROM t1 #Solution 2: # nested INNER JOIN can trim the volume of the intermediate table, which gives us better performance SELECT t.left_operand, t.operator, t.right_operand, (CASE WHEN v1_value>v2.value AND operator = '>' THEN "true" WHEN v1_value<v2.value AND operator = '<' THEN "true" WHEN v1_value=v2.value AND operator = '=' THEN "true" ELSE "false" END) AS value FROM (SELECT e.*, v1.value AS v1_value FROM Expressions AS e INNER JOIN Variables AS v1 ON e.left_operand = v1.name) AS t INNER JOIN Variables AS v2 ON t.right_operand = v2.name #Solution 3: SELECT t.left_operand, t.operator, t.right_operand, (CASE WHEN operator = '>' THEN IF(v1_value>v2.value, "true", "false") WHEN operator = '<' THEN IF(v1_value<v2.value, "true", "false") WHEN operator = '=' THEN IF(v1_value=v2.value, "true", "false") END) AS value FROM (SELECT e.*, v1.value AS v1_value FROM Expressions AS e INNER JOIN Variables AS v1 ON e.left_operand = v1.name) AS t INNER JOIN Variables AS v2 ON t.right_operand = v2.name

---

#### Apples & Oranges | Medium | üîí LeetCode

Table: Sales +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | sale_date     | date    | | fruit         | enum    | | sold_num      | int     | +---------------+---------+ (sale_date,fruit) is the primary key for this table. This table contains the sales of "apples" and "oranges" sold each day. Write an SQL query to report the difference between number of apples and oranges sold each day. Return the result table ordered by sale_date in format ('YYYY-MM-DD'). The query result format is in the following example: Sales table: +------------+------------+-------------+ | sale_date  | fruit      | sold_num    | +------------+------------+-------------+ | 2020-05-01 | apples     | 10          | | 2020-05-01 | oranges    | 8           | | 2020-05-02 | apples     | 15          | | 2020-05-02 | oranges    | 15          | | 2020-05-03 | apples     | 20          | | 2020-05-03 | oranges    | 0           | | 2020-05-04 | apples     | 15          | | 2020-05-04 | oranges    | 16          | +------------+------------+-------------+ Result table: +------------+--------------+ | sale_date  | diff         | +------------+--------------+ | 2020-05-01 | 2            | | 2020-05-02 | 0            | | 2020-05-03 | 20           | | 2020-05-04 | -1           | +------------+--------------+ Day 2020-05-01, 10 apples and 8 oranges were sold (Difference  10 - 8 = 2). Day 2020-05-02, 15 apples and 15 oranges were sold (Difference 15 - 15 = 0). Day 2020-05-03, 20 apples and 0 oranges were sold (Difference 20 - 0 = 20). Day 2020-05-04, 15 apples and 16 oranges were sold (Difference 15 - 16 = -1). Solution sql #Solution 1: SELECT sale_date, sum(CASE WHEN fruit='apples' THEN sold_num ELSE -sold_num END) AS diff FROM Sales GROUP BY sale_date #Solution 2: SELECT sale_date, sold_num-sold AS diff FROM ((SELECT * FROM sales WHERE fruit = 'apples') a JOIN (SELECT sale_date AS sale, fruit, sold_num AS sold FROM sales WHERE fruit = 'oranges') b ON a.sale_date = b.sale)

---

#### Active Users | Medium | üîí LeetCode

Table Accounts: +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | id            | int     | | name          | varchar | +---------------+---------+ the id is the primary key for this table. This table contains the account id and the user name of each account. Table Logins: +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | id            | int     | | login_date    | date    | +---------------+---------+ There is no primary key for this table, it may contain duplicates. This table contains the account id of the user who logged in and the login date. A user may log in multiple times in the day. Write an SQL query to find the id and the name of active users. Active users are those who logged in to their accounts for 5 or more consecutive days. Return the result table ordered by the id. The query result format is in the following example: Accounts table: +----+----------+ | id | name     | +----+----------+ | 1  | Winston  | | 7  | Jonathan | +----+----------+ Logins table: +----+------------+ | id | login_date | +----+------------+ | 7  | 2020-05-30 | | 1  | 2020-05-30 | | 7  | 2020-05-31 | | 7  | 2020-06-01 | | 7  | 2020-06-02 | | 7  | 2020-06-02 | | 7  | 2020-06-03 | | 1  | 2020-06-07 | | 7  | 2020-06-10 | +----+------------+ Result table: +----+----------+ | id | name     | +----+----------+ | 7  | Jonathan | +----+----------+ User Winston with id = 1 logged in 2 times only in 2 different days, so, Winston is not an active user. User Jonathan with id = 7 logged in 7 times in 6 different days, five of them were consecutive days, so, Jonathan is an active user. Follow up question: Can you write a general solution if the active users are those who logged in to their accounts for n or more consecutive days? Solution sql #Solution 1: WITH t1 AS ( SELECT id,login_date, lead(login_date,4) OVER(PARTITION BY id ORDER BY login_date) date_5 FROM (SELECT DISTINCT * FROM Logins) b ) SELECT DISTINCT a.id, a.name FROM t1 INNER JOIN accounts a ON t1.id = a.id WHERE DATEDIFF(t1.date_5,login_date) = 4 ORDER BY id #Soltion 2: SELECT * FROM Accounts WHERE id IN (SELECT DISTINCT t1.id FROM Logins AS t1 INNER JOIN Logins AS t2 ON t1.id = t2.id AND datediff(t1.login_date, t2.login_date) BETWEEN 1 AND 4 GROUP BY t1.id, t1.login_date HAVING count(DISTINCT(t2.login_date)) = 4) ORDER BY id

---

#### Rectangles Area | Medium | üîí LeetCode

Table: Points +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | id            | int     | | x_value       | int     | | y_value       | int     | +---------------+---------+ id is the primary key for this table. Each point is represented as a 2D Dimensional (x_value, y_value). Write an SQL query to report of all possible rectangles which can be formed by any two points of the table. Each row in the result contains three columns (p1, p2, area) where: p1 and p2 are the id of two opposite corners of a rectangle and p1 < p2. Area of this rectangle is represented by the column area. Report the query in descending order by area in case of tie in ascending order by p1 and p2. Points table: +----------+-------------+-------------+ | id       | x_value     | y_value     | +----------+-------------+-------------+ | 1        | 2           | 8           | | 2        | 4           | 7           | | 3        | 2           | 10          | +----------+-------------+-------------+ Result table: +----------+-------------+-------------+ | p1       | p2          | area        | +----------+-------------+-------------+ | 2        | 3           | 6           | | 1        | 2           | 2           | +----------+-------------+-------------+ p1 should be less than p2 and area greater than 0. p1 = 1 and p2 = 2, has an area equal to |2-4| * |8-7| = 2. p1 = 2 and p2 = 3, has an area equal to |4-2| * |7-10| = 2. p1 = 1 and p2 = 3 It's not possible because has an area equal to 0. Solution sql SELECT t1.id AS p1, t2.id AS p2, ABS(t1.x_value-t2.x_value)*ABS(t1.y_value-t2.y_value) AS area FROM Points AS t1 INNER JOIN Points AS t2 ON t1.id < t2.id AND t1.x_value != t2.x_value AND t1.y_value != t2.y_value ORDER BY area DESC, p1, p2

---

#### Calculate Salaries | Medium | üîí LeetCode

Table Salaries: +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | company_id    | int     | | employee_id   | int     | | employee_name | varchar | | salary        | int     | +---------------+---------+ (company_id, employee_id) is the primary key for this table. This table contains the company id, the id, the name and the salary for an employee. Write an SQL query to find the salaries of the employees after applying taxes. The tax rate is calculated for each company based on the following criteria: 0% If the max salary of any employee in the company is less than 1000$. 24% If the max salary of any employee in the company is in the range [1000, 10000] inclusive. 49% If the max salary of any employee in the company is greater than 10000$. Return the result table in any order. Round the salary to the nearest integer. The query result format is in the following example: Salaries table: +------------+-------------+---------------+--------+ | company_id | employee_id | employee_name | salary | +------------+-------------+---------------+--------+ | 1          | 1           | Tony          | 2000   | | 1          | 2           | Pronub        | 21300  | | 1          | 3           | Tyrrox        | 10800  | | 2          | 1           | Pam           | 300    | | 2          | 7           | Bassem        | 450    | | 2          | 9           | Hermione      | 700    | | 3          | 7           | Bocaben       | 100    | | 3          | 2           | Ognjen        | 2200   | | 3          | 13          | Nyancat       | 3300   | | 3          | 15          | Morninngcat   | 1866   | +------------+-------------+---------------+--------+ Result table: +------------+-------------+---------------+--------+ | company_id | employee_id | employee_name | salary | +------------+-------------+---------------+--------+ | 1          | 1           | Tony          | 1020   | | 1          | 2           | Pronub        | 10863  | | 1          | 3           | Tyrrox        | 5508   | | 2          | 1           | Pam           | 300    | | 2          | 7           | Bassem        | 450    | | 2          | 9           | Hermione      | 700    | | 3          | 7           | Bocaben       | 76     | | 3          | 2           | Ognjen        | 1672   | | 3          | 13          | Nyancat       | 2508   | | 3          | 15          | Morninngcat   | 5911   | +------------+-------------+---------------+--------+ For company 1, Max salary is 21300. Employees in company 1 have taxes = 49% For company 2, Max salary is 700. Employees in company 2 have taxes = 0% For company 3, Max salary is 7777. Employees in company 3 have taxes = 24% The salary after taxes = salary - (taxes percentage / 100) * salary For example, Salary for Morninngcat (3, 15) after taxes = 7777 - 7777 * (24 / 100) = 7777 - 1866.48 = 5910.52, which is rounded to 5911. Solution sql #Solution 1: WITH t1 AS ( SELECT company_id, employee_id, employee_name, salary AS sa, MAX(salary) OVER(PARTITION BY company_id) AS maximum FROM salaries) SELECT company_id, employee_id, employee_name, CASE WHEN t1.maximum<1000 THEN t1.sa WHEN t1.maximum BETWEEN 1000 AND 10000 THEN ROUND(t1.sa*.76,0) ELSE ROUND(t1.sa*.51,0) END AS salary FROM t1 #Soltion 2: SELECT Salaries.company_id, Salaries.employee_id, Salaries.employee_name, ROUND(CASE WHEN salary_max<1000 THEN Salaries.salary WHEN salary_max>=1000 AND salary_max<=10000 THEN Salaries.salary * 0.76 ELSE Salaries.salary * 0.51 END, 0) AS salary FROM Salaries INNER JOIN ( SELECT company_id, MAX(salary) AS salary_max FROM Salaries GROUP BY company_id) AS t ON Salaries.company_id = t.company_id

---

#### Sales by Day of the Week | Hard | üîí LeetCode

Table: Orders +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | order_id      | int     | | customer_id   | int     | | order_date    | date    | | item_id       | varchar | | quantity      | int     | +---------------+---------+ (ordered_id, item_id) is the primary key for this table. This table contains information of the orders placed. order_date is the date when item_id was ordered by the customer with id customer_id. Table: Items +---------------------+---------+ | Column Name         | Type    | +---------------------+---------+ | item_id             | varchar | | item_name           | varchar | | item_category       | varchar | +---------------------+---------+ item_id is the primary key for this table. item_name is the name of the item. item_category is the category of the item. You are the business owner and would like to obtain a sales report for category items and day of the week. Write an SQL query to report how many units in each category have been ordered on each day of the week. Return the result table ordered by category. The query result format is in the following example: Orders table: +------------+--------------+-------------+--------------+-------------+ | order_id   | customer_id  | order_date  | item_id      | quantity    | +------------+--------------+-------------+--------------+-------------+ | 1          | 1            | 2020-06-01  | 1            | 10          | | 2          | 1            | 2020-06-08  | 2            | 10          | | 3          | 2            | 2020-06-02  | 1            | 5           | | 4          | 3            | 2020-06-03  | 3            | 5           | | 5          | 4            | 2020-06-04  | 4            | 1           | | 6          | 4            | 2020-06-05  | 5            | 5           | | 7          | 5            | 2020-06-05  | 1            | 10          | | 8          | 5            | 2020-06-14  | 4            | 5           | | 9          | 5            | 2020-06-21  | 3            | 5           | +------------+--------------+-------------+--------------+-------------+ Items table: +------------+----------------+---------------+ | item_id    | item_name      | item_category | +------------+----------------+---------------+ | 1          | LC Alg. Book   | Book          | | 2          | LC DB. Book    | Book          | | 3          | LC SmarthPhone | Phone         | | 4          | LC Phone 2020  | Phone         | | 5          | LC SmartGlass  | Glasses       | | 6          | LC T-Shirt XL  | T-Shirt       | +------------+----------------+---------------+ Result table: +------------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+ | Category   | Monday    | Tuesday   | Wednesday | Thursday  | Friday    | Saturday  | Sunday    | +------------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+ | Book       | 20        | 5         | 0         | 0         | 10        | 0         | 0         | | Glasses    | 0         | 0         | 0         | 0         | 5         | 0         | 0         | | Phone      | 0         | 0         | 5         | 1         | 0         | 0         | 10        | | T-Shirt    | 0         | 0         | 0         | 0         | 0         | 0         | 0         | +------------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+ On Monday (2020-06-01, 2020-06-08) were sold a total of 20 units (10 + 10) in the category Book (ids: 1, 2). On Tuesday (2020-06-02) were sold a total of 5 units  in the category Book (ids: 1, 2). On Wednesday (2020-06-03) were sold a total of 5 units in the category Phone (ids: 3, 4). On Thursday (2020-06-04) were sold a total of 1 unit in the category Phone (ids: 3, 4). On Friday (2020-06-05) were sold 10 units in the category Book (ids: 1, 2) and 5 units in Glasses (ids: 5). On Saturday there are no items sold. On Sunday (2020-06-14, 2020-06-21) were sold a total of 10 units (5 +5) in the category Phone (ids: 3, 4). There are no sales of T-Shirt. Solution sql WITH t1 AS( SELECT DISTINCT item_category, CASE WHEN dayname(order_date)='Monday' THEN SUM(quantity) OVER(PARTITION BY item_category,dayname(order_date)) ELSE 0 END AS Monday, CASE WHEN dayname(order_date)='Tuesday' THEN SUM(quantity) OVER(PARTITION BY item_category,dayname(order_date)) ELSE 0 END AS Tuesday, CASE WHEN dayname(order_date)='Wednesday' THEN SUM(quantity) OVER(PARTITION BY item_category,dayname(order_date)) ELSE 0 END AS Wednesday, CASE WHEN dayname(order_date)='Thursday' THEN SUM(quantity) OVER(PARTITION BY item_category,dayname(order_date)) ELSE 0 END AS Thursday, CASE WHEN dayname(order_date)='Friday' THEN SUM(quantity) OVER(PARTITION BY item_category,dayname(order_date)) ELSE 0 END AS Friday, CASE WHEN dayname(order_date)='Saturday' THEN SUM(quantity) OVER(PARTITION BY item_category,dayname(order_date)) ELSE 0 END AS Saturday, CASE WHEN dayname(order_date)='Sunday' THEN SUM(quantity) OVER(PARTITION BY item_category,dayname(order_date)) ELSE 0 END AS Sunday FROM orders o RIGHT JOIN items i USING (item_id)) SELECT item_category AS category, SUM(Monday) AS Monday, SUM(Tuesday) AS Tuesday, SUM(Wednesday) Wednesday, SUM(Thursday) Thursday, SUM(Friday) Friday, SUM(Saturday) Saturday, SUM(Sunday) Sunday FROM t1 GROUP BY item_category

---

#### Group Sold Products By The Date | Easy | üîí LeetCode

Table Activities: +-------------+---------+ | Column Name | Type    | +-------------+---------+ | sell_date   | date    | | product     | varchar | +-------------+---------+ There is no primary key for this table, it may contains duplicates. Each row of this table contains the product name and the date it was sold in a market. Write an SQL query to find for each date, the number of distinct products sold and their names. The sold-products names for each date should be sorted lexicographically. Return the result table ordered by sell_date. The query result format is in the following example. Activities table: +------------+-------------+ | sell_date  | product     | +------------+-------------+ | 2020-05-30 | Headphone   | | 2020-06-01 | Pencil      | | 2020-06-02 | Mask        | | 2020-05-30 | Basketball  | | 2020-06-01 | Bible       | | 2020-06-02 | Mask        | | 2020-05-30 | T-Shirt     | +------------+-------------+ Result table: +------------+----------+------------------------------+ | sell_date  | num_sold | products                     | +------------+----------+------------------------------+ | 2020-05-30 | 3        | Basketball,Headphone,T-shirt | | 2020-06-01 | 2        | Bible,Pencil                 | | 2020-06-02 | 1        | Mask                         | +------------+----------+------------------------------+ For 2020-05-30, Sold items were (Headphone, Basketball, T-shirt), we sort them lexicographically and separate them by comma. For 2020-06-01, Sold items were (Pencil, Bible), we sort them lexicographically and separate them by comma. For 2020-06-02, Sold item is (Masks), we just return it. Solution sql SELECT sell_date, COUNT(DISTINCT product) AS num_sold, group_concat(DISTINCT product) AS products FROM activities GROUP BY 1 ORDER BY 1

---

#### Friendly Movies Streamed Last Month | Easy | üîí LeetCode

Table: TVProgram +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | program_date  | date    | | content_id    | int     | | channel       | varchar | +---------------+---------+ (program_date, content_id) is the primary key for this table. This table contains information of the programs on the TV. content_id is the id of the program in some channel on the TV. Table: Content +------------------+---------+ | Column Name      | Type    | +------------------+---------+ | content_id       | varchar | | title            | varchar | | Kids_content     | enum    | | content_type     | varchar | +------------------+---------+ content_id is the primary key for this table. Kids_content is an enum that takes one of the values ('Y', 'N') where: 'Y' means is content for kids otherwise 'N' is not content for kids. content_type is the category of the content as movies, series, etc. Write an SQL query to report the distinct titles of the kid-friendly movies streamed in June 2020. Return the result table in any order. The query result format is in the following example. TVProgram table: +--------------------+--------------+-------------+ | program_date       | content_id   | channel     | +--------------------+--------------+-------------+ | 2020-06-10 08:00   | 1            | LC-Channel  | | 2020-05-11 12:00   | 2            | LC-Channel  | | 2020-05-12 12:00   | 3            | LC-Channel  | | 2020-05-13 14:00   | 4            | Disney Ch   | | 2020-06-18 14:00   | 4            | Disney Ch   | | 2020-07-15 16:00   | 5            | Disney Ch   | +--------------------+--------------+-------------+ Content table: +------------+----------------+---------------+---------------+ | content_id | title          | Kids_content  | content_type  | +------------+----------------+---------------+---------------+ | 1          | Leetcode Movie | N             | Movies        | | 2          | Alg. for Kids  | Y             | Series        | | 3          | Database Sols  | N             | Series        | | 4          | Aladdin        | Y             | Movies        | | 5          | Cinderella     | Y             | Movies        | +------------+----------------+---------------+---------------+ Result table: +--------------+ | title        | +--------------+ | Aladdin      | +--------------+ "Leetcode Movie" is not a content for kids. "Alg. for Kids" is not a movie. "Database Sols" is not a movie "Alladin" is a movie, content for kids and was streamed in June 2020. "Cinderella" was not streamed in June 2020. Solution sql SELCT DISTINCT title FROM (SELCT content_id, title FROM content WHERE kids_content = 'Y' AND content_type = 'Movies') a JOIN tvprogram USING (content_id) WHERE month(program_date) = 6

---

#### Countries You Can Safely Invest In | Medium | üîí LeetCode

Table Person: +----------------+---------+ | Column Name    | Type    | +----------------+---------+ | id             | int     | | name           | varchar | | phone_number   | varchar | +----------------+---------+ id is the primary key for this table. Each row of this table contains the name of a person and their phone number. Phone number will be in the form 'xxx-yyyyyyy' where xxx is the country code (3 characters) and yyyyyyy is the phone number (7 characters) where x and y are digits. Both can contain leading zeros. Table Country: +----------------+---------+ | Column Name    | Type    | +----------------+---------+ | name           | varchar | | country_code   | varchar | +----------------+---------+ country_code is the primary key for this table. Each row of this table contains the country name and its code. country_code will be in the form 'xxx' where x is digits. Table Calls: +-------------+------+ | Column Name | Type | +-------------+------+ | caller_id   | int  | | callee_id   | int  | | duration    | int  | +-------------+------+ There is no primary key for this table, it may contain duplicates. Each row of this table contains the caller id, callee id and the duration of the call in minutes. caller_id != callee_id A telecommunications company wants to invest in new countries. The country intends to invest in the countries where the average call duration of the calls in this country is strictly greater than the global average call duration. Write an SQL query to find the countries where this company can invest. Return the result table in any order. The query result format is in the following example. Person table: +----+----------+--------------+ | id | name     | phone_number | +----+----------+--------------+ | 3  | Jonathan | 051-1234567  | | 12 | Elvis    | 051-7654321  | | 1  | Moncef   | 212-1234567  | | 2  | Maroua   | 212-6523651  | | 7  | Meir     | 972-1234567  | | 9  | Rachel   | 972-0011100  | +----+----------+--------------+ Country table: +----------+--------------+ | name     | country_code | +----------+--------------+ | Peru     | 051          | | Israel   | 972          | | Morocco  | 212          | | Germany  | 049          | | Ethiopia | 251          | +----------+--------------+ Calls table: +-----------+-----------+----------+ | caller_id | callee_id | duration | +-----------+-----------+----------+ | 1         | 9         | 33       | | 2         | 9         | 4        | | 1         | 2         | 59       | | 3         | 12        | 102      | | 3         | 12        | 330      | | 12        | 3         | 5        | | 7         | 9         | 13       | | 7         | 1         | 3        | | 9         | 7         | 1        | | 1         | 7         | 7        | +-----------+-----------+----------+ Result table: +----------+ | country  | +----------+ | Peru     | +----------+ The average call duration for Peru is (102 + 102 + 330 + 330 + 5 + 5) / 6 = 145.666667 The average call duration for Israel is (33 + 4 + 13 + 13 + 3 + 1 + 1 + 7) / 8 = 9.37500 The average call duration for Morocco is (33 + 4 + 59 + 59 + 3 + 7) / 6 = 27.5000 Global call duration average = (2 * (33 + 3 + 59 + 102 + 330 + 5 + 13 + 3 + 1 + 7)) / 20 = 55.70000 Since Peru is the only country where average call duration is greater than the global average, it's the only recommended country. Solution sql WITH t1 AS( SELECT caller_id AS id, duration AS total FROM (SELECT caller_id, duration FROM calls UNION ALL SELECT callee_id, duration FROM calls) a ) SELECT name AS country FROM (SELECT distinct avg(total) OVER(PARTITION BY code) AS avg_call, avg(total) OVER() AS global_avg, c.name FROM ((SELECT *, coalesce(total,0) AS duration, SUBSTRING(phone_number FROM 1 for 3) AS code FROM person RIGHT JOIN t1 USING (id)) b join country c ON c.country_code = b.code)) d WHERE avg_call > global_avg

---

#### Customer Order Frequency | Easy | üîí LeetCode

Table: Customers +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | customer_id   | int     | | name          | varchar | | country       | varchar | +---------------+---------+ customer_id is the primary key for this table. This table contains information of the customers in the company. Table: Product +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | product_id    | int     | | description   | varchar | | price         | int     | +---------------+---------+ product_id is the primary key for this table. This table contains information of the products in the company. price is the product cost. Table: Orders +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | order_id      | int     | | customer_id   | int     | | product_id    | int     | | order_date    | date    | | quantity      | int     | +---------------+---------+ order_id is the primary key for this table. This table contains information on customer orders. customer_id is the id of the customer who bought "quantity" products with id "product_id". Order_date is the date in format ('YYYY-MM-DD') when the order was shipped. Write an SQL query to report the customer_id and customer_name of customers who have spent at least $100 in each month of June and July 2020. Return the result table in any order. The query result format is in the following example. Customers +--------------+-----------+-------------+ | customer_id  | name      | country     | +--------------+-----------+-------------+ | 1            | Winston   | USA         | | 2            | Jonathan  | Peru        | | 3            | Moustafa  | Egypt       | +--------------+-----------+-------------+ Product +--------------+-------------+-------------+ | product_id   | description | price       | +--------------+-------------+-------------+ | 10           | LC Phone    | 300         | | 20           | LC T-Shirt  | 10          | | 30           | LC Book     | 45          | | 40           | LC Keychain | 2           | +--------------+-------------+-------------+ Orders +--------------+-------------+-------------+-------------+-----------+ | order_id     | customer_id | product_id  | order_date  | quantity  | +--------------+-------------+-------------+-------------+-----------+ | 1            | 1           | 10          | 2020-06-10  | 1         | | 2            | 1           | 20          | 2020-07-01  | 1         | | 3            | 1           | 30          | 2020-07-08  | 2         | | 4            | 2           | 10          | 2020-06-15  | 2         | | 5            | 2           | 40          | 2020-07-01  | 10        | | 6            | 3           | 20          | 2020-06-24  | 2         | | 7            | 3           | 30          | 2020-06-25  | 2         | | 9            | 3           | 30          | 2020-05-08  | 3         | +--------------+-------------+-------------+-------------+-----------+ Result table: +--------------+------------+ | customer_id  | name       | +--------------+------------+ | 1            | Winston    | +--------------+------------+ Winston spent $300 (300 * 1) in June and $100 ( 10 * 1 + 45 * 2) in July 2020. Jonathan spent $600 (300 * 2) in June and $20 ( 2 * 10) in July 2020. Moustafa spent $110 (10 * 2 + 45 * 2) in June and $0 in July 2020. Solution sql #Solution 1: SELECT o.customer_id, name JOIN Product p ON o.product_id = p.product_id JOIN Customers c ON o.customer_id = c.customer_id GROUP BY 1, 2 HAVING SUM(CASE WHEN date_format(order_date, '%Y-%m')='2020-06' THEN price*quantity END) >= 100 AND SUM(CASE WHEN date_format(order_date, '%Y-%m')='2020-07' THEN price*quantity END) >= 100; #Solution 2: SELECT customer_id, name FROM ( SELECT o.customer_id, c.name, sum(CASE WHEN left(o.order_date,7) = '2020-06' THEN p.price * o.quantity END) AS JuneSpend, sum(CASE WHEN left(o.order_date,7) = '2020-07' THEN p.price * o.quantity END) AS JulySpend FROM Orders o LEFT JOIN Customers c ON o.customer_id = c.customer_id lEFT JOIN Product p ON o.product_id = p.product_id GROUP BY o.customer_id HAVING JuneSpend >= 100 AND JulySpend >= 100 ) AS temp #Solution 3: SELECT o.customer_id, c.name FROM Customers c, Product p, Orders o WHERE c.customer_id = o.customer_id AND p.product_id = o.product_id GROUP BY o.customer_id HAVING ( SUM(CASE WHEN o.order_date LIKE '2020-06%' THEN o.quantity*p.price ELSE 0 END) >= 100 and SUM(CASE WHEN o.order_date LIKE '2020-07%' THEN o.quantity*p.price ELSE 0 END) >= 100 );

---

#### Find Users With Valid E-Mails | Easy | üîí LeetCode

Table: Users +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | user_id       | int     | | name          | varchar | | mail          | varchar | +---------------+---------+ user_id is the primary key for this table. This table contains information of the users signed up in a website. Some e-mails are invalid. Write an SQL query to find the users who have valid emails. A valid e-mail has a prefix name and a domain where: The prefix name is a string that may contain letters (upper or lower case), digits, underscore '_', period '.' and/or dash '-'. The prefix name must start with a letter. The domain is '@leetcode.com'. Return the result table in any order. The query result format is in the following example. Users +---------+-----------+-------------------------+ | user_id | name      | mail                    | +---------+-----------+-------------------------+ | 1       | Winston   | winston@leetcode.com    | | 2       | Jonathan  | jonathanisgreat         | | 3       | Annabelle | bella-@leetcode.com     | | 4       | Sally     | sally.come@leetcode.com | | 5       | Marwan    | quarz#2020@leetcode.com | | 6       | David     | david69@gmail.com       | | 7       | Shapiro   | .shapo@leetcode.com     | +---------+-----------+-------------------------+ Result table: +---------+-----------+-------------------------+ | user_id | name      | mail                    | +---------+-----------+-------------------------+ | 1       | Winston   | winston@leetcode.com    | | 3       | Annabelle | bella-@leetcode.com     | | 4       | Sally     | sally.come@leetcode.com | +---------+-----------+-------------------------+ The mail of user 2 doesn't have a domain. The mail of user 5 has # sign which is not allowed. The mail of user 6 doesn't have leetcode domain. The mail of user 7 starts with a period. Solution sql #Solution 1: SELECT user_id, name, mail FROM Users WHERE mail regexp "^[a-zA-Z]+[a-zA-Z0-9_\\./\\-]{0,}@leetcode\\.com$" ORDER BY user_id #Solution 2: SELECT * FROM Users WHERE regexp_like(mail, '^[A-Za-z]+[A-Za-z0-9\_\.\-]*@leetcode.com')

---

#### Patients With a Condition | Easy | üîí LeetCode

Table: Patients +--------------+---------+ | Column Name  | Type    | +--------------+---------+ | patient_id   | int     | | patient_name | varchar | | conditions   | varchar | +--------------+---------+ patient_id is the primary key for this table. 'conditions' contains 0 or more code separated by spaces. This table contains information of the patients in the hospital. Write an SQL query to report the patient_id, patient_name all conditions of patients who have Type I Diabetes. Type I Diabetes always starts with DIAB1 prefix Return the result table in any order. The query result format is in the following example. Patients +------------+--------------+--------------+ | patient_id | patient_name | conditions   | +------------+--------------+--------------+ | 1          | Daniel       | YFEV COUGH   | | 2          | Alice        |              | | 3          | Bob          | DIAB100 MYOP | | 4          | George       | ACNE DIAB100 | | 5          | Alain        | DIAB201      | +------------+--------------+--------------+ Result table: +------------+--------------+--------------+ | patient_id | patient_name | conditions   | +------------+--------------+--------------+ | 3          | Bob          | DIAB100 MYOP | | 4          | George       | ACNE DIAB100 | +------------+--------------+--------------+ Bob and George both have a condition that starts with DIAB1. Solution sql SELECT patient_id, patient_name, conditions FROM Patients WHERE conditions LIKE '%DIAB1%'

---

#### The Most Recent Three Orders | Medium | üîí LeetCode

Table: Customers +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | customer_id   | int     | | name          | varchar | +---------------+---------+ customer_id is the primary key for this table. This table contains information about customers. Table: Orders +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | order_id      | int     | | order_date    | date    | | customer_id   | int     | | cost          | int     | +---------------+---------+ order_id is the primary key for this table. This table contains information about the orders made customer_id. Each customer has one order per day. Write an SQL query to find the most recent 3 orders of each user. If a user ordered less than 3 orders return all of their orders. Return the result table sorted by customer_name in ascending order and in case of a tie by the customer_id in ascending order. If there still a tie, order them by the order_date in descending order. The query result format is in the following example: Customers +-------------+-----------+ | customer_id | name      | +-------------+-----------+ | 1           | Winston   | | 2           | Jonathan  | | 3           | Annabelle | | 4           | Marwan    | | 5           | Khaled    | +-------------+-----------+ Orders +----------+------------+-------------+------+ | order_id | order_date | customer_id | cost | +----------+------------+-------------+------+ | 1        | 2020-07-31 | 1           | 30   | | 2        | 2020-07-30 | 2           | 40   | | 3        | 2020-07-31 | 3           | 70   | | 4        | 2020-07-29 | 4           | 100  | | 5        | 2020-06-10 | 1           | 1010 | | 6        | 2020-08-01 | 2           | 102  | | 7        | 2020-08-01 | 3           | 111  | | 8        | 2020-08-03 | 1           | 99   | | 9        | 2020-08-07 | 2           | 32   | | 10       | 2020-07-15 | 1           | 2    | +----------+------------+-------------+------+ Result table: +---------------+-------------+----------+------------+ | customer_name | customer_id | order_id | order_date | +---------------+-------------+----------+------------+ | Annabelle     | 3           | 7        | 2020-08-01 | | Annabelle     | 3           | 3        | 2020-07-31 | | Jonathan      | 2           | 9        | 2020-08-07 | | Jonathan      | 2           | 6        | 2020-08-01 | | Jonathan      | 2           | 2        | 2020-07-30 | | Marwan        | 4           | 4        | 2020-07-29 | | Winston       | 1           | 8        | 2020-08-03 | | Winston       | 1           | 1        | 2020-07-31 | | Winston       | 1           | 10       | 2020-07-15 | +---------------+-------------+----------+------------+ Winston has 4 orders, we discard the order of "2020-06-10" because it is the oldest order. Annabelle has only 2 orders, we return them. Jonathan has exactly 3 orders. Marwan ordered only one time. We sort the result table by customer_name in ascending order, by customer_id in ascending order and by order_date in descending order in case of a tie. Follow-up: Can you write a general solution for the most recent `n` orders? Solution sql WITH tmp AS ( SELECT a.name, a.customer_id, b.order_id, b.order_date, ROW_NUMBER() OVER(PARTITION BY a.name, a.customer_id ORDER BY b.order_date DESC) AS rnk FROM Customers AS a JOIN Orders AS b ON a.customer_id = b.customer_id ) SELECT name AS customer_name, customer_id, order_id, order_date FROM tmp WHERE rnk <= 3 ORDER BY customer_name, customer_id, order_date DESC;

---

#### Fix Product Name Format | Easy | üîí LeetCode

Table: Sales +--------------+---------+ | Column Name  | Type    | +--------------+---------+ | sale_id      | int     | | product_name | varchar | | sale_date    | date    | +--------------+---------+ sale_id is the primary key for this table. Each row of this table contains the product name and the date it was sold. Since table Sales was filled manually in the year 2000, product_name may contain leading and/or trailing white spaces, also they are case-insensitive. Write an SQL query to report product_name in lowercase without leading or trailing white spaces. sale_date in the format ('YYYY-MM') total the number of times the product was sold in this month. Return the result table ordered by product_name in ascending order, in case of a tie order it by sale_date in ascending order. The query result format is in the following example. Sales +------------+------------------+--------------+ | sale_id    | product_name     | sale_date    | +------------+------------------+--------------+ | 1          |      LCPHONE     | 2000-01-16   | | 2          |    LCPhone       | 2000-01-17   | | 3          |     LcPhOnE      | 2000-02-18   | | 4          |      LCKeyCHAiN  | 2000-02-19   | | 5          |   LCKeyChain     | 2000-02-28   | | 6          | Matryoshka       | 2000-03-31   | +------------+------------------+--------------+ Result table: +--------------+--------------+----------+ | product_name | sale_date    | total    | +--------------+--------------+----------+ | lcphone      | 2000-01      | 2        | | lckeychain   | 2000-02      | 2        | | lcphone      | 2000-02      | 1        | | matryoshka   | 2000-03      | 1        | +--------------+--------------+----------+ In January, 2 LcPhones were sold, please note that the product names are not case sensitive and may contain spaces. In Februery, 2 LCKeychains and 1 LCPhone were sold. In March, 1 matryoshka was sold. Solution sql SELECT TRIM(LOWER(product_name)) AS product_name, DATE_FORMAT(sale_date, '%Y-%m') AS sale_date, COUNT(*) AS total FROM Sales GROUP BY 1, DATE_FORMAT(sale_date, '%Y-%m') ORDER BY 1, 2;

---

#### The Most Recent Orders for Each Product | Medium | üîí LeetCode

Table: Customers +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | customer_id   | int     | | name          | varchar | +---------------+---------+ customer_id is the primary key for this table. This table contains information about the customers. Table: Orders +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | order_id      | int     | | order_date    | date    | | customer_id   | int     | | product_id    | int     | +---------------+---------+ order_id is the primary key for this table. This table contains information about the orders made by customer_id. There will be no product ordered by the same user more than once in one day. Table: Products +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | product_id    | int     | | product_name  | varchar | | price         | int     | +---------------+---------+ product_id is the primary key for this table. This table contains information about the Products. Write an SQL query to find the most recent order(s) of each product. Return the result table sorted by product_name in ascending order and in case of a tie by the product_id in ascending order. If there still a tie, order them by the order_id in ascending order. The query result format is in the following example: Customers +-------------+-----------+ | customer_id | name      | +-------------+-----------+ | 1           | Winston   | | 2           | Jonathan  | | 3           | Annabelle | | 4           | Marwan    | | 5           | Khaled    | +-------------+-----------+ Orders +----------+------------+-------------+------------+ | order_id | order_date | customer_id | product_id | +----------+------------+-------------+------------+ | 1        | 2020-07-31 | 1           | 1          | | 2        | 2020-07-30 | 2           | 2          | | 3        | 2020-08-29 | 3           | 3          | | 4        | 2020-07-29 | 4           | 1          | | 5        | 2020-06-10 | 1           | 2          | | 6        | 2020-08-01 | 2           | 1          | | 7        | 2020-08-01 | 3           | 1          | | 8        | 2020-08-03 | 1           | 2          | | 9        | 2020-08-07 | 2           | 3          | | 10       | 2020-07-15 | 1           | 2          | +----------+------------+-------------+------------+ Products +------------+--------------+-------+ | product_id | product_name | price | +------------+--------------+-------+ | 1          | keyboard     | 120   | | 2          | mouse        | 80    | | 3          | screen       | 600   | | 4          | hard disk    | 450   | +------------+--------------+-------+ Result table: +--------------+------------+----------+------------+ | product_name | product_id | order_id | order_date | +--------------+------------+----------+------------+ | keyboard     | 1          | 6        | 2020-08-01 | | keyboard     | 1          | 7        | 2020-08-01 | | mouse        | 2          | 8        | 2020-08-03 | | screen       | 3          | 3        | 2020-08-29 | +--------------+------------+----------+------------+ keyboard's most recent order is in 2020-08-01, it was ordered two times this day. mouse's most recent order is in 2020-08-03, it was ordered only once this day. screen's most recent order is in 2020-08-29, it was ordered only once this day. The hard disk was never ordered and we don't include it in the result table. Solution sql SELECT p.product_name, o.product_id, o.order_id, o.order_date FROM( SELECT product_id, order_id, order_date, RANK() OVER(PARTITION BY product_id ORDER BY order_date DESC) AS seq FROM orders ) o LEFT JOIN products p ON o.product_id = p.product_id WHERE o.seq = 1 ORDER BY 1,2,3

---

#### Bank Account Summary | Medium | üîí LeetCode

Table: Users +--------------+---------+ | Column Name  | Type    | +--------------+---------+ | user_id      | int     | | user_name    | varchar | | credit       | int     | +--------------+---------+ user_id is the primary key for this table. Each row of this table contains the current credit information for each user. Table: Transaction +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | trans_id      | int     | | paid_by       | int     | | paid_to       | int     | | amount        | int     | | transacted_on | date    | +---------------+---------+ trans_id is the primary key for this table. Each row of this table contains the information about the transaction in the bank. User with id (paid_by) transfer money to user with id (paid_to). Leetcode Bank (LCB) helps its coders in making virtual payments. Our bank records all transactions in the table Transaction, we want to find out the current balance of all users and check wheter they have breached their credit limit (If their current credit is less than 0). Write an SQL query to report. user_id user_name credit, current balance after performing transactions. credit_limit_breached, check credit_limit ("Yes" or "No") Return the result table in any order. The query result format is in the following example. Users table: +------------+--------------+-------------+ | user_id    | user_name    | credit      | +------------+--------------+-------------+ | 1          | Moustafa     | 100         | | 2          | Jonathan     | 200         | | 3          | Winston      | 10000       | | 4          | Luis         | 800         | +------------+--------------+-------------+ Transaction table: +------------+------------+------------+----------+---------------+ | trans_id   | paid_by    | paid_to    | amount   | transacted_on | +------------+------------+------------+----------+---------------+ | 1          | 1          | 3          | 400      | 2020-08-01    | | 2          | 3          | 2          | 500      | 2020-08-02    | | 3          | 2          | 1          | 200      | 2020-08-03    | +------------+------------+------------+----------+---------------+ Result table: +------------+------------+------------+-----------------------+ | user_id    | user_name  | credit     | credit_limit_breached | +------------+------------+------------+-----------------------+ | 1          | Moustafa   | -100       | Yes                   | | 2          | Jonathan   | 500        | No                    | | 3          | Winston    | 9990       | No                    | | 4          | Luis       | 800        | No                    | +------------+------------+------------+-----------------------+ Moustafa paid $400 on "2020-08-01" and received $200 on "2020-08-03", credit (100 -400 +200) = -$100 Jonathan received $500 on "2020-08-02" and paid $200 on "2020-08-08", credit (200 +500 -200) = $500 Winston received $400 on "2020-08-01" and paid $500 on "2020-08-03", credit (10000 +400 -500) = $9990 Luis didn't received any transfer, credit = $800 Solution sql SELECT Users.user_id AS user_id , Users.user_name AS user_name , credit+IFNULL(SUM(trans),0) AS credit , CASE WHEN credit+IFNULL(SUM(trans),0)>0 THEN 'No' ELSE 'Yes' END AS credit_limit_breached FROM( SELECT paid_by AS user_id, -amount AS trans FROM Transaction UNION ALL SELECT paid_to AS user_id, amount AS trans FROM Transaction ) t RIGHT JOIN users ON t.user_id=users.user_id GROUP BY user_id

---

#### Unique Orders and Customers Per Month | Easy | üîí LeetCode

Table: Orders +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | order_id      | int     | | order_date    | date    | | customer_id   | int     | | invoice       | int     | +---------------+---------+ order_id is the primary key for this table. This table contains information about the orders made by customer_id. Write an SQL query to find the number of unique orders and the number of unique users with invoices > $20 for each different month. Return the result table sorted in any order. The query result format is in the following example: Orders +----------+------------+-------------+------------+ | order_id | order_date | customer_id | invoice    | +----------+------------+-------------+------------+ | 1        | 2020-09-15 | 1           | 30         | | 2        | 2020-09-17 | 2           | 90         | | 3        | 2020-10-06 | 3           | 20         | | 4        | 2020-10-20 | 3           | 21         | | 5        | 2020-11-10 | 1           | 10         | | 6        | 2020-11-21 | 2           | 15         | | 7        | 2020-12-01 | 4           | 55         | | 8        | 2020-12-03 | 4           | 77         | | 9        | 2021-01-07 | 3           | 31         | | 10       | 2021-01-15 | 2           | 20         | +----------+------------+-------------+------------+ Result table: +---------+-------------+----------------+ | month   | order_count | customer_count | +---------+-------------+----------------+ | 2020-09 | 2           | 2              | | 2020-10 | 1           | 1              | | 2020-12 | 2           | 1              | | 2021-01 | 1           | 1              | +---------+-------------+----------------+ In September 2020 we have two orders from 2 different customers with invoices > $20. In October 2020 we have two orders from 1 customer, and only one of the two orders has invoice > $20. In November 2020 we have two orders from 2 different customers but invoices < $20, so we don't include that month. In December 2020 we have two orders from 1 customer both with invoices > $20. In January 2021 we have two orders from 2 different customers, but only one of them with invoice > $20. Solution sql #Solution 1: SELECT DATE_FORMAT(order_date, '%Y-%m') AS month, COUNT(DISTINCT order_id) AS order_count, COUNT(DISTINCT customer_id) AS customer_count FROM Orders WHERE invoice > 20 GROUP BY YEAR(order_date), MONTH(order_date); #Solution 2: SELECT LEFT(order_date, 7) AS month, COUNT(DISTINCT order_id) AS order_count, COUNT(DISTINCT customer_id) AS customer_count FROM orders WHERE invoice > 20 GROUP BY month

---

#### Warehouse Manager | Easy | üîí LeetCode

Table: Warehouse +--------------+---------+ | Column Name  | Type    | +--------------+---------+ | name         | varchar | | product_id   | int     | | units        | int     | +--------------+---------+ (name, product_id) is the primary key for this table. Each row of this table contains the information of the products in each warehouse. Table: Products +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | product_id    | int     | | product_name  | varchar | | Width         | int     | | Length        | int     | | Height        | int     | +---------------+---------+ product_id is the primary key for this table. Each row of this table contains the information about the product dimensions (Width, Lenght and Height) in feets of each product. Write an SQL query to report, How much cubic feet of volume does the inventory occupy in each warehouse. warehouse_name volume Return the result table in any order. The query result format is in the following example. Warehouse table: +------------+--------------+-------------+ | name       | product_id   | units       | +------------+--------------+-------------+ | LCHouse1   | 1            | 1           | | LCHouse1   | 2            | 10          | | LCHouse1   | 3            | 5           | | LCHouse2   | 1            | 2           | | LCHouse2   | 2            | 2           | | LCHouse3   | 4            | 1           | +------------+--------------+-------------+ Products table: +------------+--------------+------------+----------+-----------+ | product_id | product_name | Width      | Length   | Height    | +------------+--------------+------------+----------+-----------+ | 1          | LC-TV        | 5          | 50       | 40        | | 2          | LC-KeyChain  | 5          | 5        | 5         | | 3          | LC-Phone     | 2          | 10       | 10        | | 4          | LC-T-Shirt   | 4          | 10       | 20        | +------------+--------------+------------+----------+-----------+ Result table: +----------------+------------+ | warehouse_name | volume     | +----------------+------------+ | LCHouse1       | 12250      | | LCHouse2       | 20250      | | LCHouse3       | 800        | +----------------+------------+ Volume of product_id = 1 (LC-TV), 5x50x40 = 10000 Volume of product_id = 2 (LC-KeyChain), 5x5x5 = 125 Volume of product_id = 3 (LC-Phone), 2x10x10 = 200 Volume of product_id = 4 (LC-T-Shirt), 4x10x20 = 800 LCHouse1: 1 unit of LC-TV + 10 units of LC-KeyChain + 5 units of LC-Phone. Total volume: 1*10000 + 10*125  + 5*200 = 12250 cubic feet LCHouse2: 2 units of LC-TV + 2 units of LC-KeyChain. Total volume: 2*10000 + 2*125 = 20250 cubic feet LCHouse3: 1 unit of LC-T-Shirt. Total volume: 1*800 = 800 cubic feet. Solution sql SELECT a.name AS warehouse_name, SUM(a.units * b.Width * b.Length * b.Height) AS volume FROM Warehouse AS a LEFT JOIN Products AS b ON a.product_id = b.product_id GROUP BY a.name;

---

#### Customer Who Visited but Did Not Make Any Transactions | Easy | üîí LeetCode

Table: Visits +-------------+---------+ | Column Name | Type    | +-------------+---------+ | visit_id    | int     | | customer_id | int     | +-------------+---------+ visit_id is the primary key for this table. This table contains information about the customers who visited the mall. Table: Transactions +----------------+---------+ | Column Name    | Type    | +----------------+---------+ | transaction_id | int     | | visit_id       | int     | | amount         | int     | +----------------+---------+ transaction_id is the primary key for this table. This table contains information about the customers who visited the mall. Write an SQL query to find the IDs of the users who visited without making any transactions and the number of times they made these types of visits. Return the result table sorted in any orders. The query result format is in the following example: Visits +----------+-------------+ | visit_id | customer_id | +----------+-------------+ | 1        | 23          | | 2        | 9           | | 4        | 30          | | 5        | 54          | | 6        | 96          | | 7        | 54          | | 8        | 54          | +----------+-------------+ Transactions +----------------+----------+--------+ | transaction_id | visit_id | amount | +----------------+----------+--------+ | 2              | 5        | 310    | | 3              | 5        | 300    | | 9              | 5        | 200    | | 12             | 1        | 910    | | 13             | 2        | 970    | +----------------+----------+--------+ Result table: +-------------+----------------+ | customer_id | count_no_trans | +-------------+----------------+ | 54          | 2              | | 30          | 1              | | 96          | 1              | +-------------+----------------+ Customer with id = 23 visited the mall once and made one transaction during the visit with id = 12. Customer with id = 9 visited the mall once and made one transaction during the visit with id = 13. Customer with id = 30 visited the mall once and did not make any transactions. Customer with id = 54 visited the mall three times. During 2 visits they did not make any transactions, and during one visit they made 3 transactions. Customer with id = 96 visited the mall once and did not make any transactions. As we can see, users with IDs 30 and 96 visited the mall one time without making any transactions. Also user 54 visited the mall twice and did not make any transactions. Solution sql #Solution 1: SELECT a.customer_id, COUNT(a.visit_id) AS count_no_trans FROM Visits AS a LEFT JOIN Transactions AS b ON a.visit_id = b.visit_id WHERE b.transaction_id IS NULL GROUP BY a.customer_id; #Solution 2: SELECT customer_id, count(visit_id) AS count_no_trans FROM Visits WHERE visit_id NOT IN (SELECT visit_id FROM Transactions GROUP BY visit_id) GROUP BY customer_id

---

#### Bank Account Summary II | Easy | üîí LeetCode

Table: Users +--------------+---------+ | Column Name  | Type    | +--------------+---------+ | account      | int     | | name         | varchar | +--------------+---------+ account is the primary key for this table. Each row of this table contains the account number of each user in the bank. Table: Transactions +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | trans_id      | int     | | account       | int     | | amount        | int     | | transacted_on | date    | +---------------+---------+ trans_id is the primary key for this table. Each row of this table contains all changes made to all accounts. amount is positive if the user received money and negative if they transferred money. All accounts start with a balance 0. Write an SQL query to report the name and balance of users with a balance higher than 10000. The balance of an account is equal to the sum of the amounts of all transactions involving that account. Return the result table in any order. The query result format is in the following example. Users table: +------------+--------------+ | account    | name         | +------------+--------------+ | 900001     | Alice        | | 900002     | Bob          | | 900003     | Charlie      | +------------+--------------+ Transactions table: +------------+------------+------------+---------------+ | trans_id   | account    | amount     | transacted_on | +------------+------------+------------+---------------+ | 1          | 900001     | 7000       |  2020-08-01   | | 2          | 900001     | 7000       |  2020-09-01   | | 3          | 900001     | -3000      |  2020-09-02   | | 4          | 900002     | 1000       |  2020-09-12   | | 5          | 900003     | 6000       |  2020-08-07   | | 6          | 900003     | 6000       |  2020-09-07   | | 7          | 900003     | -4000      |  2020-09-11   | +------------+------------+------------+---------------+ Result table: +------------+------------+ | name       | balance    | +------------+------------+ | Alice      | 11000      | +------------+------------+ Alice's balance is (7000 + 7000 - 3000) = 11000. Bob's balance is 1000. Charlie's balance is (6000 + 6000 - 4000) = 8000. Solution sql #Solution 1: SELECT u.name AS NAME,SUM(t.amount) AS BALANCE FROM Transactions t LEFT JOIN Users u ON u.account = t.account GROUP BY u.account HAVING SUM(t.amount)>10000; #Solution 2: WITH tmp AS( SELECT t.account, u.name, SUM(amount) AS balance FROM Transactions t LEFT JOIN Users u ON t.account = u.account GROUP BY account ) SELECT name, balance FROM tmp WHERE balance > 10000

---

#### The Most Frequently Ordered Products for Each Customer | Medium | üîí LeetCode

Table: Customers +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | customer_id   | int     | | name          | varchar | +---------------+---------+ customer_id is the primary key for this table. This table contains information about the customers. Table: Orders +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | order_id      | int     | | order_date    | date    | | customer_id   | int     | | product_id    | int     | +---------------+---------+ order_id is the primary key for this table. This table contains information about the orders made by customer_id. No customer will order the same product more than once in a single day. Table: Products +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | product_id    | int     | | product_name  | varchar | | price         | int     | +---------------+---------+ product_id is the primary key for this table. This table contains information about the products. Write an SQL query to find the most frequently ordered product(s) for each customer. The result table should have the product_id and product_name for each customer_id who ordered at least one order. Return the result table in any order. The query result format is in the following example: Customers +-------------+-------+ | customer_id | name  | +-------------+-------+ | 1           | Alice | | 2           | Bob   | | 3           | Tom   | | 4           | Jerry | | 5           | John  | +-------------+-------+ Orders +----------+------------+-------------+------------+ | order_id | order_date | customer_id | product_id | +----------+------------+-------------+------------+ | 1        | 2020-07-31 | 1           | 1          | | 2        | 2020-07-30 | 2           | 2          | | 3        | 2020-08-29 | 3           | 3          | | 4        | 2020-07-29 | 4           | 1          | | 5        | 2020-06-10 | 1           | 2          | | 6        | 2020-08-01 | 2           | 1          | | 7        | 2020-08-01 | 3           | 3          | | 8        | 2020-08-03 | 1           | 2          | | 9        | 2020-08-07 | 2           | 3          | | 10       | 2020-07-15 | 1           | 2          | +----------+------------+-------------+------------+ Products +------------+--------------+-------+ | product_id | product_name | price | +------------+--------------+-------+ | 1          | keyboard     | 120   | | 2          | mouse        | 80    | | 3          | screen       | 600   | | 4          | hard disk    | 450   | +------------+--------------+-------+ Result table: +-------------+------------+--------------+ | customer_id | product_id | product_name | +-------------+------------+--------------+ | 1           | 2          | mouse        | | 2           | 1          | keyboard     | | 2           | 2          | mouse        | | 2           | 3          | screen       | | 3           | 3          | screen       | | 4           | 1          | keyboard     | +-------------+------------+--------------+ Alice (customer 1) ordered the mouse three times and the keyboard one time, so the mouse is the most frquently ordered product for them. Bob (customer 2) ordered the keyboard, the mouse, and the screen one time, so those are the most frquently ordered products for them. Tom (customer 3) only ordered the screen (two times), so that is the most frquently ordered product for them. Jerry (customer 4) only ordered the keyboard (one time), so that is the most frquently ordered product for them. John (customer 5) did not order anything, so we do not include them in the result table. Solution sql #Solution 1: SELECT customer_id, Products.product_id, Products.product_name FROM (SELECT customer_id, product_id, order_count, RANK() OVER(PARTITION BY customer_id ORDER BY order_count DESC) r From (SELECT customer_id, product_id, COUNT(DISTINCT order_id) AS order_count FROM Orders GROUP BY customer_id, product_id) order_counts) order_counts_ranked JOIN Products ON order_counts_ranked.product_id = Products.product_id WHERE r = 1; #solution- 2: SELECT customer_id, T.product_id, product_name FROM( SELECT customer_id, product_id, RANK() OVER( PARTITION BY customer_id ORDER BY COUNT(*) DESC ) AS RK FROM Orders o GROUP BY customer_id, product_id ) T LEFT JOIN Products p on p.product_id = t.product_id WHERE RK=1 #Solution-3: WITH tmp AS ( SELECT a.customer_id, b.product_id, c.product_name, COUNT(b.order_id) OVER(PARTITION BY a.customer_id, b.product_id) AS freq FROM Customers AS a JOIN Orders AS b ON a.customer_id = b.customer_id JOIN Products AS c ON b.product_id = c.product_id ), tmp1 AS ( SELECT customer_id, product_id, product_name, freq, DENSE_RANK() OVER(PARTITION BY customer_id ORDER BY freq DESC) AS rnk FROM tmp ) SELECT DISTINCT customer_id, product_id, product_name FROM tmp1 WHERE rnk = 1;

---

#### Sellers With No Sales | Easy | üîí LeetCode

Table: Customer +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | customer_id   | int     | | customer_name | varchar | +---------------+---------+ customer_id is the primary key for this table. Each row of this table contains the information of each customer in the WebStore. Table: Orders +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | order_id      | int     | | sale_date     | date    | | order_cost    | int     | | customer_id   | int     | | seller_id     | int     | +---------------+---------+ order_id is the primary key for this table. Each row of this table contains all orders made in the webstore. sale_date is the date when the transaction was made between the customer (customer_id) and the seller (seller_id). Table: Seller +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | seller_id     | int     | | seller_name   | varchar | +---------------+---------+ seller_id is the primary key for this table. Each row of this table contains the information of each seller. Write an SQL query to report the names of all sellers who did not make any sales in 2020. Return the result table ordered by seller_name in ascending order. The query result format is in the following example. Customer table: +--------------+---------------+ | customer_id  | customer_name | +--------------+---------------+ | 101          | Alice         | | 102          | Bob           | | 103          | Charlie       | +--------------+---------------+ Orders table: +-------------+------------+--------------+-------------+-------------+ | order_id    | sale_date  | order_cost   | customer_id | seller_id   | +-------------+------------+--------------+-------------+-------------+ | 1           | 2020-03-01 | 1500         | 101         | 1           | | 2           | 2020-05-25 | 2400         | 102         | 2           | | 3           | 2019-05-25 | 800          | 101         | 3           | | 4           | 2020-09-13 | 1000         | 103         | 2           | | 5           | 2019-02-11 | 700          | 101         | 2           | +-------------+------------+--------------+-------------+-------------+ Seller table: +-------------+-------------+ | seller_id   | seller_name | +-------------+-------------+ | 1           | Daniel      | | 2           | Elizabeth   | | 3           | Frank       | +-------------+-------------+ Result table: +-------------+ | seller_name | +-------------+ | Frank       | +-------------+ Daniel made 1 sale in March 2020. Elizabeth made 2 sales in 2020 and 1 sale in 2019. Frank made 1 sale in 2019 but no sales in 2020. Solution sql SELECT seller_name FROM Seller WHERE seller_id NOT IN ( SELECT DISTINCT seller_id FROM Orders WHERE YEAR(sale_date)='2020' ) ORDER BY seller_name;

---

#### Find the Missing IDs | Medium | üîí LeetCode

Table: Customers +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | customer_id   | int     | | customer_name | varchar | +---------------+---------+ customer_id is the primary key for this table. Each row of this table contains the name and the id customer. Write an SQL query to find the missing customer IDs. The missing IDs are ones that are not in the Customers table but are in the range between 1 and the maximum customer_id present in the table. Notice that the maximum customer_id will not exceed 100. Return the result table ordered by ids in ascending order. The query result format is in the following example. Customer table: +-------------+---------------+ | customer_id | customer_name | +-------------+---------------+ | 1           | Alice         | | 4           | Bob           | | 5           | Charlie       | +-------------+---------------+ Result table: +-----+ | ids | +-----+ | 2   | | 3   | +-----+ The maximum customer_id present in the table is 5, so in the range [1,5], IDs 2 and 3 are missing from the table. Solution sql WITH RECURSIVE CTE AS( SELECT 1 AS 'id', MAX(c.customer_id) AS 'Max_Id' FROM Customers c UNION ALL SELECT id+1, Max_Id FROM CTE WHERE id < Max_id ) SELECT id AS 'ids' FROM CTE c WHERE c.id NOT IN (SELECT customer_id FROM Customers) ORDER BY 1 ASC

---

#### All Valid Triplets That Can Represent a Country | Easy | üîí LeetCode

Table: SchoolA +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | student_id    | int     | | student_name  | varchar | +---------------+---------+ student_id is the primary key for this table. Each row of this table contains the name and the id of a student in school A. All student_name are distinct. Table: SchoolB +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | student_id    | int     | | student_name  | varchar | +---------------+---------+ student_id is the primary key for this table. Each row of this table contains the name and the id of a student in school B. All student_name are distinct. Table: SchoolC +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | student_id    | int     | | student_name  | varchar | +---------------+---------+ student_id is the primary key for this table. Each row of this table contains the name and the id of a student in school C. All student_name are distinct. There is a country with three schools, where each student is enrolled in exactly one school. The country is joining a competition and wants to select one student from each school to represent the country such that: member_A is selected from SchoolA, member_B is selected from SchoolB, member_C is selected from SchoolC, and The selected students' names and IDs are pairwise distinct (i.e. no two students share the same name, and no two students share the same ID). Write an SQL query to find all the possible triplets representing the country under the given constraints. Return the result table in any order. The query result format is in the following example. SchoolA table: +------------+--------------+ | student_id | student_name | +------------+--------------+ | 1          | Alice        | | 2          | Bob          | +------------+--------------+ SchoolB table: +------------+--------------+ | student_id | student_name | +------------+--------------+ | 3          | Tom          | +------------+--------------+ SchoolC table: +------------+--------------+ | student_id | student_name | +------------+--------------+ | 3          | Tom          | | 2          | Jerry        | | 10         | Alice        | +------------+--------------+ Result table: +----------+----------+----------+ | member_A | member_B | member_C | +----------+----------+----------+ | Alice    | Tom      | Jerry    | | Bob      | Tom      | Alice    | +----------+----------+----------+ Let us see all the possible triplets. - (Alice, Tom, Tom) --> Rejected because member_B and member_C have the same name and the same ID. - (Alice, Tom, Jerry) --> Valid triplet. - (Alice, Tom, Alice) --> Rejected because member_A and member_C have the same name. - (Bob, Tom, Tom) --> Rejected because member_B and member_C have the same name and the same ID. - (Bob, Tom, Jerry) --> Rejected because member_A and member_C have the same ID. - (Bob, Tom, Alice) --> Valid triplet. Solution sql SELECT a.student_name AS 'member_A', b.student_name AS 'member_B', c.student_name AS 'member_C' FROM SchoolA AS a JOIN SchoolB AS b ON a.student_id <> b.student_id AND a.student_name <> b.student_name JOIN SchoolC AS c ON a.student_id <> c.student_id AND b.student_id <> c.student_id AND a.student_name <> c.student_name AND b.student_name <> c.student_name;

---

#### Percentage of Users Attended a Contest | Easy | üîí LeetCode

Table: Users +-------------+---------+ | Column Name | Type    | +-------------+---------+ | user_id     | int     | | user_name   | varchar | +-------------+---------+ user_id is the primary key for this table. Each row of this table contains the name and the id of a user. Table: Register +-------------+---------+ | Column Name | Type    | +-------------+---------+ | contest_id  | int     | | user_id     | int     | +-------------+---------+ (contest_id, user_id) is the primary key for this table. Each row of this table contains the id of a user and the contest they registered into. Write an SQL query to find the percentage of the users registered in each contest rounded to two decimals. Return the result table ordered by percentage in descending order. In case of a tie, order it by contest_id in ascending order. The query result format is in the following example. Users table: +---------+-----------+ | user_id | user_name | +---------+-----------+ | 6       | Alice     | | 2       | Bob       | | 7       | Alex      | +---------+-----------+ Register table: +------------+---------+ | contest_id | user_id | +------------+---------+ | 215        | 6       | | 209        | 2       | | 208        | 2       | | 210        | 6       | | 208        | 6       | | 209        | 7       | | 209        | 6       | | 215        | 7       | | 208        | 7       | | 210        | 2       | | 207        | 2       | | 210        | 7       | +------------+---------+ Result table: +------------+------------+ | contest_id | percentage | +------------+------------+ | 208        | 100.0      | | 209        | 100.0      | | 210        | 100.0      | | 215        | 66.67      | | 207        | 33.33      | +------------+------------+ All the users registered in contests 208, 209, and 210. The percentage is 100% and we sort them in the answer table in ascending order. Alice and Alex registered in contest 215 and the percentage is ((2/3) * 100) = 66.67% Bob registered in contest 207 and the percentage is ((1/3) * 100) = 33.33% Solution sql SELECT contest_id, ROUND(COUNT(user_id)*100.00/(SELECT COUNT(*) FROM users),2) as percentage FROM register GROUP BY contest_id ORDER BY percentage desc, contest_id

---

#### Hopper Company Queries I | Hard | üîí LeetCode

Table: Drivers +-------------+---------+ | Column Name | Type    | +-------------+---------+ | driver_id   | int     | | join_date   | date    | +-------------+---------+ driver_id is the primary key for this table. Each row of this table contains the driver's ID and the date they joined the Hopper company. Table: Rides +--------------+---------+ | Column Name  | Type    | +--------------+---------+ | ride_id      | int     | | user_id      | int     | | requested_at | date    | +--------------+---------+ ride_id is the primary key for this table. Each row of this table contains the ID of a ride, the user's ID that requested it, and the day they requested it. There may be some ride requests in this table that were not accepted. Table: AcceptedRides +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | ride_id       | int     | | driver_id     | int     | | ride_distance | int     | | ride_duration | int     | +---------------+---------+ ride_id is the primary key for this table. Each row of this table contains some information about an accepted ride. It is guaranteed that each accepted ride exists in the Rides table. Write an SQL query to report the following statistics for each month of 2020: The number of drivers currently with the Hopper company by the end of the month (active_drivers). The number of accepted rides in that month (accepted_rides). Return the result table ordered by month in ascending order, where month is the month's number (January is 1, February is 2, etc.). The query result format is in the following example. Drivers table: +-----------+------------+ | driver_id | join_date  | +-----------+------------+ | 10        | 2019-12-10 | | 8         | 2020-1-13  | | 5         | 2020-2-16  | | 7         | 2020-3-8   | | 4         | 2020-5-17  | | 1         | 2020-10-24 | | 6         | 2021-1-5   | +-----------+------------+ Rides table: +---------+---------+--------------+ | ride_id | user_id | requested_at | +---------+---------+--------------+ | 6       | 75      | 2019-12-9    | | 1       | 54      | 2020-2-9     | | 10      | 63      | 2020-3-4     | | 19      | 39      | 2020-4-6     | | 3       | 41      | 2020-6-3     | | 13      | 52      | 2020-6-22    | | 7       | 69      | 2020-7-16    | | 17      | 70      | 2020-8-25    | | 20      | 81      | 2020-11-2    | | 5       | 57      | 2020-11-9    | | 2       | 42      | 2020-12-9    | | 11      | 68      | 2021-1-11    | | 15      | 32      | 2021-1-17    | | 12      | 11      | 2021-1-19    | | 14      | 18      | 2021-1-27    | +---------+---------+--------------+ AcceptedRides table: +---------+-----------+---------------+---------------+ | ride_id | driver_id | ride_distance | ride_duration | +---------+-----------+---------------+---------------+ | 10      | 10        | 63            | 38            | | 13      | 10        | 73            | 96            | | 7       | 8         | 100           | 28            | | 17      | 7         | 119           | 68            | | 20      | 1         | 121           | 92            | | 5       | 7         | 42            | 101           | | 2       | 4         | 6             | 38            | | 11      | 8         | 37            | 43            | | 15      | 8         | 108           | 82            | | 12      | 8         | 38            | 34            | | 14      | 1         | 90            | 74            | +---------+-----------+---------------+---------------+ Result table: +-------+----------------+----------------+ | month | active_drivers | accepted_rides | +-------+----------------+----------------+ | 1     | 2              | 0              | | 2     | 3              | 0              | | 3     | 4              | 1              | | 4     | 4              | 0              | | 5     | 5              | 0              | | 6     | 5              | 1              | | 7     | 5              | 1              | | 8     | 5              | 1              | | 9     | 5              | 0              | | 10    | 6              | 0              | | 11    | 6              | 2              | | 12    | 6              | 1              | +-------+----------------+----------------+ By the end of January --> two active drivers (10, 8) and no accepted rides. By the end of February --> three active drivers (10, 8, 5) and no accepted rides. By the end of March --> four active drivers (10, 8, 5, 7) and one accepted ride (10). By the end of April --> four active drivers (10, 8, 5, 7) and no accepted rides. By the end of May --> five active drivers (10, 8, 5, 7, 4) and no accepted rides. By the end of June --> five active drivers (10, 8, 5, 7, 4) and one accepted ride (13). By the end of July --> five active drivers (10, 8, 5, 7, 4) and one accepted ride (7). By the end of August --> five active drivers (10, 8, 5, 7, 4) and one accepted ride (17). By the end of Septemeber --> five active drivers (10, 8, 5, 7, 4) and no accepted rides. By the end of October --> six active drivers (10, 8, 5, 7, 4, 1) and no accepted rides. By the end of November --> six active drivers (10, 8, 5, 7, 4, 1) and two accepted rides (20, 5). By the end of December --> six active drivers (10, 8, 5, 7, 4, 1) and one accepted ride (2). Solution sql SELECT t.month, COUNT(DISTINCT driver_id) active_drivers, COUNT(DISTINCT rides.ride_id) accepted_rides FROM ((SELECT 1 AS month) UNION (SELECT 2 AS month) UNION (SELECT 3 AS month) UNION (SELECT 4 AS month) UNION (SELECT 5 AS month) UNION (SELECT 6 AS month) UNION (SELECT 7 AS month) UNION (SELECT 8 AS month) UNION (SELECT 9 AS month) UNION (SELECT 10 AS month) UNION (SELECT 11 AS month) UNION (SELECT 12 AS month)) t LEFT JOIN (SELECT driver_id, (CASE WHEN year(join_date) = 2019 THEN '1' ELSE month(join_date) END) `month` FROM Drivers WHERE year(join_date) <= 2020) d ON d.month <= t.month LEFT JOIN (SELECT month(requested_at) AS `month`, a.ride_id FROM AcceptedRides a JOIN Rides r ON r.ride_id = a.ride_id WHERE year(requested_at) = 2020) rides ON t.month = rides.month GROUP BY t.month ORDER BY t.month

---

#### Hopper Company Queries II | Hard | üîí LeetCode

Table: Drivers +-------------+---------+ | Column Name | Type    | +-------------+---------+ | driver_id   | int     | | join_date   | date    | +-------------+---------+ driver_id is the primary key for this table. Each row of this table contains the driver's ID and the date they joined the Hopper company. Table: Rides +--------------+---------+ | Column Name  | Type    | +--------------+---------+ | ride_id      | int     | | user_id      | int     | | requested_at | date    | +--------------+---------+ ride_id is the primary key for this table. Each row of this table contains the ID of a ride, the user's ID that requested it, and the day they requested it. There may be some ride requests in this table that were not accepted. Table: AcceptedRides +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | ride_id       | int     | | driver_id     | int     | | ride_distance | int     | | ride_duration | int     | +---------------+---------+ ride_id is the primary key for this table. Each row of this table contains some information about an accepted ride. It is guaranteed that each accepted ride exists in the Rides table. Write an SQL query to report the percentage of working drivers (working_percentage) for each month of 2020 where: Note that if the number of available drivers during a month is zero, we consider the working_percentage to be 0. Return the result table ordered by month in ascending order, where month is the month's number (January is 1, February is 2, etc.). Round working_percentage to the nearest 2 decimal places. The query result format is in the following example. Drivers table: +-----------+------------+ | driver_id | join_date  | +-----------+------------+ | 10        | 2019-12-10 | | 8         | 2020-1-13  | | 5         | 2020-2-16  | | 7         | 2020-3-8   | | 4         | 2020-5-17  | | 1         | 2020-10-24 | | 6         | 2021-1-5   | +-----------+------------+ Rides table: +---------+---------+--------------+ | ride_id | user_id | requested_at | +---------+---------+--------------+ | 6       | 75      | 2019-12-9    | | 1       | 54      | 2020-2-9     | | 10      | 63      | 2020-3-4     | | 19      | 39      | 2020-4-6     | | 3       | 41      | 2020-6-3     | | 13      | 52      | 2020-6-22    | | 7       | 69      | 2020-7-16    | | 17      | 70      | 2020-8-25    | | 20      | 81      | 2020-11-2    | | 5       | 57      | 2020-11-9    | | 2       | 42      | 2020-12-9    | | 11      | 68      | 2021-1-11    | | 15      | 32      | 2021-1-17    | | 12      | 11      | 2021-1-19    | | 14      | 18      | 2021-1-27    | +---------+---------+--------------+ AcceptedRides table: +---------+-----------+---------------+---------------+ | ride_id | driver_id | ride_distance | ride_duration | +---------+-----------+---------------+---------------+ | 10      | 10        | 63            | 38            | | 13      | 10        | 73            | 96            | | 7       | 8         | 100           | 28            | | 17      | 7         | 119           | 68            | | 20      | 1         | 121           | 92            | | 5       | 7         | 42            | 101           | | 2       | 4         | 6             | 38            | | 11      | 8         | 37            | 43            | | 15      | 8         | 108           | 82            | | 12      | 8         | 38            | 34            | | 14      | 1         | 90            | 74            | +---------+-----------+---------------+---------------+ Result table: +-------+--------------------+ | month | working_percentage | +-------+--------------------+ | 1     | 0.00               | | 2     | 0.00               | | 3     | 25.00              | | 4     | 0.00               | | 5     | 0.00               | | 6     | 20.00              | | 7     | 20.00              | | 8     | 20.00              | | 9     | 0.00               | | 10    | 0.00               | | 11    | 33.33              | | 12    | 16.67              | +-------+--------------------+ By the end of January --> two active drivers (10, 8) and no accepted rides. The percentage is 0%. By the end of February --> three active drivers (10, 8, 5) and no accepted rides. The percentage is 0%. By the end of March --> four active drivers (10, 8, 5, 7) and one accepted ride by driver (10). The percentage is (1 / 4) * 100 = 25%. By the end of April --> four active drivers (10, 8, 5, 7) and no accepted rides. The percentage is 0%. By the end of May --> five active drivers (10, 8, 5, 7, 4) and no accepted rides. The percentage is 0%. By the end of June --> five active drivers (10, 8, 5, 7, 4) and one accepted ride by driver (10). The percentage is (1 / 5) * 100 = 20%. By the end of July --> five active drivers (10, 8, 5, 7, 4) and one accepted ride by driver (8). The percentage is (1 / 5) * 100 = 20%. By the end of August --> five active drivers (10, 8, 5, 7, 4) and one accepted ride by driver (7). The percentage is (1 / 5) * 100 = 20%. By the end of Septemeber --> five active drivers (10, 8, 5, 7, 4) and no accepted rides. The percentage is 0%. By the end of October --> six active drivers (10, 8, 5, 7, 4, 1) and no accepted rides. The percentage is 0%. By the end of November --> six active drivers (10, 8, 5, 7, 4, 1) and two accepted rides by two different drivers (1, 7). The percentage is (2 / 6) * 100 = 33.33%. By the end of December --> six active drivers (10, 8, 5, 7, 4, 1) and one accepted ride by driver (4). The percentage is (1 / 6) * 100 = 16.67%. Solution sql SELECT months_drivers.month, ROUND(COALESCE(100 * COALESCE(total_active_drivers, 0) / total_drivers, 0), 2) AS working_percentage FROM ( SELECT month, COUNT(driver_id) AS total_drivers FROM Drivers AS a RIGHT JOIN ( SELECT "2020-1-31" AS day, 1 AS month UNION SELECT "2020-2-29", 2 UNION SELECT "2020-3-31", 3 UNION SELECT "2020-4-30", 4 UNION SELECT "2020-5-31", 5 UNION SELECT "2020-6-30", 6 UNION SELECT "2020-7-31", 7 UNION SELECT "2020-8-31", 8 UNION SELECT "2020-9-30", 9 UNION SELECT "2020-10-31", 10 UNION SELECT "2020-11-30", 11 UNION SELECT "2020-12-31", 12 ) AS months ON join_date <= day GROUP BY month ) months_drivers LEFT JOIN ( SELECT month, COUNT(DISTINCT b.driver_id) AS total_active_drivers FROM ( SELECT ride_id, CAST(substr(requested_at, 6, 2) AS unsigned) AS month FROM Rides WHERE substr(requested_at, 1, 4) = "2020" ) month_rides JOIN AcceptedRides AS b ON month_rides.ride_id = b.ride_id GROUP BY month ) months_active_drivers ON months_drivers.month = months_active_drivers.month;

---

#### Hopper Company Queries III | Hard | üîí LeetCode

Table: Drivers +-------------+---------+ | Column Name | Type    | +-------------+---------+ | driver_id   | int     | | join_date   | date    | +-------------+---------+ driver_id is the primary key for this table. Each row of this table contains the driver's ID and the date they joined the Hopper company. Table: Rides +--------------+---------+ | Column Name  | Type    | +--------------+---------+ | ride_id      | int     | | user_id      | int     | | requested_at | date    | +--------------+---------+ ride_id is the primary key for this table. Each row of this table contains the ID of a ride, the user's ID that requested it, and the day they requested it. There may be some ride requests in this table that were not accepted. Table: AcceptedRides +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | ride_id       | int     | | driver_id     | int     | | ride_distance | int     | | ride_duration | int     | +---------------+---------+ ride_id is the primary key for this table. Each row of this table contains some information about an accepted ride. It is guaranteed that each accepted ride exists in the Rides table. Write an SQL query to compute the average_ride_distance and average_ride_duration of every 3-month window starting from January - March 2020 to October - December 2020. Round average_ride_distance and average_ride_duration to the nearest two decimal places. The average_ride_distance is calculated by summing up the total ride_distance values from the three months and dividing it by 3. The average_ride_duration is calculated in a similar way. Return the result table ordered by month in ascending order, where month is the starting month's number (January is 1, February is 2, etc.). The query result format is in the following example. Drivers table: +-----------+------------+ | driver_id | join_date  | +-----------+------------+ | 10        | 2019-12-10 | | 8         | 2020-1-13  | | 5         | 2020-2-16  | | 7         | 2020-3-8   | | 4         | 2020-5-17  | | 1         | 2020-10-24 | | 6         | 2021-1-5   | +-----------+------------+ Rides table: +---------+---------+--------------+ | ride_id | user_id | requested_at | +---------+---------+--------------+ | 6       | 75      | 2019-12-9    | | 1       | 54      | 2020-2-9     | | 10      | 63      | 2020-3-4     | | 19      | 39      | 2020-4-6     | | 3       | 41      | 2020-6-3     | | 13      | 52      | 2020-6-22    | | 7       | 69      | 2020-7-16    | | 17      | 70      | 2020-8-25    | | 20      | 81      | 2020-11-2    | | 5       | 57      | 2020-11-9    | | 2       | 42      | 2020-12-9    | | 11      | 68      | 2021-1-11    | | 15      | 32      | 2021-1-17    | | 12      | 11      | 2021-1-19    | | 14      | 18      | 2021-1-27    | +---------+---------+--------------+ AcceptedRides table: +---------+-----------+---------------+---------------+ | ride_id | driver_id | ride_distance | ride_duration | +---------+-----------+---------------+---------------+ | 10      | 10        | 63            | 38            | | 13      | 10        | 73            | 96            | | 7       | 8         | 100           | 28            | | 17      | 7         | 119           | 68            | | 20      | 1         | 121           | 92            | | 5       | 7         | 42            | 101           | | 2       | 4         | 6             | 38            | | 11      | 8         | 37            | 43            | | 15      | 8         | 108           | 82            | | 12      | 8         | 38            | 34            | | 14      | 1         | 90            | 74            | +---------+-----------+---------------+---------------+ Result table: +-------+-----------------------+-----------------------+ | month | average_ride_distance | average_ride_duration | +-------+-----------------------+-----------------------+ | 1     | 21.00                 | 12.67                 | | 2     | 21.00                 | 12.67                 | | 3     | 21.00                 | 12.67                 | | 4     | 24.33                 | 32.00                 | | 5     | 57.67                 | 41.33                 | | 6     | 97.33                 | 64.00                 | | 7     | 73.00                 | 32.00                 | | 8     | 39.67                 | 22.67                 | | 9     | 54.33                 | 64.33                 | | 10    | 56.33                 | 77.00                 | +-------+-----------------------+-----------------------+ By the end of January --> average_ride_distance = (0+0+63)/3=21, average_ride_duration = (0+0+38)/3=12.67 By the end of February --> average_ride_distance = (0+63+0)/3=21, average_ride_duration = (0+38+0)/3=12.67 By the end of March --> average_ride_distance = (63+0+0)/3=21, average_ride_duration = (38+0+0)/3=12.67 By the end of April --> average_ride_distance = (0+0+73)/3=24.33, average_ride_duration = (0+0+96)/3=32.00 By the end of May --> average_ride_distance = (0+73+100)/3=57.67, average_ride_duration = (0+96+28)/3=41.33 By the end of June --> average_ride_distance = (73+100+119)/3=97.33, average_ride_duration = (96+28+68)/3=64.00 By the end of July --> average_ride_distance = (100+119+0)/3=73.00, average_ride_duration = (28+68+0)/3=32.00 By the end of August --> average_ride_distance = (119+0+0)/3=39.67, average_ride_duration = (68+0+0)/3=22.67 By the end of Septemeber --> average_ride_distance = (0+0+163)/3=54.33, average_ride_duration = (0+0+193)/3=64.33 By the end of October --> average_ride_distance = (0+163+6)/3=56.33, average_ride_duration = (0+193+38)/3=77.00 Solution sql SELECT month, COALESCE(ROUND(SUM(ride_distance)/3,2),0) AS average_ride_distance, COALESCE(ROUND(SUM(ride_duration)/3,2),0) AS average_ride_duration FROM ( SELECT months.month, ride_id FROM Rides RIGHT JOIN ( SELECT "2020-1-1" AS start, "2020-3-31" AS last, 1 AS month UNION SELECT "2020-2-1", "2020-4-30", 2 UNION SELECT "2020-3-1", "2020-5-31", 3 UNION SELECT "2020-4-1", "2020-6-30", 4 UNION SELECT "2020-5-1", "2020-7-31", 5 UNION SELECT "2020-6-1", "2020-8-31", 6 UNION SELECT "2020-7-1", "2020-9-30", 7 UNION SELECT "2020-8-1", "2020-10-31", 8 UNION SELECT "2020-9-1", "2020-11-30", 9 UNION SELECT "2020-10-1", "2020-12-31", 10 ) AS months ON months.start <= requested_at AND months.last >= requested_at ) total LEFT JOIN AcceptedRides AS a ON total.ride_id=a.ride_id GROUP BY month ORDER BY month;

---

#### Average Time of Process per Machine | Easy | üîí LeetCode

Table: Activity +----------------+---------+ | Column Name    | Type    | +----------------+---------+ | machine_id     | int     | | process_id     | int     | | activity_type  | enum    | | timestamp      | float   | +----------------+---------+ The table shows the user activities for a factory website. (machine_id, process_id, activity_type) is the primary key of this table. machine_id is the ID of a machine. process_id is the ID of a process running on the machine with ID machine_id. activity_type is an ENUM of type ('start', 'end'). timestamp is a float representing the current time in seconds. 'start' means the machine starts the process at the given timestamp and 'end' means the machine ends the process at the given timestamp. The 'start' timestamp will always be before the 'end' timestamp for every (machine_id, process_id) pair. There is a factory website that has several machines each running the same number of processes. Write an SQL query to find the average time each machine takes to complete a process. The time to complete a process is the 'end' timestamp minus the 'start' timestamp. The average time is calculated by the total time to complete every process on the machine divided by the number of processes that were run. The resulting table should have the machine_id along with the average time as processing_time, which should be rounded to 3 decimal places. The query result format is in the following example: Activity table: +------------+------------+---------------+-----------+ | machine_id | process_id | activity_type | timestamp | +------------+------------+---------------+-----------+ | 0          | 0          | start         | 0.712     | | 0          | 0          | end           | 1.520     | | 0          | 1          | start         | 3.140     | | 0          | 1          | end           | 4.120     | | 1          | 0          | start         | 0.550     | | 1          | 0          | end           | 1.550     | | 1          | 1          | start         | 0.430     | | 1          | 1          | end           | 1.420     | | 2          | 0          | start         | 4.100     | | 2          | 0          | end           | 4.512     | | 2          | 1          | start         | 2.500     | | 2          | 1          | end           | 5.000     | +------------+------------+---------------+-----------+ Result table: +------------+-----------------+ | machine_id | processing_time | +------------+-----------------+ | 0          | 0.894           | | 1          | 0.995           | | 2          | 1.456           | +------------+-----------------+ There are 3 machines running 2 processes each. Machine 0's average time is ((1.520 - 0.712) + (4.120 - 3.140)) / 2 = 0.894 Machine 1's average time is ((1.550 - 0.550) + (1.420 - 0.430)) / 2 = 0.995 Machine 2's average time is ((4.512 - 4.100) + (5.000 - 2.500)) / 2 = 1.456 Solution sql SELECT machine_id, ROUND(SUM(IF(activity_type='start', -timestamp, timestamp)) / COUNT(DISTINCT process_id), 3) AS processing_time FROM Activity GROUP BY machine_id ORDER BY machine_id

---

#### Fix Names in a Table | Easy | üîí LeetCode

Table: Users +----------------+---------+ | Column Name    | Type    | +----------------+---------+ | user_id        | int     | | name           | varchar | +----------------+---------+ user_id is the primary key for this table. This table contains the ID and the name of the user. The name consists of only lowercase and uppercase characters. Write an SQL query to fix the names so that only the first character is uppercase and the rest are lowercase. Return the result table ordered by user_id. The query result format is in the following example: Users table: +---------+-------+ | user_id | name  | +---------+-------+ | 1       | aLice | | 2       | bOB   | +---------+-------+ Result table: +---------+-------+ | user_id | name  | +---------+-------+ | 1       | Alice | | 2       | Bob   | +---------+-------+ Solution sql select user_id, CONCAT(UPPER(LEFT(name,1)),LOWER(SUBSTRING(name,2))) AS name FROM Users ORDER BY user_id

---

#### Product's Worth Over Invoices | Easy | üîí LeetCode

Table: Product +-------------+---------+ | Column Name | Type    | +-------------+---------+ | product_id  | int     | | name        | varchar | +-------------+---------+ product_id is the primary key for this table. This table contains the ID and the name of the product. The name consists of only lowercase English letters. No two products have the same name. Table: Invoice +-------------+------+ | Column Name | Type | +-------------+------+ | invoice_id  | int  | | product_id  | int  | | rest        | int  | | paid        | int  | | canceled    | int  | | refunded    | int  | +-------------+------+ invoice_id is the primary key for this table and the id of this invoice. product_id is the id of the product for this invoice. rest is the amount left to pay for this invoice. paid is the amount paid for this invoice. canceled is the amount canceled for this invoice. refunded is the amount refunded for this invoice. Write an SQL query that will, for all products, return each product name with total amount due, paid, canceled, and refunded across all invoices. Return the result table ordered by product_name. The query result format is in the following example: Product table: +------------+-------+ | product_id | name  | +------------+-------+ | 0          | ham   | | 1          | bacon | +------------+-------+ Invoice table: +------------+------------+------+------+----------+----------+ | invoice_id | product_id | rest | paid | canceled | refunded | +------------+------------+------+------+----------+----------+ | 23         | 0          | 2    | 0    | 5        | 0        | | 12         | 0          | 0    | 4    | 0        | 3        | | 1          | 1          | 1    | 1    | 0        | 1        | | 2          | 1          | 1    | 0    | 1        | 1        | | 3          | 1          | 0    | 1    | 1        | 1        | | 4          | 1          | 1    | 1    | 1        | 0        | +------------+------------+------+------+----------+----------+ Result table: +-------+------+------+----------+----------+ | name  | rest | paid | canceled | refunded | +-------+------+------+----------+----------+ | bacon | 3    | 3    | 3        | 3        | | ham   | 2    | 4    | 5        | 3        | +-------+------+------+----------+----------+ - The amount of money left to pay for bacon is 1 + 1 + 0 + 1 = 3 - The amount of money paid for bacon is 1 + 0 + 1 + 1 = 3 - The amount of money canceled for bacon is 0 + 1 + 1 + 1 = 3 - The amount of money refunded for bacon is 1 + 1 + 1 + 0 = 3 - The amount of money left to pay for ham is 2 + 0 = 2 - The amount of money paid for ham is 0 + 4 = 4 - The amount of money canceled for ham is 5 + 0 = 5 - The amount of money refunded for ham is 0 + 3 = 3 Solution sql SELECT p.name AS name, SUM(i.rest) AS rest, SUM(i.paid) AS paid, SUM(i.canceled) AS canceled, SUM(i.refunded) AS refunded FROM Invoice i LEFT JOIN Product p ON p.product_id = i.product_id GROUP BY name ORDER BY name;

---

#### Invalid Tweets | Easy | üîí LeetCode

Table: Tweets +----------------+---------+ | Column Name    | Type    | +----------------+---------+ | tweet_id       | int     | | content        | varchar | +----------------+---------+ tweet_id is the primary key for this table. This table contains all the tweets in a social media app. Write an SQL query to find the IDs of the invalid tweets. The tweet is invalid if the number of characters used in the content of the tweet is strictly greater than 15. Return the result table in any order. The query result format is in the following example: Tweets table: +----------+----------------------------------+ | tweet_id | content                          | +----------+----------------------------------+ | 1        | Vote for Biden                   | | 2        | Let us make America great again! | +----------+----------------------------------+ Result table: +----------+ | tweet_id | +----------+ | 2        | +----------+ Tweet 1 has length = 14. It is a valid tweet. Tweet 2 has length = 32. It is an invalid tweet. Solution sql SELECT tweet_id FROM Tweets WHERE LENGTH(content) > 15;

---

#### Daily Leads and Partners | Easy | üîí LeetCode

Table: DailySales +-------------+---------+ | Column Name | Type    | +-------------+---------+ | date_id     | date    | | make_name   | varchar | | lead_id     | int     | | partner_id  | int     | +-------------+---------+ This table does not have a primary key. This table contains the date and the name of the product sold and the IDs of the lead and partner it was sold to. The name consists of only lowercase English letters. Write an SQL query that will, for each date_id and make_name, return the number of distinct lead_id's and distinct partner_id's. Return the result table in any order. The query result format is in the following example: DailySales table: +-----------+-----------+---------+------------+ | date_id   | make_name | lead_id | partner_id | +-----------+-----------+---------+------------+ | 2020-12-8 | toyota    | 0       | 1          | | 2020-12-8 | toyota    | 1       | 0          | | 2020-12-8 | toyota    | 1       | 2          | | 2020-12-7 | toyota    | 0       | 2          | | 2020-12-7 | toyota    | 0       | 1          | | 2020-12-8 | honda     | 1       | 2          | | 2020-12-8 | honda     | 2       | 1          | | 2020-12-7 | honda     | 0       | 1          | | 2020-12-7 | honda     | 1       | 2          | | 2020-12-7 | honda     | 2       | 1          | +-----------+-----------+---------+------------+ Result table: +-----------+-----------+--------------+-----------------+ | date_id   | make_name | unique_leads | unique_partners | +-----------+-----------+--------------+-----------------+ | 2020-12-8 | toyota    | 2            | 3               | | 2020-12-7 | toyota    | 1            | 2               | | 2020-12-8 | honda     | 2            | 2               | | 2020-12-7 | honda     | 3            | 2               | +-----------+-----------+--------------+-----------------+ For 2020-12-8, toyota gets leads = [0, 1] and partners = [0, 1, 2] while honda gets leads = [1, 2] and partners = [1, 2]. For 2020-12-7, toyota gets leads = [0] and partners = [1, 2] while honda gets leads = [0, 1, 2] and partners = [1, 2]. Solution sql SELECT date_id, make_name, COUNT(DISTINCT lead_id) AS unique_leads, COUNT(DISTINCT partner_id) AS unique_partners FROM DailySales GROUP BY date_id, make_name

---

#### Number of Calls Between Two Persons | Medium | üîí LeetCode

Table: Calls +-------------+---------+ | Column Name | Type    | +-------------+---------+ | from_id     | int     | | to_id       | int     | | duration    | int     | +-------------+---------+ This table does not have a primary key, it may contain duplicates. This table contains the duration of a phone call between from_id and to_id. from_id != to_id Write an SQL query to report the number of calls and the total call duration between each pair of distinct persons (person1, person2) where person1 < person2. Return the result table in any order. The query result format is in the following example: Calls table: +---------+-------+----------+ | from_id | to_id | duration | +---------+-------+----------+ | 1       | 2     | 59       | | 2       | 1     | 11       | | 1       | 3     | 20       | | 3       | 4     | 100      | | 3       | 4     | 200      | | 3       | 4     | 200      | | 4       | 3     | 499      | +---------+-------+----------+ Result table: +---------+---------+------------+----------------+ | person1 | person2 | call_count | total_duration | +---------+---------+------------+----------------+ | 1       | 2       | 2          | 70             | | 1       | 3       | 1          | 20             | | 3       | 4       | 4          | 999            | +---------+---------+------------+----------------+ Users 1 and 2 had 2 calls and the total duration is 70 (59 + 11). Users 1 and 3 had 1 call and the total duration is 20. Users 3 and 4 had 4 calls and the total duration is 999 (100 + 200 + 200 + 499). Solution sql #Solution 1: SELECT from_id AS person1,to_id AS person2, COUNT(duration) AS call_count, SUM(duration) AS total_duration FROM (SELECT * FROM Calls UNION ALL SELECT to_id, from_id, duration FROM Calls) t1 WHERE from_id < to_id GROUP BY person1, person2 #Solution 2: SELECT IF(from_id<to_id,from_id,to_id) person1, IF(from_id>to_id,from_id,to_id) person2, COUNT(*) call_count, SUM(duration) total_duration FROM Calls GROUP BY IF(from_id<to_id,from_id,to_id), IF(from_id>to_id,from_id,to_id);

---

#### Biggest Window Between Visits | Medium | üîí LeetCode

Table: UserVisits +-------------+------+ | Column Name | Type | +-------------+------+ | user_id     | int  | | visit_date  | date | +-------------+------+ This table does not have a primary key. This table contains logs of the dates that users vistied a certain retailer. Assume today's date is '2021-1-1'. Write an SQL query that will, for each user_id, find out the largest window of days between each visit and the one right after it (or today if you are considering the last visit). Return the result table ordered by user_id. The query result format is in the following example: UserVisits table: +---------+------------+ | user_id | visit_date | +---------+------------+ | 1       | 2020-11-28 | | 1       | 2020-10-20 | | 1       | 2020-12-3  | | 2       | 2020-10-5  | | 2       | 2020-12-9  | | 3       | 2020-11-11 | +---------+------------+ Result table: +---------+---------------+ | user_id | biggest_window| +---------+---------------+ | 1       | 39            | | 2       | 65            | | 3       | 51            | +---------+---------------+ For the first user, the windows in question are between dates: - 2020-10-20 and 2020-11-28 with a total of 39 days. - 2020-11-28 and 2020-12-3 with a total of 5 days. - 2020-12-3 and 2021-1-1 with a total of 29 days. Making the biggest window the one with 39 days. For the second user, the windows in question are between dates: - 2020-10-5 and 2020-12-9 with a total of 65 days. - 2020-12-9 and 2021-1-1 with a total of 23 days. Making the biggest window the one with 65 days. For the third user, the only window in question is between dates 2020-11-11 and 2021-1-1 with a total of 51 days. Solution sql SELECT user_id, max(diff) AS biggest_window FROM ( SELECT user_id, datediff(coalesce(lead(visit_date) OVER (PARTITION BY user_id ORDER BY visit_date), '2021-01-01'), visit_date) AS diff FROM userVisits ) t GROUP BY user_id ORDER BY user_id

---

#### Count Apples and Oranges | Medium | üîí LeetCode

Table: Boxes +--------------+------+ | Column Name  | Type | +--------------+------+ | box_id       | int  | | chest_id     | int  | | apple_count  | int  | | orange_count | int  | +--------------+------+ box_id is the primary key for this table. chest_id is a foreign key of the chests table. This table contains information about the boxes and the number of oranges and apples they contain. Each box may contain a chest, which also can contain oranges and apples. Table: Chests +--------------+------+ | Column Name  | Type | +--------------+------+ | chest_id     | int  | | apple_count  | int  | | orange_count | int  | +--------------+------+ chest_id is the primary key for this table. This table contains information about the chests we have, and the corresponding number if oranges and apples they contain. Write an SQL query to count the number of apples and oranges in all the boxes. If a box contains a chest, you should also include the number of apples and oranges it has. Return the result table in any order. The query result format is in the following example: Boxes table: +--------+----------+-------------+--------------+ | box_id | chest_id | apple_count | orange_count | +--------+----------+-------------+--------------+ | 2      | null     | 6           | 15           | | 18     | 14       | 4           | 15           | | 19     | 3        | 8           | 4            | | 12     | 2        | 19          | 20           | | 20     | 6        | 12          | 9            | | 8      | 6        | 9           | 9            | | 3      | 14       | 16          | 7            | +--------+----------+-------------+--------------+ Chests table: +----------+-------------+--------------+ | chest_id | apple_count | orange_count | +----------+-------------+--------------+ | 6        | 5           | 6            | | 14       | 20          | 10           | | 2        | 8           | 8            | | 3        | 19          | 4            | | 16       | 19          | 19           | +----------+-------------+--------------+ Result table: +-------------+--------------+ | apple_count | orange_count | +-------------+--------------+ | 151         | 123          | +-------------+--------------+ box 2 has 6 apples and 15 oranges. box 18 has 4 + 20 (from the chest) = 24 apples and 15 + 10 (from the chest) = 25 oranges. box 19 has 8 + 19 (from the chest) = 27 apples and 4 + 4 (from the chest) = 8 oranges. box 12 has 19 + 8 (from the chest) = 27 apples and 20 + 8 (from the chest) = 28 oranges. box 20 has 12 + 5 (from the chest) = 17 apples and 9 + 6 (from the chest) = 15 oranges. box 8 has 9 + 5 (from the chest) = 14 apples and 9 + 6 (from the chest) = 15 oranges. box 3 has 16 + 20 (from the chest) = 36 apples and 7 + 10 (from the chest) = 17 oranges. Total number of apples = 6 + 24 + 27 + 27 + 17 + 14 + 36 = 151 Total number of oranges = 15 + 25 + 8 + 28 + 15 + 15 + 17 = 123 Solution sql SELECT sum(IFNULL(box.apple_count, 0) + IFNULL(chest.apple_count, 0)) AS apple_count, sum(IFNULL(box.orange_count, 0) + IFNULL(chest.orange_count, 0)) AS orange_count FROM Boxes AS box LEFT JOIN Chests AS chest ON box.chest_id = chest.chest_id;

---

#### Find Followers Count | Easy | üîí LeetCode

Table: Followers +-------------+------+ | Column Name | Type | +-------------+------+ | user_id     | int  | | follower_id | int  | +-------------+------+ (user_id, follower_id) is the primary key for this table. This table contains the IDs of a user and a follower in a social media app where the follower follows the user. Write an SQL query that will, for each user, return the number of followers. Return the result table ordered by user_id. The query result format is in the following example: Followers table: +---------+-------------+ | user_id | follower_id | +---------+-------------+ | 0       | 1           | | 1       | 0           | | 2       | 0           | | 2       | 1           | +---------+-------------+ Result table: +---------+----------------+ | user_id | followers_count| +---------+----------------+ | 0       | 1              | | 1       | 1              | | 2       | 2              | +---------+----------------+ The followers of 0 are {1} The followers of 1 are {0} The followers of 2 are {0,1} Solution sql SELECT user_id, COUNT(DISTINCT follower_id) followers_count FROM followers GROUP BY user_id ORDER BY user_id

---

#### The Number of Employees Which Report to Each Employee | Easy | üîí LeetCode

Table: Employees +-------------+----------+ | Column Name | Type     | +-------------+----------+ | employee_id | int      | | name        | varchar  | | reports_to  | int      | | age         | int      | +-------------+----------+ employee_id is the primary key for this table. This table contains information about the employees and the id of the manager they report to. Some employees do not report to anyone (reports_to is null). For this problem, we will consider a manager an employee who has at least 1 other employee reporting to them. Write an SQL query to report the ids and the names of all managers, the number of employees who report directly to them, and the average age of the reports rounded to the nearest integer. Return the result table ordered by employee_id. The query result format is in the following example: Employees table: +-------------+---------+------------+-----+ | employee_id | name    | reports_to | age | +-------------+---------+------------+-----+ | 9           | Hercy   | null       | 43  | | 6           | Alice   | 9          | 41  | | 4           | Bob     | 9          | 36  | | 2           | Winston | null       | 37  | +-------------+---------+------------+-----+ Result table: +-------------+-------+---------------+-------------+ | employee_id | name  | reports_count | average_age | +-------------+-------+---------------+-------------+ | 9           | Hercy | 2             | 39          | +-------------+-------+---------------+-------------+ Hercy has 2 people report directly to him, Alice and Bob. Their average age is (41+36)/2 = 38.5, which is 39 after rounding it to the nearest integer. Solution sql SELECT e1.reports_to AS employee_id, e2.name, COUNT(e1.reports_to) AS reports_count, ROUND(AVG(e1.age),0) AS average_age FROM employees e1 JOIN employees e2 ON e1.reports_to=e2.employee_id GROUP BY e1.reports_to ORDER BY e1.reports_to

---

#### Find Total Time Spent by Each Employee | Easy | üîí LeetCode

Table: Employees +-------------+------+ | Column Name | Type | +-------------+------+ | emp_id      | int  | | event_day   | date | | in_time     | int  | | out_time    | int  | +-------------+------+ (emp_id, event_day, in_time) is the primary key of this table. The table shows the employees' entries and exits in an office. event_day is the day at which this event happened and in_time is the minute at which the employee entered the office and out_time is the time at which he got outnumbered from 1 to 1440. It's guaranteed that no two events on the same day intersect in time. Write an SQL query to calculate the total time in minutes spent by each employee on each day at the office. Note that within one day, an employee can enter and leave more than once. Return the result table in any order. The query result format is in the following example: Employees table: +--------+------------+---------+----------+ | emp_id | event_day  | in_time | out_time | +--------+------------+---------+----------+ | 1      | 2020-11-28 | 4       | 32       | | 1      | 2020-11-28 | 55      | 200      | | 1      | 2020-12-03 | 1       | 42       | | 2      | 2020-11-28 | 3       | 33       | | 2      | 2020-12-09 | 47      | 74       | +--------+------------+---------+----------+ Result table: +------------+--------+------------+ | day        | emp_id | total_time | +------------+--------+------------+ | 2020-11-28 | 1      | 173        | | 2020-11-28 | 2      | 30         | | 2020-12-03 | 1      | 41         | | 2020-12-09 | 2      | 27         | +------------+--------+------------+ Employee 1 has three events two on day 2020-11-28 with a total of (32 - 4) + (200-55) = 173 and one on day 2020-12-03 with a total of (42 - 1) = 41. Employee 2 has two events one on day 2020-11-28 with a total of (33-3) = 30 and one on day 2020-12-09 with a total of (74 - 47) = 27. Solution sql SELECT event_day AS day, emp_id, SUM(out_time - in_time) AS total_time FROM Employees GROUP BY day, emp_id

---

#### Leetflex Banned Accounts | Medium | üîí LeetCode

Table: LogInfo +-------------+----------+ | Column Name | Type     | +-------------+----------+ | account_id  | int      | | ip_address  | int      | | login       | datetime | | logout      | datetime | +-------------+----------+ There is no primary key for this table, and it may contain duplicates. The table contains information about the login and logout dates of Leetflex accounts. It also contains the IP address from which the account logged in and out. It is guaranteed that the logout time is after the login time. Write an SQL query to find the account_id of the accounts that should be banned from Leetflex. An account should be banned if it was logged in at some moment from two different IP addresses. Return the result table in any order. The query result format is in the following example: LogInfo table: +------------+------------+---------------------+---------------------+ | account_id | ip_address | login               | logout              | +------------+------------+---------------------+---------------------+ | 1          | 1          | 2021-02-01 09:00:00 | 2021-02-01 09:30:00 | | 1          | 2          | 2021-02-01 08:00:00 | 2021-02-01 11:30:00 | | 2          | 6          | 2021-02-01 20:30:00 | 2021-02-01 22:00:00 | | 2          | 7          | 2021-02-02 20:30:00 | 2021-02-02 22:00:00 | | 3          | 9          | 2021-02-01 16:00:00 | 2021-02-01 16:59:59 | | 3          | 13         | 2021-02-01 17:00:00 | 2021-02-01 17:59:59 | | 4          | 10         | 2021-02-01 16:00:00 | 2021-02-01 17:00:00 | | 4          | 11         | 2021-02-01 17:00:00 | 2021-02-01 17:59:59 | +------------+------------+---------------------+---------------------+ Result table: +------------+ | account_id | +------------+ | 1          | | 4          | +------------+ Account ID 1 --> The account was active from "2021-02-01 09:00:00" to "2021-02-01 09:30:00" with two different IP addresses (1 and 2). It should be banned. Account ID 2 --> The account was active from two different addresses (6, 7) but in two different times. Account ID 3 --> The account was active from two different addresses (9, 13) on the same day but they do not intersect at any moment. Account ID 4 --> The account was active from "2021-02-01 17:00:00" to "2021-02-01 17:00:00" with two different IP addresses (10 and 11). It should be banned. Solution sql SELECT DISTINCT l1.account_id FROM LogInfo l1 JOIN LogInfo l2 ON l1.account_id = l2.account_id AND l1.ip_address != l2.ip_address WHERE NOT (l1.login > l2.logout OR l1.logout < l2.login)

---

#### Recyclable and Low Fat Products | Easy | üîí LeetCode

Table: Products +-------------+---------+ | Column Name | Type    | +-------------+---------+ | product_id  | int     | | low_fats    | enum    | | recyclable  | enum    | +-------------+---------+ product_id is the primary key for this table. low_fats is an ENUM of type ('Y', 'N') where 'Y' means this product is low fat and 'N' means it is not. recyclable is an ENUM of types ('Y', 'N') where 'Y' means this product is recyclable and 'N' means it is not. Write an SQL query to find the ids of products that are both low fat and recyclable. Return the result table in any order. The query result format is in the following example: Products table: +-------------+----------+------------+ | product_id  | low_fats | recyclable | +-------------+----------+------------+ | 0           | Y        | N          | | 1           | Y        | Y          | | 2           | N        | Y          | | 3           | Y        | Y          | | 4           | N        | N          | +-------------+----------+------------+ Result table: +-------------+ | product_id  | +-------------+ | 1           | | 3           | +-------------+ Only products 1 and 3 are both low fat and recyclable. Solution sql SELECT product_id FROM Products WHERE low_fats = "Y" AND recyclable = "Y"

---

#### Find the Subtasks That Did Not Execute | Hard | üîí LeetCode

Table: Tasks +----------------+---------+ | Column Name    | Type    | +----------------+---------+ | task_id        | int     | | subtasks_count | int     | +----------------+---------+ task_id is the primary key for this table. Each row in this table indicates that task_id was divided into subtasks_count subtasks labelled from 1 to subtasks_count. It is guaranteed that 2 <= subtasks_count <= 20. Table: Executed +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | task_id       | int     | | subtask_id    | int     | +---------------+---------+ (task_id, subtask_id) is the primary key for this table. Each row in this table indicates that for the task task_id, the subtask with ID subtask_id was executed successfully. It is guaranteed that subtask_id <= subtasks_count for each task_id. Write an SQL query to report the IDs of the missing subtasks for each task_id. Return the result table in any order. The query result format is in the following example: Tasks table: +---------+----------------+ | task_id | subtasks_count | +---------+----------------+ | 1       | 3              | | 2       | 2              | | 3       | 4              | +---------+----------------+ Executed table: +---------+------------+ | task_id | subtask_id | +---------+------------+ | 1       | 2          | | 3       | 1          | | 3       | 2          | | 3       | 3          | | 3       | 4          | +---------+------------+ Result table: +---------+------------+ | task_id | subtask_id | +---------+------------+ | 1       | 1          | | 1       | 3          | | 2       | 1          | | 2       | 2          | +---------+------------+ Task 1 was divided into 3 subtasks (1, 2, 3). Only subtask 2 was executed successfully, so we include (1, 1) and (1, 3) in the answer. Task 2 was divided into 2 subtasks (1, 2). No subtask was executed successfully, so we include (2, 1) and (2, 2) in the answer. Task 3 was divided into 4 subtasks (1, 2, 3, 4). All of the subtasks were executed successfully. Solution sql WITH RECURSIVE CTE AS (SELECT 1 AS subtask_id UNION ALL SELECT subtask_id + 1 FROM CTE WHERE subtask_id < (SELECT MAX(subtasks_count) FROM Tasks) ) SELECT Tasks.task_id, CTE.subtask_id FROM CTE INNER JOIN Tasks ON CTE.subtask_id <= Tasks.subtasks_count LEFT JOIN Executed ON Tasks.task_id = Executed.task_id AND CTE.subtask_id = Executed.subtask_id WHERE Executed.subtask_id IS NULL ORDER BY NULL

---

#### Product's Price for Each Store | Easy | üîí LeetCode

Table: Products +-------------+---------+ | Column Name | Type    | +-------------+---------+ | product_id  | int     | | store       | enum    | | price       | int     | +-------------+---------+ (product_id,store) is the primary key for this table. store is an ENUM of type ('store1', 'store2', 'store3') where each represents the store this product is available at. price is the price of the product at this store. Write an SQL query to find the price of each product in each store. Return the result table in any order. The query result format is in the following example: Products table: +-------------+--------+-------+ | product_id  | store  | price | +-------------+--------+-------+ | 0           | store1 | 95    | | 0           | store3 | 105   | | 0           | store2 | 100   | | 1           | store1 | 70    | | 1           | store3 | 80    | +-------------+--------+-------+ Result table: +-------------+--------+--------+--------+ | product_id  | store1 | store2 | store3 | +-------------+--------+--------+--------+ | 0           | 95     | 100    | 105    | | 1           | 70     | null   | 80     | +-------------+--------+--------+--------+ Product 0 price's are 95 for store1, 100 for store2 and, 105 for store3. Product 1 price's are 70 for store1, 80 for store3 and, it's not sold in store2. Solution sql SELECT product_id, SUM(CASE WHEN store='store1' THEN price END) AS store1, SUM(CASE WHEN store='store2' THEN price END) AS store2, SUM(CASE WHEN store='store3' THEN price END) AS store3 FROM Products GROUP BY product_id

---

#### Grand Slam Titles | Medium | üîí LeetCode

Table: Players +----------------+---------+ | Column Name    | Type    | +----------------+---------+ | player_id      | int     | | player_name    | varchar | +----------------+---------+ player_id is the primary key for this table. Each row in this table contains the name and the ID of a tennis player. Table: Championships +---------------+---------+ | Column Name   | Type    | +---------------+---------+ | year          | int     | | Wimbledon     | int     | | Fr_open       | int     | | US_open       | int     | | Au_open       | int     | +---------------+---------+ year is the primary key for this table. Each row of this table containts the IDs of the players who won one each tennis tournament of the grand slam. Write an SQL query to report the number of grand slam tournaments won by each player. Do not include the players who did not win any tournament. Return the result table in any order. The query result format is in the following example: Players table: +-----------+-------------+ | player_id | player_name | +-----------+-------------+ | 1         | Nadal       | | 2         | Federer     | | 3         | Novak       | +-----------+-------------+ Championships table: +------+-----------+---------+---------+---------+ | year | Wimbledon | Fr_open | US_open | Au_open | +------+-----------+---------+---------+---------+ | 2018 | 1         | 1       | 1       | 1       | | 2019 | 1         | 1       | 2       | 2       | | 2020 | 2         | 1       | 2       | 2       | +------+-----------+---------+---------+---------+ Result table: +-----------+-------------+-------------------+ | player_id | player_name | grand_slams_count | +-----------+-------------+-------------------+ | 2         | Federer     | 5                 | | 1         | Nadal       | 7                 | +-----------+-------------+-------------------+ Player 1 (Nadal) won 7 titles: Wimbledon (2018, 2019), Fr_open (2018, 2019, 2020), US_open (2018), and Au_open (2018). Player 2 (Federer) won 5 titles: Wimbledon (2020), US_open (2019, 2020), and Au_open (2019, 2020). Player 3 (Novak) did not win anything, we did not include them in the result table. Solution sql #Solution 1: SELECT player_id, player_name, SUM((IF(Wimbledon = player_id,1,0) + IF(Fr_open = player_id,1,0) + IF(US_open = player_id,1,0) + IF(Au_open = player_id,1,0))) as grand_slams_count FROM Players INNER JOIN Championships ON Wimbledon = player_id OR Fr_open = player_id OR US_open = player_id OR Au_open = player_id GROUP BY player_id; #Solution 2: WITH cte AS (SELECT wimbledon AS id FROM   championships UNION ALL SELECT fr_open AS id FROM   championships UNION ALL SELECT us_open AS id FROM   championships UNION ALL SELECT au_open AS id FROM   championships) SELECT player_id, player_name, Count(*) AS grand_slams_count FROM   players INNER JOIN cte ON players.player_id = cte.id GROUP  BY 1, 2 ORDER  BY NULL;

---

#### Primary Department for Each Employee | Easy | üîí LeetCode

Table: Employee +--------------+---------+ | Column Name  |  Type   | +--------------+---------+ | employee_id  | int     | | deprtment_id | int     | | primary_flag | varchar | +--------------+---------+ (employee_id, department_id) is the primary key for this table. employee_id is the id of the employee. department_id is the id of the department to which the employee belongs. primary_flag is an ENUM of type ('Y', 'N'). If the flag is 'Y', the department is the primary department for the employee. If the flag is 'N', the department is not the primary. Employees can belong to multiple departments. When the employee joins other departments, they need to decide which department is their primary department. Note that when an employee belongs to only one department, their primary column is 'N'. Write an SQL query to report all the employees with their primary department. For employees who belong to one department, report their only department. Return the result table in any order. The query result format is in the following example. Employee table: +-------------+---------------+--------------+ | employee_id | department_id | primary_flag | +-------------+---------------+--------------+ | 1           | 1             | N            | | 2           | 1             | Y            | | 2           | 2             | N            | | 3           | 3             | N            | | 4           | 2             | N            | | 4           | 3             | Y            | | 4           | 4             | N            | +-------------+---------------+--------------+ Result table: +-------------+---------------+ | employee_id | department_id | +-------------+---------------+ | 1           | 1             | | 2           | 1             | | 3           | 3             | | 4           | 3             | +-------------+---------------+ - The Primary department for employee 1 is 1. - The Primary department for employee 2 is 1. - The Primary department for employee 3 is 3. - The Primary department for employee 4 is 3. Solution sql #Solution 1: SELECT employee_id,department_id FROM employee WHERE primary_flag = 'Y' OR employee_id IN (SELECT employee_id FROM employee GROUP BY employee_id HAVING COUNT(department_id) = 1) #Solution 2: (SELECT employee_id, department_id FROM Employee WHERE primary_flag = 'Y') UNION (SELECT employee_id, department_id FROM Employee GROUP BY employee_id HAVING COUNT(employee_id) = 1 ORDER BY NULL);

---

#### SELECT *

FROM olympic_2377 ORDER BY gold_medals DESC,silver_medals DESC,bronze_medals DESC,country ASC;

---

#### --Question 101

-- Table: Visits -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | user_id       | int     | -- | visit_date    | date    | -- +---------------+---------+ -- (user_id, visit_date) is the primary key for this table. -- Each row of this table indicates that user_id has visited the bank in visit_date. -- Table: Transactions -- +------------------+---------+ -- | Column Name      | Type    | -- +------------------+---------+ -- | user_id          | int     | -- | transaction_date | date    | -- | amount           | int     | -- +------------------+---------+ -- There is no primary key for this table, it may contain duplicates. -- Each row of this table indicates that user_id has done a transaction of amount in transaction_date. -- It is guaranteed that the user has visited the bank in the transaction_date.(i.e The Visits table contains (user_id, transaction_date) in one row) -- A bank wants to draw a chart of the number of transactions bank visitors did in one visit to the bank and the corresponding number of visitors who have done this number of transaction in one visit. -- Write an SQL query to find how many users visited the bank and didn't do any transactions, how many visited the bank and did one transaction and so on. -- The result table will contain two columns: -- transactions_count which is the number of transactions done in one visit. -- visits_count which is the corresponding number of users who did transactions_count in one visit to the bank. -- transactions_count should take all values from 0 to max(transactions_count) done by one or more users. -- Order the result table by transactions_count. -- The query result format is in the following example: -- Visits table: -- +---------+------------+ -- | user_id | visit_date | -- +---------+------------+ -- | 1       | 2020-01-01 | -- | 2       | 2020-01-02 | -- | 12      | 2020-01-01 | -- | 19      | 2020-01-03 | -- | 1       | 2020-01-02 | -- | 2       | 2020-01-03 | -- | 1       | 2020-01-04 | -- | 7       | 2020-01-11 | -- | 9       | 2020-01-25 | -- | 8       | 2020-01-28 | -- +---------+------------+ -- Transactions table: -- +---------+------------------+--------+ -- | user_id | transaction_date | amount | -- +---------+------------------+--------+ -- | 1       | 2020-01-02       | 120    | -- | 2       | 2020-01-03       | 22     | -- | 7       | 2020-01-11       | 232    | -- | 1       | 2020-01-04       | 7      | -- | 9       | 2020-01-25       | 33     | -- | 9       | 2020-01-25       | 66     | -- | 8       | 2020-01-28       | 1      | -- | 9       | 2020-01-25       | 99     | -- +---------+------------------+--------+ -- Result table: -- +--------------------+--------------+ -- | transactions_count | visits_count | -- +--------------------+--------------+ -- | 0                  | 4            | -- | 1                  | 5            | -- | 2                  | 0            | -- | 3                  | 1            | -- +--------------------+--------------+ -- * For transactions_count = 0, The visits (1, "2020-01-01"), (2, "2020-01-02"), (12, "2020-01-01") and (19, "2020-01-03") did no transactions so visits_count = 4. -- * For transactions_count = 1, The visits (2, "2020-01-03"), (7, "2020-01-11"), (8, "2020-01-28"), (1, "2020-01-02") and (1, "2020-01-04") did one transaction so visits_count = 5. -- * For transactions_count = 2, No customers visited the bank and did two transactions so visits_count = 0. -- * For transactions_count = 3, The visit (9, "2020-01-25") did three transactions so visits_count = 1. -- * For transactions_count >= 4, No customers visited the bank and did more than three transactions so we will stop at transactions_count = 3 -- Solution WITH RECURSIVE t1 AS( SELECT visit_date, COALESCE(num_visits,0) as num_visits, COALESCE(num_trans,0) as num_trans FROM (( SELECT visit_date, user_id, COUNT(*) as num_visits FROM visits GROUP BY 1, 2) AS a LEFT JOIN ( SELECT transaction_date, user_id, count(*) as num_trans FROM transactions GROUP BY 1, 2) AS b ON a.visit_date = b.transaction_date and a.user_id = b.user_id) ), t2 AS ( SELECT MAX(num_trans) as trans FROM t1 UNION ALL SELECT trans-1 FROM t2 WHERE trans >= 1) SELECT trans as transactions_count, COALESCE(visits_count,0) as visits_count FROM t2 LEFT JOIN ( SELECT num_trans as transactions_count, COALESCE(COUNT(*),0) as visits_count FROM t1 GROUP BY 1 ORDER BY 1) AS a ON a.transactions_count = t2.trans ORDER BY 1

---

#### What is Index in SQL?

With the help of Indexes, information retrieval from the database happens faster and with greater efficiency. Thus, indexes improve performance. There are three types of indexes: Clustered: Used for reordering tables and searching information with key values. Non-clustered: Used for maintaining the order of the tables. Unique: They ban fields from having duplicate values. There can be many non-clustered indexes in a table, however, there can be only one clustered index.

---

#### What is a Synonym in SQL?

As the name suggests, a synonym is used to give different names to the same object in the database. In the case of object-renaming or object schema-change, existing applications can continue to use older names because of synonyms. A synonym must only reference an object and not another synonym. Additionally, synonyms can also be used to reference objects in different databases or servers, by using 3 or 4 part object names. There can be many names for a single database object as long as all the names directly refer to the same database object. You must ensure that you know answers to such SQL interview questions as answering them correctly will give you the much-needed confidence for the more difficult ones.

---

#### Mention some advantages of Synonyms.

Below are some advantages of using Synonyms: Synonyms create a layer of abstraction for the specific object For objects, with complex 3 or 4 part names, residing on the same server, Synonyms can give a simpler alias Offers the flexibility to change object location without having to change the existing code When the name of an object is changed or dropped, Synonym offers backward compatibility for older applications Synonyms are also useful in front-end query tools such as Access linked tables and spreadsheets if there is a direct link to these tables

---

#### Are there any disadvantages to using Synonyms?

Yes, there are some disadvantages. Synonyms are only loosely linked to the referenced object and thus, can be deleted without warning when being used to reference a different database object Inside chaining cannot take place, meaning that the synonym of a synonym cannot be created One cannot create a table with the same Synonym name The checking for the object for which the Synonym is created happens at runtime and not at the time of creation. This means if there is an error, such as a spelling error, it will only show up at runtime creating a problem in accessing the object Synonyms cannot be referenced in DDL statements For SQL interview questions that ask you to talk about the advantages or disadvantages of a certain component or tool, ensure that you list as many as you can. Also, you can make your answer to such an SQL interview question meaty by adding personal anecdotes about some of the advantages or disadvantages.

---

#### Are NULL values equal to zero?

No. NULL values show an absence of characters, whereas zero is a numerical value. NULL values occur when a character is unavailable or not known. NULL values should also not be confused with blank space because a blank space is not supposed to have any data attached to it, whereas a NULL value shows a data record without any value assigned to it.

---

#### What are Scalar subqueries and Correlated subqueries?

A Scalar subquery is when a query returns just one row and one column of data. A Correlated subquery occurs when a query cannot process without information from an outer query. In such cases, table aliases define the scope of the argument and the subquery is parameterized by an outer query. Thus, there is a correlation between the inner and outer queries. As a result, back and forth execution takes place where a single row of results from the outer query passes parameters to the inner query. SQL interview questions like the one above try to ascertain the depth of your knowledge of SQL.

---

#### What is the difference between NVL and NVL2 functions?

The function NVL (exp1, exp2) is a conversion function that changes exp1 into the target exp2 under the condition that exp1 is NULL. The data type of exp1 is the same as that of a return value. The function NVL2 (exp1, exp2, exp3), on the other hand, is a checking function, which determines whether exp1 is null or not. When exp1 is not null, exp2 is returned as the result. When exp1 is null, exp3 is returned as the result.

---

#### What do you mean by ‚Äòauto increment‚Äô?

With the auto-increment command, one can generate unique numbers when new records are added to a table. This function is especially useful when one wants to automatically generate the primary key field values upon inserting new records. This command comes in handy on several platforms. The auto-increment command for the SQL servers is ‚Äúidentity‚Äù.

---

#### What is the main use of ‚Äòrecursive stored procedure‚Äô?

The main use of the recursive stored procedure is to make the code calls till the time certain boundary conditions are reached. This helps programmers enhance productivity by using the same code multiple times. An SQL interview question like this one shows that even though some of the advanced concepts may be easy to understand, they may be difficult to recount when suddenly faced with the question. Thus, when you prepare for SQL interview questions, ensure to revise all types of concepts.

---

#### Describe ‚Äòdatawarehouse‚Äô in SQL.

A ‚Äòdatawarehouse‚Äô is a system used for analyzing and reporting data. It is very similar to a physical warehouse where inventory is stored and assessed before being sent to a customer. Here, data is stored, analyzed, and reported. A datawarehouse functions as a central repository of data integrated from different areas and sources and makes this data available for use.

---

#### What is DBMS?

DBMS is an abbreviation for Database Management System for creating and managing databases. There are two types of databases: Relational Database Management Systems (RDBMS) - Data is stored in tables. Non-Relational Database Management Systems - Mostly referred to as NoSQL, stores data in non-tabular format.

---

#### What is the difference between SQL and MySQL?

Structured Query Language is utilized for handling and modifying data in relational databases. With SQL, you can generate and alter databases, tables, and other related objects, alongside executing various data operations, including record insertion, updates, and deletions. MySQL, on the other hand, is a specific relational database management system (RDBMS) that uses SQL as its primary language for managing data. MySQL is an open-source RDBMS that is widely used for web applications,

---

#### List the type of SQL statements or subsets.

Below are the popular subsets used in SQL: DDL (Data Definition Language) - It is used to define and structure tables. Users can CREATE, ALTER, and DELETE the database tables. DCL (Data Control Language) - Administrators use it to give users privileges to GRANT or REVOKE permissions to the database. DML (Data Manipulation Language) - It allows users to either UPDATE, INSERT, RETRIEVE, or DELETE information from the database.

---

#### Define what joins are in SQL.

Joins is a statement used to join two or more rows based on their relationship. There are four types of Join statements: Left Join Right Join Inner Join Full Join

---

#### What is a Primary Key?

A primary key is used to identify unique rows or tables in a database. Primary keys must always contain unique values. Null or duplicate values are not considered primary keys.

---

#### What is a Foreign Key?

A foreign key is used to link two or more tables together. Its values match with a primary key from a different table. Foreign keys are like references between tables.

---

#### What is a unique key?

A unique key ensures a table has a unique value not found or contained in other rows or columns. Unlike the primary key, the unique key may have multiple columns. You can create a unique key using the keyword "UNIQUE" when defining the table.

---

#### Create an employee table example.

Below is how to create an employee table: Image 15-05-23 at 10.29 PM_11zon.webp

---

#### What is a SELECT statement used for?

SELECT is a DML command used for fetching one or more tables. It queries for information which usually returns a set of results.

---

#### Name the clauses used in the SELECT statement.

WHERE - filters the rows according to their criteria ORDER BY - Sorts the tables/rows according to the ASC clause (ascending order) or DESC clause (descending order) GROUP BY - groups data from different tables that have similar rows in the database

---

#### What are CHAR and VARCHAR?

CHAR is a fixed-length string character, whereas VARCHAR is a variable-length string data structure. VARCHAR is preferred over CHAR because it is more space-efficient when storing strings with variable lengths.

---

#### List the types of relationships found in SQL.

One-to-one relationship - This relationship exists between two tables when a single row in one table corresponds to a single row in another table. This relationship is usually established using a foreign key constraint. One-to-Many/Many-to-One - This relationship exists between two tables when a single row in one table corresponds to multiple rows in another table. This relationship is also established using a foreign key constraint. Many-to-Many - This relationship exists between two tables when multiple rows in one table correspond to multiple rows in another table. This relationship is usually implemented using an intermediate table that contains foreign keys to the two tables being related.

---

#### What is the difference between TRUNCATE and DELETE?

The truncate command is used when you want to delete all rows and values from a table. It is a DDL type of command which is faster. While the DELETE command is used when you want to delete a specific row in a table. It is a DML command type and less efficient than the truncate statement.

---

#### What is a cursor?

A cursor is a temporary memory allocated by the server when performing any DML queries. They are used to store Database Tables. Basically a cursor in sql is an object in database code that allows processes to process rows one by one. While in other programming languages sets of data is processed individually through a loop, in SQL, data is processed in a set through a cursor. Two types of cursors are Implicit cursors and Explicit cursors. Implicit Cursors: They are Default Cursors of SQL SERVER. Allocated when the user performs DML operations. Explicit Cursors: They are created by users in need. They are used for Fetching data from Tables in Row-By-Row Manner.

---

#### Define normalization.

Normalization is a method of breaking down larger, complex data into smaller tables. It helps in filtering unnecessary, redundant data and leaves only unique values.

---

#### What is ETL?

ETL is an acronym for Extract, Transform, and Load. It is a process where you extract data from different sources, transform the data quality, and finally load it into the database.

---

#### What is the difference between Local and Global variables?

Local variables are used inside a function and can‚Äôt be reused by other functions, whereas global variables can be accessed and used throughout the program.

---

#### What is a subquery?

A subquery is a query that is found in another query. Usually referred to as an inner query, its output is typically used by another query.

---

#### What is ACID?

ACID in SQL refers to a set of properties that guarantee the reliable and consistent processing of database transactions. It is an acronym where each letter stands for one of the properties: Atomicity: Ensures that a transaction is either fully completed or not executed at all. If any part of a transaction fails, the entire transaction is rolled back, and the database remains unchanged. Consistency: Guarantees that the database transitions from one consistent state to another upon the completion of a transaction. All data must adhere to predefined rules and constraints. Isolation: Provides a degree of separation between concurrent transactions, ensuring that they do not interfere with one other. It helps maintain data integrity by controlling the visibility of changes made by one transaction to another. Durability: Guarantees that after a transaction has been committed, the modifications made to the database become permanent, even if a system failure or crash occurs. ACID properties are vital in maintaining data integrity and consistency in relational database management systems (RDBMS) and ensuring the robustness of transactions.

---

#### Define stored procedure.

A stored procedure is a function that contains a group of query statements that can be reused. They are stored inside a named object in the database and can be executed anytime they are required.

---

#### What are triggers in SQL?

Triggers are special stored procedures that run when there's an event in the database server, such as changing data in a table. A trigger is different from a regular stored procedure as it cannot be directly called like a regular stored procedure.

---

#### Define an ER.

An Entity Relationship (ER) diagram is a visual representation of the relationship tables found in the database. It displays the table structures and primary and foreign keys.

---

#### When are Triggers used?

Triggers in SQL are used to automatically enforce business rules or maintain data integrity by executing predefined actions in response to specific database events, such as INSERT, UPDATE, or DELETE. Common use cases include data validation, data auditing, and maintaining referential integrity or complex relationships between tables.

---

#### What are Sparse Columns?

Sparse columns are columns that provide optimized storage for null values. They reduce space that is usually taken up by null values and can be defined by using CREATE or ALTER statements.

---

#### Define Check Constraints.

Check constraints are used for checking and ensuring that values in a table follow domain integrity. Users can apply Check constraints to single and multiple columns.

---

#### What is Collation?

In SQL, collation refers to a set of rules that govern the proper ordering, comparison, and representation of characters in a particular character set or encoding. Collation influences how text data in a database is sorted, searched, and compared. It typically accounts for various linguistic considerations such as case sensitivity, accent sensitivity, and specific language-based conventions.

---

#### Write a SQL query for the salespeople and customers who live in the same city.

To write a SQL query that shows salespeople and customers who live in the same city, you need to have information about both salespeople and customers. Here's an example SQL query assuming you have two tables: salespeople and customers. Image 15-05-23 at 10.30 PM_11zon.webp In this query, we're selecting the salesperson name, customer name, and city from two tables (salespeople and customers) using an INNER JOIN to connect them based on the condition that the city in the salespeople table equals the city in the customers table.

---

#### Write a SQL query to find orders where the order amount exists between 1000 and 5000.

To find orders with an order amount between 1000 and 5000, you can use the following SQL query: Image 15-05-23 at 10.30 PM (1)_11zon.webp In this query, replace "orders" with the actual name of your orders table, and "order_amount" with the appropriate column name representing the order amount in your table. This query will return all rows where the order amount falls between 1000 and 5000, inclusive.

---

#### Write a SQL query to find those employees whose salaries are less than 7000.

Image 15-05-23 at 10.30 PM (2)_11zon.webp

---

#### What is a Filtered Index?

A filtered index is a non-clustered index that comes with optimized disk restore. It is created when a column has few values for queries. The purpose of a filtered index is to optimize query performance by reducing the size of the index and the number of index pages that need to be read. It helps in improving performance, storage reduction, and index maintenance.

---

#### What is a Clause?

A clause is one of the SQL query statements that filters or customizes data for a query. It allows users to limit the results by providing a conditional statement to the query. It is typically used when a large amount of data is in the database.

---

#### Write a SQL query that removes duplicates from the table.

The following SQL query removes the duplicate values Image 15-05-23 at 10.30 PM (3)_11zon.webp

---

#### What is a Case Function?

A case function is a SQL logic that uses the if-then-else statements. It evaluates the conditions of a table and returns multiple result expressions.

---

#### Define a VIEW.

A view is a virtual table containing values in one or multiple tables. Views restrict data by selecting only required values to make queries easy.

---

#### What is a SCHEMA?

A schema in SQL is a collection of database objects, including tables, indexes, sequences, and other schema objects. It defines how data is organized in a relational database system. It is used to manage database objects and control access to them by different users.

---

#### Differentiate between HAVING and WHERE clauses.

These conditions are used for searching values except that the HAVING clause is used with the SELECT statement accompanied by the GROUP BY clause. The HAVING clause is used in combination with the GROUP BY clause to filter the data based on aggregate values, while the WHERE clause is used to filter the data based on individual values.

---

#### Define what is meant by CTE.

In SQL, a CTE (Common Table Expression) is a temporary result set, often used to simplify complex queries by breaking them into smaller, more manageable pieces. A CTE is created using the WITH clause and is available only within the context of the query that follows it.

---

#### What are SQL operators?

Operators are special characters or words that perform specific operations. They are used with the WHERE clause to filter data in most cases.

---

#### Write a SQL query to find the second-highest salary.

Image 15-05-23 at 10.31 PM_11zon.webp

---

#### What is CDC?

CDC means change data capture. It records the recent activities made by the INSERT, DELETE, and UPDATE statements made to the tables. It is basically a process of identifying and capturing changes made to data in the database and returning those changes in real time. This capture of changes from transactions in a source database and transferring them to the target, all in real-time, keeps the system in sync. This allows for reliable data copying and zero-downtime cloud migrations.

---

#### Define Auto Increment.

‚ÄúAUTO INCREMENT‚Äù is a clause used to generate unique values whenever a new record is created and inserted into a table. It means that every time a new row is inserted into the table, the database system automatically generates a new value for that column.

---

#### What is a COALESCE?

COALESCE is a function that takes a set of inputs and returns the first non-null values. It is used to handle null values in a query's result set.

---

#### -- Question 86

-- Get the highest answer rate question from a table survey_log with these columns: id, action, question_id, answer_id, q_num, timestamp. -- id means user id; action has these kind of values: "show", "answer", "skip"; answer_id is not null when action column is "answer", -- while is null for "show" and "skip"; q_num is the numeral order of the question in current session. -- Write a sql query to identify the question which has the highest answer rate. -- Example: -- Input: -- +------+-----------+--------------+------------+-----------+------------+ -- | id   | action    | question_id  | answer_id  | q_num     | timestamp  | -- +------+-----------+--------------+------------+-----------+------------+ -- | 5    | show      | 285          | null       | 1         | 123        | -- | 5    | answer    | 285          | 124124     | 1         | 124        | -- | 5    | show      | 369          | null       | 2         | 125        | -- | 5    | skip      | 369          | null       | 2         | 126        | -- +------+-----------+--------------+------------+-----------+------------+ -- Output: -- +-------------+ -- | survey_log  | -- +-------------+ -- |    285      | -- +-------------+ -- Explanation: -- question 285 has answer rate 1/1, while question 369 has 0/1 answer rate, so output 285. -- Note: The highest answer rate meaning is: answer number's ratio in show number in the same question. -- Solution with t1 as( select a.question_id, coalesce(b.answer/a.show_1,0) as rate from (select question_id, coalesce(count(*),0) as show_1 from survey_log where action != 'answer' group by question_id) a left join (select question_id, coalesce(count(*),0) as answer from survey_log where action = 'answer' group by question_id) b on a.question_id = b.question_id) select a.question_id as survey_log from ( select t1.question_id, rank() over(order by rate desc) as rk from t1) a where a.rk = 1

---

#### -- Question 88

-- Table: Candidate -- +-----+---------+ -- | id  | Name    | -- +-----+---------+ -- | 1   | A       | -- | 2   | B       | -- | 3   | C       | -- | 4   | D       | -- | 5   | E       | -- +-----+---------+ -- Table: Vote -- +-----+--------------+ -- | id  | CandidateId  | -- +-----+--------------+ -- | 1   |     2        | -- | 2   |     4        | -- | 3   |     3        | -- | 4   |     2        | -- | 5   |     5        | -- +-----+--------------+ -- id is the auto-increment primary key, -- CandidateId is the id appeared in Candidate table. -- Write a sql to find the name of the winning candidate, the above example will return the winner B. -- +------+ -- | Name | -- +------+ -- | B    | -- +------+ -- Notes: -- You may assume there is no tie, in other words there will be only one winning candidate -- Solution with t1 as ( select *, rank() over(order by b.votes desc) as rk from candidate c join (select candidateid, count(*) as votes from vote group by candidateid) b on c.id = b.candidateid) select t1.name from t1 where t1.rk=1

---

#### -- Question 57

-- The Employee table holds all employees. Every employee has an Id, a salary, and there is also a column for the department Id. -- +----+-------+--------+--------------+ -- | Id | Name  | Salary | DepartmentId | -- +----+-------+--------+--------------+ -- | 1  | Joe   | 70000  | 1            | -- | 2  | Jim   | 90000  | 1            | -- | 3  | Henry | 80000  | 2            | -- | 4  | Sam   | 60000  | 2            | -- | 5  | Max   | 90000  | 1            | -- +----+-------+--------+--------------+ -- The Department table holds all departments of the company. -- +----+----------+ -- | Id | Name     | -- +----+----------+ -- | 1  | IT       | -- | 2  | Sales    | -- +----+----------+ -- Write a SQL query to find employees who have the highest salary in each of the departments. -- For the above tables, your SQL query should return the following rows (order of rows does not matter). -- +------------+----------+--------+ -- | Department | Employee | Salary | -- +------------+----------+--------+ -- | IT         | Max      | 90000  | -- | IT         | Jim      | 90000  | -- | Sales      | Henry    | 80000  | -- +------------+----------+--------+ -- Explanation: -- Max and Jim both have the highest salary in the IT department and Henry has the highest salary in the Sales department. -- Solution select a.Department, a.Employee, a.Salary from( select d.name as Department, e.name as Employee, Salary, rank() over(partition by d.name order by salary desc) as rk from employee e join department d on e.departmentid = d.id) a where a.rk=1

---

#### WITH exams AS (

SELECT student_id,subject_name,COUNT(1) AS attended_exams FROM examinations_1280 GROUP BY student_id,subject_name ), combinations AS ( SELECT st.*,sb.subject_name FROM students_1280 st CROSS JOIN subjects_1280 sb ) SELECT c.student_id,c.student_name,c.subject_name,COALESCE(e.attended_exams,0) FROM combinations c LEFT JOIN exams e ON e.student_id = c.student_id AND e.subject_name = c.subject_name ORDER BY c.student_id,c.subject_name;

---

#### What is SQL and how does it differ from other programming languages?

Why you might get asked this: Understanding the fundamental differences between SQL and other programming languages is crucial for roles that involve database management and data manipulation, such as a Database Administrator or Data Analyst. How to answer: Define SQL as a domain-specific language used for managing and manipulating relational databases. Highlight that SQL is declarative, focusing on what data to retrieve rather than how to retrieve it. Contrast SQL with general-purpose programming languages, emphasizing its specialized use for database operations. Example answer: "SQL, or Structured Query Language, is a domain-specific language designed for managing and manipulating relational databases. Unlike general-purpose programming languages, SQL is declarative, meaning it focuses on what data to retrieve rather than how to retrieve it."

---

#### Explain the difference between INNER JOIN and LEFT JOIN with examples.

Why you might get asked this: Understanding the difference between INNER JOIN and LEFT JOIN is essential for roles that require complex data retrieval and manipulation, such as a Data Engineer or SQL Developer. How to answer: Define INNER JOIN as a join that returns only the matching rows from both tables. Explain LEFT JOIN as a join that returns all rows from the left table and the matching rows from the right table, with NULLs for non-matching rows. Provide a simple example query for each join to illustrate the differences. Example answer: "An INNER JOIN returns only the rows that have matching values in both tables, while a LEFT JOIN returns all rows from the left table and the matching rows from the right table, with NULL values for non-matching rows. For example, SELECT * FROM Orders INNER JOIN Customers ON Orders.CustomerID = Customers.CustomerID retrieves only the orders with matching customers, whereas SELECT * FROM Orders LEFT JOIN Customers ON Orders.CustomerID = Customers.CustomerID retrieves all orders, including those without matching customers."

---

#### Write a SQL query to find the second highest salary from a table named Employees.

Why you might get asked this: This question tests your ability to write complex SQL queries and demonstrates your problem-solving skills, which are crucial for roles like Data Analyst or Database Developer. How to answer: Explain the use of the LIMIT clause to restrict the number of rows returned. Describe the use of a subquery to find the highest salary and exclude it from the results. Provide a sample query using ORDER BY and LIMIT to retrieve the second highest salary. Example answer: "To find the second highest salary from a table named Employees, you can use a subquery to first identify the highest salary and then exclude it from the results. The query would look like this: SELECT MAX(Salary) FROM Employees WHERE Salary < (SELECT MAX(Salary) FROM Employees)."

---

#### What are primary keys and foreign keys? Provide examples.

Why you might get asked this: Understanding primary keys and foreign keys is fundamental for ensuring data integrity and establishing relationships between tables, which is crucial for roles like Database Administrator or Data Architect. How to answer: Define a primary key as a unique identifier for each record in a table. Explain a foreign key as a field in one table that uniquely identifies a row of another table. Provide examples using simple table structures, such as an EmployeeID in an Employees table and a DepartmentID in a Departments table. Example answer: "A primary key is a unique identifier for each record in a table, ensuring that no two rows have the same key. A foreign key is a field in one table that uniquely identifies a row of another table, establishing a relationship between the two tables, such as EmployeeID in an Employees table and DepartmentID in a Departments table."

---

#### Write a SQL query to retrieve all records from a table named Products where the price is greater than 100.

Why you might get asked this: This question assesses your ability to write basic SQL queries for data retrieval, a fundamental skill for any role involving database management, such as a Data Analyst or SQL Developer. How to answer: Explain the use of the SELECT statement to retrieve data from the table. Describe the WHERE clause to filter records based on the price condition. Provide a sample query using SELECT * FROM Products WHERE price > 100. Example answer: "To retrieve all records from a table named Products where the price is greater than 100, you can use the following SQL query: SELECT * FROM Products WHERE price > 100; This query selects all columns from the Products table where the price column has a value greater than 100."

---

#### Explain the concept of normalization and its types.

Why you might get asked this: Understanding the concept of normalization and its types is crucial for ensuring efficient database design and data integrity, which is essential for roles like Database Administrator or Data Architect, for example. How to answer: Define normalization as the process of organizing data to reduce redundancy and improve data integrity. Briefly describe the different normal forms, such as 1NF, 2NF, and 3NF, and their purposes. Provide a simple example to illustrate how normalization is applied in a database. Example answer: "Normalization is the process of organizing data in a database to reduce redundancy and improve data integrity. It involves dividing large tables into smaller, related tables and defining relationships between them to ensure data consistency."

---

#### Write a SQL query to count the number of employees in each department from a table named Employees.

Why you might get asked this: This question evaluates your ability to write aggregate queries, a fundamental skill for roles that involve data analysis and reporting, such as a Data Analyst or Business Intelligence Developer, for example. How to answer: Explain the use of the GROUP BY clause to group records by department. Describe the use of the COUNT function to count the number of employees in each group. Provide a sample query using SELECT Department, COUNT(*) FROM Employees GROUP BY Department. Example answer: "To count the number of employees in each department from a table named Employees, you can use the GROUP BY clause along with the COUNT function. The query would look like this: SELECT Department, COUNT(*) FROM Employees GROUP BY Department;"

---

#### What is a subquery? Provide an example of a subquery in a SELECT statement.

Why you might get asked this: Understanding subqueries and their application in SELECT statements is essential for roles that require complex data retrieval and manipulation, such as a Data Analyst or SQL Developer, for example. How to answer: Define a subquery as a query nested within another query. Explain that subqueries can be used in SELECT, INSERT, UPDATE, or DELETE statements. Provide a simple example, such as SELECT * FROM Employees WHERE Salary > (SELECT AVG(Salary) FROM Employees). Example answer: "A subquery is a query nested within another query, often used to perform operations that require multiple steps. For example, SELECT * FROM Employees WHERE Salary > (SELECT AVG(Salary) FROM Employees) retrieves employees with salaries above the average."

---

#### Write a SQL query to find all customers who have placed more than 5 orders from a table named Orders.

Why you might get asked this: This question tests your ability to write complex SQL queries involving aggregate functions and conditional logic, which are crucial skills for roles that require data analysis and reporting, such as a Data Analyst or SQL Developer, for example. How to answer: Explain the use of the GROUP BY clause to group records by customer. Describe the use of the HAVING clause to filter groups with more than 5 orders. Provide a sample query using SELECT CustomerID FROM Orders GROUP BY CustomerID HAVING COUNT(*) > 5. Example answer: "To find all customers who have placed more than 5 orders from a table named Orders, you can use the GROUP BY clause to group records by customer and the HAVING clause to filter groups with more than 5 orders. The query would look like this: SELECT CustomerID FROM Orders GROUP BY CustomerID HAVING COUNT(*) > 5;"

---

#### Explain the difference between UNION and UNION ALL.

Why you might get asked this: Understanding the difference between UNION and UNION ALL is crucial for roles that require data consolidation and query optimization, such as a Data Analyst or SQL Developer, for example. How to answer: Define UNION as a command that combines the results of two queries and removes duplicate rows. Explain UNION ALL as a command that combines the results of two queries without removing duplicates. Provide a simple example query for each to illustrate the differences. Example answer: "A UNION combines the results of two queries and removes duplicate rows, ensuring each row is unique in the final result set. In contrast, UNION ALL combines the results of two queries without removing duplicates, which can be more efficient when duplicates are not a concern."

---

#### Write a SQL query to update the email address of a customer in a table named Customers.

Why you might get asked this: This question assesses your ability to perform data updates, a fundamental skill for roles that involve database management and maintenance, such as a Database Administrator or SQL Developer, for example. How to answer: Explain the use of the UPDATE statement to modify existing records in the table. Describe the SET clause to specify the new email address. Include the WHERE clause to target the specific customer whose email address needs updating. Example answer: "To update the email address of a customer in a table named Customers, you can use the UPDATE statement along with the SET clause to specify the new email address. The query would look like this: UPDATE Customers SET email = 'newemail@example.com' WHERE customer_id = 1;"

---

#### What are indexes in SQL? How do they improve query performance?

Why you might get asked this: Understanding indexes and their impact on query performance is crucial for optimizing database operations, which is essential for roles that involve database management and optimization, such as a Database Administrator or SQL Developer, for example. How to answer: Define indexes as database objects that improve the speed of data retrieval operations. Explain that indexes work by creating a data structure that allows for faster searches. Highlight that while indexes improve read performance, they can slow down write operations due to the overhead of maintaining the index. Example answer: "Indexes in SQL are special data structures that improve the speed of data retrieval operations on a database table. They work by creating a quick lookup reference for the database, significantly reducing the time it takes to find specific rows."

---

#### Write a SQL query to delete all records from a table named Logs where the created_at date is older than 1 year.

Why you might get asked this: This question evaluates your ability to perform data maintenance tasks, which are crucial for roles that involve database management and optimization, such as a Database Administrator or SQL Developer, for example. How to answer: Explain the use of the DELETE statement to remove records from the table. Describe the WHERE clause to filter records based on the created_at date. Provide a sample query using DELETE FROM Logs WHERE created_at < NOW() - INTERVAL 1 YEAR. Example answer: "To delete all records from a table named Logs where the created_at date is older than 1 year, you can use the following SQL query: DELETE FROM Logs WHERE created_at < NOW() - INTERVAL 1 YEAR; This query ensures that only records older than one year are removed, keeping your table up-to-date."

---

#### Explain the ACID properties in the context of database transactions.

Why you might get asked this: Understanding the ACID properties is crucial for ensuring data integrity and reliability in database transactions, which is essential for roles that involve database management and optimization, such as a Database Administrator or SQL Developer, for example. How to answer: Define ACID as a set of properties that ensure reliable database transactions. Briefly describe each property: Atomicity, Consistency, Isolation, and Durability. Provide a simple example to illustrate how these properties maintain data integrity. Example answer: "ACID properties ensure reliable database transactions by maintaining data integrity. They stand for Atomicity, Consistency, Isolation, and Durability, which collectively guarantee that transactions are processed reliably."

---

#### Write a SQL query to retrieve the top 3 highest-paid employees from a table named Employees.

Why you might get asked this: This question tests your ability to write queries that involve sorting and limiting results, which is crucial for roles that require data analysis and reporting, such as a Data Analyst or SQL Developer, for example. How to answer: Explain the use of the ORDER BY clause to sort the salaries in descending order. Describe the use of the LIMIT clause to restrict the number of rows returned to three. Provide a sample query using SELECT * FROM Employees ORDER BY Salary DESC LIMIT 3. Example answer: "To retrieve the top 3 highest-paid employees from a table named Employees, you can use the ORDER BY clause to sort the salaries in descending order and the LIMIT clause to restrict the number of rows returned to three. The query would look like this: SELECT * FROM Employees ORDER BY Salary DESC LIMIT 3;"

---

#### What is a view in SQL? How is it different from a table?

Why you might get asked this: Understanding the concept of views and their differences from tables is crucial for roles that involve database management and optimization, such as a Database Administrator or SQL Developer, for example. How to answer: Define a view as a virtual table based on the result set of a SQL query. Explain that views do not store data physically but provide a way to simplify complex queries. Highlight that unlike tables, views are dynamic and reflect changes in the underlying data in real-time. Example answer: "A view in SQL is a virtual table created based on the result set of a SQL query. Unlike a table, a view does not store data physically but provides a way to simplify complex queries."

---

#### Write a SQL query to find the total sales amount from a table named Sales grouped by product.

Why you might get asked this: This question evaluates your ability to perform aggregate calculations and group data, which are essential skills for roles that involve data analysis and reporting, such as a Data Analyst or Business Intelligence Developer, for example. How to answer: Explain the use of the SUM function to calculate the total sales amount. Describe the GROUP BY clause to group the results by product. Provide a sample query using SELECT product, SUM(amount) FROM Sales GROUP BY product. Example answer: "To find the total sales amount from a table named Sales grouped by product, you can use the SUM function along with the GROUP BY clause. The query would look like this: SELECT product, SUM(amount) FROM Sales GROUP BY product;"

---

#### Explain the concept of stored procedures and their advantages.

Why you might get asked this: Understanding stored procedures and their advantages is crucial for roles that involve database management and optimization, such as a Database Administrator or SQL Developer, for example. How to answer: Define a stored procedure as a precompiled collection of SQL statements. Explain that stored procedures improve performance by reducing the need for repeated parsing and compilation. Highlight that they enhance security by encapsulating business logic and restricting direct access to data. Example answer: "A stored procedure is a precompiled collection of SQL statements that can be executed as a single unit. They improve performance by reducing the need for repeated parsing and compilation, and enhance security by encapsulating business logic and restricting direct access to data."

---

#### Write a SQL query to find all products that have not been sold from a table named Products and a table named Sales.

Why you might get asked this: This question tests your ability to perform complex data retrieval operations involving multiple tables, which is crucial for roles that require advanced SQL skills, such as a Data Analyst or SQL Developer, for example. How to answer: Explain the use of a subquery to identify products that have been sold. Describe the use of the NOT IN clause to filter out sold products from the Products table. Provide a sample query using SELECT * FROM Products WHERE ProductID NOT IN (SELECT ProductID FROM Sales). Example answer: "To find all products that have not been sold, you can use a subquery to identify sold products and then filter them out from the Products table. The query would look like this: SELECT * FROM Products WHERE ProductID NOT IN (SELECT ProductID FROM Sales);"

---

#### What is the purpose of the GROUP BY clause? Provide an example.

Why you might get asked this: Understanding the purpose of the GROUP BY clause is essential for roles that involve data aggregation and reporting, such as a Data Analyst or Business Intelligence Developer, for example. How to answer: Explain that the GROUP BY clause is used to group rows that have the same values in specified columns. Highlight that it allows aggregate functions like SUM, COUNT, and AVG to be applied to each group. Provide a simple example, such as SELECT department, COUNT(*) FROM Employees GROUP BY department. Example answer: "The GROUP BY clause is used to group rows that have the same values in specified columns, allowing aggregate functions to be applied to each group. For example, SELECT department, COUNT(*) FROM Employees GROUP BY department counts the number of employees in each department."

---

#### Write a SQL query to retrieve the names of employees who have the same job title as 'Manager'.

Why you might get asked this: This question tests your ability to write SQL queries that involve string matching and filtering, which is crucial for roles that require data retrieval and manipulation, such as a Data Analyst or SQL Developer, for example. How to answer: Explain the use of the SELECT statement to retrieve employee names. Describe the WHERE clause to filter employees with the job title 'Manager'. Provide a sample query using SELECT name FROM Employees WHERE job_title = 'Manager'. Example answer: "To retrieve the names of employees who have the same job title as 'Manager', you can use the following SQL query: SELECT name FROM Employees WHERE job_title = 'Manager'; This query selects the names of all employees whose job title is 'Manager' from the Employees table."

---

#### Explain the difference between a clustered index and a non-clustered index.

Why you might get asked this: Understanding the difference between a clustered index and a non-clustered index is crucial for optimizing database performance, which is essential for roles that involve database management and optimization, such as a Database Administrator or SQL Developer, for example. How to answer: Define a clustered index as a type of index that sorts and stores the data rows in the table based on the index key. Explain that a non-clustered index creates a separate structure to store the index and includes a pointer to the data rows. Highlight that a table can have only one clustered index but multiple non-clustered indexes. Example answer: "A clustered index sorts and stores the data rows in the table based on the index key, making data retrieval faster. In contrast, a non-clustered index creates a separate structure to store the index and includes a pointer to the data rows, allowing for multiple non-clustered indexes on a table."

---

#### Write a SQL query to find the average salary of employees in each department from a table named Employees.

Why you might get asked this: This question evaluates your ability to perform aggregate calculations and group data, which are essential skills for roles that involve data analysis and reporting, such as a Data Analyst or Business Intelligence Developer, for example. How to answer: Explain the use of the AVG function to calculate the average salary. Describe the GROUP BY clause to group the results by department. Provide a sample query using SELECT department, AVG(salary) FROM Employees GROUP BY department. Example answer: "To find the average salary of employees in each department from a table named Employees, you can use the AVG function along with the GROUP BY clause. The query would look like this: SELECT department, AVG(salary) FROM Employees GROUP BY department;"

---

#### What is a trigger in SQL? Provide an example of when you might use one.

Why you might get asked this: Understanding triggers and their applications is crucial for automating database tasks and ensuring data integrity, which is essential for roles that involve database management and optimization, such as a Database Administrator or SQL Developer, for example. How to answer: Define a trigger as a special type of stored procedure that automatically executes in response to certain events on a table or view. Explain that triggers can be used to enforce business rules, maintain audit trails, or synchronize tables. Provide an example, such as using a trigger to automatically update a stock quantity in an inventory table when a new order is inserted. Example answer: "A trigger in SQL is a special type of stored procedure that automatically executes in response to certain events on a table or view. For example, you might use a trigger to automatically update a stock quantity in an inventory table when a new order is inserted."

---

#### Write a SQL query to retrieve all distinct values from a column named Category in a table named Products.

Why you might get asked this: This question tests your ability to write queries that retrieve unique values, a fundamental skill for roles that involve data analysis and reporting, such as a Data Analyst or SQL Developer, for example. How to answer: Explain the use of the SELECT DISTINCT statement to retrieve unique values. Describe the FROM clause to specify the table name. Provide a sample query using SELECT DISTINCT Category FROM Products. Example answer: "To retrieve all distinct values from a column named Category in a table named Products, you can use the SELECT DISTINCT statement. The query would look like this: SELECT DISTINCT Category FROM Products;"

---

#### What are window functions and how do they differ from aggregate functions?

Why you might get asked this: Understanding window functions is crucial for advanced data analysis and reporting tasks, which is essential for roles like Data Analyst or Business Intelligence Developer. How to answer: Define window functions as functions that perform calculations across related rows within a result set. Explain that unlike aggregate functions, window functions don't group rows into a single output row. Mention that window functions use the OVER clause to define the window of rows. Example answer: "Window functions perform calculations across a set of related rows without collapsing them into a single row like aggregate functions do. They use the OVER clause to define the window of rows, enabling calculations like running totals, rankings, and moving averages while preserving individual row details."

---

#### Write a SQL query to find the nth highest salary using window functions.

Why you might get asked this: This question tests your understanding of advanced SQL techniques for ranking and ordering data, which is crucial for roles involving complex data analysis. How to answer: Explain the use of the ROW_NUMBER() or DENSE_RANK() window function. Describe how to order the data and filter for the specific rank. Provide a sample query using window functions to find the nth highest salary. Example answer: "To find the nth highest salary using window functions, you can use DENSE_RANK() to rank salaries and filter for the specific position. The query would look like: SELECT * FROM (SELECT *, DENSE_RANK() OVER (ORDER BY salary DESC) as rank FROM Employees) ranked WHERE rank = n;"

---

#### Explain the difference between HAVING and WHERE clauses.

Why you might get asked this: Understanding the distinction between HAVING and WHERE is fundamental for proper query construction, especially important for roles involving data filtering and aggregation. How to answer: Explain that WHERE filters rows before grouping occurs. Describe that HAVING filters groups after GROUP BY has been applied. Mention that HAVING can work with aggregate functions while WHERE cannot. Example answer: "The WHERE clause filters individual rows before any grouping occurs, while the HAVING clause filters groups after the GROUP BY operation. WHERE cannot use aggregate functions, but HAVING can, making it essential for filtering grouped data based on aggregate conditions."

---

#### What is a Common Table Expression (CTE) and when would you use it?

Why you might get asked this: Understanding CTEs is important for writing readable and maintainable complex queries, which is valuable for roles involving advanced SQL development. How to answer: Define CTE as a named temporary result set that exists within the scope of a single statement. Explain that CTEs improve query readability and can be referenced multiple times. Mention use cases like recursive queries, complex joins, and breaking down complex logic. Example answer: "A Common Table Expression (CTE) is a named temporary result set defined using the WITH clause that exists only for the duration of a query. CTEs improve readability, enable recursive operations, and can be referenced multiple times within the same query, making complex queries more maintainable."

---

#### Write a SQL query to find duplicate records in a table.

Why you might get asked this: Identifying duplicate data is a common data quality task essential for roles involving data cleaning and database maintenance. How to answer: Explain using GROUP BY with the columns to check for duplicates. Describe using HAVING with COUNT to filter groups with more than one record. Provide a sample query that identifies duplicate records. Example answer: "To find duplicate records, you can group by the columns that should be unique and use HAVING to filter groups with more than one record: SELECT column1, column2, COUNT() FROM table_name GROUP BY column1, column2 HAVING COUNT() > 1;"

---

#### What is the difference between DELETE, TRUNCATE, and DROP?

Why you might get asked this: Understanding different methods of removing data is crucial for database management and maintenance roles. How to answer: Explain DELETE removes specific rows and can use WHERE clause. Describe TRUNCATE removes all rows but keeps table structure. Mention DROP removes the entire table including structure. Example answer: "DELETE removes specific rows based on conditions and can be rolled back, TRUNCATE removes all rows quickly but cannot be rolled back in most databases, and DROP removes the entire table structure and data permanently. TRUNCATE is faster than DELETE for removing all data."

---

#### How do you handle NULL values in SQL queries?

Why you might get asked this: Proper NULL handling is essential for accurate data analysis and preventing unexpected query results. How to answer: Explain using IS NULL and IS NOT NULL for checking NULL values. Mention functions like COALESCE, ISNULL, or IFNULL for handling NULLs. Describe how NULLs behave in comparisons and aggregate functions. Example answer: "NULL values require special handling using IS NULL or IS NOT NULL operators. Functions like COALESCE can replace NULLs with default values. NULLs in aggregate functions are typically ignored, and any comparison with NULL returns unknown, not true or false."

---

#### Write a SQL query to calculate a running total.

Why you might get asked this: Running totals are common in financial and analytical reports, making this skill valuable for data analysis roles. How to answer: Explain using window functions with the SUM function. Describe the ORDER BY clause within the OVER clause. Provide a sample query showing running total calculation. Example answer: "To calculate a running total, use the SUM window function with an ORDER BY clause: SELECT date, amount, SUM(amount) OVER (ORDER BY date) as running_total FROM sales ORDER BY date;"

---

#### What are the different types of constraints in SQL?

Why you might get asked this: Understanding constraints is fundamental for maintaining data integrity, which is crucial for database design and administration roles. How to answer: List the main constraint types: PRIMARY KEY, FOREIGN KEY, UNIQUE, NOT NULL, CHECK. Briefly explain the purpose of each constraint type. Mention how constraints ensure data integrity and business rules. Example answer: "SQL constraints include PRIMARY KEY (unique identifier), FOREIGN KEY (referential integrity), UNIQUE (no duplicates), NOT NULL (required values), and CHECK (custom validation rules). These constraints ensure data integrity and enforce business rules at the database level."

---

#### Explain the concept of database transactions and isolation levels.

Why you might get asked this: Understanding transactions is crucial for maintaining data consistency, especially important for roles involving financial or critical business data. How to answer: Define a transaction as a unit of work that either completes entirely or fails entirely. Explain the four isolation levels: READ UNCOMMITTED, READ COMMITTED, REPEATABLE READ, SERIALIZABLE. Mention the trade-offs between isolation levels and performance. Example answer: "A database transaction is a logical unit of work that maintains data consistency. Isolation levels control how transaction changes are visible to other concurrent transactions, ranging from READ UNCOMMITTED (lowest isolation, highest concurrency) to SERIALIZABLE (highest isolation, lowest concurrency)."

---

#### Write a SQL query to pivot data from rows to columns.

Why you might get asked this: Data pivoting is essential for creating reports and transforming data for analysis, valuable for business intelligence roles. How to answer: Explain the concept of pivoting data using CASE statements or PIVOT function. Describe how to transform row data into column format. Provide a sample query showing data transformation. Example answer: "To pivot data, you can use CASE statements with aggregate functions: SELECT product, SUM(CASE WHEN month = 'Jan' THEN sales ELSE 0 END) as Jan_Sales, SUM(CASE WHEN month = 'Feb' THEN sales ELSE 0 END) as Feb_Sales FROM sales_data GROUP BY product;"

---

#### What is the difference between RANK(), DENSE_RANK(), and ROW_NUMBER()?

Why you might get asked this: Understanding ranking functions is important for data analysis and reporting tasks that require ordering and positioning data. How to answer: Explain ROW_NUMBER() assigns unique sequential numbers. Describe RANK() leaves gaps after ties. Mention DENSE_RANK() doesn't leave gaps after ties. Example answer: "ROW_NUMBER() assigns unique sequential numbers regardless of ties. RANK() assigns the same rank to tied values but leaves gaps in subsequent rankings. DENSE_RANK() assigns the same rank to tied values without leaving gaps in the sequence."

---

#### How do you optimize SQL query performance?

Why you might get asked this: Query optimization is crucial for maintaining application performance, especially important for senior database roles. How to answer: Mention proper indexing strategies and query structure. Explain analyzing execution plans and identifying bottlenecks. Describe techniques like avoiding SELECT *, using appropriate joins, and limiting result sets. Example answer: "SQL query optimization involves proper indexing, analyzing execution plans, avoiding SELECT *, using appropriate join types, limiting result sets with WHERE clauses, and ensuring statistics are up to date. Regular monitoring and profiling help identify performance bottlenecks."

---

#### What are user-defined functions and how do they differ from stored procedures?

Why you might get asked this: Understanding different database objects is important for advanced database development and maintenance roles. How to answer: Define user-defined functions as reusable code blocks that return values. Explain that functions return values while stored procedures may not. Mention that functions can be used in SELECT statements while procedures cannot. Example answer: "User-defined functions are reusable code blocks that return values and can be used within SQL statements like SELECT queries. Unlike stored procedures, functions must return a value and cannot perform operations like INSERT, UPDATE, or DELETE on the same database."

---

#### Write a SQL query to find the percentage of total sales for each product.

Why you might get asked this: Calculating percentages is common in business analysis and reporting, valuable for analytical roles. How to answer: Explain using window functions to calculate total sales. Describe how to calculate individual product sales as a percentage of total. Provide a sample query showing percentage calculation. Example answer: "To find the percentage of total sales for each product: SELECT product, sales, (sales * 100.0 / SUM(sales) OVER()) as percentage_of_total FROM product_sales;"

---

#### What is the difference between correlated and non-correlated subqueries?

Why you might get asked this: Understanding subquery types is important for writing efficient complex queries, essential for advanced SQL development roles. How to answer: Define non-correlated subqueries as independent of the outer query. Explain correlated subqueries reference columns from the outer query. Mention performance implications of each type. Example answer: "Non-correlated subqueries are independent and execute once, returning results used by the outer query. Correlated subqueries reference the outer query and execute once for each row of the outer query, often making them slower but more flexible for row-by-row comparisons."

---

#### How do you handle date and time operations in SQL?

Why you might get asked this: Date and time manipulation is common in business applications, important for roles involving temporal data analysis. How to answer: Mention common date functions like DATE_ADD, DATEDIFF, EXTRACT. Explain formatting dates and handling time zones. Describe best practices for date storage and querying. Example answer: "Date and time operations use functions like DATE_ADD for arithmetic, DATEDIFF for calculating differences, and EXTRACT for getting specific parts. Always consider time zones, use appropriate data types (DATE, DATETIME, TIMESTAMP), and be careful with date formatting for consistent results."

---

#### Write a SQL query to find records that exist in one table but not in another.

Why you might get asked this: Finding data differences between tables is common in data validation and migration tasks. How to answer: Explain using LEFT JOIN with IS NULL condition. Describe alternative approaches using NOT EXISTS or EXCEPT. Provide sample queries showing different methods. Example answer: "To find records in table A but not in table B, use: SELECT a.* FROM tableA a LEFT JOIN tableB b ON a.id = b.id WHERE b.id IS NULL; Alternatively, use NOT EXISTS: SELECT * FROM tableA WHERE NOT EXISTS (SELECT 1 FROM tableB WHERE tableB.id = tableA.id);"

---

#### What is database denormalization and when would you use it?

Why you might get asked this: Understanding when to denormalize is important for performance optimization in large-scale systems. How to answer: Define denormalization as intentionally introducing redundancy for performance. Explain scenarios where denormalization is beneficial. Mention trade-offs between performance and data integrity. Example answer: "Denormalization intentionally introduces redundancy to improve query performance by reducing joins. It's useful for read-heavy systems, data warehouses, and reporting databases where query speed is more important than storage efficiency, but it requires careful maintenance to ensure data consistency."

---

#### Explain the difference between a primary key and a unique key.

Why you might get asked this: Understanding key constraints is fundamental for database design and data integrity. How to answer: Explain that primary keys cannot be NULL and there can be only one per table. Describe that unique keys can be NULL and there can be multiple per table. Mention their roles in indexing and referential integrity. Example answer: "A primary key uniquely identifies rows, cannot contain NULL values, and there can be only one per table. A unique key also ensures uniqueness but can contain NULL values and there can be multiple unique keys per table. Both automatically create indexes."

---

#### Write a SQL query to find the median value from a column.

Why you might get asked this: Calculating statistical measures like median is important for data analysis roles. How to answer: Explain using window functions with PERCENTILE_CONT or similar functions. Describe alternative approaches using ROW_NUMBER for databases without built-in median functions. Provide sample queries for calculating median. Example answer: "To find the median, use PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY column_name) or for databases without this function: SELECT AVG(salary) FROM (SELECT salary, ROW_NUMBER() OVER (ORDER BY salary) as rn, COUNT(*) OVER() as cnt FROM employees) WHERE rn IN ((cnt+1)/2, (cnt+2)/2);"

---

#### What are the advantages and disadvantages of using views?

Why you might get asked this: Understanding views is important for database design and security implementation. How to answer: List advantages: security, simplification, data abstraction. Mention disadvantages: performance overhead, dependency issues. Explain when views are most beneficial. Example answer: "Views provide security by hiding sensitive columns, simplify complex queries, and offer data abstraction. However, they can have performance overhead, create dependencies, and complex views may not be updatable. They're best for frequently used complex queries and security requirements."

---

#### How do you implement full-text search in SQL?

Why you might get asked this: Full-text search capabilities are important for applications requiring advanced search functionality. How to answer: Explain full-text indexes and search functions like MATCH AGAINST. Mention different search modes (natural language, Boolean). Describe limitations and alternatives. Example answer: "Full-text search uses specialized indexes and functions like MATCH() AGAINST() in MySQL or CONTAINS() in SQL Server. It supports natural language and Boolean search modes, ranking results by relevance. For complex requirements, dedicated search engines like Elasticsearch might be more appropriate."

---

#### Write a SQL query to find the first and last record for each group.

Why you might get asked this: Finding boundary records is common in time-series analysis and reporting. How to answer: Explain using window functions with FIRST_VALUE and LAST_VALUE. Describe alternative approaches using subqueries and joins. Provide sample queries showing different methods. Example answer: "To find first and last records per group: SELECT *, FIRST_VALUE(value) OVER (PARTITION BY group_id ORDER BY date), LAST_VALUE(value) OVER (PARTITION BY group_id ORDER BY date ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) FROM table_name;"

---

#### What is the purpose of the COALESCE function?

Why you might get asked this: Understanding NULL handling functions is important for data quality and accurate reporting. How to answer: Define COALESCE as a function that returns the first non-NULL value. Explain its use in handling NULL values and providing defaults. Provide examples of practical applications. Example answer: "COALESCE returns the first non-NULL value from a list of expressions, making it useful for handling NULL values and providing default values. For example, COALESCE(middle_name, '') returns an empty string if middle_name is NULL, ensuring consistent output formatting."

---

#### Explain the concept of recursive queries and provide an example.

Why you might get asked this: Recursive queries are important for hierarchical data processing, valuable for advanced database development roles. How to answer: Define recursive queries as queries that reference themselves. Explain the structure with anchor and recursive members. Provide an example using hierarchical data like organizational charts. Example answer: "Recursive queries use Common Table Expressions to process hierarchical data by referencing themselves. They consist of an anchor member (base case) and recursive member. Example: WITH RECURSIVE emp_hierarchy AS (SELECT id, name, manager_id, 1 as level FROM employees WHERE manager_id IS NULL UNION ALL SELECT e.id, e.name, e.manager_id, eh.level+1 FROM employees e JOIN emp_hierarchy eh ON e.manager_id = eh.id) SELECT * FROM emp_hierarchy;"

---

#### What are materialized views and how do they differ from regular views?

Why you might get asked this: Understanding materialized views is important for performance optimization in data warehousing and analytics. How to answer: Define materialized views as physical storage of view results. Explain performance benefits and refresh mechanisms. Describe trade-offs with storage and data freshness. Example answer: "Materialized views physically store query results, providing faster access than regular views that execute queries each time. They're ideal for complex aggregations and reporting but require refresh strategies to maintain data currency and consume additional storage space."

---

#### Write a SQL query to calculate year-over-year growth percentage.

Why you might get asked this: Year-over-year calculations are common in business analytics and financial reporting. How to answer: Explain using window functions with LAG to get previous year values. Describe the formula for calculating growth percentage. Provide a sample query showing the calculation. Example answer: "To calculate year-over-year growth: SELECT year, revenue, LAG(revenue) OVER (ORDER BY year) as prev_year_revenue, ((revenue - LAG(revenue) OVER (ORDER BY year)) * 100.0 / LAG(revenue) OVER (ORDER BY year)) as yoy_growth_pct FROM annual_revenue ORDER BY year;"

---

#### How do you handle large dataset queries efficiently?

Why you might get asked this: Optimizing queries for large datasets is crucial for enterprise-level database performance. How to answer: Mention partitioning strategies and proper indexing. Explain query optimization techniques and pagination. Describe using appropriate hardware and configuration. Example answer: "For large datasets, use table partitioning, proper indexing, query optimization with execution plan analysis, pagination for result sets, and consider parallel processing. Also implement appropriate WHERE clauses to limit data scanned and use summary tables for frequently accessed aggregations."

---

#### What is the difference between CHAR and VARCHAR data types?

Why you might get asked this: Understanding data types is fundamental for efficient database design and storage optimization. How to answer: Explain CHAR as fixed-length and VARCHAR as variable-length. Mention storage implications and performance considerations. Describe when to use each type. Example answer: "CHAR is fixed-length and pads shorter values with spaces, while VARCHAR is variable-length and stores only the actual characters. CHAR is faster for fixed-size data but wastes space, while VARCHAR is more storage-efficient but has slight performance overhead for variable-length data."

---

#### Write a SQL query to find gaps in sequential data.

Why you might get asked this: Finding gaps in sequences is common in inventory management and audit scenarios. How to answer: Explain using window functions to identify missing sequences. Describe comparing expected vs actual sequence values. Provide a sample query for gap detection. Example answer: "To find gaps in sequential data: SELECT (LAG(id) OVER (ORDER BY id) + 1) as gap_start, (id - 1) as gap_end FROM table_name WHERE id - LAG(id) OVER (ORDER BY id) > 1;"

---

#### Explain the concept of database partitioning and its types.

Why you might get asked this: Understanding partitioning is important for managing large databases and improving query performance. How to answer: Define partitioning as dividing large tables into smaller manageable pieces. Explain different types: range, list, hash, and composite partitioning. Mention benefits like improved performance and maintenance. Example answer: "Database partitioning divides large tables into smaller, manageable segments based on partition keys. Types include range (date ranges), list (specific values), hash (even distribution), and composite (combination). Benefits include improved query performance, easier maintenance, and parallel processing capabilities."

---

#### What are database locks and how do they work?

Why you might get asked this: Understanding locking mechanisms is crucial for database concurrency and performance management. How to answer: Define locks as mechanisms to control concurrent access to data. Explain different lock types: shared, exclusive, update locks. Mention deadlocks and lock escalation. Example answer: "Database locks control concurrent access to data, preventing conflicts between transactions. Types include shared locks (allow multiple reads), exclusive locks (prevent all other access), and update locks (prevent deadlocks during updates). Proper lock management prevents data corruption while maintaining concurrency."

---

#### Write a SQL query to transpose rows to columns dynamically.

Why you might get asked this: Dynamic transposition is useful for flexible reporting and data presentation. How to answer: Explain challenges of dynamic pivoting without knowing column names. Describe using dynamic SQL or specific database features. Provide an approach using conditional aggregation. Example answer: "Dynamic transposition requires dynamic SQL since column names aren't known beforehand. Example approach: Build the SQL string dynamically based on distinct values in the pivot column, then execute it. Some databases offer PIVOT operators, but most require conditional aggregation with dynamically built CASE statements."

---

#### How do you implement audit trails in SQL databases?

Why you might get asked this: Audit trails are important for compliance and security requirements in enterprise applications. How to answer: Explain using triggers to capture data changes. Mention audit table design with old/new values and metadata. Describe alternative approaches like Change Data Capture. Example answer: "Audit trails track data changes using triggers that insert records into audit tables containing old values, new values, operation type, user, and timestamp. Alternative approaches include Change Data Capture (CDC) features, database logs analysis, or application-level logging for better performance."

---

#### What is the difference between OLTP and OLAP systems?

Why you might get asked this: Understanding different database architectures is important for system design and data architecture roles. How to answer: Define OLTP as transaction-focused systems for daily operations. Explain OLAP as analytics-focused systems for decision support. Mention design differences and optimization strategies. Example answer: "OLTP (Online Transaction Processing) systems handle high-volume transactions with normalized databases optimized for INSERT, UPDATE, DELETE operations. OLAP (Online Analytical Processing) systems are designed for complex queries and reporting with denormalized, dimensional models optimized for SELECT operations and aggregations."

---

#### Write a SQL query to find the top N customers by sales in each region.

Why you might get asked this: Ranking within groups is common in business analytics and competitive analysis. How to answer: Explain using window functions with partitioning. Describe ranking and filtering for top N results. Provide a sample query using ROW_NUMBER or RANK. Example answer: "To find top N customers by sales in each region: SELECT * FROM (SELECT customer, region, sales, ROW_NUMBER() OVER (PARTITION BY region ORDER BY sales DESC) as rn FROM customer_sales) ranked WHERE rn <= N;"

---

#### How do you handle database schema migrations?

Why you might get asked this: Schema migrations are crucial for application deployment and database evolution management. How to answer: Explain version control for database schemas. Mention migration tools and rollback strategies. Describe testing and deployment best practices. Example answer: "Database schema migrations use version-controlled scripts with tools like Flyway or Liquibase. Each migration is numbered sequentially, tested thoroughly, and includes rollback procedures. Best practices include backward compatibility, data migration validation, and coordination with application deployments."

---

#### What are the considerations for choosing appropriate data types?

Why you might get asked this: Proper data type selection affects storage efficiency, performance, and data integrity. How to answer: Mention storage requirements and performance implications. Explain precision needs and range considerations. Describe future scalability and standardization. Example answer: "Data type selection considers storage efficiency, query performance, data range and precision requirements, and future scalability. Choose the smallest appropriate type, consider indexing implications, ensure proper precision for calculations, and maintain consistency across similar fields in the database."

---

#### Write a SQL query to calculate moving averages.

Why you might get asked this: Moving averages are important for trend analysis and financial calculations. How to answer: Explain using window functions with frame specifications. Describe different frame options like ROWS and RANGE. Provide sample queries for different moving average periods. Example answer: "To calculate a moving average: SELECT date, value, AVG(value) OVER (ORDER BY date ROWS BETWEEN 2 PRECEDING AND CURRENT ROW) as moving_avg_3_days FROM sales_data ORDER BY date;"

---

#### How do you implement row-level security in SQL databases?

Why you might get asked this: Row-level security is important for multi-tenant applications and data privacy compliance. How to answer: Explain using security policies and predicates. Mention role-based access control implementation. Describe alternative approaches using views and functions. Example answer: "Row-level security uses security policies with predicates to filter rows based on user context. Implementation involves creating security functions that return filter conditions, then applying them as policies. Alternative approaches include using views with user-based WHERE clauses or application-level filtering."

---

#### What is the purpose of database connection pooling?

Why you might get asked this: Connection pooling is crucial for application performance and resource management. How to answer: Explain reducing connection overhead and resource usage. Mention improved application scalability and performance. Describe configuration considerations and best practices. Example answer: "Database connection pooling reuses existing connections instead of creating new ones for each request, reducing overhead and improving performance. It manages a pool of connections shared among application threads, preventing connection exhaustion and providing better resource utilization and scalability."

---

#### Write a SQL query to find customers who haven't placed orders in the last 6 months.

Why you might get asked this: Identifying inactive customers is important for customer retention and marketing analytics. How to answer: Explain using LEFT JOIN with date filtering. Describe alternative approaches with NOT EXISTS. Provide sample queries showing different methods. Example answer: "To find inactive customers: SELECT c.* FROM customers c LEFT JOIN orders o ON c.customer_id = o.customer_id AND o.order_date >= DATE_SUB(NOW(), INTERVAL 6 MONTH) WHERE o.customer_id IS NULL;"

---

#### How do you handle database backup and recovery strategies?

Why you might get asked this: Backup and recovery planning is critical for database administration and business continuity. How to answer: Explain different backup types: full, incremental, differential. Mention recovery models and point-in-time recovery. Describe testing and automation strategies. Example answer: "Database backup strategies include full backups (complete database), incremental (changes since last backup), and differential (changes since last full backup). Recovery planning involves defining RTO/RPO requirements, implementing automated backup schedules, regular restore testing, and maintaining both local and offsite copies."

---

#### What are the best practices for SQL query writing?

Why you might get asked this: Following best practices is important for maintainable, efficient, and secure database code. How to answer: Mention code formatting, naming conventions, and documentation. Explain performance optimization and security considerations. Describe testing and code review practices. Example answer: "SQL best practices include consistent formatting and naming conventions, avoiding SELECT *, using proper indexing, parameterized queries for security, meaningful aliases, appropriate JOINs, query optimization with execution plans, comprehensive testing, and thorough documentation for complex logic."

---

#### Write a SQL query to find overlapping date ranges.

Why you might get asked this: Finding overlapping periods is common in scheduling, reservation, and temporal data analysis. How to answer: Explain the logic for detecting overlapping intervals. Describe using self-joins or window functions. Provide sample queries for overlap detection. Example answer: "To find overlapping date ranges: SELECT a., b. FROM reservations a JOIN reservations b ON a.id < b.id AND a.start_date <= b.end_date AND a.end_date >= b.start_date;"

---

#### How do you implement database replication and what are its types?

Why you might get asked this: Database replication is important for high availability, scalability, and disaster recovery. How to answer: Explain master-slave and master-master replication. Mention synchronous vs asynchronous replication. Describe use cases and trade-offs. Example answer: "Database replication types include master-slave (read replicas for scaling reads), master-master (bi-directional for high availability), and cluster replication. Synchronous replication ensures consistency but affects performance, while asynchronous replication provides better performance but potential data lag."

---

#### What is database sharding and when would you implement it?

Why you might get asked this: Sharding is important for scaling very large databases beyond single-server capabilities. How to answer: Define sharding as horizontal partitioning across servers. Explain sharding strategies and key selection. Mention complexity and trade-offs. Example answer: "Database sharding horizontally partitions data across multiple servers using a shard key. It's implemented when vertical scaling limits are reached, enabling linear scaling. However, it adds complexity for cross-shard queries, transactions, and requires careful shard key selection to avoid hotspots."

---

#### Write a SQL query to calculate retention rates.

Why you might get asked this: Retention analysis is crucial for understanding customer behavior and business performance. How to answer: Explain defining cohorts and retention periods. Describe calculating percentage of returning users. Provide sample queries for retention calculation. Example answer: "To calculate retention rates: SELECT cohort_month, period_number, COUNT(DISTINCT user_id) * 100.0 / first_month_users as retention_rate FROM user_activity_cohorts GROUP BY cohort_month, period_number ORDER BY cohort_month, period_number;"

---

#### How do you monitor and troubleshoot database performance issues?

Why you might get asked this: Performance monitoring is crucial for maintaining database health and application performance. How to answer: Mention monitoring tools and key metrics. Explain query analysis and execution plans. Describe proactive monitoring and alerting. Example answer: "Database performance monitoring involves tracking metrics like CPU, memory, I/O, and query response times using tools like performance dashboards, slow query logs, and execution plan analysis. Implement alerts for threshold breaches, regular index analysis, and maintain baseline performance metrics for comparison."

---

#### What are database constraints and how do they ensure data integrity?

Why you might get asked this: Understanding constraints is fundamental for maintaining data quality and business rule enforcement. How to answer: List constraint types and their purposes. Explain how constraints prevent invalid data. Mention performance implications and best practices. Example answer: "Database constraints enforce data integrity rules: PRIMARY KEY ensures unique identification, FOREIGN KEY maintains referential integrity, UNIQUE prevents duplicates, NOT NULL requires values, and CHECK validates business rules. They prevent invalid data entry and maintain consistency across the database."

---

#### Write a SQL query to generate a calendar table.

Why you might get asked this: Calendar tables are useful for date-based reporting and analytics applications. How to answer: Explain using recursive CTEs or number sequences. Describe adding date attributes and business logic. Provide sample queries for calendar generation. Example answer: "To generate a calendar table: WITH RECURSIVE calendar AS (SELECT '2024-01-01' as date UNION ALL SELECT DATE_ADD(date, INTERVAL 1 DAY) FROM calendar WHERE date < '2024-12-31') SELECT date, YEAR(date) as year, MONTH(date) as month, DAY(date) as day, DAYNAME(date) as day_name FROM calendar;"

---

#### How do you implement database versioning and change management?

Why you might get asked this: Version control for databases is important for team collaboration and deployment management. How to answer: Explain database migration tools and version control. Mention change scripts and rollback procedures. Describe integration with application deployment. Example answer: "Database versioning uses migration tools like Flyway or Liquibase with version-controlled SQL scripts. Each change is numbered sequentially, includes rollback procedures, and integrates with CI/CD pipelines. This ensures consistent schema evolution across environments and enables reliable deployments."

---

#### What are the security considerations for SQL databases?

Why you might get asked this: Database security is critical for protecting sensitive data and preventing breaches. How to answer: Mention access control, encryption, and SQL injection prevention. Explain audit logging and network security. Describe principle of least privilege and regular security updates. Example answer: "SQL database security includes access control with role-based permissions, encryption at rest and in transit, SQL injection prevention through parameterized queries, comprehensive audit logging, network security with firewalls, regular security updates, and implementing the principle of least privilege for user access."

---

#### Write a SQL query to find the longest consecutive sequence.

Why you might get asked this: Finding consecutive sequences is useful in gaming, finance, and behavioral analysis. How to answer: Explain using window functions to identify sequence breaks. Describe grouping consecutive elements. Provide sample queries for sequence analysis. Example answer: "To find longest consecutive sequence: SELECT MAX(consecutive_count) FROM (SELECT COUNT(*) as consecutive_count FROM (SELECT *, ROW_NUMBER() OVER (ORDER BY value) - ROW_NUMBER() OVER (PARTITION BY value ORDER BY value) as grp FROM sequences) grouped GROUP BY grp) counts;"

---

#### How do you handle time zone considerations in global applications?

Why you might get asked this: Time zone handling is important for international applications and accurate temporal data management. How to answer: Explain storing times in UTC and converting for display. Mention time zone data types and functions. Describe best practices for global applications. Example answer: "Handle time zones by storing all timestamps in UTC and converting to local time zones for display. Use timezone-aware data types like TIMESTAMPTZ, implement proper conversion functions, maintain time zone reference data, and consider daylight saving time changes in business logic."

---

#### What is the difference between database clustering and replication?

Why you might get asked this: Understanding different high-availability architectures is important for system design decisions. How to answer: Define clustering as multiple servers acting as one system. Explain replication as copying data to multiple servers. Mention use cases and implementation differences. Example answer: "Database clustering involves multiple servers working together as a single system with shared storage, providing high availability and load distribution. Replication copies data across separate database instances for read scaling and disaster recovery. Clustering offers automatic failover, while replication requires manual or automated failover management."

---

#### Write a SQL query to implement a recommendation system using collaborative filtering.

Why you might get asked this: Basic recommendation logic is useful for understanding how data-driven features work in applications. How to answer: Explain finding users with similar preferences. Describe recommending items based on similar users' choices. Provide sample queries for collaborative filtering. Example answer: "Basic collaborative filtering: SELECT p2.product_id, COUNT(*) as similarity_score FROM purchases p1 JOIN purchases p2 ON p1.user_id = p2.user_id JOIN purchases p3 ON p3.product_id = p1.product_id WHERE p3.user_id = @target_user AND p2.product_id NOT IN (SELECT product_id FROM purchases WHERE user_id = @target_user) GROUP BY p2.product_id ORDER BY similarity_score DESC;"

---

#### How do you implement data archiving strategies?

Why you might get asked this: Data archiving is important for managing database size and maintaining performance while preserving historical data. How to answer: Explain identifying data for archiving based on age or usage. Mention archival storage options and retrieval methods. Describe automation and compliance considerations. Example answer: "Data archiving strategies involve identifying old or infrequently accessed data, moving it to cheaper storage while maintaining accessibility. Implement automated archiving jobs based on date or usage patterns, use compressed storage formats, maintain indexes for archived data retrieval, and ensure compliance with data retention policies."

---

#### What are the considerations for database capacity planning?

Why you might get asked this: Capacity planning is crucial for maintaining database performance and avoiding resource constraints. How to answer: Mention monitoring current usage trends and growth patterns. Explain projecting future requirements and resource needs. Describe planning for peak loads and scalability. Example answer: "Database capacity planning involves monitoring current storage, CPU, memory, and I/O usage, analyzing growth trends, projecting future requirements based on business growth, planning for peak loads, considering data retention policies, and implementing monitoring alerts for proactive scaling decisions."

---

#### Write a SQL query to detect anomalies in time-series data.

Why you might get asked this: Anomaly detection is important for monitoring systems and identifying unusual patterns in business data. How to answer: Explain using statistical functions to identify outliers. Describe comparing current values to historical averages. Provide sample queries for anomaly detection. Example answer: "To detect anomalies using standard deviation: SELECT *, CASE WHEN ABS(value - avg_value) > 2 * stddev_value THEN 'Anomaly' ELSE 'Normal' END as status FROM (SELECT *, AVG(value) OVER (ORDER BY timestamp ROWS BETWEEN 30 PRECEDING AND 1 PRECEDING) as avg_value, STDDEV(value) OVER (ORDER BY timestamp ROWS BETWEEN 30 PRECEDING AND 1 PRECEDING) as stddev_value FROM time_series_data) analyzed;"

---

#### How do you implement database disaster recovery procedures?

Why you might get asked this: Disaster recovery planning is critical for business continuity and data protection. How to answer: Explain backup strategies and offsite storage. Mention recovery time and point objectives. Describe testing and documentation requirements. Example answer: "Disaster recovery involves regular backups with offsite storage, defining RTO/RPO objectives, maintaining secondary sites or cloud infrastructure, implementing automated failover procedures, regular disaster recovery testing, comprehensive documentation, and staff training for emergency procedures."

---

#### What are the emerging trends in database technology?

Why you might get asked this: Understanding technology trends is important for making informed architectural decisions and career development. How to answer: Mention cloud-native databases and serverless architectures. Explain NewSQL and distributed database systems. Describe AI/ML integration and real-time analytics. Example answer: "Emerging database trends include cloud-native and serverless databases for auto-scaling, NewSQL systems combining ACID guarantees with horizontal scaling, AI/ML integration for automated optimization, real-time analytics with streaming databases, multi-model databases supporting various data types, and edge computing databases for IoT applications."

---

#### Write a SQL query to implement a simple rating system with weighted averages.

Why you might get asked this: Rating systems are common in e-commerce and review applications. How to answer: Explain weighting ratings by factors like recency or reviewer credibility. Describe calculating weighted averages and handling edge cases. Provide sample queries for rating calculations. Example answer: "To implement weighted ratings: SELECT product_id, SUM(rating * weight) / SUM(weight) as weighted_avg_rating FROM (SELECT product_id, rating, CASE WHEN reviewer_level = 'expert' THEN 2.0 WHEN review_date > DATE_SUB(NOW(), INTERVAL 30 DAY) THEN 1.5 ELSE 1.0 END as weight FROM reviews) weighted_reviews GROUP BY product_id;"

---

#### How do you optimize database storage and reduce costs?

Why you might get asked this: Storage optimization is important for managing database costs and improving performance. How to answer: Mention data compression and archiving strategies. Explain proper data type selection and index optimization. Describe partitioning and storage tiering approaches. Example answer: "Database storage optimization involves implementing data compression, choosing appropriate data types, archiving old data, optimizing indexes by removing unused ones, implementing table partitioning, using storage tiering for different data access patterns, and regularly analyzing storage usage patterns to identify optimization opportunities."

---

#### What are the key considerations for migrating from legacy database systems?

Why you might get asked this: Database migration is common in modernization projects and requires careful planning and execution. How to answer: Explain assessing current system and defining migration strategy. Mention data mapping, testing, and rollback procedures. Describe minimizing downtime and ensuring data integrity. Example answer: "Legacy database migration requires thorough assessment of current system, data mapping and transformation planning, choosing appropriate migration tools, extensive testing with production-like data, implementing rollback procedures, planning for minimal downtime, training staff on new systems, and post-migration monitoring to ensure performance and data integrity."

---

#### SELECT w1.id

FROM weather_197 w1 JOIN weather_197 w2 ON w1.record_date-1=w2.record_date AND w1.temperature>w2.temperature;

---

#### -- Question 9

-- Table: Activity -- +--------------+---------+ -- | Column Name  | Type    | -- +--------------+---------+ -- | player_id    | int     | -- | device_id    | int     | -- | event_date   | date    | -- | games_played | int     | -- +--------------+---------+ -- (player_id, event_date) is the primary key of this table. -- This table shows the activity of players of some game. -- Each row is a record of a player who logged in and played a number of games (possibly 0) before logging out on some day using some device. -- Write a SQL query that reports the device that is first logged in for each player. -- The query result format is in the following example: -- Activity table: -- +-----------+-----------+------------+--------------+ -- | player_id | device_id | event_date | games_played | -- +-----------+-----------+------------+--------------+ -- | 1         | 2         | 2016-03-01 | 5            | -- | 1         | 2         | 2016-05-02 | 6            | -- | 2         | 3         | 2017-06-25 | 1            | -- | 3         | 1         | 2016-03-02 | 0            | -- | 3         | 4         | 2018-07-03 | 5            | -- +-----------+-----------+------------+--------------+ -- Result table: -- +-----------+-----------+ -- | player_id | device_id | -- +-----------+-----------+ -- | 1         | 2         | -- | 2         | 3         | -- | 3         | 1         | -- +-----------+-----------+ -- Solution With table1 as ( Select player_id, device_id, Rank() OVER(partition by player_id order by event_date) as rk From Activity ) Select t.player_id, t.device_id from table1 as t where t.rk=1

---

#### -- Table Name for Test-Case 1: terms_2118

-- Table Name for Test-Case 2: terms_2118_tc_2 WITH terms AS ( SELECT power,ABS(factor) AS factor, (CASE WHEN factor < 0 THEN '-' ELSE '+' END) AS sign, (CASE WHEN power = 1 THEN CONCAT(ABS(factor),'X') WHEN power = 0 THEN ABS(factor)::TEXT ELSE CONCAT(ABS(factor),'X^',power) END) AS term FROM terms_2118 ) SELECT CONCAT(STRING_AGG(CONCAT(sign,term),'' ORDER BY power DESC),'=0') AS equation FROM terms; -- Solution of the follow-up question (Table : terms_2118_tc_3) WITH grouped_terms AS ( SELECT power,SUM(factor) AS factor FROM terms_2118_tc_3 GROUP BY power ), terms AS ( SELECT power,ABS(factor) AS factor, (CASE WHEN factor < 0 THEN '-' ELSE '+' END) AS sign, (CASE WHEN power = 1 THEN CONCAT(ABS(factor),'X') WHEN power = 0 THEN ABS(factor)::TEXT ELSE CONCAT(ABS(factor),'X^',power) END) AS term FROM grouped_terms ) SELECT CONCAT(STRING_AGG(CONCAT(sign,term),'' ORDER BY power DESC),'=0') AS equation FROM terms;

---

#### SELECT ROUND(CAST(SUM(item_count * order_occurrences) / SUM(order_occurrences) AS NUMERIC), 1) AS mean

FROM items_per_order;

---

#### SELECT id,

SUM(CASE WHEN month = 'Jan' THEN revenue ELSE NULL END) AS Jan_Revenue, SUM(CASE WHEN month = 'Feb' THEN revenue ELSE NULL END) AS Feb_Revenue, SUM(CASE WHEN month = 'Mar' THEN revenue ELSE NULL END) AS Mar_Revenue, SUM(CASE WHEN month = 'Apr' THEN revenue ELSE NULL END) AS Apr_Revenue, SUM(CASE WHEN month = 'May' THEN revenue ELSE NULL END) AS May_Revenue, SUM(CASE WHEN month = 'Jun' THEN revenue ELSE NULL END) AS Jun_Revenue, SUM(CASE WHEN month = 'Jul' THEN revenue ELSE NULL END) AS Jul_Revenue, SUM(CASE WHEN month = 'Aug' THEN revenue ELSE NULL END) AS Aug_Revenue, SUM(CASE WHEN month = 'Sep' THEN revenue ELSE NULL END) AS Sep_Revenue, SUM(CASE WHEN month = 'Oct' THEN revenue ELSE NULL END) AS Oct_Revenue, SUM(CASE WHEN month = 'Nov' THEN revenue ELSE NULL END) AS Nov_Revenue, SUM(CASE WHEN month = 'Dec' THEN revenue ELSE NULL END) AS Dec_Revenue FROM department_1179 GROUP BY id ORDER BY id; -- Extra (SELECT id::TEXT, SUM(CASE WHEN month = 'Jan' THEN revenue ELSE 0 END) AS Jan_Revenue, SUM(CASE WHEN month = 'Feb' THEN revenue ELSE 0 END) AS Feb_Revenue, SUM(CASE WHEN month = 'Mar' THEN revenue ELSE 0 END) AS Mar_Revenue, SUM(revenue) AS Total FROM department_1179 GROUP BY id) UNION (SELECT NULL, SUM(CASE WHEN month = 'Jan' THEN revenue ELSE 0 END) AS JTR, SUM(CASE WHEN month = 'Feb' THEN revenue ELSE 0 END) AS FTR, SUM(CASE WHEN month = 'Mar' THEN revenue ELSE 0 END) AS MTR, SUM(revenue) AS TR FROM department_1179 GROUP BY 1) ORDER BY 1;

---

#### WITH ranked_genders AS (

SELECT *, RANK() OVER (PARTITION BY gender ORDER BY user_id) AS rnk, CASE WHEN gender = 'female' THEN 0 WHEN gender = 'other' THEN 1 ELSE 2 END AS rnk2 FROM genders_2308 ) SELECT user_id,gender FROM ranked_genders ORDER BY rnk,rnk2;

---

#### SELECT ROUND((COUNT(CASE WHEN order_date = customer_pref_delivery_date THEN 1 ELSE NULL END)::NUMERIC/COUNT(*))*100,2)

AS immediate_percentage FROM delivery_1173;

---

#### SELECT TO_CHAR(order_date,'YYYY-MM') AS month,

COUNT(order_id) AS order_count, COUNT(DISTINCT customer_id) AS customer_count FROM orders_1565 WHERE invoice > 20 GROUP BY TO_CHAR(order_date,'YYYY-MM');

---

#### SELECT user_id,INITCAP(name)

FROM users_1667 ORDER BY user_id;

---

#### SELECT e.*,

CASE WHEN operator = '=' THEN v1.value = v2.value WHEN operator = '>' THEN v1.value > v2.value WHEN operator = '<' THEN v1.value < v2.value END AS value FROM expressions_1440 e INNER JOIN variables_1440 v1 ON e.left_operand = v1.name INNER JOIN variables_1440 v2 ON e.right_operand = v2.name;

---

#### WITH airports AS (

SELECT departure_airport AS airport,flights_count FROM flights_2112 UNION ALL SELECT arrival_airport AS airport,flights_count FROM flights_2112 ), grouped_airport AS ( SELECT airport,SUM(flights_count) AS flights_count FROM airports GROUP BY airport ) SELECT airport FROM grouped_airport WHERE flights_count = (SELECT MAX(flights_count) FROM grouped_airport);

---

#### -- Question 44

-- Table: Department -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | id            | int     | -- | revenue       | int     | -- | month         | varchar | -- +---------------+---------+ -- (id, month) is the primary key of this table. -- The table has information about the revenue of each department per month. -- The month has values in ["Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"]. -- Write an SQL query to reformat the table such that there is a department id column and a revenue column for each month. -- The query result format is in the following example: -- Department table: -- +------+---------+-------+ -- | id   | revenue | month | -- +------+---------+-------+ -- | 1    | 8000    | Jan   | -- | 2    | 9000    | Jan   | -- | 3    | 10000   | Feb   | -- | 1    | 7000    | Feb   | -- | 1    | 6000    | Mar   | -- +------+---------+-------+ -- Result table: -- +------+-------------+-------------+-------------+-----+-------------+ -- | id   | Jan_Revenue | Feb_Revenue | Mar_Revenue | ... | Dec_Revenue | -- +------+-------------+-------------+-------------+-----+-------------+ -- | 1    | 8000        | 7000        | 6000        | ... | null        | -- | 2    | 9000        | null        | null        | ... | null        | -- | 3    | null        | 10000       | null        | ... | null        | -- +------+-------------+-------------+-------------+-----+-------------+ -- Note that the result table has 13 columns (1 for the department id + 12 for the months). -- Solution select id, sum(if(month='Jan',revenue,null)) as Jan_Revenue, sum(if(month='Feb',revenue,null)) as Feb_Revenue, sum(if(month='Mar',revenue,null)) as Mar_Revenue, sum(if(month='Apr',revenue,null)) as Apr_Revenue, sum(if(month='May',revenue,null)) as May_Revenue, sum(if(month='Jun',revenue,null)) as Jun_Revenue, sum(if(month='Jul',revenue,null)) as Jul_Revenue, sum(if(month='Aug',revenue,null)) as Aug_Revenue, sum(if(month='Sep',revenue,null)) as Sep_Revenue, sum(if(month='Oct',revenue,null)) as Oct_Revenue, sum(if(month='Nov',revenue,null)) as Nov_Revenue, sum(if(month='Dec',revenue,null)) as Dec_Revenue from Department group by id

---

#### WITH monthly_income_data AS (

SELECT t.account_id,EXTRACT(MONTH FROM day) AS mnth,SUM(amount) AS total_income FROM transactions_1843 t INNER JOIN accounts_1843 a ON t.account_id = a.account_id AND t.type = 'Creditor' GROUP BY t.account_id,EXTRACT(MONTH FROM day),a.max_income HAVING SUM(amount)>a.max_income ) SELECT DISTINCT m1.account_id FROM monthly_income_data m1 INNER JOIN monthly_income_data m2 ON m1.account_id=m2.account_id AND m1.mnth + 1 = m2.mnth;

---

#### What is the difference between RANK(), DENSE_RANK(), and ROW_NUMBER()?

ROW_NUMBER() assigns a unique sequential number to each row. RANK() gives the same rank to ties but leaves gaps. DENSE_RANK() gives the same rank to ties without leaving gaps. SELECT name, salary, RANK() OVER (ORDER BY salary DESC) AS rank, DENSE_RANK() OVER (ORDER BY salary DESC) AS dense_rank, ROW_NUMBER() OVER (ORDER BY salary DESC) AS row_num FROM employees;

---

#### How do you find the second highest salary from an Employee table?

SELECT MAX(salary) AS SecondHighest FROM employees WHERE salary < (SELECT MAX(salary) FROM employees); Or using LIMIT ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî - SELECT DISTINCT salary FROM employees ORDER BY salary DESC LIMIT 1 OFFSET 1;

---

#### Explain Common Table Expressions (CTEs) and their use.

CTEs are temporary result sets used to simplify complex joins and subqueries. WITH DeptTotal AS ( SELECT department_id, SUM(salary) AS total_salary FROM employees GROUP BY department_id ) SELECT e.name, e.salary, d.total_salary FROM employees e JOIN DeptTotal d ON e.department_id = d.department_id;

---

#### How do you detect and remove duplicate records from a table?

To find duplicates: SELECT name, COUNT(*) FROM employees GROUP BY name HAVING COUNT(*) > 1; To delete duplicates (keeping the lowest ID): DELETE FROM employees WHERE id NOT IN ( SELECT MIN(id) FROM employees GROUP BY name, department_id, salary );

---

#### What is a window function? Give an example.

A window function performs a calculation across a set of table rows related to the current row. Example: Running Total SELECT name, salary, SUM(salary) OVER (PARTITION BY department_id ORDER BY salary) AS running_total FROM employees;

---

#### Write a query to pivot data in SQL.

Using CASE WHEN: SELECT department_id, SUM(CASE WHEN gender = ‚ÄòM‚Äô THEN 1 ELSE 0 END) AS male_count, SUM(CASE WHEN gender = ‚ÄòF‚Äô THEN 1 ELSE 0 END) AS female_count FROM employees GROUP BY department_id;

---

#### Explain the difference between INNER JOIN, LEFT JOIN, RIGHT JOIN, and FULL JOIN.

INNER JOIN: Returns matching rows. LEFT JOIN: Returns all from the left table, and matched rows from the right. RIGHT JOIN: All from the right table, and matched from the left. FULL JOIN: All rows when there‚Äôs a match in one of the tables.

---

#### What is the use of EXISTS vs IN vs JOIN?

IN works on a list of values. EXISTS returns true if subquery returns rows. JOIN merges rows from multiple tables. EXISTS is faster than IN in correlated subqueries with large data sets. SELECT name FROM employees e WHERE EXISTS ( SELECT 1 FROM departments d WHERE d.manager_id = e.id );

---

#### What is a recursive CTE?

Used to query hierarchical data like org charts. WITH RECURSIVE EmployeeHierarchy AS ( SELECT id, name, manager_id FROM employees WHERE manager_id IS NULL UNION ALL SELECT e.id, e.name, e.manager_id FROM employees e INNER JOIN EmployeeHierarchy eh ON e.manager_id = eh.id ) SELECT * FROM EmployeeHierarchy;

---

#### How would you optimize a slow SQL query?

Use EXPLAIN to analyze. Add indexes on filtered/joined columns. Avoid **SELECT ***; select only required columns. Use CTEs or temp tables for complex subqueries. Minimize use of functions in WHERE clause.

---

#### What is the difference between CROSS JOIN and INNER JOIN?

CROSS JOIN: Returns the Cartesian product of two tables. No condition is used. INNER JOIN: Returns only matching rows based on a join condition. ‚Äî CROSS JOIN SELECT * FROM employees CROSS JOIN departments; ‚Äî INNER JOIN SELECT * FROM employees INNER JOIN departments ON employees.department_id = departments.id;

---

#### How do you calculate a rolling average using SQL?

SELECT name, salary, AVG(salary) OVER (ORDER BY hire_date ROWS BETWEEN 2 PRECEDING AND CURRENT ROW) AS rolling_avg FROM employees; This gives a 3-row moving average (current row + 2 previous rows).

---

#### Explain MERGE (aka UPSERT) statement.

Used to insert, update, or delete records based on conditions. MERGE INTO target_table AS target USING source_table AS source ON target.id = source.id WHEN MATCHED THEN UPDATE SET target.name = source.name WHEN NOT MATCHED THEN INSERT (id, name) VALUES (source.id, source.name);

---

#### How do you find gaps in a sequence?

Suppose you have employee IDs and want to find missing ones: SELECT (t1.id + 1) AS start_gap FROM employees t1 LEFT JOIN employees t2 ON t1.id + 1 = t2.id WHERE t2.id IS NULL;

---

#### How do you rank items within groups in SQL (e.g., top 3 per department)?

SELECT * FROM ( SELECT name, department_id, salary, RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) AS dept_rank FROM employees ) ranked WHERE dept_rank <= 3;

---

#### How do you handle NULLs in aggregations?

Use COALESCE or default values: SELECT department_id, SUM(COALESCE(salary, 0)) AS total_salary FROM employees GROUP BY department_id;

---

#### Difference between DELETE, TRUNCATE, and DROP?

Press enter or click to view image in full size

---

#### How do you perform full outer join in MySQL (which doesn‚Äôt support it directly)?

SELECT * FROM table1 LEFT JOIN table2 ON table1.id = table2.id UNION SELECT * FROM table1 RIGHT JOIN table2 ON table1.id = table2.id;

---

#### What is the use of LAG() and LEAD()?

LAG(): Get value from a previous row. LEAD(): Get value from a following row. SELECT name, salary, LAG(salary, 1) OVER (ORDER BY hire_date) AS prev_salary, LEAD(salary, 1) OVER (ORDER BY hire_date) AS next_salary FROM employees;

---

#### What is a correlated subquery?

A subquery that depends on the outer query for its value. SELECT name, salary FROM employees e WHERE salary > ( SELECT AVG(salary) FROM employees WHERE department_id = e.department_id );

---

#### What is the difference between HAVING and WHERE clauses?

WHERE filters rows before grouping. HAVING filters rows after grouping (used with aggregates). ‚Äî Example SELECT department_id, COUNT(*) AS emp_count FROM employees WHERE status = ‚ÄòActive‚Äô GROUP BY department_id HAVING COUNT(*) > 5;

---

#### What are indexes? What are their types and trade-offs?

Indexes speed up query lookups by creating a data structure (usually B-tree). Types: Single-column index Composite index Unique index Full-text index Bitmap index (for low-cardinality columns) Trade-offs: Faster reads. Slower inserts/updates/deletes. Consumes storage.

---

#### How do you detect slow queries in a SQL database?

Use EXPLAIN or EXPLAIN ANALYZE. Use Query Execution Plan to see: Full Table Scans Missing Indexes High Cost Steps EXPLAIN SELECT * FROM employees WHERE salary > 100000;

---

#### What‚Äôs the difference between normalization and denormalization?

Press enter or click to view image in full size

---

#### What is the difference between UNION, UNION ALL, INTERSECT, and EXCEPT?

Press enter or click to view image in full size

---

#### How do you implement pagination in SQL?

‚Äî For PostgreSQL/MySQL SELECT * FROM employees ORDER BY name LIMIT 10 OFFSET 20; ‚Äî For SQL Server SELECT * FROM ( SELECT *, ROW_NUMBER() OVER (ORDER BY name) AS rn FROM employees ) AS sub WHERE rn BETWEEN 21 AND 30;

---

#### How can you pivot and unpivot data in SQL Server?

‚Äî PIVOT example SELECT * FROM ( SELECT department, gender FROM employees ) AS source PIVOT ( COUNT(gender) FOR gender IN ([M], [F]) ) AS pivoted;

---

#### How do you remove duplicate rows but keep the most recent based on a timestamp?

DELETE FROM employees WHERE id NOT IN ( SELECT MAX(id) FROM employees GROUP BY email );

---

#### How do you perform case-insensitive searches in SQL?

SELECT * FROM employees WHERE LOWER(name) = ‚Äòjohn doe‚Äô; Or using ILIKE in PostgreSQL: SELECT * FROM employees WHERE name ILIKE ‚Äòjohn%‚Äô;

---

#### What are materialized views and how are they different from regular views?

Feature

---

#### WITH RECURSIVE max_id AS(

SELECT MAX(customer_id) AS mx_id FROM customers_1613 ), cte AS ( SELECT 1 AS id UNION ALL SELECT id+1 AS id FROM cte c INNER JOIN max_id m ON true WHERE c.id<m.mx_id ) SELECT ct.id AS ids FROM cte ct LEFT JOIN customers_1613 c ON ct.id = c.customer_id WHERE c.customer_id IS NULL ORDER BY ids;

---

#### -- Table Name for Test-Case 1: candidates_2004_tc_2

-- Table Name for Test-Case 2: candidates_2004 WITH seniors AS ( SELECT *, SUM(salary) OVER (ORDER BY salary,employee_id) AS occupied_budget, 70000-SUM(salary) OVER (ORDER BY salary,employee_id) AS remaining_budget FROM candidates_2004_tc_2 WHERE experience = 'Senior' ), left_budget AS ( SELECT COALESCE(MIN(remaining_budget),70000) AS budget FROM seniors WHERE remaining_budget >= 0 ), juniors AS ( SELECT c.*, SUM(c.salary) OVER (ORDER BY c.salary,c.employee_id) AS occupied_budget, lb.budget-SUM(c.salary) OVER (ORDER BY c.salary,c.employee_id) AS remaining_budget FROM candidates_2004_tc_2 c CROSS JOIN left_budget lb WHERE experience = 'Junior' ), hired_candidates AS ( SELECT employee_id,experience FROM juniors WHERE remaining_budget >= 0 UNION SELECT employee_id,experience FROM seniors WHERE remaining_budget >= 0 UNION SELECT NULL,'Senior' UNION SELECT NULL,'Junior' ) SELECT experience,COALESCE(COUNT(employee_id),0) FROM hired_candidates GROUP BY experience;

---

#### WITH order_counts AS (

SELECT product_id,EXTRACT(year FROM purchase_date) AS yr,COUNT(order_id) AS order_count FROM orders_2292 GROUP BY product_id,EXTRACT(year FROM purchase_date) HAVING COUNT(order_id) >= 3 ORDER BY 1,2 ) SELECT DISTINCT oc1.product_id FROM order_counts oc1 INNER JOIN order_counts oc2 ON oc1.product_id = oc2.product_id AND oc1.yr+1 = oc2.yr;

---

#### -- Question 11

-- Write a SQL query to find all duplicate emails in a table named Person. -- +----+---------+ -- | Id | Email   | -- +----+---------+ -- | 1  | a@b.com | -- | 2  | c@d.com | -- | 3  | a@b.com | -- +----+---------+ -- For example, your query should return the following for the above table: -- +---------+ -- | Email   | -- +---------+ -- | a@b.com | -- +---------+ -- Solution Select Email from (Select Email, count(Email) from person group by Email having count(Email)>1) a

---

#### -- Question 56

-- Mary is a teacher in a middle school and she has a table seat storing students' names and their corresponding seat ids. -- The column id is continuous increment. -- Mary wants to change seats for the adjacent students. -- Can you write a SQL query to output the result for Mary? -- +---------+---------+ -- |    id   | student | -- +---------+---------+ -- |    1    | Abbot   | -- |    2    | Doris   | -- |    3    | Emerson | -- |    4    | Green   | -- |    5    | Jeames  | -- +---------+---------+ -- For the sample input, the output is: -- +---------+---------+ -- |    id   | student | -- +---------+---------+ -- |    1    | Doris   | -- |    2    | Abbot   | -- |    3    | Green   | -- |    4    | Emerson | -- |    5    | Jeames  | -- +---------+---------+ -- Solution select row_number() over (order by (if(id%2=1,id+1,id-1))) as id, student from seat

---

#### -- Question 29

-- Table: Sales -- +-------------+-------+ -- | Column Name | Type  | -- +-------------+-------+ -- | sale_id     | int   | -- | product_id  | int   | -- | year        | int   | -- | quantity    | int   | -- | price       | int   | -- +-------------+-------+ -- sale_id is the primary key of this table. -- product_id is a foreign key to Product table. -- Note that the price is per unit. -- Table: Product -- +--------------+---------+ -- | Column Name  | Type    | -- +--------------+---------+ -- | product_id   | int     | -- | product_name | varchar | -- +--------------+---------+ -- product_id is the primary key of this table. -- Write an SQL query that reports the total quantity sold for every product id. -- The query result format is in the following example: -- Sales table: -- +---------+------------+------+----------+-------+ -- | sale_id | product_id | year | quantity | price | -- +---------+------------+------+----------+-------+ -- | 1       | 100        | 2008 | 10       | 5000  | -- | 2       | 100        | 2009 | 12       | 5000  | -- | 7       | 200        | 2011 | 15       | 9000  | -- +---------+------------+------+----------+-------+ -- Product table: -- +------------+--------------+ -- | product_id | product_name | -- +------------+--------------+ -- | 100        | Nokia        | -- | 200        | Apple        | -- | 300        | Samsung      | -- +------------+--------------+ -- Result table: -- +--------------+----------------+ -- | product_id   | total_quantity | -- +--------------+----------------+ -- | 100          | 22             | -- | 200          | 15             | -- +--------------+----------------+ -- Solution Select a.product_id, sum(a.quantity) as total_quantity from sales a join product b on a.product_id = b.product_id group by a.product_id

---

#### What is the difference between a population and a sample?

A population represents the entirety of all items that are being studied. A sample is a finite subset of the population that is selected to represent the entire group. A sample is usually selected because the population is too large or costly to study in its entirety. Population and sample An example of population data is a census, and a good example of a sample is a survey.

---

#### What is the difference between inferential and descriptive statistics?

Descriptive statistics describes some sample or population. Inferential statistics attempts to infer from some sample to the larger population. inferential and descriptive statistics

---

#### What are quantitative and qualitative data?

Quantitative data are measures of values or counts and are expressed as numbers. Quantitative data refers to numerical data (e.g. how many, how much, or how often). Qualitative data are measures of ‚Äòtypes‚Äô and may be represented by a name, symbol, or a number code. Qualitative data is also known as categorical data.

---

#### What is the meaning of standard deviation?

Standard deviation is a statistic that measures the dispersion of a dataset relative to its mean. It is the average amount of variability in your dataset. It tells you, on average, how far each value lies from the mean. A high standard deviation means that values are generally far from the mean, while a low standard deviation indicates that values are clustered close to the mean. The standard deviation is calculated as the square root of variance by determining each data point‚Äôs deviation relative to the mean. standard deviation formula

---

#### What is the difference between long format and wide format data?

A dataset can be written in two different formats: wide and long. Wide format is where we have a single row for every data point with multiple columns to hold the values of various attributes. The long format is where for each data point we have as many rows as the number of attributes and each row contains the value of a particular attribute for a given data point. long format and wide format data

---

#### Give an example where the median is a better measure than the mean

The median is a better measure of central tendency than the mean when the distribution of data values is skewed or when there are clear outliers.

---

#### How do you calculate the needed sample size?

To calculate the sample size needed for a survey or experiment: Define the population size: The first thing is to determine the total number of your target demographic. If you are dealing with a larger population, you can approximate the total population between several educated guesses. Decide on a margin of error: Also known as a ‚Äúconfidence interval‚Äù. The margin of error indicates how much of a difference you are willing to allow between your sample mean and the mean of the population. Choose a confidence level: Your confidence level indicates how assured you are that the actual mean will fall within your chosen margin of error. The most common confidence levels are 90%, 95%, and 99%. Your specified confidence level corresponds with a z-score. Z-scores for the three most common confidence levels are: 90% = 1.645 95% = 1.96 99% = 2.576

---

#### Calculate your sample size: Finally, you can use these values to calculate the sample size. You can do this by using the formula or by using a sample size using a calculator online.

Calculation of sample size

---

#### What are the types of sampling in Statistics?

The four main types of data sampling in Statistics are: Simple random sampling: This method involves pure random division. Each individual has the same probability of being chosen to be a part of the sample. simple random sampling

---

#### Stratified sampling: This method involves dividing the population into unique groups that represent the entire population. While sampling, these groups can be organized and then drawn a sample from each group separately.

cluster sampling

---

#### Systematic sampling: This sampling method involves choosing the sample members from a larger according to a random starting point but with a fixed, periodic interval called sampling interval. The sampling interval is calculated by diving the population by the desired sample size. This type of sampling method has a predefined range, hence the least time-consuming.

systematic sampling

---

#### What is Bessel‚Äôs correction?

In statistics, Bessel‚Äôs correction is the use of n-1 instead of n in several formulas, including the sample variance and standard deviation, where n is the number of observations in a sample. This method corrects the bias in the estimation of the population variance. It also partially corrects the bias in the estimation of the population standard deviation, thereby, providing more accurate results.

---

#### What do you understand by the term Normal Distribution?

Normal distribution, also known as the Gaussian distribution, is a bell-shaped frequency distribution curve. Most of the data values in a normal distribution tend to cluster around the mean. Normal distribution

---

#### What is the assumption of normality?

This assumption of normality dictates that if many independent random samples are collected from a population and some value of interest (like the sample mean) is calculated, and then a histogram is created to visualize the distribution of sample means, a normal distribution should be observed.

---

#### How do you convert a normal distribution to standard normal distribution?

The standard normal distribution, also called the z-distribution, is a special normal distribution where the mean is equal to 0 and the standard deviation is equal to 1. Any nonstandard normal distribution can be standardized by transforming each data value x into a z-score. To convert the point x from a normal distribution into a z-score with this formula: z = (x-¬µ) / œÉ

---

#### What are left-skewed distribution and right-skewed distribution?

Skewness is a way to describe the symmetry of a distribution. A left-skewed (Negative Skew) distribution is one in which the left tail is longer than that of the right tail. For this distribution, mean < median < mode. Similarly, right-skewed (Positively Skew) distribution is one in which the right tail is longer than the left one. For this distribution, mean > median > mode. left-skewed distribution and right-skewed distribution

---

#### What are some of the properties of a normal distribution?

Some of the properties of a Normal Distribution are as follows: Unimodal: normal distribution has only one peak. (i.e., one mode) Symmetric: a normal distribution is perfectly symmetrical around its centre. (i.e., the right side of the centre is a mirror image of the left side) The Mean, Mode, and Median are all located in the centre (i.e., are all equal) Asymptotic: normal distributions are continuous and have tails that are asymptotic. The curve approaches the x-axis, but it never touches. normal distribution

---

#### What is the Binomial Distribution formula?

The binomial distribution formula is for any random variable X, given by; P(x; n, p) = nCx * px (1 ‚Äì p)n ‚Äì x Where: n = the number of trials x = 0, 1, 2, ... p = probability of success on an individual trial q = 1 - p = probability of failure on an individual trial

---

#### What are the criteria that Binomial distributions must meet?

The 4 criteria that Binomial distributions must meet are: There is a fixed number of trials. The outcome of each trial is independent of one another. Each trail represents one of two outcomes (‚Äúsuccess‚Äù or ‚Äúfailure‚Äù). The probability of ‚Äúsuccess‚Äù p is the same across all trials.

---

#### What is an Outlier?

An outlier is a data point that differs significantly from other data points in a dataset. An outlier may be due to variability in measurement, or it may indicate an experimental error. Outliers can greatly impact the statistical analyses and skew the results of any hypothesis tests. outlier It is important to carefully identify potential outliers in the dataset and appropriately deal with them for accurate results.

---

#### Mention methods to screen for outliers in a dataset.

There are many different ways to screen for outliers ina dataset. Some of them are:

---

#### Visualization (e.g. box plot) is another useful way to see the data distribution at a glance and to detect outliers. This chart highlights statistical information like minimum and maximum values (the range), the median, and the interquartile range for the data. When reviewing a box plot, an outlier is a data point outside the box plot‚Äôs whiskers.

Interquartile range method

---

#### A common method is the Interquartile range method. This method is helpful if there are few values on the extreme ends of the dataset, but you aren‚Äôt sure whether any of them might count as outliers. The interquartile range (IQR) also called midspread tells the range of the middle half of a dataset. The IQR can be used to create ‚Äúfences‚Äù around the data then, the outliers can be defined as any values greater than the upper fence or less than the lower fence.

To use the IQR method: Sort the data from low to high Identify the first quartile (Q1), the median, and the third quartile (Q3). Calculate the IQR; IQR = Q3 ‚Äì Q1 Calculate the upper fence; Q3 + (1.5 * IQR) and the lower fence; Q1 ‚Äì (1.5 * IQR) Use the fences to highlight any outliers (all values that fall outside your fences).

---

#### Another way to identify outliers is to use Z-score. The Z-score is just how many standard deviations away from the mean value that a certain data point is. To calculate z-score use the formula, z = (x-¬µ) / œÉ

If the z-score is positive, the data point is above average. If the z-score is negative, the data point is below average. If the z-score is close to zero, the data point is close to average. If the z-score is above or below 3 (assuming z-score = 3 is considered as a cut-off value to set the limit), it is an outlier and the data point is considered unusual. Other methods to screen outliers include Isolation Forest and DBScan clustering.

---

#### What types of biases can you encounter while sampling?

Sampling bias occurs when a sample is not representative of a target population during an investigation or a survey. The three main that one can encounter while sampling is: Selection bias: It involves the selection of individual or grouped data in a way that is not random. Undercoverage bias: This type of bias occurs when some population members are inadequately represented in the sample. Survivorship bias occurs when a sample concentrates on the ‚Äòsurviving‚Äô or existing observations and ignores those that have already ceased to exist. This can lead to wrong conclusions in numerous different means.

---

#### What is the meaning of an inliner?

An inlier is a data value that lies within the general distribution of other observed values but is an error. Inliers are difficult to distinguish from good data values, therefore, they are sometimes difficult to find and correct. An example of an inlier might be a value recorded in the wrong units.

---

#### What is hypothesis testing?

Hypothesis testing is a type of statistical inference that uses data from a sample to conclude about the population data. Before performing the testing, an assumption is made about the population parameter. This assumption is called the null hypothesis and is denoted by H0. An alternative hypothesis (denoted Ha), which is the logical opposite of the null hypothesis, is then defined. The hypothesis testing procedure involves using sample data to determine whether or not H0 should be rejected. The acceptance of the alternative hypothesis (Ha) follows the rejection of the null hypothesis (H0).

---

#### What is the p-value in hypothesis testing?

A p-value is a number that describes the probability of finding the observed or more extreme results when the null hypothesis (H0) is True. P-values are used in hypothesis testing to help decide whether to reject the null hypothesis or not. The smaller the p-value, the stronger the evidence that you should reject the null hypothesis.

---

#### When should you use a t-test vs. a z-test?

A T-test asks whether a difference between the means of two groups is unlikely to have occurred because of random chance. It is usually used when dealing with problems with a limited sample size (n < 30). If the population standard deviation is known, the sample size is less than or equal to 30, or if the population standard deviation is unknown, use the T-test. A Z-test, on the other hand, compares a sample to a defined population and is typically used for dealing with problems relating to large samples (i.e., n > 30). Generally, you should use a Z-test when the population‚Äôs standard deviation is known, and the sample size exceeds 30.

---

#### What is the difference between one-tail and two-tail hypothesis testing?

One-tailed tests allow for the possibility of an effect in one direction. Here, the critical region lies only on one tail. one-tail hypothesis testing Two-tailed tests test for the possibility of an effect in two directions‚Äîpositive and negative. Here, the critical region is one of both tails. two-tail hypothesis testing

---

#### What is the difference between type I vs. type II errors?

A type I error occurs when the null hypothesis true in the population is rejected. It is also known as false-positive. A type II error occurs when the null hypothesis that is false in the population fails to get rejected. It is also known as a false-negative. null hypothesis

---

#### What is the Central Limit Theorem?

The Central Limit Theorem (CLT) states that, given a sufficiently large sample size from a population with a finite level of variance, the sampling distribution of the mean will be normally distributed regardless of if the population is normally distributed. Central Limit Theorem

---

#### What general conditions must be satisfied for the central limit theorem to hold?

The central limit theorem states that the sampling distribution of the mean will always follow a normal distribution under the following conditions: The sample size is sufficiently large (i.e., the sample size is n ‚â• 30). The samples are independent and identically distributed random variables. The population‚Äôs distribution has finite variance.

---

#### What are correlation and covariance in statistics?

Correlation indicates how strongly two variables are related. The value of correlation between two variables ranges from -1 to +1. The -1 value represents a high negative correlation, i.e., if the value in one variable increases, then the value in the other variable will decrease. Similarly, +1 means a positive correlation, i.e., an increase in one variable leads to an increase in the other. Whereas 0 means there is no correlation. correlation in statistics Covariance, on the other hand, is a measure that indicates the extent to which a pair of random variables vary with each other. A higher number denotes a higher dependency. covariance in statistics

---

#### What is the difference between Point Estimate and Confidence Interval Estimate?

A point estimate gives a single value as an estimate of a population parameter. For example, a sample standard deviation is a point estimate of a population‚Äôs standard deviation. A confidence interval estimate gives a range of values likely to contain the population parameter. It is the most common type of interval estimate because it tells us how likely this interval is to contain the population parameter. Point Estimate and Confidence Interval Estimate

---

#### Mention the relationship between standard error and margin of error?

As the standard error increases, the margin of error also increases. The margin of error can be calculated using the standard error with this formula: Margin of error = Critical value * Standard error of the sample

---

#### How would you define Kurtosis?

Kurtosis is the extent to which the values of a distribution‚Äôs tails differ from the centre of the distribution. Outliers are detected in a data distribution using kurtosis. The higher the kurtosis, the higher the number of outliers in the data.

---

#### What is the proportion of confidence interval that will not contain the population parameter?

Alpha (Œ±) is the portion of the confidence interval that will not contain the population parameter. Œ± = 1 ‚Äì CL = the probability a confidence interval will not include the population parameter. 1 ‚Äì Œ± = CL = the probability the population parameter will be in the interval For example, if the confidence level (CL) is 95%, then, Œ± = 1 ‚Äì 0.95, or Œ± = 0.05.

---

#### What is the Law of Large Numbers in statistics?

According to the law of large numbers in statistics, an increase in the number of trials performed will cause a positive proportional increase in the average of the results, becoming the expected value. For example, the probability of flipping a fair coin and landing heads is closer to 0.5 when flipped 100, 000 times compared to when flipped 50 times.

---

#### What is the goal of A/B testing?

A/B testing is statistical hypothesis testing. It is an analytical method for making decisions that estimate population parameters based on sample statistics. The goal is usually to identify any changes to a web page to maximize or increase the outcome of interest. A/B testing is a fantastic method to figure out the best online promotional and marketing strategies for your business.

---

#### What do you understand by sensitivity and specificity?

Sensitivity is a measure of the proportion of actual positive cases that got predicted as positive (or true positive). Specificity is a measure of the proportion of actual negative cases that got predicted as negative (or true negative). The calculation of Sensitivity and Specificity is pretty straightforward. sensitivity and specificity

---

#### What is Resampling and what are the common methods of resampling?

Resampling involves the selection of randomized cases with replacement from the original data sample in such a way that each number of the sample drawn has several cases that are similar to the original data sample. Two common methods of resampling are: Bootstrapping and Normal resampling Cross Validation

---

#### What is Linear Regression?

In statistics, linear regression is an approach for modeling the relationship between one or more predictor variables (X) and one outcome variable (y). If there is one predictor variable, it is called simple linear regression. If there is more than one predictor variable, it is called multiple linear regression. Linear Regression

---

#### What are the assumptions required for linear regression?

The linear regression has four key assumptions: Linear relationship: There‚Äôs a linear relationship between X and the mean of Y. Independence: Observations are independent of each other. Normality: The distribution of Y along X should be the Normal Distribution. Homoscedasticity: The variation in the outcome or response variable is the same for any value of X.

---

#### What is a ROC curve?

The Receiver Operator Characteristic (ROC) curve is a graphical representation of the performance of a classification model at various thresholds. The curve plots True Positive Rate (TPR) vs. False Positive Rate(FPR) at different classification thresholds. ROC curve

---

#### What is Cost Function?

The cost function is an important parameter that measures the performance of a machine learning model for a given dataset. It measures how wrong the model is in estimating the relationship between input and output parameters. Conclusion This article discussed why a Data Scientist should master Statistics and some important and frequently asked Statistics Data Science Interview Questions and  Answers. To sum up, the following are the major takeaways from the article: We learned about Sampling, the different types of Sampling, and how to calculate the needed sample size. We covered Central Tendency and Probability Distributions. We discussed Relationship between Variables and the difference between Covariance and Correlation. We covered Hypotheses Testing and P-value and discussed when to use the T-test and Z-test. We discussed Regression and the assumptions of Linear Regression.

---

#### WITH cnts AS (

SELECT *, COUNT(salary) OVER (PARTITION BY salary) AS c FROM employees_1875 ) SELECT employee_id,name,salary, DENSE_RANK() OVER (ORDER BY salary) AS team_id FROM cnts WHERE c <> 1;

---

#### Recyclable and low-fat products

Write a solution to find the IDs of products that are both low-fat and recyclable. Return the result table in any order. Input: Products table: +-------------+----------+------------+ | product_id  | low_fats | recyclable | +-------------+----------+------------+ | 0           | Y        | N          | | 1           | Y        | Y          | | 2           | N        | Y          | | 3           | Y        | Y          | | 4           | N        | N          | +-------------+----------+------------+ Output: +-------------+ | product_id  | +-------------+ | 1           | | 3           | +-------------+ Explanation: Only products 1 and 3 are both low fat and recyclable. SELECT product_id FROM Products WHERE low_fats='Y' AND recyclable='Y'

---

#### Find customer referee

Find the names of the customers that are not referred by the customer with id=2. Return the result table in any order. Input: Customer table: +----+------+------------+ | id | name | referee_id | +----+------+------------+ | 1  | Will | null       | | 2  | Jane | null       | | 3  | Alex | 2          | | 4  | Bill | null       | | 5  | Zack | 1          | | 6  | Mark | 2          | +----+------+------------+ Output: +------+ | name | +------+ | Will | | Jane | | Bill | | Zack | +------+ SELECT name FROM Customer WHERE referee_id <> 2 OR referee_id IS NULL

---

#### Big countries

A country is big if it has an area of at least three million or a population of at least 25 million. Write a solution to find the name, population and area of the big countries. Return the table in any order. Input: World table: +-------------+-----------+---------+------------+--------------+ | name        | continent | area    | population | gdp          | +-------------+-----------+---------+------------+--------------+ | Afghanistan | Asia      | 652230  | 25500100   | 20343000000  | | Albania     | Europe    | 28748   | 2831741    | 12960000000  | | Algeria     | Africa    | 2381741 | 37100000   | 188681000000 | | Andorra     | Europe    | 468     | 78115      | 3712000000   | | Angola      | Africa    | 1246700 | 20609294   | 100990000000 | +-------------+-----------+---------+------------+--------------+ Output: +-------------+------------+---------+ | name        | population | area    | +-------------+------------+---------+ | Afghanistan | 25500100   | 652230  | | Algeria     | 37100000   | 2381741 | +-------------+------------+---------+ SELECT name , population , area FROM World WHERE area>=3000000 OR population>=25000000

---

#### Article views I

Write a solution to find all the authors who viewed at least one of their own articles. Return the result table sorted by id in ascending order. Input: Views table: +------------+-----------+-----------+------------+ | article_id | author_id | viewer_id | view_date  | +------------+-----------+-----------+------------+ | 1          | 3         | 5         | 2019-08-01 | | 1          | 3         | 6         | 2019-08-02 | | 2          | 7         | 7         | 2019-08-01 | | 2          | 7         | 6         | 2019-08-02 | | 4          | 7         | 1         | 2019-07-22 | | 3          | 4         | 4         | 2019-07-21 | | 3          | 4         | 4         | 2019-07-21 | +------------+-----------+-----------+------------+ Output: +------+ | id   | +------+ | 4    | | 7    | +------+ SELECT DISTINCT author_id AS id FROM Views WHERE author_id=viewer_id ORDER BY author_id

---

#### Invalid tweets

Write a solution to find the IDs of the invalid tweets. The tweet is invalid if the number of characters used in the content of the tweet is strictly greater than 15. Return the result table in any order. Input: Tweets table: +----------+----------------------------------+ | tweet_id | content                          | +----------+----------------------------------+ | 1        | Vote for Biden                   | | 2        | Let us make America great again! | +----------+----------------------------------+ Output: +----------+ | tweet_id | +----------+ | 2        | +----------+ Explanation: Tweet 1 has length = 14. It is a valid tweet. Tweet 2 has length = 32. It is an invalid tweet. SELECT tweet_id FROM Tweets WHERE LENGTH(content)>15 Basic Joins (9 Questions)

---

#### Replace employee ID with the unique identifier

Write a solution to show the unique ID of each user. If a user does not have a unique ID, replace just null. Return the result table in any order. Input: Employees table: +----+----------+ | id | name     | +----+----------+ | 1  | Alice    | | 7  | Bob      | | 11 | Meir     | | 90 | Winston  | | 3  | Jonathan | +----+----------+ EmployeeUNI table: +----+-----------+ | id | unique_id | +----+-----------+ | 3  | 1         | | 11 | 2         | | 90 | 3         | +----+-----------+ Output: +-----------+----------+ | unique_id | name     | +-----------+----------+ | null      | Alice    | | null      | Bob      | | 2         | Meir     | | 3         | Winston  | | 1         | Jonathan | +-----------+----------+ Explanation: Alice and Bob do not have a unique ID, We will show null instead. The unique ID of Meir is 2. The unique ID of Winston is 3. The unique ID of Jonathan is 1. SELECT eu.unique_id , e.name FROM Employees e LEFT JOIN EmployeeUNI eu ON e.id=eu.id

---

#### Product sales analysis I

Write a solution to report the product_name, year and price for each sale_id in the Sales table. Return the resulting table in any order. Input: Sales table: +---------+------------+------+----------+-------+ | sale_id | product_id | year | quantity | price | +---------+------------+------+----------+-------+ | 1       | 100        | 2008 | 10       | 5000  | | 2       | 100        | 2009 | 12       | 5000  | | 7       | 200        | 2011 | 15       | 9000  | +---------+------------+------+----------+-------+ Product table: +------------+--------------+ | product_id | product_name | +------------+--------------+ | 100        | Nokia        | | 200        | Apple        | | 300        | Samsung      | +------------+--------------+ Output: +--------------+-------+-------+ | product_name | year  | price | +--------------+-------+-------+ | Nokia        | 2008  | 5000  | | Nokia        | 2009  | 5000  | | Apple        | 2011  | 9000  | +--------------+-------+-------+ Explanation: From sale_id = 1, we can conclude that Nokia was sold for 5000 in the year 2008. From sale_id = 2, we can conclude that Nokia was sold for 5000 in the year 2009. From sale_id = 7, we can conclude that Apple was sold for 9000 in the year 2011. SELECT p.product_name , s.year , s.price FROM Sales s LEFT JOIN Product p ON s.product_id=p.product_id

---

#### Customers who visited but did not make any transactions

Write a solution to find the IDs of the users who visited without making any transactions and the number of times they made these types of visits. Return the result table sorted in any order. Input: Visits +----------+-------------+ | visit_id | customer_id | +----------+-------------+ | 1        | 23          | | 2        | 9           | | 4        | 30          | | 5        | 54          | | 6        | 96          | | 7        | 54          | | 8        | 54          | +----------+-------------+ Transactions +----------------+----------+--------+ | transaction_id | visit_id | amount | +----------------+----------+--------+ | 2              | 5        | 310    | | 3              | 5        | 300    | | 9              | 5        | 200    | | 12             | 1        | 910    | | 13             | 2        | 970    | +----------------+----------+--------+ Output: +-------------+----------------+ | customer_id | count_no_trans | +-------------+----------------+ | 54          | 2              | | 30          | 1              | | 96          | 1              | +-------------+----------------+ Explanation: Customer with id = 23 visited the mall once and made one transaction during the visit with id = 12. Customer with id = 9 visited the mall once and made one transaction during the visit with id = 13. Customer with id = 30 visited the mall once and did not make any transactions. Customer with id = 54 visited the mall three times. During 2 visits they did not make any transactions, and during one visit they made 3 transactions. Customer with id = 96 visited the mall once and did not make any transactions. As we can see, users with IDs 30 and 96 visited the mall one time without making any transactions. Also, user 54 visited the mall twice and did not make any transactions. SELECT v.customer_id , COUNT(*) AS count_no_trans FROM Visits v LEFT JOIN Transactions t ON v.visit_id=t.visit_id WHERE transaction_id IS NULL GROUP BY 1

---

#### Rising temperature

Write a solution to find all date IDs with higher temperatures compared to its previous dates (yesterday). Return the result table in any order. Input: Weather table: +----+------------+-------------+ | id | recordDate | temperature | +----+------------+-------------+ | 1  | 2015-01-01 | 10          | | 2  | 2015-01-02 | 25          | | 3  | 2015-01-03 | 20          | | 4  | 2015-01-04 | 30          | +----+------------+-------------+ Output: +----+ | id | +----+ | 2  | | 4  | +----+ Explanation: In 2015-01-02, the temperature was higher than the previous day (10 -> 25). In 2015-01-04, the temperature was higher than the previous day (20 -> 30). SELECT w1.id FROM Weather w1, Weather w2 WHERE w1.temperature > w2.temperature AND DATEDIFF(w1.recordDate, w2.recordDate) = 1

---

#### Average time of process per machine

There is a factory website that has several machines each running the same number of processes. Write a solution to find the average time each machine takes to complete a process. The time to complete a process is the end timestamp minus the start timestamp. The average time is calculated by the total time to complete every process on the machine divided by the number of processes that were run. The resulting table should have the machine_id along with the average time as processing_time, which should be rounded to 3 decimal places. Return the result table in any order. Input: Activity table: +------------+------------+---------------+-----------+ | machine_id | process_id | activity_type | timestamp | +------------+------------+---------------+-----------+ | 0          | 0          | start         | 0.712     | | 0          | 0          | end           | 1.520     | | 0          | 1          | start         | 3.140     | | 0          | 1          | end           | 4.120     | | 1          | 0          | start         | 0.550     | | 1          | 0          | end           | 1.550     | | 1          | 1          | start         | 0.430     | | 1          | 1          | end           | 1.420     | | 2          | 0          | start         | 4.100     | | 2          | 0          | end           | 4.512     | | 2          | 1          | start         | 2.500     | | 2          | 1          | end           | 5.000     | +------------+------------+---------------+-----------+ Output: +------------+-----------------+ | machine_id | processing_time | +------------+-----------------+ | 0          | 0.894           | | 1          | 0.995           | | 2          | 1.456           | +------------+-----------------+ Explanation: There are 3 machines running 2 processes each. Machine 0's average time is ((1.520 - 0.712) + (4.120 - 3.140)) / 2 = 0.894 Machine 1's average time is ((1.550 - 0.550) + (1.420 - 0.430)) / 2 = 0.995 Machine 2's average time is ((4.512 - 4.100) + (5.000 - 2.500)) / 2 = 1.456 SELECT machine_id , ROUND(AVG(a2.timestamp - a1.timestamp), 3) AS processing_time FROM Activity a1 INNER JOIN Activity a2 ON a1.machine_id=a2.machine_id AND a1.process_id=a2.process_id AND a1.activity_type='start' AND a2.activity_type='end' GROUP BY a1.machine_id

---

#### Employee bonus

Write a solution to report the name and bonus amount of each employee with a bonus of less than 1,000. Return the result table in any order. Input: Employee table: +-------+--------+------------+--------+ | empId | name   | supervisor | salary | +-------+--------+------------+--------+ | 3     | Brad   | null       | 4000   | | 1     | John   | 3          | 1000   | | 2     | Dan    | 3          | 2000   | | 4     | Thomas | 3          | 4000   | +-------+--------+------------+--------+ Bonus table: +-------+-------+ | empId | bonus | +-------+-------+ | 2     | 500   | | 4     | 2000  | +-------+-------+ Output: +------+-------+ | name | bonus | +------+-------+ | Brad | null  | | John | null  | | Dan  | 500   | +------+-------+ SELECT e.name , b.bonus FROM Employee e LEFT JOIN Bonus b ON e.empId=b.empId WHERE bonus<1000 OR bonus IS NULL

---

#### Students and examinations

Write a solution to find the number of times each student attended each exam. Return the result table ordered by student_id and subject_name. Input: Students table: +------------+--------------+ | student_id | student_name | +------------+--------------+ | 1          | Alice        | | 2          | Bob          | | 13         | John         | | 6          | Alex         | +------------+--------------+ Subjects table: +--------------+ | subject_name | +--------------+ | Math         | | Physics      | | Programming  | +--------------+ Examinations table: +------------+--------------+ | student_id | subject_name | +------------+--------------+ | 1          | Math         | | 1          | Physics      | | 1          | Programming  | | 2          | Programming  | | 1          | Physics      | | 1          | Math         | | 13         | Math         | | 13         | Programming  | | 13         | Physics      | | 2          | Math         | | 1          | Math         | +------------+--------------+ Output: +------------+--------------+--------------+----------------+ | student_id | student_name | subject_name | attended_exams | +------------+--------------+--------------+----------------+ | 1          | Alice        | Math         | 3              | | 1          | Alice        | Physics      | 2              | | 1          | Alice        | Programming  | 1              | | 2          | Bob          | Math         | 1              | | 2          | Bob          | Physics      | 0              | | 2          | Bob          | Programming  | 1              | | 6          | Alex         | Math         | 0              | | 6          | Alex         | Physics      | 0              | | 6          | Alex         | Programming  | 0              | | 13         | John         | Math         | 1              | | 13         | John         | Physics      | 1              | | 13         | John         | Programming  | 1              | +------------+--------------+--------------+----------------+ Explanation: The result table should contain all students and all subjects. Alice attended the Math exam 3 times, the Physics exam 2 times, and the Programming exam 1 time. Bob attended the Math exam 1 time, the Programming exam 1 time, and did not attend the Physics exam. Alex did not attend any exams. John attended the Math exam 1 time, the Physics exam 1 time, and the Programming exam 1 time. SELECT s.student_id , s.student_name , sub.subject_name , COUNT(e.student_id) AS attended_exams FROM Students s CROSS JOIN Subjects sub LEFT JOIN Examinations e ON s.student_id=e.student_id AND sub.subject_name=e.subject_name GROUP BY 1, 2, 3 ORDER BY 1, 3 The cross join here is to ensure that we have every unique combination of student and subject. In the event a student has not attended an exam for a particular subject, it will have a value of zero.

---

#### Managers with at least 5 direct reports

Write a solution to find managers with at least five direct reports. Return the result table in any order. Input: Employee table: +-----+-------+------------+-----------+ | id  | name  | department | managerId | +-----+-------+------------+-----------+ | 101 | John  | A          | null      | | 102 | Dan   | A          | 101       | | 103 | James | A          | 101       | | 104 | Amy   | A          | 101       | | 105 | Anne  | A          | 101       | | 106 | Ron   | B          | 101       | +-----+-------+------------+-----------+ Output: +------+ | name | +------+ | John | +------+ SELECT name FROM Employee WHERE id IN (SELECT managerId FROM Employee GROUP BY 1 HAVING COUNT(1) >= 5) SELECT e.name FROM Employee e INNER JOIN Employee m ON e.id=m.managerId GROUP BY m.managerId HAVING COUNT(m.managerId) >= 5 There are two slightly different ways to approach this problem, but both use a similar logic.

---

#### Confirmation rate

The confirmation rate of a user is the number of confirmed messages divided by the total number of requested confirmation messages. The confirmation rate of a user that did not request any confirmation messages is 0. Round the confirmation rate to two decimal places. Write a solution to find the confirmation rate of each user. Return the result table in any order. Input: Signups table: +---------+---------------------+ | user_id | time_stamp          | +---------+---------------------+ | 3       | 2020-03-21 10:16:13 | | 7       | 2020-01-04 13:57:59 | | 2       | 2020-07-29 23:09:44 | | 6       | 2020-12-09 10:39:37 | +---------+---------------------+ Confirmations table: +---------+---------------------+-----------+ | user_id | time_stamp          | action    | +---------+---------------------+-----------+ | 3       | 2021-01-06 03:30:46 | timeout   | | 3       | 2021-07-14 14:00:00 | timeout   | | 7       | 2021-06-12 11:57:29 | confirmed | | 7       | 2021-06-13 12:58:28 | confirmed | | 7       | 2021-06-14 13:59:27 | confirmed | | 2       | 2021-01-22 00:00:00 | confirmed | | 2       | 2021-02-28 23:59:59 | timeout   | +---------+---------------------+-----------+ Output: +---------+-------------------+ | user_id | confirmation_rate | +---------+-------------------+ | 6       | 0.00              | | 3       | 0.00              | | 7       | 1.00              | | 2       | 0.50              | +---------+-------------------+ Explanation: User 6 did not request any confirmation messages. The confirmation rate is 0. User 3 made 2 requests and both timed out. The confirmation rate is 0. User 7 made 3 requests and all were confirmed. The confirmation rate is 1. User 2 made 2 requests where one was confirmed and the other timed out. The confirmation rate is 1 / 2 = 0.5. SELECT s.user_id, ROUND(AVG(IF(c.action='confirmed', 1, 0)), 2) AS confirmation_rate FROM Signups s LEFT JOIN Confirmations c ON s.user_id=c.user_id GROUP BY user_id Basic Aggregate Functions (8 Questions)

---

#### Not boring movies

Write a solution to report the movies with an odd-numbered ID and a description that is not boring. Return the result table ordered by rating in descending order. Input: Cinema table: +----+------------+-------------+--------+ | id | movie      | description | rating | +----+------------+-------------+--------+ | 1  | War        | great 3D    | 8.9    | | 2  | Science    | fiction     | 8.5    | | 3  | irish      | boring      | 6.2    | | 4  | Ice song   | Fantacy     | 8.6    | | 5  | House card | Interesting | 9.1    | +----+------------+-------------+--------+ Output: +----+------------+-------------+--------+ | id | movie      | description | rating | +----+------------+-------------+--------+ | 5  | House card | Interesting | 9.1    | | 1  | War        | great 3D    | 8.9    | +----+------------+-------------+--------+ Explanation: We have three movies with odd-numbered IDs: 1, 3, and 5. The movie with ID = 3 is boring so we do not include it in the answer. SELECT * FROM Cinema WHERE MOD(id, 2) = 1 AND description <> 'boring' ORDER BY rating DESC

---

#### Average selling price

Write a solution to find the average selling price for each product. average_price should be rounded to two decimal places. Return the result table in any order. Input: Prices table: +------------+------------+------------+--------+ | product_id | start_date | end_date   | price  | +------------+------------+------------+--------+ | 1          | 2019-02-17 | 2019-02-28 | 5      | | 1          | 2019-03-01 | 2019-03-22 | 20     | | 2          | 2019-02-01 | 2019-02-20 | 15     | | 2          | 2019-02-21 | 2019-03-31 | 30     | +------------+------------+------------+--------+ UnitsSold table: +------------+---------------+-------+ | product_id | purchase_date | units | +------------+---------------+-------+ | 1          | 2019-02-25    | 100   | | 1          | 2019-03-01    | 15    | | 2          | 2019-02-10    | 200   | | 2          | 2019-03-22    | 30    | +------------+---------------+-------+ Output: +------------+---------------+ | product_id | average_price | +------------+---------------+ | 1          | 6.96          | | 2          | 16.96         | +------------+---------------+ Explanation: Average selling price = Total Price of Product / Number of products sold. Average selling price for product 1 = ((100 * 5) + (15 * 20)) / 115 = 6.96 Average selling price for product 2 = ((200 * 15) + (30 * 30)) / 230 = 16.96 SELECT p.product_id , COALESCE(round(SUM(units*price)/SUM(units), 2), 0) AS average_price FROM Prices p LEFT JOIN UnitsSold u ON p.product_id=u.product_id AND u.purchase_date BETWEEN p.start_date AND p.end_date GROUP BY 1

---

#### Project employees I

Write an SQL query that reports the average experience years of all the employees for each project, rounded to two digits. Return the result table in any order. Input: Project table: +-------------+-------------+ | project_id  | employee_id | +-------------+-------------+ | 1           | 1           | | 1           | 2           | | 1           | 3           | | 2           | 1           | | 2           | 4           | +-------------+-------------+ Employee table: +-------------+--------+------------------+ | employee_id | name   | experience_years | +-------------+--------+------------------+ | 1           | Khaled | 3                | | 2           | Ali    | 2                | | 3           | John   | 1                | | 4           | Doe    | 2                | +-------------+--------+------------------+ Output: +-------------+---------------+ | project_id  | average_years | +-------------+---------------+ | 1           | 2.00          | | 2           | 2.50          | +-------------+---------------+ Explanation: The average experience years for the first project is (3 + 2 + 1) / 3 = 2.00 and for the second project is (3 + 2) / 2 = 2.50 SELECT project_id , ROUND(AVG(experience_years), 2) AS average_years FROM Project p LEFT JOIN Employee e ON p.employee_id=e.employee_id GROUP BY 1

---

#### Percentage of users who attended a contest

Write a solution to find the percentage of the users registered in each contest rounded to two decimals. Return the result table ordered by percentage in descending order. In case of a tie, order it by contest_id in ascending order. Input: Users table: +---------+-----------+ | user_id | user_name | +---------+-----------+ | 6       | Alice     | | 2       | Bob       | | 7       | Alex      | +---------+-----------+ Register table: +------------+---------+ | contest_id | user_id | +------------+---------+ | 215        | 6       | | 209        | 2       | | 208        | 2       | | 210        | 6       | | 208        | 6       | | 209        | 7       | | 209        | 6       | | 215        | 7       | | 208        | 7       | | 210        | 2       | | 207        | 2       | | 210        | 7       | +------------+---------+ Output: +------------+------------+ | contest_id | percentage | +------------+------------+ | 208        | 100.0      | | 209        | 100.0      | | 210        | 100.0      | | 215        | 66.67      | | 207        | 33.33      | +------------+------------+ Explanation: All the users registered in contests 208, 209, and 210. The percentage is 100% and we sort them in the answer table by contest_id in ascending order. Alice and Alex registered in contest 215 and the percentage is ((2/3) * 100) = 66.67% Bob registered in contest 207 and the percentage is ((1/3) * 100) = 33.33% SELECT contest_id , ROUND(100*COUNT(1)/(SELECT COUNT(DISTINCT user_id) FROM Users), 2) AS percentage FROM Register GROUP BY contest_id ORDER BY percentage DESC, contest_id

---

#### Queries quality and percentage

We define query quality as the average of the ratio between query rating and its position. We also define poor_query_percentage as the percentage of all queries with rating less than three. Both quality and poor_query_percentage should be rounded to two decimal places. Return the result table in any order. Input: Queries table: +------------+-------------------+----------+--------+ | query_name | result            | position | rating | +------------+-------------------+----------+--------+ | Dog        | Golden Retriever  | 1        | 5      | | Dog        | German Shepherd   | 2        | 5      | | Dog        | Mule              | 200      | 1      | | Cat        | Shirazi           | 5        | 2      | | Cat        | Siamese           | 3        | 3      | | Cat        | Sphynx            | 7        | 4      | +------------+-------------------+----------+--------+ Output: +------------+---------+-----------------------+ | query_name | quality | poor_query_percentage | +------------+---------+-----------------------+ | Dog        | 2.50    | 33.33                 | | Cat        | 0.66    | 33.33                 | +------------+---------+-----------------------+ Explanation: Dog queries quality is ((5 / 1) + (5 / 2) + (1 / 200)) / 3 = 2.50 Dog queries poor_ query_percentage is (1 / 3) * 100 = 33.33 Cat queries quality equals ((2 / 5) + (3 / 3) + (4 / 7)) / 3 = 0.66 Cat queries poor_ query_percentage is (1 / 3) * 100 = 33.33 SELECT query_name , ROUND(AVG(rating/position), 2) AS quality , ROUND(100*AVG(IF(rating<3, 1, 0)), 2) AS poor_query_percentage FROM Queries WHERE query_name IS NOT NULL GROUP BY 1

---

#### Monthly transactions I

Write an SQL query to find for each month and country, the number of transactions and their total amount, the number of approved transactions and their total amount. Return the result table in any order. Input: Transactions table: +------+---------+----------+--------+------------+ | id   | country | state    | amount | trans_date | +------+---------+----------+--------+------------+ | 121  | US      | approved | 1000   | 2018-12-18 | | 122  | US      | declined | 2000   | 2018-12-19 | | 123  | US      | approved | 2000   | 2019-01-01 | | 124  | DE      | approved | 2000   | 2019-01-07 | +------+---------+----------+--------+------------+ Output: +----------+---------+-------------+----------------+--------------------+-----------------------+ | month    | country | trans_count | approved_count | trans_total_amount | approved_total_amount | +----------+---------+-------------+----------------+--------------------+-----------------------+ | 2018-12  | US      | 2           | 1              | 3000               | 1000                  | | 2019-01  | US      | 1           | 1              | 2000               | 2000                  | | 2019-01  | DE      | 1           | 1              | 2000               | 2000                  | +----------+---------+-------------+----------------+--------------------+-----------------------+ SELECT date_format(trans_date, '%Y-%m') AS month , country , COUNT(1) AS trans_count , SUM(IF(state='approved', 1, 0)) AS approved_count , SUM(amount) as trans_total_amount , SUM(IF(state='approved', amount, 0)) AS approved_total_amount FROM Transactions GROUP BY 1, 2

---

#### Immediate food delivery II

If the customer‚Äôs preferred delivery date is the same as the order date, then the order is called immediate. Otherwise, it is called scheduled. The first order of a customer is the order with the earliest order date that the customer made. It is guaranteed that a customer has precisely one first order. Write a solution to find the percentage of immediate orders in the first orders of all customers, rounded to two decimal places. Input: Delivery table: +-------------+-------------+------------+-----------------------------+ | delivery_id | customer_id | order_date | customer_pref_delivery_date | +-------------+-------------+------------+-----------------------------+ | 1           | 1           | 2019-08-01 | 2019-08-02                  | | 2           | 2           | 2019-08-02 | 2019-08-02                  | | 3           | 1           | 2019-08-11 | 2019-08-12                  | | 4           | 3           | 2019-08-24 | 2019-08-24                  | | 5           | 3           | 2019-08-21 | 2019-08-22                  | | 6           | 2           | 2019-08-11 | 2019-08-13                  | | 7           | 4           | 2019-08-09 | 2019-08-09                  | +-------------+-------------+------------+-----------------------------+ Output: +----------------------+ | immediate_percentage | +----------------------+ | 50.00                | +----------------------+ Explanation: The customer id 1 has a first order with delivery id 1 and it is scheduled. The customer id 2 has a first order with delivery id 2 and it is immediate. The customer id 3 has a first order with delivery id 5 and it is scheduled. The customer id 4 has a first order with delivery id 7 and it is immediate. Hence, half the customers have immediate first orders. SELECT ROUND(100*AVG(order_date=customer_pref_delivery_date), 2) AS immediate_percentage FROM Delivery WHERE (customer_id, order_date) IN (SELECT customer_id, MIN(order_date) FROM Delivery GROUP BY 1)

---

#### Game play analysis IV

Write a solution to report the fraction of players that logged in again on the day after the day they first logged in, rounded to two decimal places. In other words, you need to count the number of players that logged in for at least two consecutive days starting from their first login date, then divide that number by the total number of players. Input: Activity table: +-----------+-----------+------------+--------------+ | player_id | device_id | event_date | games_played | +-----------+-----------+------------+--------------+ | 1         | 2         | 2016-03-01 | 5            | | 1         | 2         | 2016-03-02 | 6            | | 2         | 3         | 2017-06-25 | 1            | | 3         | 1         | 2016-03-02 | 0            | | 3         | 4         | 2018-07-03 | 5            | +-----------+-----------+------------+--------------+ Output: +-----------+ | fraction  | +-----------+ | 0.33      | +-----------+ Explanation: Only the player with id 1 logged back in after the first day he had logged in so the answer is 1/3 = 0.33 SELECT ROUND(COUNT(DISTINCT player_id)/(SELECT COUNT(DISTINCT player_id) FROM Activity), 2) AS fraction FROM Activity WHERE (player_id, date_sub(event_date, INTERVAL 1 DAY)) IN (SELECT player_id, MIN(event_date) FROM Activity GROUP BY 1) Sorting and Grouping (7 Questions)

---

#### Number of unique subjects taught by each teacher

Write a solution to calculate the number of unique subjects each teacher teaches in the university. Return the result table in any order. Input: Teacher table: +------------+------------+---------+ | teacher_id | subject_id | dept_id | +------------+------------+---------+ | 1          | 2          | 3       | | 1          | 2          | 4       | | 1          | 3          | 3       | | 2          | 1          | 1       | | 2          | 2          | 1       | | 2          | 3          | 1       | | 2          | 4          | 1       | +------------+------------+---------+ Output: +------------+-----+ | teacher_id | cnt | +------------+-----+ | 1          | 2   | | 2          | 4   | +------------+-----+ Explanation: Teacher 1: - They teach subject 2 in departments 3 and 4. - They teach subject 3 in department 3. Teacher 2: - They teach subject 1 in department 1. - They teach subject 2 in department 1. - They teach subject 3 in department 1. - They teach subject 4 in department 1. SELECT teacher_id , COUNT(DISTINCT subject_id) AS cnt FROM Teacher GROUP BY 1

---

#### User activity for the past 30 days I

Write a solution to find the daily active user count for a period of 30 days ending 2019‚Äì07‚Äì27 inclusively. A user was active on someday if they made at least one activity on that day. Return the result table in any order. Input: Activity table: +---------+------------+---------------+---------------+ | user_id | session_id | activity_date | activity_type | +---------+------------+---------------+---------------+ | 1       | 1          | 2019-07-20    | open_session  | | 1       | 1          | 2019-07-20    | scroll_down   | | 1       | 1          | 2019-07-20    | end_session   | | 2       | 4          | 2019-07-20    | open_session  | | 2       | 4          | 2019-07-21    | send_message  | | 2       | 4          | 2019-07-21    | end_session   | | 3       | 2          | 2019-07-21    | open_session  | | 3       | 2          | 2019-07-21    | send_message  | | 3       | 2          | 2019-07-21    | end_session   | | 4       | 3          | 2019-06-25    | open_session  | | 4       | 3          | 2019-06-25    | end_session   | +---------+------------+---------------+---------------+ Output: +------------+--------------+ | day        | active_users | +------------+--------------+ | 2019-07-20 | 2            | | 2019-07-21 | 2            | +------------+--------------+ Explanation: Note that we do not care about days with zero active users. SELECT activity_date AS day, COUNT(DISTINCT user_id) AS active_users FROM Activity WHERE activity_date BETWEEN '2019-06-28' AND '2019-07-27' GROUP BY 1

---

#### Product sales analysis III

Write a solution to select the product_id, year, quantity and price for the first year of every product sold. Return the resulting table in any order. Input: Sales table: +---------+------------+------+----------+-------+ | sale_id | product_id | year | quantity | price | +---------+------------+------+----------+-------+ | 1       | 100        | 2008 | 10       | 5000  | | 2       | 100        | 2009 | 12       | 5000  | | 7       | 200        | 2011 | 15       | 9000  | +---------+------------+------+----------+-------+ Product table: +------------+--------------+ | product_id | product_name | +------------+--------------+ | 100        | Nokia        | | 200        | Apple        | | 300        | Samsung      | +------------+--------------+ Output: +------------+------------+----------+-------+ | product_id | first_year | quantity | price | +------------+------------+----------+-------+ | 100        | 2008       | 10       | 5000  | | 200        | 2011       | 15       | 9000  | +------------+------------+----------+-------+ SELECT product_id , year AS first_year , quantity , price FROM Sales WHERE (product_id, year) IN (SELECT product_id, MIN(year) FROM Sales GROUP BY 1)

---

#### Classes with more than 5 students

Write a solution to find all the classes that have at least five students. Return the result table in any order. Input: Courses table: +---------+----------+ | student | class    | +---------+----------+ | A       | Math     | | B       | English  | | C       | Math     | | D       | Biology  | | E       | Math     | | F       | Computer | | G       | Math     | | H       | Math     | | I       | Math     | +---------+----------+ Output: +---------+ | class   | +---------+ | Math    | +---------+ Explanation: - Math has 6 students, so we include it. - English has 1 student, so we do not include it. - Biology has 1 student, so we do not include it. - Computer has 1 student, so we do not include it. SELECT class FROM Courses GROUP BY 1 HAVING COUNT(*) >= 5

---

#### Find followers count

Write a solution that will, for each user, return the number of followers. Return the result table ordered by user_id in ascending order. Input: Followers table: +---------+-------------+ | user_id | follower_id | +---------+-------------+ | 0       | 1           | | 1       | 0           | | 2       | 0           | | 2       | 1           | +---------+-------------+ Output: +---------+----------------+ | user_id | followers_count| +---------+----------------+ | 0       | 1              | | 1       | 1              | | 2       | 2              | +---------+----------------+ Explanation: The followers of 0 are {1} The followers of 1 are {0} The followers of 2 are {0,1} SELECT user_id , COUNT(*) AS followers_count FROM Followers GROUP BY 1 ORDER BY 1

---

#### Biggest single number

A single number is a number that appeared only once in the MyNumbers table. Find the largest single number. If there is no single number, report null. Example 1: Input: MyNumbers table: +-----+ | num | +-----+ | 8   | | 8   | | 3   | | 3   | | 1   | | 4   | | 5   | | 6   | +-----+ Output: +-----+ | num | +-----+ | 6   | +-----+ Explanation: The single numbers are 1, 4, 5, and 6. Since 6 is the largest single number, we return it. Example 2: Input: MyNumbers table: +-----+ | num | +-----+ | 8   | | 8   | | 7   | | 7   | | 3   | | 3   | | 3   | +-----+ Output: +------+ | num  | +------+ | null | +------+ Explanation: There are no single numbers in the input table so we return null. SELECT MAX(num) AS num FROM ( SELECT * FROM MyNumbers GROUP BY 1 HAVING COUNT(*)=1 ) _

---

#### Customers who bought all products

Write a solution to report the customer ids from the Customer table that bought all the products in the Product table. Return the result table in any order. Input: Customer table: +-------------+-------------+ | customer_id | product_key | +-------------+-------------+ | 1           | 5           | | 2           | 6           | | 3           | 5           | | 3           | 6           | | 1           | 6           | +-------------+-------------+ Product table: +-------------+ | product_key | +-------------+ | 5           | | 6           | +-------------+ Output: +-------------+ | customer_id | +-------------+ | 1           | | 3           | +-------------+ Explanation: The customers who bought all the products (5 and 6) are customers with IDs 1 and 3. SELECT customer_id FROM Customer GROUP BY 1 HAVING COUNT(DISTINCT product_key)=(SELECT COUNT(*) FROM Product) That‚Äôs a wrap for part one. Generally speaking, the problems here are relatively straightforward and they offer great practice for writing basic SQL queries. Advanced Select and Joins (7 Questions)

---

#### The number of employees which report to each employee

For this problem, we will consider a manager an employee who has at least 1 other employee reporting to them. Write a solution to report the ids and the names of all managers, the number of employees who report directly to them, and the average age of the reports rounded to the nearest integer. Return the result table ordered by employee_id. Input: Employees table: +-------------+---------+------------+-----+ | employee_id | name    | reports_to | age | +-------------+---------+------------+-----+ | 9           | Hercy   | null       | 43  | | 6           | Alice   | 9          | 41  | | 4           | Bob     | 9          | 36  | | 2           | Winston | null       | 37  | +-------------+---------+------------+-----+ Output: +-------------+-------+---------------+-------------+ | employee_id | name  | reports_count | average_age | +-------------+-------+---------------+-------------+ | 9           | Hercy | 2             | 39          | +-------------+-------+---------------+-------------+ Explanation: Hercy has 2 people report directly to him, Alice and Bob. Their average age is (41+36)/2 = 38.5, which is 39 after rounding it to the nearest integer. SELECT e1.employee_id , e1.name , COUNT(*) AS reports_count , ROUND(AVG(e2.age), 0) AS average_age FROM Employees e1, Employees e2 WHERE e1.employee_id=e2.reports_to GROUP BY 1, 2 ORDER BY 1

---

#### Primary department for each employee

Employees can belong to multiple departments. When the employee joins other departments, they need to decide which department is their primary department. Note that when an employee belongs to only one department, their primary column is N. Write a solution to report all the employees with their primary department. For employees who belong to one department, report their only department. Return the result table in any order. Input: Employee table: +-------------+---------------+--------------+ | employee_id | department_id | primary_flag | +-------------+---------------+--------------+ | 1           | 1             | N            | | 2           | 1             | Y            | | 2           | 2             | N            | | 3           | 3             | N            | | 4           | 2             | N            | | 4           | 3             | Y            | | 4           | 4             | N            | +-------------+---------------+--------------+ Output: +-------------+---------------+ | employee_id | department_id | +-------------+---------------+ | 1           | 1             | | 2           | 1             | | 3           | 3             | | 4           | 3             | +-------------+---------------+ Explanation: - The Primary department for employee 1 is 1. - The Primary department for employee 2 is 1. - The Primary department for employee 3 is 3. - The Primary department for employee 4 is 3. SELECT employee_id, department_id FROM Employee WHERE primary_flag='Y' UNION SELECT employee_id, department_id FROM Employee GROUP BY 1 HAVING COUNT(*)=1 The trick here is to separate employees into two buckets: those with multiple departments and those with only one. Each bucket would have its query and resulting table. Once you have the two tables, you simply need to union them together as seen in the solution above.

---

#### Triangle judgement

Report for every three line segments whether they can form a triangle. Return the result table in any order. Triangle table: +----+----+----+ | x  | y  | z  | +----+----+----+ | 13 | 15 | 30 | | 10 | 20 | 15 | +----+----+----+ Output: +----+----+----+----------+ | x  | y  | z  | triangle | +----+----+----+----------+ | 13 | 15 | 30 | No       | | 10 | 20 | 15 | Yes      | +----+----+----+----------+ SELECT x , y , z , CASE WHEN (x + y <= z OR x + z <= y OR y + z <= x) THEN 'No' ELSE 'Yes' END AS triangle FROM Triangle

---

#### Consecutive numbers

Find all numbers that appear at least three times consecutively. Return the result table in any order. Input: Logs table: +----+-----+ | id | num | +----+-----+ | 1  | 1   | | 2  | 1   | | 3  | 1   | | 4  | 2   | | 5  | 1   | | 6  | 2   | | 7  | 2   | +----+-----+ Output: +-----------------+ | ConsecutiveNums | +-----------------+ | 1               | +-----------------+ Explanation: 1 is the only number that appears consecutively for at least three times. WITH cte AS ( SELECT num , LEAD(num, 1) OVER() AS lead1 , LEAD(num, 2) OVER() AS lead2 FROM logs ) SELECT DISTINCT num AS ConsecutiveNums FROM cte WHERE num=lead1 AND lead1=lead2 Create two columns for leading values, one succeeding by one row and the other succeeding by two rows. If the current number equals the next two, then the number is considered to appear consecutively at least three times.

---

#### Product price at a given date

Write a solution to find the prices of all products on 2019‚Äì08‚Äì16. Assume the price of all products before any change is 10. Return the result table in any order. Input: Products table: +------------+-----------+-------------+ | product_id | new_price | change_date | +------------+-----------+-------------+ | 1          | 20        | 2019-08-14  | | 2          | 50        | 2019-08-14  | | 1          | 30        | 2019-08-15  | | 1          | 35        | 2019-08-16  | | 2          | 65        | 2019-08-17  | | 3          | 20        | 2019-08-18  | +------------+-----------+-------------+ Output: +------------+-------+ | product_id | price | +------------+-------+ | 2          | 50    | | 1          | 35    | | 3          | 10    | +------------+-------+ SELECT product_id, 10 AS price FROM Products WHERE product_id NOT IN (SELECT DISTINCT product_id FROM Products WHERE change_date<='2019-08-16') UNION SELECT product_id, new_price AS price FROM Products WHERE (product_id, change_date) IN (SELECT product_id, MAX(change_date) FROM Products WHERE change_date<='2019-08-16' GROUP BY 1) Similar to the employee department question above, the trick here is to split up your query into two parts: one for products with price change before 2019‚Äì08‚Äì16, and one for after. For products with price change after 2019‚Äì08‚Äì16, set the default price as 10. On the other hand, for products with price change before 2019‚Äì08‚Äì16, return the most recent price.

---

#### Last person to fit in the bus

There is a queue of people waiting to board a bus. However, the bus has a weight limit of 1,000 kilograms, so there may be some people who cannot board. Write a solution to find the person_name of the last person that can fit on the bus without exceeding the weight limit. The test cases are generated such that the first person does not exceed the weight limit. Input: Queue table: +-----------+-------------+--------+------+ | person_id | person_name | weight | turn | +-----------+-------------+--------+------+ | 5         | Alice       | 250    | 1    | | 4         | Bob         | 175    | 5    | | 3         | Alex        | 350    | 2    | | 6         | John Cena   | 400    | 3    | | 1         | Winston     | 500    | 6    | | 2         | Marie       | 200    | 4    | +-----------+-------------+--------+------+ Output: +-------------+ | person_name | +-------------+ | John Cena   | +-------------+ Explanation: The folowing table is ordered by the turn for simplicity. +------+----+-----------+--------+--------------+ | Turn | ID | Name      | Weight | Total Weight | +------+----+-----------+--------+--------------+ | 1    | 5  | Alice     | 250    | 250          | | 2    | 3  | Alex      | 350    | 600          | | 3    | 6  | John Cena | 400    | 1000         | (last person to board) | 4    | 2  | Marie     | 200    | 1200         | (cannot board) | 5    | 4  | Bob       | 175    | ___          | | 6    | 1  | Winston   | 500    | ___          | +------+----+-----------+--------+--------------+ SELECT q1.person_name FROM Queue q1 LEFT JOIN Queue q2 ON q1.turn >= q2.turn GROUP BY q1.turn HAVING SUM(q2.weight) <= 1000 ORDER BY SUM(q2.weight) DESC LIMIT 1 For each turn, get the weights of all the preceding turns and the current turn. If the sum of all preceding turns and current turn is less than or equal to a thousand, then return the passenger name.

---

#### Count salary categories

Write a solution to calculate the number of bank accounts for each salary category. The salary categories are Low Salary: All the salaries strictly less than 20,000 Average Salary: All the salaries in the inclusive range [20,000, 50,000] High Salary: All the salaries strictly greater than 50,000 The result table must contain all three categories. If there are no accounts in a category, return 0. Return the result table in any order. Input: Accounts table: +------------+--------+ | account_id | income | +------------+--------+ | 3          | 108939 | | 2          | 12747  | | 8          | 87709  | | 6          | 91796  | +------------+--------+ Output: +----------------+----------------+ | category       | accounts_count | +----------------+----------------+ | Low Salary     | 1              | | Average Salary | 0              | | High Salary    | 3              | +----------------+----------------+ Explanation: Low Salary: Account 2. Average Salary: No accounts. High Salary: Accounts 3, 6, and 8. SELECT 'Low Salary' AS category, SUM(income<20000) AS accounts_count FROM Accounts UNION SELECT 'Average Salary' AS category, SUM(income>=20000 AND income<=50000) AS accounts_count FROM Accounts UNION SELECT 'High Salary' AS category, SUM(income>50000) AS accounts_count FROM Accounts The reason a union is needed here and not a simple case when followed by a group by count is because we want the category without any accounts to still return a value of zero. Subqueries (7 Questions)

---

#### Employees whose manager left the company

Find the IDs of the employees whose salary is strictly less than $30,000 and whose manager left the company. When a manager leaves the company, their information is deleted from the Employees table, but the reports still have their manager_id set to the manager that left. Return the result table ordered by employee_id. Input: Employees table: +-------------+-----------+------------+--------+ | employee_id | name      | manager_id | salary | +-------------+-----------+------------+--------+ | 3           | Mila      | 9          | 60301  | | 12          | Antonella | null       | 31000  | | 13          | Emery     | null       | 67084  | | 1           | Kalel     | 11         | 21241  | | 9           | Mikaela   | null       | 50937  | | 11          | Joziah    | 6          | 28485  | +-------------+-----------+------------+--------+ Output: +-------------+ | employee_id | +-------------+ | 11          | +-------------+ Explanation: The employees with a salary less than $30000 are 1 (Kalel) and 11 (Joziah). Kalel's manager is employee 11, who is still in the company (Joziah). Joziah's manager is employee 6, who left the company because there is no row for employee 6 as it was deleted. SELECT employee_id FROM Employees WHERE salary<30000 AND manager_id NOT IN (SELECT DISTINCT employee_id FROM Employees) ORDER BY 1

---

#### Exchange seats

Write a solution to swap the seat id of every two consecutive students. If the number of students is odd, the id of the last student is not swapped. Return the result table ordered by id in ascending order. Input: Seat table: +----+---------+ | id | student | +----+---------+ | 1  | Abbot   | | 2  | Doris   | | 3  | Emerson | | 4  | Green   | | 5  | Jeames  | +----+---------+ Output: +----+---------+ | id | student | +----+---------+ | 1  | Doris   | | 2  | Abbot   | | 3  | Green   | | 4  | Emerson | | 5  | Jeames  | +----+---------+ Explanation: Note that if the number of students is odd, there is no need to change the last one's seat. WITH cte AS ( SELECT * , LAG(student) OVER() AS prev_student , LEAD(student) OVER() AS next_student FROM Seat ) SELECT id , CASE WHEN MOD(id, 2)=1 AND next_student IS NOT NULL THEN next_student WHEN MOD(id, 2)=0 THEN prev_student ELSE student END AS student FROM cte For each ID, get the previous and next student if any. If the ID is odd and there is a next student, swap places with the next student. If the ID is even, then swap places with the previous student. Otherwise, the remaining ID has to be the last student in an odd-numbered group, in which case the student remains in their original place. SELECT ROW_NUMBER() OVER() AS id , student FROM seat ORDER BY IF(MOD(id, 2)=0, id-1, id+1) There is also a more algorithmically elegant way to do what we just did, which at first glance, may seem a little difficult to comprehend. Let‚Äôs break this down. First, if the original ID is even, then minus one and conversely, if the original ID is odd, then plus one. We want to then sort the table based on the newly created IDs which indirectly swaps two consecutive seats. But now that the original IDs are swapped, how do we make sure they are still sorted based on the new student order? This is where we use the row number window function to re-assign the new IDs.

---

#### Movie rating

Write a solution to: Find the name of the user who has rated the greatest number of movies. In case of a tie, return the lexicographically smaller user name. Find the movie name with the highest average rating in February 2020. In case of a tie, return the lexicographically smaller movie name. Input: Movies table: +-------------+--------------+ | movie_id    |  title       | +-------------+--------------+ | 1           | Avengers     | | 2           | Frozen 2     | | 3           | Joker        | +-------------+--------------+ Users table: +-------------+--------------+ | user_id     |  name        | +-------------+--------------+ | 1           | Daniel       | | 2           | Monica       | | 3           | Maria        | | 4           | James        | +-------------+--------------+ MovieRating table: +-------------+--------------+--------------+-------------+ | movie_id    | user_id      | rating       | created_at  | +-------------+--------------+--------------+-------------+ | 1           | 1            | 3            | 2020-01-12  | | 1           | 2            | 4            | 2020-02-11  | | 1           | 3            | 2            | 2020-02-12  | | 1           | 4            | 1            | 2020-01-01  | | 2           | 1            | 5            | 2020-02-17  | | 2           | 2            | 2            | 2020-02-01  | | 2           | 3            | 2            | 2020-03-01  | | 3           | 1            | 3            | 2020-02-22  | | 3           | 2            | 4            | 2020-02-25  | +-------------+--------------+--------------+-------------+ Output: +--------------+ | results      | +--------------+ | Daniel       | | Frozen 2     | +--------------+ Explanation: Daniel and Monica have rated 3 movies ("Avengers", "Frozen 2" and "Joker") but Daniel is smaller lexicographically. Frozen 2 and Joker have a rating average of 3.5 in February but Frozen 2 is smaller lexicographically. (SELECT u.name AS results FROM MovieRating r LEFT JOIN Users u ON r.user_id=u.user_id GROUP BY u.user_id ORDER BY count(*) DESC, u.name LIMIT 1) UNION ALL (SELECT m.title AS results FROM MovieRating r LEFT JOIN Movies m ON r.movie_id=m.movie_id WHERE r.created_at like '2020-02%' GROUP BY r.movie_id ORDER BY AVG(r.rating) DESC, m.title LIMIT 1)

---

#### Restaurant growth

You are the restaurant owner and you want to analyze a possible expansion (there will be at least one customer every day). Compute the moving average of how much the customer paid in a seven-day window (current day plus six days before). average_amount should be rounded to two decimal places. Return the result table ordered by visited_on in ascending order. Input: Customer table: +-------------+--------------+--------------+-------------+ | customer_id | name         | visited_on   | amount      | +-------------+--------------+--------------+-------------+ | 1           | Jhon         | 2019-01-01   | 100         | | 2           | Daniel       | 2019-01-02   | 110         | | 3           | Jade         | 2019-01-03   | 120         | | 4           | Khaled       | 2019-01-04   | 130         | | 5           | Winston      | 2019-01-05   | 110         | | 6           | Elvis        | 2019-01-06   | 140         | | 7           | Anna         | 2019-01-07   | 150         | | 8           | Maria        | 2019-01-08   | 80          | | 9           | Jaze         | 2019-01-09   | 110         | | 1           | Jhon         | 2019-01-10   | 130         | | 3           | Jade         | 2019-01-10   | 150         | +-------------+--------------+--------------+-------------+ Output: +--------------+--------------+----------------+ | visited_on   | amount       | average_amount | +--------------+--------------+----------------+ | 2019-01-07   | 860          | 122.86         | | 2019-01-08   | 840          | 120            | | 2019-01-09   | 840          | 120            | | 2019-01-10   | 1000         | 142.86         | +--------------+--------------+----------------+ Explanation: 1st moving average from 2019-01-01 to 2019-01-07 has an average_amount of (100 + 110 + 120 + 130 + 110 + 140 + 150)/7 = 122.86 2nd moving average from 2019-01-02 to 2019-01-08 has an average_amount of (110 + 120 + 130 + 110 + 140 + 150 + 80)/7 = 120 3rd moving average from 2019-01-03 to 2019-01-09 has an average_amount of (120 + 130 + 110 + 140 + 150 + 80 + 110)/7 = 120 4th moving average from 2019-01-04 to 2019-01-10 has an average_amount of (130 + 110 + 140 + 150 + 80 + 110 + 130 + 150)/7 = 142.86 SELECT visited_on AS visited_on , SUM(b.day_sum) AS amount , ROUND(AVG(b.day_sum), 2) AS average_amount FROM (SELECT visited_on, SUM(amount) AS day_sum FROM Customer GROUP BY visited_on) a , (SELECT visited_on, SUM(amount) AS day_sum FROM Customer GROUP BY visited_on) b WHERE DATEDIFF(a.visited_on, b.visited_on) BETWEEN 0 AND 6 GROUP BY a.visited_on HAVING COUNT(b.visited_on) = 7 Use inner join to get the preceding six days, if applicable, for each visit date and calculate the average of the seven days total (the current day plus the six preceding days).

---

#### Friend request II: who has the most friends

Write a solution to find the people who have the most friends and the most friends number. Input: RequestAccepted table: +--------------+-------------+-------------+ | requester_id | accepter_id | accept_date | +--------------+-------------+-------------+ | 1            | 2           | 2016/06/03  | | 1            | 3           | 2016/06/08  | | 2            | 3           | 2016/06/08  | | 3            | 4           | 2016/06/09  | +--------------+-------------+-------------+ Output: +----+-----+ | id | num | +----+-----+ | 3  | 3   | +----+-----+ Explanation: The person with id 3 is a friend of people 1, 2, and 4, so he has three friends in total, which is the most number than any others. WITH cte AS ( SELECT requester_id AS id FROM RequestAccepted UNION ALL SELECT accepter_id id FROM RequestAccepted ) SELECT id, COUNT(*) AS num FROM cte GROUP BY 1 ORDER BY 2 DESC LIMIT 1 Every ID has the same number of friends as they are the number of times they appear as a row in the table. A person forms a new friend by either sending or accepting a request. Once you learn this pattern, this problem should be very easy to crack.

---

#### Investments in 2016

Write a solution to report the sum of all total investment values in 2016 tiv_2016, for all policyholders who: Have the same tiv_2015 value as one or more other policyholders Are not located in the same city as any other policyholder (lat, lon attribute pairs must be unique) Input: Insurance table: +-----+----------+----------+-----+-----+ | pid | tiv_2015 | tiv_2016 | lat | lon | +-----+----------+----------+-----+-----+ | 1   | 10       | 5        | 10  | 10  | | 2   | 20       | 20       | 20  | 20  | | 3   | 10       | 30       | 20  | 20  | | 4   | 10       | 40       | 40  | 40  | +-----+----------+----------+-----+-----+ Output: +----------+ | tiv_2016 | +----------+ | 45.00    | +----------+ Explanation: The first record in the table, like the last record, meets both of the two criteria. The tiv_2015 value 10 is the same as the third and fourth records, and its location is unique. The second record does not meet any of the two criteria. Its tiv_2015 is not like any other policyholders and its location is the same as the third record, which makes the third record fail, too. So, the result is the sum of tiv_2016 of the first and last record, which is 45. WITH cte AS ( SELECT * , COUNT(*) OVER(PARTITION BY tiv_2015) AS cnt1 , COUNT(*) OVER(PARTITION BY lat, lon) AS cnt2 FROM Insurance ) SELECT ROUND(SUM(tiv_2016), 2) AS tiv_2016 FROM cte WHERE cnt1>1 AND cnt2=1

---

#### Department top three salaries

A company‚Äôs executives are interested in seeing who earns the most money in each of the company‚Äôs departments. A high earner in a department is an employee who has a salary in the top three unique salaries for that department. Write a solution to find the employees who are high earners in each of the departments. Return the result table in any order. Input: Employee table: +----+-------+--------+--------------+ | id | name  | salary | departmentId | +----+-------+--------+--------------+ | 1  | Joe   | 85000  | 1            | | 2  | Henry | 80000  | 2            | | 3  | Sam   | 60000  | 2            | | 4  | Max   | 90000  | 1            | | 5  | Janet | 69000  | 1            | | 6  | Randy | 85000  | 1            | | 7  | Will  | 70000  | 1            | +----+-------+--------+--------------+ Department table: +----+-------+ | id | name  | +----+-------+ | 1  | IT    | | 2  | Sales | +----+-------+ Output: +------------+----------+--------+ | Department | Employee | Salary | +------------+----------+--------+ | IT         | Max      | 90000  | | IT         | Joe      | 85000  | | IT         | Randy    | 85000  | | IT         | Will     | 70000  | | Sales      | Henry    | 80000  | | Sales      | Sam      | 60000  | +------------+----------+--------+ Explanation: In the IT department: - Max earns the highest unique salary - Both Randy and Joe earn the second-highest unique salary - Will earns the third-highest unique salary In the Sales department: - Henry earns the highest salary - Sam earns the second-highest salary - There is no third-highest salary as there are only two employees WITH cte AS ( SELECT e.id , e.name AS Employee , e.salary AS Salary , DENSE_RANK() OVER(PARTITION BY d.name ORDER BY e.salary DESC) AS dept_rank , d.name AS Department FROM Employee e LEFT JOIN Department d ON e.departmentId=d.id ) SELECT Department , Employee , Salary FROM cte WHERE dept_rank<=3 Advanced String Functions, Regex and Clause (7 Questions) Now, I should note that you will rarely encounter regex-type SQL problems during real-life interviews unless you are interviewing at a company that is focused on text mining. Nevertheless, here are a few questions that you can learn or practise applying regular expressions in SQL.

---

#### Fix names in a table

Write a solution to fix the names so that only the first character is uppercase and the rest are lowercase. Return the result table ordered by user_id. Input: Users table: +---------+-------+ | user_id | name  | +---------+-------+ | 1       | aLice | | 2       | bOB   | +---------+-------+ Output: +---------+-------+ | user_id | name  | +---------+-------+ | 1       | Alice | | 2       | Bob   | +---------+-------+ SELECT user_id , CONCAT(UPPER(SUBSTR(name, 1, 1)), LOWER(SUBSTR(name, 2))) AS name FROM Users ORDER BY 1

---

#### Patients with a condition

Write a solution to find the patient_id, patient_name, and conditions of the patients who have Type I Diabetes. Type I Diabetes always starts with DIAB1 prefix. Return the result table in any order. Input: Patients table: +------------+--------------+--------------+ | patient_id | patient_name | conditions   | +------------+--------------+--------------+ | 1          | Daniel       | YFEV COUGH   | | 2          | Alice        |              | | 3          | Bob          | DIAB100 MYOP | | 4          | George       | ACNE DIAB100 | | 5          | Alain        | DIAB201      | +------------+--------------+--------------+ Output: +------------+--------------+--------------+ | patient_id | patient_name | conditions   | +------------+--------------+--------------+ | 3          | Bob          | DIAB100 MYOP | | 4          | George       | ACNE DIAB100 | +------------+--------------+--------------+ Explanation: Bob and George both have a condition that starts with DIAB1. SELECT * FROM Patients WHERE conditions LIKE 'DIAB1%' OR conditions LIKE '% DIAB1%'

---

#### Delete duplicate emails

Write a solution to delete all duplicate emails, keeping only one unique email with the smallest id. For SQL users, please note that you are supposed to write a DELETE statement and not a SELECT one. Input: Person table: +----+------------------+ | id | email            | +----+------------------+ | 1  | john@example.com | | 2  | bob@example.com  | | 3  | john@example.com | +----+------------------+ Output: +----+------------------+ | id | email            | +----+------------------+ | 1  | john@example.com | | 2  | bob@example.com  | +----+------------------+ Explanation: john@example.com is repeated two times. We keep the row with the smallest Id = 1. DELETE p1 FROM person p1, person p2 WHERE p1.email=p2.email AND p1.id>p2.id

---

#### Second highest salary

Write a solution to find the second-highest salary from the Employee table. If there is no second-highest salary, return null. Example 1 Input: Employee table: +----+--------+ | id | salary | +----+--------+ | 1  | 100    | | 2  | 200    | | 3  | 300    | +----+--------+ Output: +---------------------+ | SecondHighestSalary | +---------------------+ | 200                 | +---------------------+ Example 2 Input: Employee table: +----+--------+ | id | salary | +----+--------+ | 1  | 100    | +----+--------+ Output: +---------------------+ | SecondHighestSalary | +---------------------+ | null                | +---------------------+ SELECT MAX(salary) AS SecondHighestSalary FROM Employee WHERE salary < (SELECT MAX(salary) from Employee)

---

#### Group sold products by the date

Write a solution to find for each date the number of different products sold and their names. The sold product names for each date should be sorted lexicographically. Return the result ordered by sell_date. Input: Activities table: +------------+------------+ | sell_date  | product     | +------------+------------+ | 2020-05-30 | Headphone  | | 2020-06-01 | Pencil     | | 2020-06-02 | Mask       | | 2020-05-30 | Basketball | | 2020-06-01 | Bible      | | 2020-06-02 | Mask       | | 2020-05-30 | T-Shirt    | +------------+------------+ Output: +------------+----------+------------------------------+ | sell_date  | num_sold | products                     | +------------+----------+------------------------------+ | 2020-05-30 | 3        | Basketball,Headphone,T-shirt | | 2020-06-01 | 2        | Bible,Pencil                 | | 2020-06-02 | 1        | Mask                         | +------------+----------+------------------------------+ Explanation: For 2020-05-30, Sold items were (Headphone, Basketball, T-shirt), we sort them lexicographically and separate them by a comma. For 2020-06-01, Sold items were (Pencil, Bible), we sort them lexicographically and separate them by a comma. For 2020-06-02, the Sold item is (Mask), we just return it. SELECT sell_date , COUNT(DISTINCT product) AS num_sold , GROUP_CONCAT(DISTINCT product ORDER BY product separator ',') AS products FROM Activities GROUP BY 1

---

#### List the products ordered in a period

Write a solution to get the names of the products that have at least 100 units ordered in February 2020 and their amount. Return the result table in any order. Input: Products table: +-------------+-----------------------+------------------+ | product_id  | product_name          | product_category | +-------------+-----------------------+------------------+ | 1           | Leetcode Solutions    | Book             | | 2           | Jewels of Stringology | Book             | | 3           | HP                    | Laptop           | | 4           | Lenovo                | Laptop           | | 5           | Leetcode Kit          | T-shirt          | +-------------+-----------------------+------------------+ Orders table: +--------------+--------------+----------+ | product_id   | order_date   | unit     | +--------------+--------------+----------+ | 1            | 2020-02-05   | 60       | | 1            | 2020-02-10   | 70       | | 2            | 2020-01-18   | 30       | | 2            | 2020-02-11   | 80       | | 3            | 2020-02-17   | 2        | | 3            | 2020-02-24   | 3        | | 4            | 2020-03-01   | 20       | | 4            | 2020-03-04   | 30       | | 4            | 2020-03-04   | 60       | | 5            | 2020-02-25   | 50       | | 5            | 2020-02-27   | 50       | | 5            | 2020-03-01   | 50       | +--------------+--------------+----------+ Output: +--------------------+---------+ | product_name       | unit    | +--------------------+---------+ | Leetcode Solutions | 130     | | Leetcode Kit       | 100     | +--------------------+---------+ Explanation: Products with product_id = 1 is ordered in February a total of (60 + 70) = 130. Products with product_id = 2 is ordered in February a total of 80. Products with product_id = 3 is ordered in February a total of (2 + 3) = 5. Products with product_id = 4 was not ordered in February 2020. Products with product_id = 5 is ordered in February a total of (50 + 50) = 100. SELECT product_name , SUM(unit) AS unit FROM Orders o LEFT JOIN Products p ON o.product_id=p.product_id WHERE order_date LIKE '2020-02%' GROUP BY 1 HAVING SUM(unit)>=100

---

#### Find users with valid e-mails

Write a solution to find the users who have valid emails. A valid e-mail has a prefix name and a domain where: The prefix name is a string that may contain letters (upper or lower case), digits, underscore, period, and/or dash. The prefix name must start with a letter The domain is leetcode.com Return the result table in any order. Input: Users table: +---------+-----------+-------------------------+ | user_id | name      | mail                    | +---------+-----------+-------------------------+ | 1       | Winston   | winston@leetcode.com    | | 2       | Jonathan  | jonathanisgreat         | | 3       | Annabelle | bella-@leetcode.com     | | 4       | Sally     | sally.come@leetcode.com | | 5       | Marwan    | quarz#2020@leetcode.com | | 6       | David     | david69@gmail.com       | | 7       | Shapiro   | .shapo@leetcode.com     | +---------+-----------+-------------------------+ Output: +---------+-----------+-------------------------+ | user_id | name      | mail                    | +---------+-----------+-------------------------+ | 1       | Winston   | winston@leetcode.com    | | 3       | Annabelle | bella-@leetcode.com     | | 4       | Sally     | sally.come@leetcode.com | +---------+-----------+-------------------------+ Explanation: The mail of user 2 does not have a domain. The mail of user 5 has the # sign which is not allowed. The mail of user 6 does not have the leetcode domain. The mail of user 7 starts with a period. SELECT * FROM Users WHERE mail REGEXP '^[a-zA-Z][a-zA-Z0-9_.-]*@leetcode[.]com' And that‚Äôs a wrap! I hope these 50 SQL problems have given some insights into what to expect from a coding interview and how you would tackle them.

---

#### -- Question 107

-- The Numbers table keeps the value of number and its frequency. -- +----------+-------------+ -- |  Number  |  Frequency  | -- +----------+-------------| -- |  0       |  7          | -- |  1       |  1          | -- |  2       |  3          | -- |  3       |  1          | -- +----------+-------------+ -- In this table, the numbers are 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 3, so the median is (0 + 0) / 2 = 0. -- +--------+ -- | median | -- +--------| -- | 0.0000 | -- +--------+ -- Write a query to find the median of all numbers and name the result as median. -- Solution with t1 as( select *, sum(frequency) over(order by number) as cum_sum, (sum(frequency) over())/2 as middle from numbers) select avg(number) as median from t1 where middle between (cum_sum - frequency) and cum_sum

---

#### SELECT p.project_id,p.employee_id

FROM project_1077 p JOIN employee_1077 e ON p.employee_id=e.employee_id WHERE (p.project_id,e.experience_years) IN (SELECT p.project_id,MAX(e.experience_years) FROM project_1077 p JOIN employee_1077 e ON p.employee_id=e.employee_id GROUP BY p.project_id) ORDER BY 1; --(OR) WITH ranked AS( SELECT p.project_id,p.employee_id, DENSE_RANK() OVER (w) rnk FROM project_1077 p JOIN employee_1077 e ON p.employee_id=e.employee_id WINDOW w AS (PARTITION BY p.project_id ORDER BY e.experience_years DESC) ) SELECT project_id,employee_id FROM ranked WHERE rnk =1;

---

#### -- Question 10

-- Given a table customer holding customers information and the referee. -- +------+------+-----------+ -- | id   | name | referee_id| -- +------+------+-----------+ -- |    1 | Will |      NULL | -- |    2 | Jane |      NULL | -- |    3 | Alex |         2 | -- |    4 | Bill |      NULL | -- |    5 | Zack |         1 | -- |    6 | Mark |         2 | -- +------+------+-----------+ -- Write a query to return the list of customers NOT referred by the person with id '2'. -- For the sample data above, the result is: -- +------+ -- | name | -- +------+ -- | Will | -- | Jane | -- | Bill | -- | Zack | -- +------+ -- Solution Select name from customer where referee_id != 2 or referee_id is NULL

---

#### WITH recent_orders AS (

SELECT o1.* FROM orders_1549 o1 LEFT JOIN orders_1549 o2 ON o1.product_id = o2.product_id AND o1.order_date < o2.order_date WHERE o2.order_id IS NULL ) SELECT p.product_name,p.product_id,ro.order_id,ro.order_date FROM recent_orders ro INNER JOIN products_1549 p ON ro.product_id = p.product_id ORDER BY p.product_name,p.product_id,ro.order_id;

---

#### -- Question 111

-- Table: Activity -- +--------------+---------+ -- | Column Name  | Type    | -- +--------------+---------+ -- | player_id    | int     | -- | device_id    | int     | -- | event_date   | date    | -- | games_played | int     | -- +--------------+---------+ -- (player_id, event_date) is the primary key of this table. -- This table shows the activity of players of some game. -- Each row is a record of a player who logged in and played a number of games (possibly 0) before logging out on some day using some device. -- We define the install date of a player to be the first login day of that player. -- We also define day 1 retention of some date X to be the number of players whose install date is X and they logged back in on the day right after X, divided by the number of players whose install date is X, rounded to 2 decimal places. -- Write an SQL query that reports for each install date, the number of players that installed the game on that day and the day 1 retention. -- The query result format is in the following example: -- Activity table: -- +-----------+-----------+------------+--------------+ -- | player_id | device_id | event_date | games_played | -- +-----------+-----------+------------+--------------+ -- | 1         | 2         | 2016-03-01 | 5            | -- | 1         | 2         | 2016-03-02 | 6            | -- | 2         | 3         | 2017-06-25 | 1            | -- | 3         | 1         | 2016-03-01 | 0            | -- | 3         | 4         | 2016-07-03 | 5            | -- +-----------+-----------+------------+--------------+ -- Result table: -- +------------+----------+----------------+ -- | install_dt | installs | Day1_retention | -- +------------+----------+----------------+ -- | 2016-03-01 | 2        | 0.50           | -- | 2017-06-25 | 1        | 0.00           | -- +------------+----------+----------------+ -- Player 1 and 3 installed the game on 2016-03-01 but only player 1 logged back in on 2016-03-02 so the -- day 1 retention of 2016-03-01 is 1 / 2 = 0.50 -- Player 2 installed the game on 2017-06-25 but didn't log back in on 2017-06-26 so the day 1 retention of 2017-06-25 is 0 / 1 = 0.00 -- Solution with t1 as( select *, row_number() over(partition by player_id order by event_date) as rnk, min(event_date) over(partition by player_id) as install_dt, lead(event_date,1) over(partition by player_id order by event_date) as nxt from Activity) select distinct install_dt, count(distinct player_id) as installs, round(sum(case when nxt=event_date+1 then 1 else 0 end)/count(distinct player_id),2) as Day1_retention from t1 where rnk = 1 group by 1 order by 1

---

#### SELECT s.school_id,COALESCE(MIN(e.score),-1) AS max_filled_students

FROM school_1988 s LEFT JOIN exam_1988 e ON s.capacity >= student_count GROUP BY s.school_id ORDER BY s.school_id;

---

#### SELECT student_id,department_id,

ROUND((RANK() OVER (PARTITION BY department_id ORDER BY mark DESC)-1)*100/ (COUNT(student_id) OVER (PARTITION BY department_id)-1),2) AS percentage FROM students_2346;

---

#### SELECT app_id,

ROUND(100.0 * SUM(CASE WHEN event_type = 'click' THEN 1 ELSE 0 END) / SUM(CASE WHEN event_type = 'impression' THEN 1 ELSE 0 END), 2) AS ctr FROM events WHERE DATE_PART('YEAR', timestamp) = 2022 GROUP BY app_id;

---

#### -- Question 41

-- Table: Queries -- +-------------+---------+ -- | Column Name | Type    | -- +-------------+---------+ -- | query_name  | varchar | -- | result      | varchar | -- | position    | int     | -- | rating      | int     | -- +-------------+---------+ -- There is no primary key for this table, it may have duplicate rows. -- This table contains information collected from some queries on a database. -- The position column has a value from 1 to 500. -- The rating column has a value from 1 to 5. Query with rating less than 3 is a poor query. -- We define query quality as: -- The average of the ratio between query rating and its position. -- We also define poor query percentage as: -- The percentage of all queries with rating less than 3. -- Write an SQL query to find each query_name, the quality and poor_query_percentage. -- Both quality and poor_query_percentage should be rounded to 2 decimal places. -- The query result format is in the following example: -- Queries table: -- +------------+-------------------+----------+--------+ -- | query_name | result            | position | rating | -- +------------+-------------------+----------+--------+ -- | Dog        | Golden Retriever  | 1        | 5      | -- | Dog        | German Shepherd   | 2        | 5      | -- | Dog        | Mule              | 200      | 1      | -- | Cat        | Shirazi           | 5        | 2      | -- | Cat        | Siamese           | 3        | 3      | -- | Cat        | Sphynx            | 7        | 4      | -- +------------+-------------------+----------+--------+ -- Result table: -- +------------+---------+-----------------------+ -- | query_name | quality | poor_query_percentage | -- +------------+---------+-----------------------+ -- | Dog        | 2.50    | 33.33                 | -- | Cat        | 0.66    | 33.33                 | -- +------------+---------+-----------------------+ -- Dog queries quality is ((5 / 1) + (5 / 2) + (1 / 200)) / 3 = 2.50 -- Dog queries poor_ query_percentage is (1 / 3) * 100 = 33.33 -- Cat queries quality equals ((2 / 5) + (3 / 3) + (4 / 7)) / 3 = 0.66 -- Cat queries poor_ query_percentage is (1 / 3) * 100 = 33.33 -- Solution Select query_name, round(sum(rating/position)/count(*),2) as quality, round(avg(case when rating<3 then 1 else 0 end)*100,2) as poor_query_percentage from queries group by query_name

---

#### -- Question 73

-- Table: Actions -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | user_id       | int     | -- | post_id       | int     | -- | action_date   | date    | -- | action        | enum    | -- | extra         | varchar | -- +---------------+---------+ -- There is no primary key for this table, it may have duplicate rows. -- The action column is an ENUM type of ('view', 'like', 'reaction', 'comment', 'report', 'share'). -- The extra column has optional information about the action such as a reason for report or a type of reaction. -- Table: Removals -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | post_id       | int     | -- | remove_date   | date    | -- +---------------+---------+ -- post_id is the primary key of this table. -- Each row in this table indicates that some post was removed as a result of being reported or as a result of an admin review. -- Write an SQL query to find the average for daily percentage of posts that got removed after being reported as spam, rounded to 2 decimal places. -- The query result format is in the following example: -- Actions table: -- +---------+---------+-------------+--------+--------+ -- | user_id | post_id | action_date | action | extra  | -- +---------+---------+-------------+--------+--------+ -- | 1       | 1       | 2019-07-01  | view   | null   | -- | 1       | 1       | 2019-07-01  | like   | null   | -- | 1       | 1       | 2019-07-01  | share  | null   | -- | 2       | 2       | 2019-07-04  | view   | null   | -- | 2       | 2       | 2019-07-04  | report | spam   | -- | 3       | 4       | 2019-07-04  | view   | null   | -- | 3       | 4       | 2019-07-04  | report | spam   | -- | 4       | 3       | 2019-07-02  | view   | null   | -- | 4       | 3       | 2019-07-02  | report | spam   | -- | 5       | 2       | 2019-07-03  | view   | null   | -- | 5       | 2       | 2019-07-03  | report | racism | -- | 5       | 5       | 2019-07-03  | view   | null   | -- | 5       | 5       | 2019-07-03  | report | racism | -- +---------+---------+-------------+--------+--------+ -- Removals table: -- +---------+-------------+ -- | post_id | remove_date | -- +---------+-------------+ -- | 2       | 2019-07-20  | -- | 3       | 2019-07-18  | -- +---------+-------------+ -- Result table: -- +-----------------------+ -- | average_daily_percent | -- +-----------------------+ -- | 75.00                 | -- +-----------------------+ -- The percentage for 2019-07-04 is 50% because only one post of two spam reported posts was removed. -- The percentage for 2019-07-02 is 100% because one post was reported as spam and it was removed. -- The other days had no spam reports so the average is (50 + 100) / 2 = 75% -- Note that the output is only one number and that we do not care about the remove dates. -- Solution with t1 as( select a.action_date, (count(distinct r.post_id)+0.0)/(count(distinct a.post_id)+0.0) as result from (select action_date, post_id from actions where extra = 'spam' and action = 'report') a left join removals r on a.post_id = r.post_id group by a.action_date) select round(avg(t1.result)*100,2) as  average_daily_percent from t1

---

#### -- T-SQL Solution

WITH CTE AS ( SELECT department_name, name, salary, DENSE_RANK() OVER(PARTITION BY department_name ORDER BY salary DESC)  AS RN FROM employee AS E JOIN department AS D ON E.department_id = D.department_id ) SELECT department_name, name, salary FROM CTE WHERE RN IN (1, 2, 3) ORDER BY department_name, salary DESC, name;

---

#### SELECT teacher_id,COUNT(DISTINCT subject_id)

FROM teacher_2356 GROUP BY teacher_id;

---

#### I'm a senior reporting analyst and I consider myself proficient, here's what we generally look for when hiring.

know the difference between joins (inner and left are 95% of pulling data, I never use right joins) and how they relate to what data is being pulled. This is basic SQL. learn aggregate functions. Sometimes you want to count all widgets, sometimes you only want to count how many different widgets. Learn to use HAVING when grouping for aggregate function. pick a formatting for code use it. Some people always put the comma after the column name in a select, some people put it before the name. Some people use tab/space to give it a visual pattern (I do) while some don't. It's OK to change your formatting if you find something does or does not work for you but generally be consistent. add notes. I have a header statement I paste at the beginning of all scripts that states what the script does, any ticket #'s associated (and what the ticket request was changing), the date it was completed, and who the dev was. Force the habit of adding notes throughout the script to identify anything not obvious or to highlight import stuff. If the column name is [col1] then add a note that describes what data is in that column. learn the difference between CTE's and temp or volatile tables, and when each should be used. If using MS/T-SQL using global temp tables helps a ton in troubleshooting. learn a methodical way to troubleshoot and stick to it. This helps a ton in the beginning and will save you at least one head pounding on wall moment a week because you use "like" instead of = when dealing with integers. When starting g out with SQL I had a text file that was basically my manual for troubleshooting and added new steps when I came across a new issue.

---

#### Practical SQL Puzzles That Will Level Up Your Skill

Three real-world SQL patterns that can be applied to many problems. Mateus Trentz Mar 4, 2025 14 min read Share An image of a blue puzzle missing a single piece (SQL puzzles concept) Photo by Tanja Tepavac on Unsplash There are some SQL patterns that, once you know them, you start seeing them everywhere. The solutions to the puzzles that I will show you today are actually very simple SQL queries, but understanding the concept behind them will surely unlock new solutions to the queries you write on a day-to-day basis. These challenges are all based on real-world scenarios, as over the past few months I made a point of writing down every puzzle-like query that I had to build. I also encourage you to try them for yourself, so that you can challenge yourself first, which will improve your learning! All queries to generate the datasets will be provided in a PostgreSQL and DuckDB-friendly syntax, so that you can easily copy and play with them. At the end I will also provide you a link to a GitHub repo containing all the code, as well as the answer to the bonus challenge I will leave for you! I organized these puzzles in order of increasing difficulty, so, if you find the first ones too easy, at least take a look at the last one, which uses a technique that I truly believe you won‚Äôt have seen before. Okay, let‚Äôs get started. Analyzing ticket moves I love this puzzle because of how short and simple the final query is, even though it deals with many edge cases. The data for this challenge shows tickets moving in between Kanban stages, and the objective is to find how long, on average, tickets stay in the Doing stage. The data contains the ID of the ticket, the date the ticket was created, the date of the move, and the ‚Äúfrom‚Äù and ‚Äúto‚Äù stages of the move. The stages present are New, Doing, Review, and Done. Some things you need to know (edge cases): Tickets can move backwards, meaning tickets can go back to the Doing stage. You should not include tickets that are still stuck in the Doing stage, as there is no way to know how long they will stay there for. Tickets are not always created in the New stage. CREATE TABLE ticket_moves ( ticket_id INT NOT NULL, create_date DATE NOT NULL, move_date DATE NOT NULL, from_stage TEXT NOT NULL, to_stage TEXT NOT NULL ); INSERT INTO ticket_moves (ticket_id, create_date, move_date, from_stage, to_stage) VALUES -- Ticket 1: Created in "New", then moves to Doing, Review, Done. (1, '2024-09-01', '2024-09-03', 'New', 'Doing'), (1, '2024-09-01', '2024-09-07', 'Doing', 'Review'), (1, '2024-09-01', '2024-09-10', 'Review', 'Done'), -- Ticket 2: Created in "New", then moves: New ‚Üí Doing ‚Üí Review ‚Üí Doing again ‚Üí Review. (2, '2024-09-05', '2024-09-08', 'New', 'Doing'), (2, '2024-09-05', '2024-09-12', 'Doing', 'Review'), (2, '2024-09-05', '2024-09-15', 'Review', 'Doing'), (2, '2024-09-05', '2024-09-20', 'Doing', 'Review'), -- Ticket 3: Created in "New", then moves to Doing. (Edge case: no subsequent move from Doing.) (3, '2024-09-10', '2024-09-16', 'New', 'Doing'), -- Ticket 4: Created already in "Doing", then moves to Review. (4, '2024-09-15', '2024-09-22', 'Doing', 'Review'); A summary of the data: Ticket 1: Created in the New stage, moves normally to Doing, then Review, and then Done. Ticket 2: Created in New, then moves: New ‚Üí Doing ‚Üí Review ‚Üí Doing again ‚Üí Review. Ticket 3: Created in New, moves to Doing, but it is still stuck there. Ticket 4: Created in the Doing stage, moves to Review afterward. It might be a good idea to stop for a bit and think how you would deal with this. Can you find out how long a ticket stays on a single stage? Honestly, this sounds intimidating at first, and it looks like it will be a nightmare to deal with all the edge cases. Let me show you the full solution to the problem, and then I will explain what is happening afterward. WITH stage_intervals AS ( SELECT ticket_id, from_stage, move_date - COALESCE( LAG(move_date) OVER ( PARTITION BY ticket_id ORDER BY move_date ), create_date ) AS days_in_stage FROM ticket_moves ) SELECT SUM(days_in_stage) / COUNT(DISTINCT ticket_id) as avg_days_in_doing FROM stage_intervals WHERE from_stage = 'Doing'; The first CTE uses the LAG function to find the previous move of the ticket, which will be the time the ticket entered that stage. Calculating the duration is as simple as subtracting the previous date from the move date. What you should notice is the use of the COALESCE in the previous move date. What that does is that if a ticket doesn‚Äôt have a previous move, then it uses the date of creation of the ticket. This takes care of the cases of tickets being created directly into the Doing stage, as it still will properly calculate the time it took to leave the stage. This is the result of the first CTE, showing the time spent in each stage. Notice how the Ticket 2 has two entries, as it visited the Doing stage in two separate occasions. With this done, it‚Äôs just a matter of getting the average as the SUM of total days spent in doing, divided by the distinct number of tickets that ever left the stage. Doing it this way, instead of simply using the AVG, makes sure that the two rows for Ticket 2 get properly accounted for as a single ticket. Not so bad, right? Finding contract sequences The goal of this second challenge is to find the most recent contract sequence of every employee. A break of sequence happens when two contracts have a gap of more than one day between them. In this dataset, there are no contract overlaps, meaning that a contract for the same employee either has a gap or ends a day before the new one starts. CREATE TABLE contracts ( contract_id integer PRIMARY KEY, employee_id integer NOT NULL, start_date date NOT NULL, end_date date NOT NULL ); INSERT INTO contracts (contract_id, employee_id, start_date, end_date) VALUES -- Employee 1: Two continuous contracts (1, 1, '2024-01-01', '2024-03-31'), (2, 1, '2024-04-01', '2024-06-30'), -- Employee 2: One contract, then a gap of three days, then two contracts (3, 2, '2024-01-01', '2024-02-15'), (4, 2, '2024-02-19', '2024-04-30'), (5, 2, '2024-05-01', '2024-07-31'), -- Employee 3: One contract (6, 3, '2024-03-01', '2024-08-31'); As a summary of the data: Employee 1: Has two continuous contracts. Employee 2: One contract, then a gap of three days, then two contracts. Employee 3: One contract. The expected result, given the dataset, is that all contracts should be included except for the first contract of Employee 2, which is the only one that has a gap. Before explaining the logic behind the solution, I would like you to think about what operation can be used to join the contracts that belong to the same sequence. Focus only on the second row of data, what information do you need to know if this contract was a break or not? I hope it‚Äôs clear that this is the perfect situation for window functions, again. They are incredibly useful for solving problems like this, and understanding when to use them helps a lot in finding clean solutions to problems. First thing to do, then, is to get the end date of the previous contract for the same employee with the LAG function. Doing that, it‚Äôs simple to compare both dates and check if it was a break of sequence. WITH ordered_contracts AS ( SELECT *, LAG(end_date) OVER (PARTITION BY employee_id ORDER BY start_date) AS previous_end_date FROM contracts ), gapped_contracts AS ( SELECT *, -- Deals with the case of the first contract, which won't have -- a previous end date. In this case, it's still the start of a new -- sequence. CASE WHEN previous_end_date IS NULL OR previous_end_date < start_date - INTERVAL '1 day' THEN 1 ELSE 0 END AS is_new_sequence FROM ordered_contracts ) SELECT * FROM gapped_contracts ORDER BY employee_id ASC; An intuitive way to continue the query is to number the sequences of each employee. For example, an employee who has no gap, will always be on his first sequence, but an employee who had 5 breaks in contracts will be on his 5th sequence. Funnily enough, this is done by another window function. -- -- Previous CTEs -- sequences AS ( SELECT *, SUM(is_new_sequence) OVER (PARTITION BY employee_id ORDER BY start_date) AS sequence_id FROM gapped_contracts ) SELECT * FROM sequences ORDER BY employee_id ASC; Notice how, for Employee 2, he starts his sequence #2 after the first gapped value. To finish this query, I grouped the data by employee, got the value of their most recent sequence, and then did an inner join with the sequences to keep only the most recent one. -- -- Previous CTEs -- max_sequence AS ( SELECT employee_id, MAX(sequence_id) AS max_sequence_id FROM sequences GROUP BY employee_id ), latest_contract_sequence AS ( SELECT c.contract_id, c.employee_id, c.start_date, c.end_date FROM sequences c JOIN max_sequence m ON c.sequence_id = m.max_sequence_id AND c.employee_id = m.employee_id ORDER BY c.employee_id, c.start_date ) SELECT * FROM latest_contract_sequence; As expected, our final result is basically our starting query just with the first contract of Employee 2 missing! Tracking concurrent events Finally, the last puzzle ‚Äî I‚Äôm glad you made it this far. For me, this is the most mind-blowing one, as when I first encountered this problem I thought of a completely different solution that would be a mess to implement in SQL. For this puzzle, I‚Äôve changed the context from what I had to deal with for my job, as I think it will make it easier to explain. Imagine you‚Äôre a data analyst at an event venue, and you‚Äôre analyzing the talks scheduled for an upcoming event. You want to find the time of day where there will be the highest number of talks happening at the same time. This is what you should know about the schedules: Rooms are booked in increments of 30min, e.g. from 9h-10h30. The data is clean, there are no overbookings of meeting rooms. There can be back-to-back meetings in a single meeting room. Meeting schedule visualized (this is the actual data). CREATE TABLE meetings ( room TEXT NOT NULL, start_time TIMESTAMP NOT NULL, end_time TIMESTAMP NOT NULL ); INSERT INTO meetings (room, start_time, end_time) VALUES -- Room A meetings ('Room A', '2024-10-01 09:00', '2024-10-01 10:00'), ('Room A', '2024-10-01 10:00', '2024-10-01 11:00'), ('Room A', '2024-10-01 11:00', '2024-10-01 12:00'), -- Room B meetings ('Room B', '2024-10-01 09:30', '2024-10-01 11:30'), -- Room C meetings ('Room C', '2024-10-01 09:00', '2024-10-01 10:00'), ('Room C', '2024-10-01 11:30', '2024-10-01 12:00'); The way to solve this is using what is called a Sweep Line Algorithm, or also known as an event-based solution. This last name actually helps to understand what will be done, as the idea is that instead of dealing with intervals, which is what we have in the original data, we deal with events instead. To do this, we need to transform every row into two separate events. The first event will be the Start of the meeting, and the second event will be the End of the meeting. WITH events AS ( -- Create an event for the start of each meeting (+1) SELECT start_time AS event_time, 1 AS delta FROM meetings UNION ALL -- Create an event for the end of each meeting (-1) SELECT -- Small trick to work with the back-to-back meetings (explained later) end_time - interval '1 minute' as end_time, -1 AS delta FROM meetings ) SELECT * FROM events; Take the time to understand what is happening here. To create two events from a single row of data, we‚Äôre simply unioning the dataset on itself; the first half uses the start time as the timestamp, and the second part uses the end time. You might already notice the delta column created and see where this is going. When an event starts, we count it as +1, when it ends, we count it as -1. You might even be already thinking of another window function to solve this, and you‚Äôre actually right! But before that, let me just explain the trick I used in the end dates. As I don‚Äôt want back-to-back meetings to count as two concurrent meetings, I‚Äôm subtracting a single minute of every end date. This way, if a meeting ends and another starts at 10h30, it won‚Äôt be assumed that two meetings are concurrently happening at 10h30. Okay, back to the query and yet another window function. This time, though, the function of choice is a rolling SUM. -- -- Previous CTEs -- ordered_events AS ( SELECT event_time, delta, SUM(delta) OVER (ORDER BY event_time, delta DESC) AS concurrent_meetings FROM events ) SELECT * FROM ordered_events ORDER BY event_time DESC; The rolling SUM at the Delta column is essentially walking down every record and finding how many events are active at that time. For example, at 9 am sharp, it sees two events starting, so it marks the number of concurrent meetings as two! When the third meeting starts, the count goes up to three. But when it gets to 9h59 (10 am), then two meetings end, bringing the counter back to one. With this data, the only thing missing is to find when the highest value of concurrent meetings happens. -- -- Previous CTEs -- max_events AS ( -- Find the maximum concurrent meetings value SELECT event_time, concurrent_meetings, RANK() OVER (ORDER BY concurrent_meetings DESC) AS rnk FROM ordered_events ) SELECT event_time, concurrent_meetings FROM max_events WHERE rnk = 1; That‚Äôs it! The interval of 9h30‚Äì10h is the one with the largest number of concurrent meetings, which checks out with the schedule visualization above! This solution looks incredibly simple in my opinion, and it works for so many situations. Every time you are dealing with intervals now, you should think if the query wouldn‚Äôt be easier if you thought about it in the perspective of events. But before you move on, and to really nail down this concept, I want to leave you with a bonus challenge, which is also a common application of the Sweep Line Algorithm. I hope you give it a try! Bonus challenge The context for this one is still the same as the last puzzle, but now, instead of trying to find the period when there are most concurrent meetings, the objective is to find bad scheduling. It seems that there are overlaps in the meeting rooms, which need to be listed so it can be fixed ASAP. How would you find out if the same meeting room has two or more meetings booked at the same time? Here are some tips on how to solve it: It‚Äôs still the same algorithm. This means you will still do the UNION, but it will look slightly different. You should think in the perspective of each meeting room. You can use this data for the challenge: CREATE TABLE meetings_overlap ( room TEXT NOT NULL, start_time TIMESTAMP NOT NULL, end_time TIMESTAMP NOT NULL ); INSERT INTO meetings_overlap (room, start_time, end_time) VALUES -- Room A meetings ('Room A', '2024-10-01 09:00', '2024-10-01 10:00'), ('Room A', '2024-10-01 10:00', '2024-10-01 11:00'), ('Room A', '2024-10-01 11:00', '2024-10-01 12:00'), -- Room B meetings ('Room B', '2024-10-01 09:30', '2024-10-01 11:30'), -- Room C meetings ('Room C', '2024-10-01 09:00', '2024-10-01 10:00'), -- Overlaps with previous meeting. ('Room C', '2024-10-01 09:30', '2024-10-01 12:00'); If you‚Äôre interested in the solution to this puzzle, as well as the rest of the queries, check this GitHub repo. Conclusion The first takeaway from this blog post is that window functions are overpowered. Ever since I got more comfortable with using them, I feel that my queries have gotten so much simpler and easier to read, and I hope the same happens to you. If you‚Äôre interested in learning more about them, you would probably enjoy reading this other blog post I‚Äôve written, where I go over how you can understand and use them effectively. The second takeaway is that these patterns used in the challenges really do happen in many other places. You might need to find sequences of subscriptions, customer retention, or you might need to find overlap of tasks. There are many situations when you will need to use window functions in a very similar fashion to what was done in the puzzles. The third thing I want you to remember is about this solution to using events besides dealing with intervals. I‚Äôve looked at some problems I solved a long time ago that I could‚Äôve used this pattern on to make my life easier, and unfortunately, I didn‚Äôt know about it at the time.

---

#### WITH CTE AS

( SELECT DATE_PART('year', transaction_date) AS year, product_id, spend AS curr_year_spend, LAG(spend) OVER(PARTITION BY product_id ORDER BY transaction_date) AS prev_year_spend FROM user_transactions ) SELECT *, ROUND( (curr_year_spend - prev_year_spend) / prev_year_spend * 100, 2) AS yoy_rate FROM CTE

---

#### WITH user_visits_1709 AS (

SELECT * FROM user_visits_1709 UNION ALL SELECT DISTINCT user_id,'2021-1-1'::DATE FROM user_visits_1709 ), ranked_visits AS ( SELECT *, ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY visit_date) AS rn FROM user_visits_1709 ), user_windows AS( SELECT r1.*,r2.visit_date,r2.visit_date-r1.visit_date AS win FROM ranked_visits r1 INNER JOIN ranked_visits r2 ON r1.user_id = r2.user_id AND r1.rn+1 = r2.rn ) SELECT user_id,MAX(win) AS biggest_window FROM user_windows GROUP BY user_id;

---

#### WITH cte AS (

SELECT caller_id AS person_id,duration FROM calls_1501 UNION SELECT callee_id AS person_id,duration FROM calls_1501 ), avg_duration AS( SELECT cn.name AS country_name,c.duration AS duration, AVG(duration) OVER () avg_global_duration, AVG(duration) OVER (PARTITION BY cn.name) avg_country_duration FROM cte c INNER JOIN person_1501 p ON c.person_id=p.id INNER JOIN country_1501 cn ON cn.country_code=SUBSTR(p.phone_number,1,3) ) SELECT DISTINCT country_name FROM avg_duration WHERE avg_country_duration>avg_global_duration;

---

#### WITH RECURSIVE all_subtasks AS (

SELECT task_id,subtasks_count,1 AS subtask_id FROM tasks_1767 UNION ALL SELECT task_id,subtasks_count,subtask_id+1 AS subtask_id FROM all_subtasks WHERE subtask_id<subtasks_count ) SELECT a.task_id,a.subtask_id FROM all_subtasks a LEFT JOIN executed_1767 e ON a.task_id = e.task_id AND a.subtask_id = e.subtask_id WHERE e.task_id IS NULL ORDER BY 1,2;

---

#### SELECT p.product_name,SUM(o.unit)

FROM orders_1327 o INNER JOIN products_1327 p ON o.product_id = p.product_id WHERE DATE_TRUNC('MONTH',o.order_date)::DATE = '2020-02-01' GROUP BY p.product_name HAVING SUM(o.unit) >= 100;

---

#### -- Question 72

-- Table: Customers -- +---------------------+---------+ -- | Column Name         | Type    | -- +---------------------+---------+ -- | customer_id         | int     | -- | customer_name       | varchar | -- +---------------------+---------+ -- customer_id is the primary key for this table. -- customer_name is the name of the customer. -- Table: Orders -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | order_id      | int     | -- | customer_id   | int     | -- | product_name  | varchar | -- +---------------+---------+ -- order_id is the primary key for this table. -- customer_id is the id of the customer who bought the product "product_name". -- Write an SQL query to report the customer_id and customer_name of customers who bought products "A", "B" but did not buy the product "C" since we want to recommend them buy this product. -- Return the result table ordered by customer_id. -- The query result format is in the following example. -- Customers table: -- +-------------+---------------+ -- | customer_id | customer_name | -- +-------------+---------------+ -- | 1           | Daniel        | -- | 2           | Diana         | -- | 3           | Elizabeth     | -- | 4           | Jhon          | -- +-------------+---------------+ -- Orders table: -- +------------+--------------+---------------+ -- | order_id   | customer_id  | product_name  | -- +------------+--------------+---------------+ -- | 10         |     1        |     A         | -- | 20         |     1        |     B         | -- | 30         |     1        |     D         | -- | 40         |     1        |     C         | -- | 50         |     2        |     A         | -- | 60         |     3        |     A         | -- | 70         |     3        |     B         | -- | 80         |     3        |     D         | -- | 90         |     4        |     C         | -- +------------+--------------+---------------+ -- Result table: -- +-------------+---------------+ -- | customer_id | customer_name | -- +-------------+---------------+ -- | 3           | Elizabeth     | -- +-------------+---------------+ -- Only the customer_id with id 3 bought the product A and B but not the product C. -- Solution with t1 as ( select customer_id from orders where product_name = 'B' and customer_id in (select customer_id from orders where product_name = 'A')) Select t1.customer_id, c.customer_name from t1 join customers c on t1.customer_id = c.customer_id where t1.customer_id != all(select customer_id from orders where product_name = 'C')

---

#### -- Question 110

-- Table Person: -- +----------------+---------+ -- | Column Name    | Type    | -- +----------------+---------+ -- | id             | int     | -- | name           | varchar | -- | phone_number   | varchar | -- +----------------+---------+ -- id is the primary key for this table. -- Each row of this table contains the name of a person and their phone number. -- Phone number will be in the form 'xxx-yyyyyyy' where xxx is the country code (3 characters) and yyyyyyy is the -- phone number (7 characters) where x and y are digits. Both can contain leading zeros. -- Table Country: -- +----------------+---------+ -- | Column Name    | Type    | -- +----------------+---------+ -- | name           | varchar | -- | country_code   | varchar | -- +----------------+---------+ -- country_code is the primary key for this table. -- Each row of this table contains the country name and its code. country_code will be in the form 'xxx' where x is digits. -- Table Calls: -- +-------------+------+ -- | Column Name | Type | -- +-------------+------+ -- | caller_id   | int  | -- | callee_id   | int  | -- | duration    | int  | -- +-------------+------+ -- There is no primary key for this table, it may contain duplicates. -- Each row of this table contains the caller id, callee id and the duration of the call in minutes. caller_id != callee_id -- A telecommunications company wants to invest in new countries. The country intends to invest in the countries where the average call duration of the calls in this country is strictly greater than the global average call duration. -- Write an SQL query to find the countries where this company can invest. -- Return the result table in any order. -- The query result format is in the following example. -- Person table: -- +----+----------+--------------+ -- | id | name     | phone_number | -- +----+----------+--------------+ -- | 3  | Jonathan | 051-1234567  | -- | 12 | Elvis    | 051-7654321  | -- | 1  | Moncef   | 212-1234567  | -- | 2  | Maroua   | 212-6523651  | -- | 7  | Meir     | 972-1234567  | -- | 9  | Rachel   | 972-0011100  | -- +----+----------+--------------+ -- Country table: -- +----------+--------------+ -- | name     | country_code | -- +----------+--------------+ -- | Peru     | 051          | -- | Israel   | 972          | -- | Morocco  | 212          | -- | Germany  | 049          | -- | Ethiopia | 251          | -- +----------+--------------+ -- Calls table: -- +-----------+-----------+----------+ -- | caller_id | callee_id | duration | -- +-----------+-----------+----------+ -- | 1         | 9         | 33       | -- | 2         | 9         | 4        | -- | 1         | 2         | 59       | -- | 3         | 12        | 102      | -- | 3         | 12        | 330      | -- | 12        | 3         | 5        | -- | 7         | 9         | 13       | -- | 7         | 1         | 3        | -- | 9         | 7         | 1        | -- | 1         | 7         | 7        | -- +-----------+-----------+----------+ -- Result table: -- +----------+ -- | country  | -- +----------+ -- | Peru     | -- +----------+ -- The average call duration for Peru is (102 + 102 + 330 + 330 + 5 + 5) / 6 = 145.666667 -- The average call duration for Israel is (33 + 4 + 13 + 13 + 3 + 1 + 1 + 7) / 8 = 9.37500 -- The average call duration for Morocco is (33 + 4 + 59 + 59 + 3 + 7) / 6 = 27.5000 -- Global call duration average = (2 * (33 + 3 + 59 + 102 + 330 + 5 + 13 + 3 + 1 + 7)) / 20 = 55.70000 -- Since Peru is the only country where average call duration is greater than the global average, it's the only recommended country. -- Solution with t1 as( select caller_id as id, duration as total from (select caller_id, duration from calls union all select callee_id, duration from calls) a ) select name as country from (select distinct avg(total) over(partition by code) as avg_call, avg(total) over() as global_avg, c.name from ((select *, coalesce(total,0) as duration, substring(phone_number from 1 for 3) as code from person right join t1 using (id)) b join country c on c.country_code = b.code)) d where avg_call > global_avg

---

#### SQL Question 1: Average Post Hiatus

Given a table of Facebook posts, for each user who posted at least twice in 2024, write a SQL query to find the number of days between each user‚Äôs first post of the year and last post of the year in the year 2024. Output the user and number of the days between each user's first and last post. You can solve this SQL problem interactively and run your solution directly on DataLemur: Average Post Hiatus Facebook/Meta SQL interview question posts Table: Column Name	Type user_id	integer post_id	integer post_date	timestamp post_content	text posts Example Input: user_id	post_id	post_date	post_content 151652	599415	07/10/2024 12:00:00	Need a hug 661093	624356	07/29/2024 13:00:00	Bed. Class 8-12. Work 12-3. Gym 3-5 or 6. Then class 6-10. Another day that's gonna fly by. I miss my girlfriend 004239	784254	07/04/2024 11:00:00	Happy 4th of July! 661093	442560	07/08/2024 14:00:00	Just going to cry myself to sleep after watching Marley and Me. 151652	111766	07/12/2024 19:00:00	I'm so done with covid - need traveling ASAP! Example Output: user_id	days_between 151652	2 661093	21 Answer: First, we can use the MIN() and MAX() aggregate functions on the post_date column to retrieve the earliest and latest post dates, and substract one from another accordingly. To calculate the difference for each user, we GROUP the results by user_id, and then filter for posts made in the year 2024. To do so, we use the DATE_PART() function to extract the year from the post_date column. In the final step, to exclude users who have posted only once during the year, we apply the HAVING clause with a COUNT() condition greater than 1. This yields the final solution: SELECT user_id, MAX(post_date::DATE) - MIN(post_date::DATE) AS days_between FROM posts WHERE DATE_PART('year', post_date::DATE) = 2024 GROUP BY user_id HAVING COUNT(post_id) > 1; p.s. DataLemur Premium users can attempt part 2 of the problem which is much harder. SQL Question 2: Facebook Power Users A Facebook power user is defined as someone who posts a ton, and gets a lot of reactions on their post. For the purpose of this question, consider a Facebook power user as someone who posts at least twice a day and receives an average of 150 comments and/or reactions per post. Write a SQL query to return the IDs of all Facebook power users, along with the number of posts, and the average number of reactions per post. Use the following tables "user_post" and "post_interactions": user_post Example Input: user_id	post_id	post_date 1	1001	2024-09-01 1	1002	2024-09-01 2	1003	2024-09-02 2	1004	2024-09-03 1	1005	2024-09-02 post_interactions Example Input: post_id	comments	reactions 1001	75	200 1002	85	250 1004	60	90 1005	100	150 1003	50	70 Answer: SELECT up.user_id, COUNT(DISTINCT up.post_id) AS no_of_posts, AVG(pi.comments + pi.reactions) AS avg_interaction_per_post FROM user_post up JOIN post_interactions pi on up.post_id = pi.post_id GROUP BY up.user_id HAVING COUNT(DISTINCT up.post_id) >= 2 AND AVG(pi.comments + pi.reactions) >= 150 Grandma Addicted to Social Media & Facebook Power User SQL QUESTION 3: Can you explain the difference between WHERE and HAVING? The HAVING clause works similarly to the WHERE clause, but it is used to filter the groups of rows created by the GROUP BY clause rather than the rows of the table themselves. For example, say you were analyzing Facebook ads data: SELECT region, SUM(sales) FROM facebook_ads WHERE date > '2024-01-01' GROUP BY region HAVING SUM(sales) > 500000; This query retrieves the total sales from all ads in each region, and uses the WHERE clause to only sales made after January 1, 2024. The rows are then grouped by region and the HAVING clause filters the groups to include only those with total sales greater than $500k. SQL Question 4: Active User Retention Assume you're given a table containing information on Facebook user actions. Write a SQL query to obtain number of monthly active users (MAUs) in July 2022, including the month in numerical format "1, 2, 3". Hint: An active user is defined as a user who has performed actions such as 'sign-in', 'like', or 'comment' in both the current month and the previous month. You can type up + execute your SQL query interactively to this problem on DataLemur: Active User Retention: Facebook SQL Interview Question user_actions Table: Column Name	Type user_id	integer event_id	integer event_type	string ("sign-in, "like", "comment") event_date	datetime user_actionsExample Input: user_id	event_id	event_type	event_date 445	7765	sign-in	06/31/2022 12:00:00 742	6458	sign-in	07/03/2022 12:00:00 445	3634	like	07/05/2022 12:00:00 742	1374	comment	07/05/2022 12:00:00 648	3124	like	07/18/2022 12:00:00 Example Output for June 2022: month	monthly_active_users 6	1 In July 2022, there was only one monthly active user (MAU) with the user_id 445. Answer SELECT EXTRACT(MONTH FROM curr_month.event_date) AS mth, COUNT(DISTINCT curr_month.user_id) AS monthly_active_users FROM user_actions AS curr_month WHERE EXISTS ( SELECT last_month.user_id FROM user_actions AS last_month WHERE last_month.user_id = curr_month.user_id AND EXTRACT(MONTH FROM last_month.event_date) = EXTRACT(MONTH FROM curr_month.event_date - interval '1 month') ) AND EXTRACT(MONTH FROM curr_month.event_date) = 7 AND EXTRACT(YEAR FROM curr_month.event_date) = 2022 GROUP BY EXTRACT(MONTH FROM curr_month.event_date); For a full step-by-step explanation of the problem, click here. SQL QUESTION 5: What's the difference between a left and right join? In SQL, a join generally retrieves rows from multiple tables and combines them into a single result set. For an example of the difference between a left vs. right join, suppose you had a table of Facebook users and Facebook posts. A LEFT JOIN retrieves all rows from the left table (in this case, the users table) and any matching rows from the right table (the posts table). If there is no match in the right table, NULL values will be returned for the right table's columns. A RIGHT JOIN combines all rows from the right table (in this case, the posts table) and any matching rows from the left table (the users table). If there is no match in the left table, NULL values will be displayed for the left table's columns. Left vs. Right Join SQL Question 6: Facebook Friend Recommendations Facebook wants to recommend new friends to people who show interest in attending 2 or more of the same private Facebook events. Notes: A user interested in attending would have either 'going' or 'maybe' as their attendance status. Friend recommendations are unidirectional, meaning if user x and user y should be recommended to each other, the result table should have both user x recommended to user y and user y recommended to user x. The result should not contain duplicates (i.e., user y should not be recommended to user x multiple times). friendship_status Table: Column Name	Type user_a_id	integer user_b_id	integer status	enum ('friends', 'not_friends') Each row of this table indicates the status of the friendship between user_a_id and user_b_id. friendship_status Example Input: user_a_id	user_b_id	status 111	333	not_friends 222	333	not_friends 333	222	not_friends 222	111	friends 111	222	friends 333	111	not_friends event_rsvp Table: Column Name	Type user_id	integer event_id	integer event_type	enum ('public', 'private') attendance_status	enum ('going', 'maybe', 'not_going') event_date	date event_rsvp Example Input: user_id	event_id	event_type	attendance_status	event_date 111	567	public	going	07/12/2022 222	789	private	going	07/15/2022 333	789	private	maybe	07/15/2022 111	234	private	not_going	07/18/2022 222	234	private	going	07/18/2022 333	234	private	going	07/18/2022 Example Output: user_a_id	user_b_id 222	333 333	222 Users 222 and 333 who are not friends have shown interest in attending 2 or more of the same private events. Answer: To find pairs of friends to be recommended to each other if they're interested in attending 2 or more of the same private events we'll: Find users who are interested in attending private events. Join tables to compare the correct data Find pairs of users who are not friends but are interested in 2 or more of the same private events. This leads to the following query: WITH private_events AS ( SELECT user_id, event_id FROM event_rsvp WHERE attendance_status IN ('going', 'maybe') AND event_type = 'private' ) SELECT friends.user_a_id, friends.user_b_id FROM private_events AS events_1 INNER JOIN private_events AS events_2 ON events_1.user_id != events_2.user_id AND events_1.event_id = events_2.event_id INNER JOIN friendship_status AS friends ON events_1.user_id = friends.user_a_id AND events_2.user_id = friends.user_b_id WHERE friends.status = 'not_friends' GROUP BY friends.user_a_id, friends.user_b_id HAVING COUNT(*) >= 2; For a full step-by-step solution, and to run the code yourself, subscribe to DataLemur premium to unlock this problem: Facebook Friends Recommendation SQL Interview Question Also, if you're a nerd for Machine Learning, you can learn more about Facebook's People-You-May-Know (PYMK) algorithm here. SQL QUESTION 7: Can you explain the concept of a constraint in SQL? Constraints are just rules for your DBMS to follow when updating/inserting/deleting data. Say you had a table of Facebook employees, and their salaries, job titles, and performance review data. Here's some examples of SQL constraints you could implement: NOT NULL: This constraint could be used to ensure that certain columns in the employee table, such as the employee's first and last name, cannot contain NULL values. UNIQUE: This constraint could be used to ensure that the employee ID is unique. This would prevent duplicate entries in the employee table. PRIMARY KEY: This constraint could be used to combine the NOT NULL and UNIQUE constraints to create a primary key for the employee table. The employee ID could serve as the primary key. FOREIGN KEY: This constraint could be used to establish relationships between the employee table and other tables in the database. For example, you could use a foreign key to link the employee ID to the department ID in a department table to track which department each employee belongs to. CHECK: This constraint could be used to ensure that certain data meets specific conditions. For example, you could use a CHECK constraint to ensure that salary values are always positive numbers. DEFAULT: This constraint could be used to specify default values for certain columns. For example, you could use a DEFAULT constraint to set the employee hire date to the current date if no value is provided when a new employee is added to the database. SQL Question 8: Average Number of Shares per Post As a data analyst at Facebook, you are asked to find the average number of shares per post for each user. In the user_posts table, each row represents a post by a user. Each user may have zero or more posts. In the post_shares table, each row represents a share of a post. Each post may have zero or more shares. Please write a SQL query to find the average number of shares per post for each user. user_posts Example Input: post_id	user_id	post_text	post_date 1	1	Hello world!	06/08/2022 00:00:00 2	2	What a beautiful day!	06/10/2022 00:00:00 3	1	Hope everyone is having a good day!	06/18/2022 00:00:00 4	3	Facebook is amazing!	07/26/2022 00:00:00 5	2	Enjoying a great meal!	07/05/2022 00:00:00 post_shares Example Input: share_id	post_id	share_date 1	1	06/09/2022 00:00:00 2	2	06/11/2022 00:00:00 3	1	06/19/2022 00:00:00 4	1	06/29/2022 00:00:00 5	3	07/27/2022 00:00:00 Example Output: user_id	avg_shares_per_post 1	1.67 2	0.50 3	0.00 Answer: SELECT U.user_id, COALESCE(AVG(S.shares), 0) as avg_shares_per_post FROM user_posts as U LEFT JOIN ( SELECT post_id, COUNT(share_id) as shares FROM post_shares GROUP BY post_id ) as S on U.post_id = S.post_id GROUP BY U.user_id; This query works by first finding the total number of shares for each post by grouping on post_id in the post_shares table. Then, it joins this with user_posts on post_id to get the user_id of the user who made each post. It finally averages the total number of shares for each user using the AVG function. Null values are replaced with zero so that users who have no shares do not return null for avg_shares_per_post. In case this marketing problem was interesting, checkout how this blog on how marketing analysts use SQL. SQL Question 9: Calculate Facebook Ad Click-Through Rate Assume you have an events table on Facebook app analytics. Write a SQL query to calculate the click-through rate (CTR) for the app in 2022 and round the results to 2 decimal places. Definition and note: Percentage of click-through rate (CTR) = 100.0 * Number of clicks / Number of impressions To avoid integer division, multiply the CTR by 100.0, not 100. Before reading our solution, practice this Meta SQL question interactively: Meta SQL interview question events Table: Column Name	Type app_id	integer event_type	string timestamp	datetime events Example Input: app_id	event_type	timestamp 123	impression	07/18/2022 11:36:12 123	impression	07/18/2022 11:37:12 123	click	07/18/2022 11:37:42 234	impression	07/18/2022 14:15:12 234	click	07/18/2022 14:16:12 Example Output: app_id	ctr 123	50.00 234	100.00 Answer: We first find the number of clicks and impressions using the CASE statement to assign a value of 1 for 'click' events and 0 for other events. Then, to calculate the percentage of click-through rate (CTR) we divide the number of clicks by the number of impressions and multiplying by 100.0, rounded to 2 decimal places using the ROUND() function. This yields the following solution: SELECT app_id, ROUND(100.0 * SUM(CASE WHEN event_type = 'click' THEN 1 ELSE 0 END) / SUM(CASE WHEN event_type = 'impression' THEN 1 ELSE 0 END), 2)  AS ctr_rate FROM events WHERE timestamp >= '2022-01-01' AND timestamp < '2023-01-01' GROUP BY app_id;

---

#### -- Question 51

-- Write a SQL query to rank scores. -- If there is a tie between two scores, both should have the same ranking. -- Note that after a tie, the next ranking number should be the next consecutive integer value. -- In other words, there should be no "holes" between ranks. -- +----+-------+ -- | Id | Score | -- +----+-------+ -- | 1  | 3.50  | -- | 2  | 3.65  | -- | 3  | 4.00  | -- | 4  | 3.85  | -- | 5  | 4.00  | -- | 6  | 3.65  | -- +----+-------+ -- For example, given the above Scores table, your query should generate the following report (order by highest score): -- +-------+---------+ -- | score | Rank    | -- +-------+---------+ -- | 4.00  | 1       | -- | 4.00  | 1       | -- | 3.85  | 2       | -- | 3.65  | 3       | -- | 3.65  | 3       | -- | 3.50  | 4       | -- +-------+---------+ -- Important Note: For MySQL solutions, to escape reserved words used as column names, -- you can use an apostrophe before and after the keyword. For example `Rank`. -- Solution select Score, dense_rank() over(order by score desc) as "Rank" from scores

---

#### -- Question 103

-- Table: Users -- +----------------+---------+ -- | Column Name    | Type    | -- +----------------+---------+ -- | user_id        | int     | -- | join_date      | date    | -- | favorite_brand | varchar | -- +----------------+---------+ -- user_id is the primary key of this table. -- This table has the info of the users of an online shopping website where users can sell and buy items. -- Table: Orders -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | order_id      | int     | -- | order_date    | date    | -- | item_id       | int     | -- | buyer_id      | int     | -- | seller_id     | int     | -- +---------------+---------+ -- order_id is the primary key of this table. -- item_id is a foreign key to the Items table. -- buyer_id and seller_id are foreign keys to the Users table. -- Table: Items -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | item_id       | int     | -- | item_brand    | varchar | -- +---------------+---------+ -- item_id is the primary key of this table. -- Write an SQL query to find for each user, whether the brand of the second item (by date) they sold is their favorite brand. If a user sold less than two items, report the answer for that user as no. -- It is guaranteed that no seller sold more than one item on a day. -- The query result format is in the following example: -- Users table: -- +---------+------------+----------------+ -- | user_id | join_date  | favorite_brand | -- +---------+------------+----------------+ -- | 1       | 2019-01-01 | Lenovo         | -- | 2       | 2019-02-09 | Samsung        | -- | 3       | 2019-01-19 | LG             | -- | 4       | 2019-05-21 | HP             | -- +---------+------------+----------------+ -- Orders table: -- +----------+------------+---------+----------+-----------+ -- | order_id | order_date | item_id | buyer_id | seller_id | -- +----------+------------+---------+----------+-----------+ -- | 1        | 2019-08-01 | 4       | 1        | 2         | -- | 2        | 2019-08-02 | 2       | 1        | 3         | -- | 3        | 2019-08-03 | 3       | 2        | 3         | -- | 4        | 2019-08-04 | 1       | 4        | 2         | -- | 5        | 2019-08-04 | 1       | 3        | 4         | -- | 6        | 2019-08-05 | 2       | 2        | 4         | -- +----------+------------+---------+----------+-----------+ -- Items table: -- +---------+------------+ -- | item_id | item_brand | -- +---------+------------+ -- | 1       | Samsung    | -- | 2       | Lenovo     | -- | 3       | LG         | -- | 4       | HP         | -- +---------+------------+ -- Result table: -- +-----------+--------------------+ -- | seller_id | 2nd_item_fav_brand | -- +-----------+--------------------+ -- | 1         | no                 | -- | 2         | yes                | -- | 3         | yes                | -- | 4         | no                 | -- +-----------+--------------------+ -- The answer for the user with id 1 is no because they sold nothing. -- The answer for the users with id 2 and 3 is yes because the brands of their second sold items are their favorite brands. -- The answer for the user with id 4 is no because the brand of their second sold item is not their favorite brand. -- Solution with t1 as( select user_id, case when favorite_brand = item_brand then "yes" else "no" end as 2nd_item_fav_brand from users u left join (select o.item_id, seller_id, item_brand, rank() over(partition by seller_id order by order_date) as rk from orders o join items i using (item_id)) a on u.user_id = a.seller_id where a.rk = 2) select u.user_id as seller_id, coalesce(2nd_item_fav_brand,"no") as 2nd_item_fav_brand from users u left join t1 using(user_id)

---

#### -- Question 81

-- Table: Views -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | article_id    | int     | -- | author_id     | int     | -- | viewer_id     | int     | -- | view_date     | date    | -- +---------------+---------+ -- There is no primary key for this table, it may have duplicate rows. -- Each row of this table indicates that some viewer viewed an article (written by some author) on some date. -- Note that equal author_id and viewer_id indicate the same person. -- Write an SQL query to find all the people who viewed more than one article on the same date, sorted in ascending order by their id. -- The query result format is in the following example: -- Views table: -- +------------+-----------+-----------+------------+ -- | article_id | author_id | viewer_id | view_date  | -- +------------+-----------+-----------+------------+ -- | 1          | 3         | 5         | 2019-08-01 | -- | 3          | 4         | 5         | 2019-08-01 | -- | 1          | 3         | 6         | 2019-08-02 | -- | 2          | 7         | 7         | 2019-08-01 | -- | 2          | 7         | 6         | 2019-08-02 | -- | 4          | 7         | 1         | 2019-07-22 | -- | 3          | 4         | 4         | 2019-07-21 | -- | 3          | 4         | 4         | 2019-07-21 | -- +------------+-----------+-----------+------------+ -- Result table: -- +------+ -- | id   | -- +------+ -- | 5    | -- | 6    | -- +------+ -- Solution select distinct viewer_id as id#, count(distinct article_id) as total from views group by viewer_id, view_date having count(distinct article_id)>1 order by 1

---

#### What is SQL and its significance in databases?

SQL stands for Structured Query Language. It is a programming language used for managing and manipulating relational databases. SQL is essential for tasks like querying data, updating records, and defining the structure of databases.

---

#### Differentiate between SQL and MySQL.

SQL, a language for managing and manipulating relational databases, serves as the foundation for MySQL, a relational database management system (RDBMS).

---

#### Explain the basic structure of an SQL query.

The basic structure of an SQL query consists of a SELECT clause (specifying columns), a FROM clause (specifying tables), and optional clauses like WHERE (specifying conditions) and ORDER BY (sorting results).

---

#### What is normalization, and what are its types?

Normalization is organizing data in a database to reduce redundancy and dependency. The primary goals of normalization are to eliminate data anomalies, ensure data integrity, and minimize the chances of data redundancy. Break down larger tables into smaller, related tables and define their relationships. There are several normal forms (NF) that represent different levels of normalization, and each normal form has specific rules to achieve the desired database structure. The most common normal forms are: First Normal Form (1NF): Each column in a table must contain atomic (indivisible) values, and each row must be unique. Second Normal Form (2NF): The table must be in 1NF, and all non-key attributes must be fully functionally dependent on the primary key. This means that if a table has a composite primary key, each non-key attribute must be dependent on the entire composite key, not just part of it. Third Normal Form (3NF): The table must be in 2NF, and no transitive dependencies should exist. In other words, non-key attributes must not be dependent on other non-key attributes. Boyce-Codd Normal Form (BCNF): Similar to 3NF but stricter. It states that a table is in BCNF if, for every non-trivial functional dependency, the determinant is a superkey. Fourth Normal Form (4NF): It addresses multi-valued dependencies. A table is in 4NF if it has no non-trivial multi-valued dependencies. Fifth Normal Form (5NF): Deals with cases where a table has overlapping multi-valued dependencies. Normalization is an iterative process, and not all databases need to be normalized to the same degree. The level of normalization depends on the specific requirements of the application and the trade-offs between data redundancy and the complexity of database operations. In practice, many databases are normalized up to the third normal form (3NF) to strike a balance between simplicity and data integrity.

---

#### What is denormalization?

Denormalization is the process of intentionally introducing redundancy into a database by adding redundant data to one or more tables. This is done to improve query performance and simplify data retrieval at the cost of increased storage space and potential data integrity challenges. Denormalization is often applied in situations where the performance of read operations is more critical than the performance of write operations.

---

#### What is a primary key? How is it different from a foreign key?

A primary key uniquely identifies each record in a table and must have unique values. On the other hand, a foreign key establishes a link between two tables, referencing the primary key of another table.

---

#### What is an index, and why is it used in databases?

An index is a data structure that improves the speed of data retrieval operations on a database table. It is used to quickly locate and access the rows that match a particular column value.

---

#### Describe the difference between INNER JOIN and LEFT JOIN.

INNER JOIN returns only the rows with a match in both tables, while LEFT JOIN returns all rows from the left table and the matched rows from the right table.

---

#### How do you add a new record to a table?

INSERT INTO table_name (column1, column2, ...) VALUES (value1, value2, ...);

---

#### What are the subsets of SQL?

SQL can be broadly categorized into several subsets based on the types of operations or tasks they address. Here are some common subsets of SQL: DDL (Data Definition Language): DDL includes SQL commands that define and manage the structure of the database. Common DDL commands include: CREATE: Used to create database objects such as tables, indexes, and views. ALTER: Used to modify the structure of existing database objects. DROP: Used to delete database objects. DML (Data Manipulation Language): DML comprises SQL commands that interact with the data stored in the database. Common DML commands include: SELECT: Retrieves data from one or more tables. INSERT: Adds new rows of data into a table. UPDATE: Modifies existing data in a table. DELETE: Removes rows of data from a table. DCL (Data Control Language): DCL deals with the permissions and access control of the database. Common DCL commands include: GRANT: Provides specific privileges to database users. REVOKE: Removes specific privileges from database users. TCL (Transaction Control Language): TCL includes commands related to transactions within a database. Common TCL commands include: COMMIT: Commits a transaction, making changes permanent. ROLLBACK: Rolls back a transaction, undoing changes made during the transaction. SAVEPOINT: Sets a point within a transaction to which you can later roll back. Data Query Language (DQL): DQL is a subset of SQL specifically focused on querying and retrieving data. The primary command for DQL is SELECT, which is used to retrieve data from one or more tables. Procedural Extensions (PL/SQL, T-SQL): Some database systems extend SQL to include procedural programming constructs. For example: PL/SQL (Procedural Language/Structured Query Language) is used in Oracle Database. T-SQL (Transact-SQL) is used in Microsoft SQL Server. OLAP (Online Analytical Processing): SQL extensions for working with multidimensional data and performing complex analytical queries. These might include extensions like CUBE, ROLLUP, and window functions. OLTP (Online Transaction Processing): SQL commands optimized for transactional processing, typically involving simple CRUD (Create, Read, Update, Delete) operations.

---

#### Explain database white box testing and black box testing.

White box testing and black box testing are two different testing methodologies used in the context of databases, including SQL databases. These methodologies focus on different aspects of testing, and they are applicable to various levels of the software development life cycle. White Box Testing	Black Box Testing White box testing, also known as structural or glass box testing, is a testing method that examines the internal logic and structure of the database system. Testers have knowledge of the internal workings, code, and implementation details of the database. The objective is to ensure that all paths and branches of the code are executed and that the database functions correctly at the code level.	Black box testing, also known as functional or behavioral testing, is a testing method where the tester has no knowledge of the internal workings of the database. Testers focus on verifying the external behavior and functionality of the database without looking at the code or internal implementation details. The goal is to assess whether the database meets the specified requirements and behaves as expected.

---

#### How can you create empty tables with the same structure as another table?

In SQL, you can create an empty table with the same structure as another table using the CREATE TABLE statement along with the AS clause. This approach is commonly known as creating a table based on another table. Here‚Äôs the basic syntax: CREATE TABLE new_table AS SELECT * FROM existing_table WHERE 1 = 0; This syntax involves creating a new table (new_table) because of a SELECT statement that doesn‚Äôt retrieve any rows from the existing table (existing_table). The WHERE 1 = 0 condition ensures that no rows are selected from the existing table, creating an empty table with the same structure.

---

#### What is the difference between the DROP and TRUNCATE commands?

In SQL, DROP is used to permanently delete a table and its structure, releasing occupied space. TRUNCATE removes all data from a table, retaining the structure but not releasing space. DROP is irreversible, while TRUNCATE is faster and safer for data removal, especially in production.

---

#### What are the benefits of SQL database over NoSQL database?

SQL databases offer structured data management with predefined schemas, enforcing data consistency and integrity through ACID properties. They excel in complex querying, supporting joins, and providing strong consistency. SQL databases scale vertically by adding resources to a single server, making them suitable for applications with intricate relationships between entities. The mature SQL ecosystem offers a wide range of tools and support. In contrast, NoSQL databases prioritize schema flexibility, horizontal scalability, and eventual consistency for distributed systems. They are well-suited for unstructured or semi-structured data and high write loads. The choice between SQL and NoSQL depends on specific application requirements, data structures, and scalability needs. SQL databases excel in scenarios that demand data integrity, complex queries, and transaction support.

---

#### What is a primary key?

In SQL, a primary key is a field or a combination of fields in a table that uniquely identifies each record in that table. The primary key has two main characteristics: Uniqueness: Every value in the primary key column (or columns) must be unique across all records in the table. This ensures that each record can be uniquely identified based on its primary key value. Non-Nullability: The primary key column (or columns) cannot contain NULL values. Each record must have a non-null value in the primary key column, emphasizing its role as a unique identifier.

---

#### What is meant by table and field in SQL?

In SQL, a table is a structured representation of data organized in rows and columns. It is the fundamental storage unit within a relational database to store and organize related information. Each table consists of columns (also known as fields) and rows. TABLE	FIELD ‚Äì A table is a collection of related data entries organized in rows and columns. ‚Äì Each row in a table represents a record, and each column represents a specific attribute or field of that record. ‚Äì Tables are named and must have a unique name within the database.	‚Äì A field, also referred to as a column, is a specific attribute or property of the data stored in a table. ‚Äì Each column has a data type that defines the kind of data it can store (e.g., INT for integers, VARCHAR for variable-length character strings). ‚Äì Fields hold the actual data values for each record in the table.

---

#### What is a constraint, and why use constraints?

In SQL, a constraint is a rule applied to a table column to ensure data integrity and enforce specific conditions. Types of constraints include primary key (ensures uniqueness), foreign key (establishes relationships), unique (enforces uniqueness), check (validity checks), and NOT NULL (avoids NULL values). Constraints play a vital role in maintaining data accuracy, relationships, and adherence to business rules, providing a robust foundation for reliable database management.

---

#### What is a subquery?

In SQL, a subquery is a nested query enclosed within parentheses that is used to retrieve data based on the results of another query. It can be employed in various SQL statements, such as SELECT, INSERT, UPDATE, and DELETE. Subqueries enhance the flexibility of queries by allowing operations and decisions to be based on the outcome of another query.

---

#### What is a SQL operator?

In SQL, operators are symbols or keywords used for various operations. Types include arithmetic (e.g., +, -, *), comparison (e.g., =, <, >), logical (e.g., AND, OR, NOT), concatenation (e.g., ||), IN, LIKE, IS NULL, and BETWEEN. Operators are vital for constructing queries to perform calculations, comparisons, and string manipulations in a relational database.

---

#### What is an alias?

In SQL, an alias is a temporary name assigned to a table or column in a query. It improves readability and provides a shorter reference. For example, table aliases (e.g., ‚Äúe‚Äù for ‚Äúemployees‚Äù) and column aliases (e.g., ‚Äúincreased_salary‚Äù for a calculated column) are commonly used. Aliases are specified using the AS keyword but are often optional for column aliases.

---

#### What is the purpose of the GROUP BY clause in SQL?

The GROUP BY clause groups rows with the same values in specified columns into summary rows, like finding the total sales per category.

---

#### Explain the concept of a subquery and provide an example.

A subquery is a query embedded within another query. Example: SELECT * FROM employees WHERE department_id IN (SELECT department_id FROM departments WHERE location = 'New York');

---

#### How can you prevent SQL injection in your queries?

Use parameterized queries or prepared statements, which allow the database to distinguish between code and data, preventing malicious SQL injection.

---

#### What are stored procedures, and how are they different from functions?

Stored procedures are precompiled SQL queries stored in the database. Functions return a value and can be used in SQL statements like expressions, while procedures do not return values directly.

---

#### Describe the ACID properties in the context of database transactions.

ACID stands for Atomicity, Consistency, Isolation, and Durability. These properties ensure the reliability of database transactions by maintaining data integrity and consistency.

---

#### Explain the use of the HAVING clause in SQL.

The HAVING clause is used with the GROUP BY clause to filter the results of aggregate functions based on specified conditions.

---

#### Differentiate between UNION and UNION ALL.

UNION combines and returns unique rows from two or more SELECT statements, while UNION ALL returns all rows, including duplicates.

---

#### What is the purpose of the COALESCE function?

The COALESCE function returns the first non-null expression in a list. It often replaces null values with a default or alternative value.

---

#### How do you perform a self-join in SQL?

A self-join is performed by joining a table with itself. Example: SELECT e1.name, e2.name FROM employees e1 INNER JOIN employees e2 ON e1.manager_id = e2.employee_id;

---

#### Explain the concept of database transactions.

A transaction is a sequence of one or more SQL statements that are executed as a single unit. It ensures the consistency and integrity of the database by either committing changes or rolling back to the previous state.

---

#### What is the purpose of the window functions in SQL?

Window functions perform calculations across a set of rows related to the current row. Examples include ROW_NUMBER(), RANK(), and LEAD().

---

#### Explain the differences between clustered and non-clustered indexes.

A clustered index determines the physical order of data in a table, while a non-clustered index does not affect the physical order but provides a separate structure to improve query performance.

---

#### How does the SQL Server optimizer work?

The SQL Server optimizer generates and evaluates various execution plans to choose the most efficient one based on factors like indexes, statistics, and query complexity.

---

#### What are common table expressions (CTEs), and when would you use them?

CTEs are named temporary result sets defined within the scope of a SELECT, INSERT, UPDATE, or DELETE statement. They are used to simplify complex queries and improve readability.

---

#### Discuss the concept of materialized views in databases.

Materialized views are precomputed and stored result sets, updated periodically based on the underlying data. They improve query performance by reducing the need to recalculate results.

---

#### How can you optimize a query‚Äôs performance in SQL?

Query performance can be optimized by using indexes, avoiding SELECT *, optimizing joins, and ensuring up-to-date statistics.

---

#### Explain the purpose of the OLAP and OLTP database systems.

OLAP (Online Analytical Processing) databases are designed for complex queries and reporting, while OLTP (Online Transaction Processing) databases focus on quick, transactional data processing.

---

#### What is the difference between a view and a table?

A table is a physical storage structure, while a view is a virtual table created by a SELECT query. Views provide a way to simplify complex queries and control access to data.

---

#### Describe the process of database sharding.

Database sharding involves breaking an extensive database into smaller, more manageable pieces called shards. Each shard is stored on a separate server, improving scalability and performance.

---

#### Explain the use of the APPLY operator in SQL.

The APPLY operator invokes a table-valued function for each row returned by an outer table expression. It is handy for joining with functions that take parameters.

---

#### How to update a table?

Use the below syntax to update a table: UPDATE table_name SET col_1 = value_1, column_2 = value_2 WHERE condition;

---

#### How do you sort records in a table?

To sort records in a table in SQL, you can use the ORDER BY clause in your SELECT statement. The ORDER BY clause allows you to specify one or more columns by which the result set should be sorted. The sorting can be done in ascending (ASC) or descending (DESC) order. Here is the basic syntax for sorting records in a table: SELECT column1, column2, ... FROM table_name ORDER BY column1 [ASC | DESC], column2 [ASC | DESC], ...; SELECT: Specifies the columns you want to retrieve. FROM: Specifies the table from which to retrieve data. ORDER BY: Specifies the columns by which to sort the result set. ASC: Optional keyword for ascending order (default if not specified). DESC: Keyword for descending order.

---

#### What is the DISTINCT statement, and how do you use it?

The DISTINCT keyword in SQL is used to eliminate duplicate rows from the result set of a SELECT query. It returns only unique values for the specified columns. Here‚Äôs the basic syntax for using the DISTINCT statement: SELECT DISTINCT column1, column2, ... FROM table_name; SELECT DISTINCT: Specifies that only distinct (unique) values should be returned. column1, column2, ...: Specifies the columns for which you want to retrieve distinct values. FROM table_name: Specifies the table from which to retrieve data. Example: Consider a ‚Äústudents‚Äù table with columns ‚Äústudent_id‚Äù and ‚Äúcourse_id.‚Äù If you want to retrieve a list of unique course IDs from this table, you can use the DISTINCT keyword: SELECT DISTINCT course_id FROM students; This query returns only distinct values from the ‚Äúcourse_id‚Äù column in the ‚Äústudents‚Äù table.

---

#### What are entities? Give some examples.

In the context of SQL and databases, an ‚Äúentity‚Äù typically refers to a table or an object that can be uniquely identified and is used to store and represent data. Entities are fundamental building blocks in database design and correspond to real-world objects or concepts.

---

#### What scalar functions do you know?

Scalar functions in SQL are functions that operate on a single value and return a single value. These functions can be used within SQL queries to perform operations on individual columns or literals. Here are some commonly used scalar functions in SQL: String Functions: UPPER(str): Converts a string to uppercase. SELECT UPPER('hello') AS result; -- Result: 'HELLO' LOWER(str): Converts a string to lowercase.SELECT LOWER('Hello') AS result; -- Result: 'hello' CONCAT(str1, str2, ‚Ä¶): Concatenates two or more strings.SELECT CONCAT('John', ' ', 'Doe') AS full_name; -- Result: 'John Doe' LENGTH(str): Returns the length of a string.SELECT LENGTH('apple') AS str_length; -- Result: 5 Numeric Functions: ABS(num): Returns the absolute value of a number.SELECT ABS(-10) AS absolute_value; -- Result: 10 ROUND(num, decimals): Rounds a number to the specified number of decimal places.SELECT ROUND(3.14159, 2) AS rounded_value; -- Result: 3.14 SQRT(num): Returns the square root of a number.SELECT SQRT(16) AS square_root; -- Result: 4 RAND(): Returns a random number between 0 and 1.SELECT RAND() AS random_number; -- Result: (random value between 0 and 1) Date and Time Functions: NOW(): Returns the current date and time.SELECT NOW() AS current_datetime; -- Result: 'YYYY-MM-DD HH:MI:SS' DATE_FORMAT(date, format): Formats a date according to the specified format.SELECT DATE_FORMAT(NOW(), '%Y-%m-%d') AS formatted_date; -- Result: 'YYYY-MM-DD' DATEDIFF(date1, date2): Returns the difference in days between two dates.SELECT DATEDIFF('2022-01-01', '2022-01-10') AS date_difference; -- Result: -9 Mathematical Functions: POWER(base, exponent): Returns the result of raising a number to a specified power.SELECT POWER(2, 3) AS result; -- Result: 8 CEIL(num): Returns the smallest integer greater than or equal to a number.SELECT CEIL(4.3) AS result; -- Result: 5 FLOOR(num): Returns the largest integer less than or equal to a number.SELECT FLOOR(4.8) AS result; -- Result: 4 These are just a few examples of scalar functions in SQL. Different database systems may have variations in syntax or additional functions, so it‚Äôs important to refer to the documentation of the specific database you are working with.

---

#### How do we prevent duplicate records when making a query?

To prevent duplicate records when making a query in SQL, you can use the DISTINCT keyword in the SELECT statement. The DISTINCT keyword filters out duplicate rows from the result set, ensuring that only unique values are returned. Here‚Äôs the basic syntax: SELECT DISTINCT column1, column2, ... FROM table_name WHERE conditions;

---

#### How do you add a record to a table?

In SQL, you use the INSERT statement to add a new record or row to a table. The basic syntax for the INSERT statement is as follows: INSERT INTO table_name (column1, column2, ..., columnN) VALUES (value1, value2, ..., valueN);

---

#### What are SQL operators?

SQL operators are symbols or keywords that perform operations on one or more expressions in SQL queries. They are used to perform mathematical operations, comparison operations, logical operations, and other manipulations on data within the database. SQL operators can be broadly categorized into several types: Arithmetic Operators: Addition (+): Adds two numbers. SELECT salary + bonus AS total_income FROM employees; Subtraction (-): Subtracts the right operand from the left operand. SELECT total_sales - expenses AS profit FROM financial_data; Multiplication (*): Multiplies two numbers. SELECT quantity * unit_price AS total_cost FROM orders; Division (/): Divides the left operand by the right operand.SELECT revenue / num_customers AS average_revenue FROM sales_summary; Modulus (%): Returns the remainder of the division of the left operand by the right operand. SELECT order_id % 1000 AS short_order_id FROM orders; Comparison Operators: Equal to (=): Tests if two expressions are equal. SELECT * FROM products WHERE category_id = 1; Not equal to (<> or !=): Tests if two expressions are not equal. SELECT * FROM customers WHERE country_code <> 'US'; Greater than (>): Tests if the left operand is greater than the right operand. SELECT * FROM employees WHERE salary > 50000; Less than (<): Tests if the left operand is less than the right operand. SELECT * FROM products WHERE unit_price < 10; Greater than or equal to (>=): Tests if the left operand is greater than or equal to the right operand. SELECT * FROM orders WHERE order_date >= '2022-01-01'; Less than or equal to (<=): Tests if the left operand is less than or equal to the right operand. SELECT * FROM customers WHERE registration_year <= 2020; Logical Operators: AND (AND): Combines two conditions. Returns true if both conditions are true. SELECT * FROM products WHERE category_id = 1 AND stock_quantity > 0; OR (OR): Combines two conditions. Returns true if at least one condition is true. SELECT * FROM employees WHERE department_id = 1 OR department_id = 2; NOT (NOT): Negates a condition. Returns true if the condition is false, and vice versa. SELECT * FROM customers WHERE NOT country_code = 'US'; Other Operators: LIKE (LIKE): Compares a value to a pattern using wildcard characters. SELECT * FROM products WHERE product_name LIKE 'Apple%'; IN (IN): Tests if a value matches any value in a list. SELECT * FROM orders WHERE customer_id IN (101, 102, 103); BETWEEN (BETWEEN): Tests if a value is within a specified range.SELECT * FROM employees WHERE salary BETWEEN 40000 AND 60000; These operators are fundamental to constructing SQL queries and expressing various conditions and calculations within the database. They play a crucial role in filtering, sorting, and manipulating data.

---

#### What do you mean by data integrity?

Data integrity in SQL refers to the accuracy, consistency, and reliability of data stored in a relational database. It ensures that the data remains valid and reliable throughout its lifecycle, from the point of entry into the database to its retrieval and modification. Maintaining data integrity is crucial for making informed decisions based on accurate and consistent information.

---

#### Why is the FLOOR function used in SQL Server?

The FLOOR function in SQL Server is used to round a numeric value down to the nearest integer that is less than or equal to the original value. It essentially removes the decimal part of a numeric value and returns the largest integer less than or equal to the input. The basic syntax of the FLOOR function is as follows: FLOOR(numeric_expression) numeric_expression: The numeric value that you want to round down to the nearest integer. Consider the student table as shown below for question no. 1, 2, and 3. SQL Coding | SQL Interview questions

---

#### Write a query to extract the username(characters before @ symbol) from the Email_ID column.

Answer: SELECT SUBSTR(Email_ID, 1, INSTR(Email_ID, '@') - 1) FROM STUDENT; Extract the position of @ from the email id first using INSTR() function then pass this position(after subtracting 1) as an argument for length in SUBSTR() function. Output ‚Äì

---

#### Write a query to extract domain name like .com, .in, .au etc. from the Email_ID column.

Answer: SELECT SUBSTR(Email_ID, INSTR(Email_ID, '.')) FROM STUDENT; Extract the position of . (dot character) from the email id first using INSTR() function then pass this position as an argument for starting position in SUBSTR() function. Output ‚Äì SQL Coding

---

#### Write a query to extract email service provider names like google, yahoo, outlook, etc. from the Email_ID column.

Answer: SELECT SUBSTR(Email_ID, INSTR(Email_ID, '@') + 1, INSTR(Email_ID, '.') - INSTR(Email_ID, '@') - 1) FROM STUDENT; Extract the position of @ from the email id first using INSTR() function, and pass it (after adding 1) as an argument for starting position in SUBSTR() function. Now extract this position of . (dot character) and subtract it from the earlier extracted @ position and pass it (after subtracting 1) as an argument for length in SUBSTR() function. Output ‚Äì SQL Coding

---

#### What is(are) the output of the following query?

SELECT CEIL(-12.43), FLOOR(-11.92) FROM DUAL; -13, -12 b. -12, -12 c. -12, -11 d. -13, -11 b CEIL() function returns the smallest integer number that is greater than or equal to the given number. So if we pass -12.43 in ceil, it returns the smallest integer value that is >= -12.43 i.e. -12. FLOOR() function returns the largest integer number that is less than or equal to the given number. So if we pass -11.92 in floor, it returns the largest integer value that is <= -11.92 i.e. -12. Output ‚Äì

---

#### Write a query to extract all the consonants present in your name.

SELECT TRANSLATE('Narendra', 'xaeiou', 'x') FROM DUAL; First, extract the consonants from the input name as extracted above, then concatenate these consonants with the character ‚Äòa‚Äô in from_string argument to remove the consonants by not specifying corresponding characters in to_string argument. So if we pass Narendra as the name in the above query, it returns vowels (a, e, a). Output ‚Äì

---

#### Write a query to extract all the vowels present in your name.

Answer: SELECT TRANSLATE('Narendra', 'a' || TRANSLATE('Narendra', 'xaeiou', 'x'), 'a') FROM DUAL; First, extract the consonants from the input name as extracted above, then concatenate these consonants with character ‚Äòa‚Äô in from_string argument to remove the consonants by not specifying corresponding characters in to_string argument. So if we pass Narendra as the name in the above query, it returns vowels (a, e, a). Output: Refer to the emp table as shown below for question no. 7 to 14.

---

#### Write a query to extract the employees‚Äô details who joined in the year 1981.

SELECT * FROM EMP WHERE TO_CHAR(HIREDATE, 'YY') = 81; Use TO_CHAR() to extract the year part from the hiredate column and select all the employees who were hired in 1981 by using WHERE clause. Output ‚Äì

---

#### Write a query to find the hiked salary for each employee after adding the commission.

SELECT EMPNO, ENAME, NVL2(COMM, SAL+COMM, SAL) AS HIKEDSAL FROM EMP; Since the commission column contains null values so directly adding it to salary will return null wherever the commission is null. Use NVL2() function to determine hiked salary based on whether the commission is null or not null. If COMM (expr1) is not null then it returns SAL+COMM (expr2). If COMM is null then it returns SAL (expr3). Output ‚Äì

---

#### Write a query to find out the employees drawing a higher salary than their managers.

SELECT E.EMPNO, E.ENAME, E.SAL, M.EMPNO, M.ENAME, M.SAL FROM EMP E, EMP M WHERE E.MGR = M.EMPNO AND E.SAL > M.SAL; Self join the emp table with itself to compare employees‚Äô salary with their manager‚Äôs salary. Output ‚Äì

---

#### Write a query to find out the subordinates (reportees) who joined the organization before their managers.

SELECT E.EMPNO, E.ENAME, E.HIREDATE, M.EMPNO, M.ENAME, M.HIREDATE FROM EMP E, EMP M WHERE E.MGR = M.EMPNO AND E.HIREDATE < M.HIREDATE; Self join the emp table with itself to compare employees hiredate with their manager‚Äôs hiredate. Output ‚Äì

---

#### Write a query to find out the employees who don‚Äôt have any subordinates (reportees) i.e. the employees who are not the managers.

Answer: SELECT * FROM EMP WHERE EMPNO NOT IN (SELECT DISTINCT NVL(MGR, 0) FROM EMP); Using simple subquery first find out the list of distinct managers EMPNOs, then select the EMPNO which does not belong to managers EMPNOs. Output ‚Äì

---

#### Write a query to find out 2nd senior-most employee i.e. who joined the organization second as per hire date.

Answer: SELECT * FROM EMP E WHERE 2 = (SELECT COUNT(DISTINCT M.HIREDATE) FROM EMP M WHERE E.HIREDATE >= M.HIREDATE); Using correlated subquery we can get 2nd senior-most employee by comparing the inner query output against 2 in WHERE clause. Output ‚Äì

---

#### Write a query to find out the 5th maximum salary.

SELECT * FROM EMP E WHERE 5 = (SELECT COUNT(DISTINCT M.SAL) FROM EMP M WHERE E.SAL <= M.SAL); Using correlated subquery we can get the 5th maximum salary by comparing the inner query output against 5 in WHERE clause. Output

---

#### Write a query to find out the deviation from average salary for the employees who are getting more than the average salary.

Note ‚Äì Round the average salary, salary difference up to two digits. Answer: SELECT ENAME, SAL, ROUND((SELECT AVG(SAL) FROM EMP),2) AS AVG, ROUND(SAL - (SELECT AVG(SAL) FROM EMP),2) AS DIFF FROM EMP WHERE SAL > (SELECT AVG(SAL) FROM EMP); First, select the employees who are getting more than the average salary, then calculate the deviation from average salary for such employees. Output : Refer to the dept table along with the above emp table for question no. 15 and 16.

---

#### Write a query to find out the employees who are getting the maximum salary in their departments.

SELECT * FROM EMP WHERE SAL IN (SELECT MAX(SAL) FROM EMP GROUP BY DEPTNO); Using simple subquery first get a list of maximum salary for each department using group by operation, then select the employees who are getting salary as per that list. Output‚Äì output

---

#### Write a query to find out department-wise minimum salary, maximum salary, total salary, and average salary.

SELECT D.DEPTNO, MIN(SAL), MAX(SAL), SUM(SAL), AVG(SAL) FROM EMP E, DEPT D WHERE E.DEPTNO = D.DEPTNO GROUP BY D.DEPTNO; First inner join employee and department table then group by DEPTNO to find out minimum, maximum, total and average salary for each department. Output ‚Äì output

---

#### Choose the correct statement(s) that will result in the desired table.

ALTER TABLE CUSTOMER RENAME CustName to Name; b. ALTER TABLE CUSTOMER RENAME COLUMN CustName to Name; c. ALTER TABLE CUSTOMER ADD Email VARCHAR2(35); d. ALTER TABLE CUSTOMER MODIFY Email VARCHAR2(35); e. ALTER TABLE CUSTOMER DROP FamilySize; f. ALTER TABLE CUSTOMER DROP COLUMN FamilySize; b, d, e Rename CustName column as Name using ‚Äì ALTER TABLE CUSTOMER RENAME COLUMN CustName to Name; Modify Email column datatype from VARCHAR2(25) to VARCHAR2(35) using ‚Äì ALTER TABLE CUSTOMER MODIFY Email VARCHAR2(35); Drop FamilySize column using ‚Äì ALTER TABLE CUSTOMER DROP FamilySize;

---

#### Consider the following table schema and data for the transaction table.

Choose the valid UPDATE statement(s) UPDATE TRANSACTION SET PrimeStatus = ‚ÄòYes‚Äô WHERE TransactionID = 1102348 b. UPDATE TRANSACTION SET PrimeStatus = ‚ÄòVALID‚Äô WHERE CustName = ‚ÄòJohn‚Äô c. UPDATE TRANSACTION SET TransactionID = NULL WHERE CustName = ‚ÄòJohn‚Äô d. UPDATE TRANSACTION SET ShoppingDate = NULL WHERE TransactionID = 1102348 d CHECK constraint allows only a set of predefined values so here only Y or N is allowed for PrimeStatus column. NOT NULL constraint does not allow NULL values so TransactionID can‚Äôt be set to NULL. We can insert NULL values in ShoppingDate Column. Output ‚Äì UPDATE TRANSACTION SET ShoppingDate = NULL WHERE TransactionID = 1102348;

---

#### What is(are) the output of the following SQL statement?

SELECT TRANSLATE('AWESOME', 'WOE', 'VU') FROM DUAL; AVESUME b. AVSOM c. AVSUM d. AWESUME c For an input string, TRANSLATE() function replaces characters specified in from_string argument by their corresponding characters in to_string argument. If there are no corresponding characters in to_string argument then the extra characters present in from_string argument are removed from the input string. SELECT TRANSLATE('AWESOME', 'WOE', 'VU') FROM DUAL; Output ‚Äì Q 71. Consider the emp and insurance table as shown below. How do you get the following output? SELECT * FROM EMP1 LEFT JOIN INSURANCE ON (EMP1.INSURANCETYPE = INSURANCE.INSURANCETYPE); b. SELECT * FROM EMP1 JOIN INSURANCE ON (EMP1.INSURANCETYPE = INSURANCE.INSURANCETYPE); c. SELECT * FROM EMP1 RIGHT JOIN INSURANCE ON (EMP1.INSURANCETYPE = INSURANCE.INSURANCETYPE); d. SELECT * FROM EMP1 FULL JOIN INSURANCE ON (EMP1.INSURANCETYPE = INSURANCE.INSURANCETYPE); c, d Right join returns all the records from the right table along with the matched records from the left table. Here, since all the emp (left) table‚Äôs insurance types are present in the insurance (right) table so full outer join will also return the same output. NOTE ‚Äì While analyzing the outputs, focus on the record values rather than their sequence in the output. output Conclusion

---

#### SELECT contest_id,ROUND((COUNT(DISTINCT user_id)*100.0)/user_count.cnt,2) AS percentage

FROM register_1633 CROSS JOIN (SELECT COUNT(*) AS cnt FROM users_1633) user_count GROUP BY contest_id,user_count.cnt ORDER BY percentage DESC,contest_id; --OR-- SELECT contest_id,ROUND((COUNT(DISTINCT user_id)*100.0)/(SELECT COUNT(*) AS cnt FROM users_1633),2) AS percentage FROM register_1633 GROUP BY contest_id ORDER BY percentage DESC,contest_id;

---

#### -- Question 50

-- Write a SQL query to get the nth highest salary from the Employee table. -- +----+--------+ -- | Id | Salary | -- +----+--------+ -- | 1  | 100    | -- | 2  | 200    | -- | 3  | 300    | -- +----+--------+ -- For example, given the above Employee table, the nth highest salary where n = 2 is 200. If there is no nth highest salary, then the query should return null. -- +------------------------+ -- | getNthHighestSalary(2) | -- +------------------------+ -- | 200                    | -- +------------------------+ -- Solution CREATE FUNCTION getNthHighestSalary(N INT) RETURNS INT BEGIN RETURN ( # Write your MySQL query statement below. select distinct a.salary from (select salary, dense_rank() over(order by salary desc) as rk from Employee) a where a.rk = N ); END

---

#### SELECT u.name,SUM(t.amount)

FROM transactions_1587 t INNER JOIN users_1587 u ON t.account=u.account GROUP BY u.name HAVING SUM(t.amount) > 10000

---

#### SELECT country_name,

CASE WHEN AVG(weather_state) <= 15 THEN 'Cold' WHEN AVG(weather_state) >= 25 THEN 'Hot' ELSE 'Warm' END AS weather_type FROM weather_1294 w INNER JOIN countries_1294 c ON w.country_id = c.country_id WHERE EXTRACT(month FROM day) = 11 GROUP BY country_name;

---

#### Top 100 SQL Interview Questions

Dan Lee's profile image Dan Lee Updated Feb 7, 2025 ‚Äî 8 min read Feature image - SQL interview prep for data analyst, data scientist and data engineer roles Table of Contents üìö SQL Interview Areas ‚≠ê SQL Interviews Across Data Roles üéØ Common SQL Topics to Master ‚úçÔ∏è SQL Interview Technical Screen üìù More SQL Interview Questions üí° How to Prepare for SQL Interviews Facebook X (formerly Twitter) LinkedIn Reddit Looking for REAL SQL interview questions asked in FAANGs and startups? Here's a comprehensive guide with REAL questions! These questions are fair game across data analyst, data engineer, backend engineer, and database administrator interviews. Companies such as Google, Amazon, Meta, Stripe, Microsoft, and many more all ask SQL questions. We will explore the question areas, uncover tips, and provide you with a detailed list of interview questions you can use to ace the interviews! Let's get startedüëá üìö SQL Interview Areas Here are common areas assessed in SQL interviews across data roles. Area 1 - Basic SQL Queries Understanding basic SQL queries is fundamental. Expect questions that test your ability to retrieve, filter, and sort data using SELECT, WHERE, ORDER BY, and GROUP BY clauses. Also, SQL joins are essential for combining data from multiple tables. You should be comfortable with INNER JOIN, LEFT JOIN, RIGHT JOIN, and FULL OUTER JOIN. Sample Questions Write a SQL query to find the second highest salary from the Employees table. How do you count the number of records in a table? Retrieve all records where the status is 'Active' from the Users table. Explain the difference between an INNER JOIN and a LEFT JOIN. Write a query to find all customers who have made more than one purchase. How do you retrieve data from three tables using joins? üí° You don't need to know all the statements in SQL for interviews. In some cases, the interviewer will allow you to look up the statement. Just know the common ones, as seen in this guide. Area 2 - Advanced SQL Concepts Requiring multiple steps to solve, advanced SQL questions assess your understanding of subqueries, window functions, CTEs (Common Table Expressions), and set operations like UNION and INTERSECT. Sample Questions Write a query to find the cumulative sum of sales per day. How do you delete duplicate records from a table? Calculate the 7-day moving average of daily sales. üí° You can get practice questions with hands-on coding on DataInterview SQL Pad. Area 3 - SQL Optimization and Performance Performance is crucial in SQL. If you are shooting for senior DS or data engineering roles, you should know how to optimize queries, use indexes effectively, and understand execution plans. Sample Questions What are the pros and cons of using indexes in a database? How does a full table scan impact query performance, and how can you avoid it? What techniques would you use to optimize a query that joins multiple large tables? Explain how the query execution plan helps in query optimization. What are common causes of deadlocks in SQL, and how can you prevent them? How does database partitioning improve query performance, and when should you use it? What is the difference between a covering index and a composite index, and when would you use each? Area 4 - SQL in Data Warehousing and ETL This is the part often assessed in data engineering or analytics engineering roles. Understanding how SQL is used in data warehousing and ETL processes is important for roles that deal with large datasets. Sample Questions What is the purpose of a staging table in ETL, and how is it used? Explain the difference between OLTP and OLAP databases. How would you design a data pipeline to handle incremental data loads? What are surrogate keys, and why are they used in data warehousing? Describe the advantages of using a star schema over a snowflake schema. What are some common challenges in maintaining data quality in ETL processes, and how do you address them? How do you implement error handling in an ETL workflow to ensure data integrity? ‚≠ê SQL Interviews Across Data Roles SQL questions are highly common across interviews in data roles from Data Analyst, Data Scientist and Data Engineer. Do expect SQL questions to show up in technical screens, and again in final rounds. In some cases, a recruiter may ask basic SQL questions such as "explain JOINs" and "UNION vs UNION ALL" just to assess your basic knowledge before letting you advance to the technical screen. Data Analyst (or BI Engineer) - Do expect SQL questions that involve table manipulation, but also in tandem with data visualization questions. Data Scientist - Expect SQL questions with hands-on coding. Most often the questions pertain to a particular product of the company you are interviewing. Data Engineer - Do expect intermediate to advanced questions and follow-ups regarding data modeling, optimization and databases. üëâ If you are looking for structured interview prep, join the Data Scientist Interview MasterClass - a live cohort led by FAANG instructors! üéØ Common SQL Topics to Master In general, you should have an in-depth understanding of the following topics: Data Retrieval and Filtering Aggregate Functions (COUNT, SUM, AVG, etc.) Joins and Subqueries Window Functions Indexes and Query Optimization Database Transactions and Isolation Levels Stored Procedures and Functions üí° Learn the ins-and-outs of these topics by practicing writing queries from scratch. This will be helpful in SQL coding interviews! ‚úçÔ∏è SQL Interview Technical Screen Here's an example technical screen you may encounter if you interview for data analyst, data engineer or data scientist position at a company like Meta (Facebook) or Amazon. The technical screen round is usually 45 minutes. The first 20-30 minutes is primarily on SQL followed by a business or product case. Tables Provided: Listings Table listing_id	title	seller_id	category	price	created_date 101	Used Bicycle	1	Sports	150	2024-01-10 102	Vintage Chair	2	Furniture	200	2024-03-15 103	Laptop	3	Electronics	800	2024-02-20 104	Smartphone	4	Electronics	500	2024-04-05 105	Dining Table Set	2	Furniture	450	2024-01-25 Sellers Table seller_id	name	join_date	location	rating 1	Alice	2023-08-12	New York	4.8 2	Bob	2022-05-20	San Francisco	4.5 3	Charlie	2023-01-05	Chicago	4.9 4	Diana	2024-02-18	Austin	4.3 5	Eve	2022-11-11	Seattle	4.7 #1 - List the titles of the top 3 most expensive listings, along with the seller name and location, for sellers who joined in 2023 or later. SELECT l.title, s.name, s.location FROM Listings l JOIN Sellers s ON l.seller_id = s.seller_id WHERE s.join_date >= '2023-01-01' ORDER BY l.price DESC LIMIT 3; #2 - Find sellers who have not listed any items in the 'Electronics' category. Display their name and total number of listings. SELECT s.name, COUNT(l.listing_id) AS total_listings FROM Sellers s LEFT JOIN Listings l ON s.seller_id = l.seller_id AND l.category = 'Electronics' WHERE l.listing_id IS NULL GROUP BY s.name; #3 - Find the seller(s) who joined the earliest but have listings priced higher than the average price in their respective categories. Display the seller name, title of the listing, and price. SELECT s.name, l.title, l.price FROM Sellers s JOIN Listings l ON s.seller_id = l.seller_id WHERE s.join_date = (SELECT MIN(join_date) FROM Sellers) AND l.price > (SELECT AVG(price) FROM Listings l2 WHERE l2.category = l.category); üìù More SQL Interview Questions These questions are fair game across data analyst, data engineer, backend engineer, and database administrator interviews at companies such as Google, Amazon, Meta, Stripe, and many moreüëá Basic SQL Interview Questions *For all data roles What is the difference between WHERE and HAVING clauses? Explain the use of GROUP BY and ORDER BY in SQL. How do you remove duplicate records from a table? What is a primary key and a foreign key? How do you use the LIKE operator? What are the different types of SQL JOINs? Explain the difference between DELETE, TRUNCATE, and DROP. What is the purpose of the DISTINCT keyword? How do you create and modify tables in SQL? What are constraints in SQL? Explain the difference between VARCHAR and CHAR data types. How do you use aggregate functions (COUNT, SUM, AVG, etc.)? What is the difference between UNION and UNION ALL? How do you use aliases in SQL? What is the purpose of the NULL value? How do you use wildcards in SQL? Explain the concept of SQL views. What is the difference between INNER JOIN and OUTER JOIN? How do you insert multiple rows into a table? What is the purpose of the BETWEEN operator? How do you use the IN operator? Explain the use of TOP and LIMIT clauses. What is the difference between DROP TABLE and DELETE FROM TABLE? How do you use string functions in SQL? What is the purpose of the COALESCE function? Advanced SQL Interview Questions (20) *For all data roles What are window functions and how do they work? Explain CTE (Common Table Expressions) and provide an example. How do you handle transactions in SQL? What are stored procedures, and why are they used? Explain the ACID properties in database systems. How do you use PIVOT and UNPIVOT operations? What are triggers and how do they work? Explain the concept of materialized views. How do you implement error handling in SQL? What are user-defined functions? How do you use MERGE statements? Explain recursive queries and their applications. What are table partitioning strategies? How do you implement row-level security? Explain the use of CROSS APPLY and OUTER APPLY. What are temporary tables and table variables? How do you handle dynamic SQL? Explain database isolation levels. What are indexed views and when should they be used? How do you implement hierarchical queries? Performance and Optimization Questions *For Data Engineers, sometimes in Senior DS roles. How do indexes improve query performance? What is a query execution plan and how do you analyze it? Explain the difference between clustered and non-clustered indexes. How do you avoid deadlocks in SQL? What strategies can you use to optimize a slow-running query? How do you identify and resolve blocking issues? What are statistics in SQL Server and why are they important? How do you optimize joins in large tables? Explain index fragmentation and how to address it. What are parameter sniffing issues and how do you resolve them? How do you optimize stored procedure performance? What is the impact of implicit conversions on performance? How do you handle missing indexes? Explain query plan caching and recompilation. What are wait statistics and how do you analyze them? Database Design and Modeling Questions *For Data Engineers, sometimes in Senior DS roles. Explain the concept of database normalization. What are the different types of relationships in databases? How do you design a database schema for a social media application? What is denormalization, and when would you use it? Explain the differences between OLTP and OLAP systems. How do you implement many-to-many relationships? What are the different normal forms (1NF through 5NF)? How do you handle soft deletes in database design? Explain the concept of data warehousing. What are dimensional modeling concepts? How do you implement versioning in database design? What are the best practices for database naming conventions? How do you handle temporal data in databases? Explain the star schema and snowflake schema. What are the considerations for designing a distributed database?

---

#### -- Question 71

-- Table: Customer -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | customer_id   | int     | -- | name          | varchar | -- | visited_on    | date    | -- | amount        | int     | -- +---------------+---------+ -- (customer_id, visited_on) is the primary key for this table. -- This table contains data about customer transactions in a restaurant. -- visited_on is the date on which the customer with ID (customer_id) have visited the restaurant. -- amount is the total paid by a customer. -- You are the restaurant owner and you want to analyze a possible expansion (there will be at least one customer every day). -- Write an SQL query to compute moving average of how much customer paid in a 7 days window (current day + 6 days before) . -- The query result format is in the following example: -- Return result table ordered by visited_on. -- average_amount should be rounded to 2 decimal places, all dates are in the format ('YYYY-MM-DD'). -- Customer table: -- +-------------+--------------+--------------+-------------+ -- | customer_id | name         | visited_on   | amount      | -- +-------------+--------------+--------------+-------------+ -- | 1           | Jhon         | 2019-01-01   | 100         | -- | 2           | Daniel       | 2019-01-02   | 110         | -- | 3           | Jade         | 2019-01-03   | 120         | -- | 4           | Khaled       | 2019-01-04   | 130         | -- | 5           | Winston      | 2019-01-05   | 110         | -- | 6           | Elvis        | 2019-01-06   | 140         | -- | 7           | Anna         | 2019-01-07   | 150         | -- | 8           | Maria        | 2019-01-08   | 80          | -- | 9           | Jaze         | 2019-01-09   | 110         | -- | 1           | Jhon         | 2019-01-10   | 130         | -- | 3           | Jade         | 2019-01-10   | 150         | -- +-------------+--------------+--------------+-------------+ -- Result table: -- +--------------+--------------+----------------+ -- | visited_on   | amount       | average_amount | -- +--------------+--------------+----------------+ -- | 2019-01-07   | 860          | 122.86         | -- | 2019-01-08   | 840          | 120            | -- | 2019-01-09   | 840          | 120            | -- | 2019-01-10   | 1000         | 142.86         | -- +--------------+--------------+----------------+ -- 1st moving average from 2019-01-01 to 2019-01-07 has an average_amount of (100 + 110 + 120 + 130 + 110 + 140 + 150)/7 = 122.86 -- 2nd moving average from 2019-01-02 to 2019-01-08 has an average_amount of (110 + 120 + 130 + 110 + 140 + 150 + 80)/7 = 120 -- 3rd moving average from 2019-01-03 to 2019-01-09 has an average_amount of (120 + 130 + 110 + 140 + 150 + 80 + 110)/7 = 120 -- 4th moving average from 2019-01-04 to 2019-01-10 has an average_amount of (130 + 110 + 140 + 150 + 80 + 110 + 130 + 150)/7 = 142.86 -- Solution select visited_on, sum(amount) over(order by visited_on rows 6 preceding), round(avg(amount) over(order by visited_on rows 6 preceding),2) from ( select visited_on, sum(amount) as amount from customer group by visited_on order by visited_on ) a order by visited_on offset 6 rows

---

#### -- Question 113

-- Table: Spending -- +-------------+---------+ -- | Column Name | Type    | -- +-------------+---------+ -- | user_id     | int     | -- | spend_date  | date    | -- | platform    | enum    | -- | amount      | int     | -- +-------------+---------+ -- The table logs the spendings history of users that make purchases from an online shopping website which has a desktop and a mobile application. -- (user_id, spend_date, platform) is the primary key of this table. -- The platform column is an ENUM type of ('desktop', 'mobile'). -- Write an SQL query to find the total number of users and the total amount spent using mobile only, desktop only and both mobile and desktop together for each date. -- The query result format is in the following example: -- Spending table: -- +---------+------------+----------+--------+ -- | user_id | spend_date | platform | amount | -- +---------+------------+----------+--------+ -- | 1       | 2019-07-01 | mobile   | 100    | -- | 1       | 2019-07-01 | desktop  | 100    | -- | 2       | 2019-07-01 | mobile   | 100    | -- | 2       | 2019-07-02 | mobile   | 100    | -- | 3       | 2019-07-01 | desktop  | 100    | -- | 3       | 2019-07-02 | desktop  | 100    | -- +---------+------------+----------+--------+ -- Result table: -- +------------+----------+--------------+-------------+ -- | spend_date | platform | total_amount | total_users | -- +------------+----------+--------------+-------------+ -- | 2019-07-01 | desktop  | 100          | 1           | -- | 2019-07-01 | mobile   | 100          | 1           | -- | 2019-07-01 | both     | 200          | 1           | -- | 2019-07-02 | desktop  | 100          | 1           | -- | 2019-07-02 | mobile   | 100          | 1           | -- | 2019-07-02 | both     | 0            | 0           | -- +------------+----------+--------------+-------------+ -- On 2019-07-01, user 1 purchased using both desktop and mobile, user 2 purchased using mobile only and user 3 purchased using desktop only. -- On 2019-07-02, user 2 purchased using mobile only, user 3 purchased using desktop only and no one purchased using both platforms. -- Solution SELECT p.spend_date, p.platform, IFNULL(SUM(amount), 0) total_amount, COUNT(DISTINCT u.user_id) total_users FROM ( SELECT DISTINCT(spend_date), 'desktop' platform FROM Spending UNION SELECT DISTINCT(spend_date), 'mobile' platform FROM Spending UNION SELECT DISTINCT(spend_date), 'both' platform FROM Spending ) p LEFT JOIN (SELECT user_id, spend_date, SUM(amount) amount, (CASE WHEN COUNT(DISTINCT platform)>1 THEN "both" ELSE platform END) platform FROM Spending GROUP BY spend_date, user_id) u ON p.platform = u.platform AND p.spend_date=u.spend_date GROUP BY p.spend_date, p.platform

---

#### -- Question 24

-- Table my_numbers contains many numbers in column num including duplicated ones. -- Can you write a SQL query to find the biggest number, which only appears once. -- +---+ -- |num| -- +---+ -- | 8 | -- | 8 | -- | 3 | -- | 3 | -- | 1 | -- | 4 | -- | 5 | -- | 6 | -- For the sample data above, your query should return the following result: -- +---+ -- |num| -- +---+ -- | 6 | -- Note: -- If there is no such number, just output null. -- Solution Select max(a.num) as num from ( select num, count(*) from my_numbers group by num having count(*)=1 ) a

---

#### SELECT class

FROM courses_596 GROUP BY class HAVING COUNT(DISTINCT student) >=5;

---

#### SELECT DISTINCT e1.employee_id

FROM employees_1978 e1 LEFT JOIN employees_1978 e2 ON e1.manager_id = e2.employee_id WHERE e1.salary < 30000 AND e2.employee_id IS NULL;

---

#### WITH cte1 AS (

SELECT TO_CHAR(c.charge_date,'YYYY-MM') AS month,t.country, COUNT(c.trans_id) AS chargeback_count, SUM(t.amount) AS chargeback_amount FROM chargebacks_1205 c JOIN transactions_1205 t ON t.id = c.trans_id GROUP BY TO_CHAR(charge_date,'YYYY-MM'),t.country ), cte2 AS ( SELECT TO_CHAR(trans_date,'YYYY-MM') AS month,country, COUNT(CASE WHEN state='approved' THEN 1 ELSE NULL END) AS approved_count, SUM(CASE WHEN state='approved' THEN amount ELSE NULL END) AS approved_amount FROM transactions_1205 GROUP BY TO_CHAR(trans_date,'YYYY-MM'),country ) SELECT c1.month,c1.country, COALESCE(c2.approved_count,0) AS approved_count, COALESCE(c2.approved_amount,0) AS approved_amount, COALESCE(c1.chargeback_count,0) AS chargeback_count, COALESCE(c1.chargeback_amount,0) AS chargeback_amount FROM cte1 c1 FULL OUTER JOIN cte2 c2 ON c1.month = c2.month ORDER BY c1.month;

---

#### SELECT s1.sale_date,s1.sold_num-s2.sold_num AS diff

FROM sales_1445 s1 INNER JOIN sales_1445 s2 ON s1.sale_date=s2.sale_date AND s1.fruit <> s2.fruit AND s1.fruit = 'apples';

---

#### SELECT DISTINCT t1.id,

CASE WHEN t1.p_id IS NULL THEN 'Root' WHEN t2.id IS NULL THEN 'Leaf' ELSE 'Inner' END AS Type FROM tree_608 t1 LEFT JOIN tree_608 t2 ON t1.id = t2.p_id ORDER BY t1.id;

---

#### SELECT COUNT(CASE WHEN device_type = 'laptop' THEN 1 END) laptop_views,

COUNT(CASE WHEN device_type IN ('tablet', 'phone') THEN 1 END) mobile_views FROM viewership;

---

#### SELECT COUNT(DISTINCT customer_id) AS rich_count

FROM store_2082 WHERE amount > 500;

---

#### SELECT e.employee_id

FROM employees_2394 e LEFT JOIN logs_2394 l ON e.employee_id = l.employee_id GROUP BY e.employee_id,e.needed_hours HAVING COALESCE(SUM(EXTRACT(hour FROM (out_time-in_time))+ FLOOR((EXTRACT(minute FROM (out_time-in_time)) + CEIL(EXTRACT(second FROM (out_time-in_time))/60))/60)),0) < e.needed_hours

---

#### SELECT u.name,COALESCE(SUM(r.distance),0) AS travelled_distance

FROM users_1407 u LEFT JOIN rides_1407 r ON u.id = r.user_id GROUP BY u.name ORDER BY travelled_distance DESC,u.name;

---

#### SELECT ROUND

( SUM(CASE WHEN signup_action = 'Confirmed' THEN 1.0 ELSE 0.0 END) / COUNT(emails.email_id) , 2 ) FROM texts LEFT JOIN emails USING(email_id)

---

#### SELECT DATE_PART('MONTH', submit_date) mth, product_id, ROUND(AVG(stars), 2)

FROM reviews GROUP BY DATE_PART('MONTH', submit_date), product_id ORDER BY DATE_PART('MONTH', submit_date), product_id;

---

#### SELECT user_id,COUNT(follower_id) AS follower_count

FROM followers_1729 GROUP BY user_id ORDER BY user_id;

---

#### SELECT user_id,MAX(time_stamp) AS last_stamp

FROM logins_1890 WHERE EXTRACT(YEAR FROM time_stamp) = 2020 GROUP BY user_id;

---

#### WITH RECURSIVE cte AS(

SELECT v.user_id,v.visit_date,t.amount FROM visits_1336 v LEFT JOIN transactions_1336 t ON v.user_id=t.user_id AND v.visit_date=t.transaction_date ), cte1 AS ( SELECT user_id,visit_date,COUNT(1) AS transactions_count FROM cte WHERE amount IS NOT NULL GROUP BY user_id,visit_date ), cte2 AS ( SELECT 0 AS transactions_count,COUNT(1) AS visits_count FROM cte WHERE amount IS NULL GROUP BY transactions_count ), cte3 AS ( SELECT transactions_count,COUNT(transactions_count) AS visit_count FROM cte1 GROUP BY transactions_count UNION SELECT * FROM cte2 ), nums AS ( SELECT 0 AS n UNION SELECT n+1 AS n FROM nums WHERE n < (SELECT MAX(transactions_count) FROM cte3) ) SELECT n.n AS transactions_count,COALESCE(visit_count,0) AS visit_count FROM nums n LEFT JOIN cte3 c ON n.n=c.transactions_count ORDER BY 1;

---

#### UPDATE salary_627

SET sex = ( CASE WHEN sex = 'm' THEN 'f' ELSE 'm' END );

---

#### SELECT event_day AS day,emp_id,SUM(out_time-in_time) AS total_time

FROM employees_1741 GROUP BY event_day,emp_id ORDER BY day,emp_id;

---

#### -- Question 69

-- Table: Users -- +----------------+---------+ -- | Column Name    | Type    | -- +----------------+---------+ -- | user_id        | int     | -- | join_date      | date    | -- | favorite_brand | varchar | -- +----------------+---------+ -- user_id is the primary key of this table. -- This table has the info of the users of an online shopping website where users can sell and buy items. -- Table: Orders -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | order_id      | int     | -- | order_date    | date    | -- | item_id       | int     | -- | buyer_id      | int     | -- | seller_id     | int     | -- +---------------+---------+ -- order_id is the primary key of this table. -- item_id is a foreign key to the Items table. -- buyer_id and seller_id are foreign keys to the Users table. -- Table: Items -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | item_id       | int     | -- | item_brand    | varchar | -- +---------------+---------+ -- item_id is the primary key of this table. -- Write an SQL query to find for each user, the join date and the number of orders they made as a buyer in 2019. -- The query result format is in the following example: -- Users table: -- +---------+------------+----------------+ -- | user_id | join_date  | favorite_brand | -- +---------+------------+----------------+ -- | 1       | 2018-01-01 | Lenovo         | -- | 2       | 2018-02-09 | Samsung        | -- | 3       | 2018-01-19 | LG             | -- | 4       | 2018-05-21 | HP             | -- +---------+------------+----------------+ -- Orders table: -- +----------+------------+---------+----------+-----------+ -- | order_id | order_date | item_id | buyer_id | seller_id | -- +----------+------------+---------+----------+-----------+ -- | 1        | 2019-08-01 | 4       | 1        | 2         | -- | 2        | 2018-08-02 | 2       | 1        | 3         | -- | 3        | 2019-08-03 | 3       | 2        | 3         | -- | 4        | 2018-08-04 | 1       | 4        | 2         | -- | 5        | 2018-08-04 | 1       | 3        | 4         | -- | 6        | 2019-08-05 | 2       | 2        | 4         | -- +----------+------------+---------+----------+-----------+ -- Items table: -- +---------+------------+ -- | item_id | item_brand | -- +---------+------------+ -- | 1       | Samsung    | -- | 2       | Lenovo     | -- | 3       | LG         | -- | 4       | HP         | -- +---------+------------+ -- Result table: -- +-----------+------------+----------------+ -- | buyer_id  | join_date  | orders_in_2019 | -- +-----------+------------+----------------+ -- | 1         | 2018-01-01 | 1              | -- | 2         | 2018-02-09 | 2              | -- | 3         | 2018-01-19 | 0              | -- | 4         | 2018-05-21 | 0              | -- +-----------+------------+----------------+ -- Solution select user_id as buyer_id, join_date, coalesce(a.orders_in_2019,0) from users left join ( select buyer_id, coalesce(count(*), 0) as orders_in_2019 from orders o join users u on u.user_id = o.buyer_id where extract('year'from order_date) = 2019 group by buyer_id) a on users.user_id = a.buyer_id

---

#### SELECT e1.employee_id

FROM employees_1270 e1 INNER JOIN employees_1270 e2 ON e1.manager_id = e2.employee_id AND e1.manager_id = 1 AND e1.employee_id <> e2.employee_id UNION SELECT e1.employee_id FROM employees_1270 e1 INNER JOIN employees_1270 e2 ON e1.manager_id = e2.employee_id AND e1.employee_id <> e2.employee_id INNER JOIN employees_1270 e3 ON e2.manager_id = e3.employee_id AND e2.manager_id = 1 AND e2.employee_id <> e3.employee_id UNION SELECT e1.employee_id FROM employees_1270 e1 INNER JOIN employees_1270 e2 ON e1.manager_id = e2.employee_id AND e1.employee_id <> e2.employee_id INNER JOIN employees_1270 e3 ON e2.manager_id = e3.employee_id AND e2.employee_id <> e3.employee_id INNER JOIN employees_1270 e4 ON e3.manager_id = e4.employee_id AND e3.manager_id = 1 AND e3.employee_id <> e4.employee_id; --------------(OR)------------ SELECT e1.employee_id FROM employees_1270 e1 INNER JOIN employees_1270 e2 ON e1.manager_id = e2.employee_id INNER JOIN employees_1270 e3 ON e2.manager_id = e3.employee_id WHERE e3.manager_id = 1 AND e1.employee_id <> 1 --------------(OR)------------ WITH RECURSIVE cte AS ( SELECT employee_id,employee_name,manager_id,1 AS level FROM employees_1270 WHERE employee_id = 1 UNION SELECT e.employee_id,e.employee_name,e.manager_id,level+1 AS level FROM cte c INNER JOIN employees_1270 e ON c.employee_id = e.manager_id WHERE level < 4 ) SELECT DISTINCT employee_id,employee_name FROM cte WHERE employee_id <> 1;

---

#### SELECT name,bonus

FROM employee_577 e JOIN bonus_577 b ON e.empId = b.empId AND b.bonus < 1000;

---

#### -- Question 58

-- Given a table tree, id is identifier of the tree node and p_id is its parent node's id. -- +----+------+ -- | id | p_id | -- +----+------+ -- | 1  | null | -- | 2  | 1    | -- | 3  | 1    | -- | 4  | 2    | -- | 5  | 2    | -- +----+------+ -- Each node in the tree can be one of three types: -- Leaf: if the node is a leaf node. -- Root: if the node is the root of the tree. -- Inner: If the node is neither a leaf node nor a root node. -- Write a query to print the node id and the type of the node. Sort your output by the node id. The result for the above sample is: -- +----+------+ -- | id | Type | -- +----+------+ -- | 1  | Root | -- | 2  | Inner| -- | 3  | Leaf | -- | 4  | Leaf | -- | 5  | Leaf | -- +----+------+ -- Explanation -- Node '1' is root node, because its parent node is NULL and it has child node '2' and '3'. -- Node '2' is inner node, because it has parent node '1' and child node '4' and '5'. -- Node '3', '4' and '5' is Leaf node, because they have parent node and they don't have child node. -- And here is the image of the sample tree as below: -- 			  1 -- 			/   \ --           2       3 --         /   \ --       4       5 -- Note -- If there is only one node on the tree, you only need to output its root attributes. -- Solution select id, case when p_id is null then 'Root' when id not in (select p_id from tree where p_id is not null group by p_id) then 'Leaf' else 'Inner' end as Type from tree order by id

---

#### SELECT ROUND(MIN(SQRT(POWER(a.x-b.x,2)+POWER(a.y-b.y,2)))::NUMERIC,2) AS shortest

FROM point_2d_612 a JOIN point_2d_612 b ON (a.x,a.y) <> (b.x,b.y);

---

#### SELECT p.name,SUM(i.rest) AS rest,SUM(i.paid) AS paid,SUM(i.canceled) AS canceled,SUM(i.refunded) AS refunded

FROM invoice_1677 i INNER JOIN product_1677 p ON i.product_id = p.product_id GROUP BY p.name ORDER BY p.name;

---

#### SELECT name

FROM candidate_574 WHERE id IN ( SELECT candidate_id FROM vote_574 GROUP BY candidate_id ORDER BY COUNT(candidate_id) DESC LIMIT 1 );

---

#### SELECT employee_id,

CASE WHEN employee_id%2 <> 0 AND LEFT(name,1)<>'M' THEN salary ELSE 0 END AS bonus FROM employees_1873;

---

#### -- Question 30

-- Table: Sales -- +-------------+-------+ -- | Column Name | Type  | -- +-------------+-------+ -- | sale_id     | int   | -- | product_id  | int   | -- | year        | int   | -- | quantity    | int   | -- | price       | int   | -- +-------------+-------+ -- (sale_id, year) is the primary key of this table. -- product_id is a foreign key to Product table. -- Note that the price is per unit. -- Table: Product -- +--------------+---------+ -- | Column Name  | Type    | -- +--------------+---------+ -- | product_id   | int     | -- | product_name | varchar | -- +--------------+---------+ -- product_id is the primary key of this table. -- Write an SQL query that reports all product names of the products in the Sales table along with their selling year and price. -- For example: -- Sales table: -- +---------+------------+------+----------+-------+ -- | sale_id | product_id | year | quantity | price | -- +---------+------------+------+----------+-------+ -- | 1       | 100        | 2008 | 10       | 5000  | -- | 2       | 100        | 2009 | 12       | 5000  | -- | 7       | 200        | 2011 | 15       | 9000  | -- +---------+------------+------+----------+-------+ -- Product table: -- +------------+--------------+ -- | product_id | product_name | -- +------------+--------------+ -- | 100        | Nokia        | -- | 200        | Apple        | -- | 300        | Samsung      | -- +------------+--------------+ -- Result table: -- +--------------+-------+-------+ -- | product_name | year  | price | -- +--------------+-------+-------+ -- | Nokia        | 2008  | 5000  | -- | Nokia        | 2009  | 5000  | -- | Apple        | 2011  | 9000  | -- +--------------+-------+-------+ -- Solution Select a.product_name, b.year, b.price from product as a join sales as b on a.product_id = b.product_id

---

#### WITH cnt AS(

SELECT COUNT(DISTINCT session_id) AS c FROM activity_1142 WHERE activity_date <= '2019-07-27' AND activity_date > '2019-07-27'::DATE - 30 GROUP BY user_id ) SELECT ROUND(AVG(c),2) AS average_sessions_per_user FROM cnt;

---

#### -- Question 61

-- Table: Stocks -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | stock_name    | varchar | -- | operation     | enum    | -- | operation_day | int     | -- | price         | int     | -- +---------------+---------+ -- (stock_name, day) is the primary key for this table. -- The operation column is an ENUM of type ('Sell', 'Buy') -- Each row of this table indicates that the stock which has stock_name had an operation on the day operation_day with the price. -- It is guaranteed that each 'Sell' operation for a stock has a corresponding 'Buy' operation in a previous day. -- Write an SQL query to report the Capital gain/loss for each stock. -- The capital gain/loss of a stock is total gain or loss after buying and selling the stock one or many times. -- Return the result table in any order. -- The query result format is in the following example: -- Stocks table: -- +---------------+-----------+---------------+--------+ -- | stock_name    | operation | operation_day | price  | -- +---------------+-----------+---------------+--------+ -- | Leetcode      | Buy       | 1             | 1000   | -- | Corona Masks  | Buy       | 2             | 10     | -- | Leetcode      | Sell      | 5             | 9000   | -- | Handbags      | Buy       | 17            | 30000  | -- | Corona Masks  | Sell      | 3             | 1010   | -- | Corona Masks  | Buy       | 4             | 1000   | -- | Corona Masks  | Sell      | 5             | 500    | -- | Corona Masks  | Buy       | 6             | 1000   | -- | Handbags      | Sell      | 29            | 7000   | -- | Corona Masks  | Sell      | 10            | 10000  | -- +---------------+-----------+---------------+--------+ -- Result table: -- +---------------+-------------------+ -- | stock_name    | capital_gain_loss | -- +---------------+-------------------+ -- | Corona Masks  | 9500              | -- | Leetcode      | 8000              | -- | Handbags      | -23000            | -- +---------------+-------------------+ -- Leetcode stock was bought at day 1 for 1000$ and was sold at day 5 for 9000$. Capital gain = 9000 - 1000 = 8000$. -- Handbags stock was bought at day 17 for 30000$ and was sold at day 29 for 7000$. Capital loss = 7000 - 30000 = -23000$. -- Corona Masks stock was bought at day 1 for 10$ and was sold at day 3 for 1010$. It was bought again at day 4 for 1000$ and was sold at day 5 for 500$. At last, it was bought at day 6 for 1000$ and was sold at day 10 for 10000$. Capital gain/loss is the sum of capital gains/losses for each ('Buy' --> 'Sell') -- operation = (1010 - 10) + (500 - 1000) + (10000 - 1000) = 1000 - 500 + 9000 = 9500$. -- Solution select stock_name, (one-two) as capital_gain_loss from( (select stock_name, sum(price) as one from stocks where operation = 'Sell' group by stock_name) b left join (select stock_name as name, sum(price) as two from stocks where operation = 'Buy' group by stock_name) c on b.stock_name = c.name) order by capital_gain_loss desc

---

#### WITH dedup AS (

SELECT * FROM logins_1454 GROUP BY id,login_date ), cte AS ( SELECT id,login_date, LEAD(login_date,4) OVER (PARTITION BY id ORDER BY login_date) AS date_5 FROM dedup ) SELECT a.id,a.name FROM cte c INNER JOIN accounts_1454 a ON a.id = c.id WHERE c.date_5-c.login_date=4;

---

#### -- Question 90

-- Table: Sales -- +-------------+-------+ -- | Column Name | Type  | -- +-------------+-------+ -- | sale_id     | int   | -- | product_id  | int   | -- | year        | int   | -- | quantity    | int   | -- | price       | int   | -- +-------------+-------+ -- sale_id is the primary key of this table. -- product_id is a foreign key to Product table. -- Note that the price is per unit. -- Table: Product -- +--------------+---------+ -- | Column Name  | Type    | -- +--------------+---------+ -- | product_id   | int     | -- | product_name | varchar | -- +--------------+---------+ -- product_id is the primary key of this table. -- Write an SQL query that selects the product id, year, quantity, and price for the first year of every product sold. -- The query result format is in the following example: -- Sales table: -- +---------+------------+------+----------+-------+ -- | sale_id | product_id | year | quantity | price | -- +---------+------------+------+----------+-------+ -- | 1       | 100        | 2008 | 10       | 5000  | -- | 2       | 100        | 2009 | 12       | 5000  | -- | 7       | 200        | 2011 | 15       | 9000  | -- +---------+------------+------+----------+-------+ -- Product table: -- +------------+--------------+ -- | product_id | product_name | -- +------------+--------------+ -- | 100        | Nokia        | -- | 200        | Apple        | -- | 300        | Samsung      | -- +------------+--------------+ -- Result table: -- +------------+------------+----------+-------+ -- | product_id | first_year | quantity | price | -- +------------+------------+----------+-------+ -- | 100        | 2008       | 10       | 5000  | -- | 200        | 2011       | 15       | 9000  | -- +------------+------------+----------+-------+ -- Solution select a.product_id, a.year as first_year, a.quantity, a.price from ( select product_id, quantity, price, year, rank() over(partition by product_id order by year) as rk from sales ) a where a.rk = 1

---

#### -- Table Name for Test-Case 1: candidates_2010

-- Table Name for Test-Case 2: candidates_2010_tc_2 WITH seniors AS ( SELECT *, SUM(salary) OVER (ORDER BY salary,employee_id) AS occupied_budget, 70000-SUM(salary) OVER (ORDER BY salary,employee_id) AS remaining_budget FROM candidates_2010 WHERE experience = 'Senior' ), left_budget AS ( SELECT COALESCE(MIN(remaining_budget),70000) AS budget FROM seniors WHERE remaining_budget >= 0 ), juniors AS ( SELECT c.*, SUM(c.salary) OVER (ORDER BY c.salary,c.employee_id) AS occupied_budget, lb.budget-SUM(c.salary) OVER (ORDER BY c.salary,c.employee_id) AS remaining_budget FROM candidates_2010 c CROSS JOIN left_budget lb WHERE experience = 'Junior' ), hired_candidates AS ( SELECT * FROM juniors WHERE remaining_budget >= 0 UNION SELECT * FROM seniors WHERE remaining_budget >= 0 ) SELECT employee_id FROM hired_candidates;

---

#### SELECT DISTINCT c.title

FROM tv_program_1495 t INNER JOIN content_1495 c ON t.content_id = c.content_id AND c.kids_content = 'Y' AND DATE_TRUNC('MONTH',t.program_date)::DATE = '2020-06-01';

---

#### -----------------------------------------------------------

--Solution 1 : ----------------------------------------------------------- WITH cte AS( SELECT id,Num, LEAD(Num,1) OVER() as Next1, LEAD(Num,2) OVER() as Next2 FROM logs_180 ) SELECT DISTINCT Num AS ConsecutiveNums FROM cte WHERE Num = Next1 AND Num = Next2; ----------------------------------------------------------- --Solution 2 : ----------------------------------------------------------- WITH cte AS( SELECT id,Num, LAG(Num) OVER() as Prev, LEAD(Num) OVER() as Next FROM logs_180 ) SELECT DISTINCT Num AS ConsecutiveNums FROM cte WHERE Num = Prev AND Num = Next; ----------------------------------------------------------- --Solution 3 : ----------------------------------------------------------- SELECT DISTINCT l1.Num AS ConsecutiveNums FROM logs_180 l1 JOIN logs_180 l2 ON l1.id=l2.id-1 AND l1.Num=l2.Num JOIN logs_180 l3 ON l1.id=l3.id-2 AND l2.Num=l3.Num ----------------------------------------------------------- --Exensible Solution (Best) : ----------------------------------------------------------- WITH ranked AS ( SELECT *, (id-ROW_NUMBER() OVER (PARTITION BY num ORDER BY id)) AS diff FROM logs_180 ) SELECT DISTINCT num AS "ConsecutiveNums" FROM ranked GROUP BY diff,num HAVING COUNT(id) >= 3;

---

#### WITH winners AS (

SELECT wimbledon AS winner_id FROM championships_1783 UNION ALL SELECT fr_open AS winner_id FROM championships_1783 UNION ALL SELECT us_open AS winner_id FROM championships_1783 UNION ALL SELECT au_open AS winner_id FROM championships_1783 ) SELECT p.player_id,p.player_name,COUNT(p.player_id) AS num_wins FROM winners w INNER JOIN players_1783 p ON w.winner_id = p.player_id GROUP BY p.player_id,p.player_name;

---

#### CREATE OR REPLACE FUNCTION pivot_products_2252()

RETURNS TEXT LANGUAGE PLPGSQL AS $$ DECLARE store_name_array TEXT[]; store_name TEXT; query_text TEXT; BEGIN --query to find all the stores given in the table SELECT ARRAY_AGG(DISTINCT store ORDER BY store) INTO store_name_array FROM products_2252; --RAISE NOTICE 'store_name_array = %',store_name_array; --prepare query query_text := 'SELECT product_id, '; --prepare case statements for all the store_name in store_name_array FOREACH store_name IN ARRAY store_name_array LOOP query_text := query_text || 'SUM(CASE WHEN store = ''' || store_name || ''' THEN price ELSE NULL END) AS "' || store_name || '",'; END LOOP; --prepare query query_text := LEFT(query_text,LENGTH(query_text)-1); query_text := query_text || ' FROM products_2252 GROUP BY product_id ORDER BY product_id'; --RAISE NOTICE '%',query_text; --return the query as text RETURN query_text; END $$; SELECT pivot_products_2252(); -- output of the function: SELECT product_id, SUM(CASE WHEN store = 'LC_Store' THEN price ELSE NULL END) AS "LC_Store", SUM(CASE WHEN store = 'Nozama' THEN price ELSE NULL END) AS "Nozama", SUM(CASE WHEN store = 'Shop' THEN price ELSE NULL END) AS "Shop", SUM(CASE WHEN store = 'Souq' THEN price ELSE NULL END) AS "Souq" FROM products_2252 GROUP BY product_id ORDER BY product_id; --running this query manually will give us expected results

---

#### --(1st approach is called co-relevant subquery because inner query is dependent on outer query)

SELECT SUM(tiv_2016) AS tiv_2016_sum FROM insurance_585 i WHERE tiv_2015 IN (SELECT tiv_2015 FROM insurance_585 WHERE pid <> i.pid) AND (lat,lon) NOT IN (SELECT lat,lon FROM insurance_585 WHERE pid <> i.pid); (OR) SELECT SUM(tiv_2016) AS tiv_2016_sum FROM insurance_585 WHERE tiv_2015 IN (SELECT tiv_2015 FROM insurance_585 GROUP BY tiv_2015 HAVING COUNT(*) > 1) AND (lat,lon) IN (SELECT lat,lon FROM insurance_585 GROUP BY lat,lon HAVING COUNT(*) = 1);

---

#### -- Question 80

-- Table: Logs -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | log_id        | int     | -- +---------------+---------+ -- id is the primary key for this table. -- Each row of this table contains the ID in a log Table. -- Since some IDs have been removed from Logs. Write an SQL query to find the start and end number of continuous ranges in table Logs. -- Order the result table by start_id. -- The query result format is in the following example: -- Logs table: -- +------------+ -- | log_id     | -- +------------+ -- | 1          | -- | 2          | -- | 3          | -- | 7          | -- | 8          | -- | 10         | -- +------------+ -- Result table: -- +------------+--------------+ -- | start_id   | end_id       | -- +------------+--------------+ -- | 1          | 3            | -- | 7          | 8            | -- | 10         | 10           | -- +------------+--------------+ -- The result table should contain all ranges in table Logs. -- From 1 to 3 is contained in the table. -- From 4 to 6 is missing in the table -- From 7 to 8 is contained in the table. -- Number 9 is missing in the table. -- Number 10 is contained in the table. -- Solution select min(log_id) as start_id, max(log_id) as end_id from( select log_id, log_id-row_number() over (order by log_id) as rk from logs) a group by rk

---

#### SELECT project_id

FROM project_1075 GROUP BY project_id ORDER BY COUNT(employee_id) DESC LIMIT 1;

---

#### SELECT u.user_id,u.join_date,COALESCE(b.orders_in_2019,0)

FROM users_1158 u LEFT JOIN (SELECT buyer_id,COUNT(order_id) AS orders_in_2019 FROM orders_1158 WHERE EXTRACT(YEAR FROM order_date) = 2019 GROUP BY buyer_id) b ON u.user_id = b.buyer_id;

---

#### -- Question 39

-- Table: Prices -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | product_id    | int     | -- | start_date    | date    | -- | end_date      | date    | -- | price         | int     | -- +---------------+---------+ -- (product_id, start_date, end_date) is the primary key for this table. -- Each row of this table indicates the price of the product_id in the period from start_date to end_date. -- For each product_id there will be no two overlapping periods. That means there will be no two intersecting periods for the same product_id. -- Table: UnitsSold -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | product_id    | int     | -- | purchase_date | date    | -- | units         | int     | -- +---------------+---------+ -- There is no primary key for this table, it may contain duplicates. -- Each row of this table indicates the date, units and product_id of each product sold. -- Write an SQL query to find the average selling price for each product. -- average_price should be rounded to 2 decimal places. -- The query result format is in the following example: -- Prices table: -- +------------+------------+------------+--------+ -- | product_id | start_date | end_date   | price  | -- +------------+------------+------------+--------+ -- | 1          | 2019-02-17 | 2019-02-28 | 5      | -- | 1          | 2019-03-01 | 2019-03-22 | 20     | -- | 2          | 2019-02-01 | 2019-02-20 | 15     | -- | 2          | 2019-02-21 | 2019-03-31 | 30     | -- +------------+------------+------------+--------+ -- UnitsSold table: -- +------------+---------------+-------+ -- | product_id | purchase_date | units | -- +------------+---------------+-------+ -- | 1          | 2019-02-25    | 100   | -- | 1          | 2019-03-01    | 15    | -- | 2          | 2019-02-10    | 200   | -- | 2          | 2019-03-22    | 30    | -- +------------+---------------+-------+ -- Result table: -- +------------+---------------+ -- | product_id | average_price | -- +------------+---------------+ -- | 1          | 6.96          | -- | 2          | 16.96         | -- +------------+---------------+ -- Average selling price = Total Price of Product / Number of products sold. -- Average selling price for product 1 = ((100 * 5) + (15 * 20)) / 115 = 6.96 -- Average selling price for product 2 = ((200 * 15) + (30 * 30)) / 230 = 16.96 -- Solution Select d.product_id, round((sum(price*units)+0.00)/(sum(units)+0.00),2) as average_price from( Select * from prices p natural join unitssold u where u.purchase_date between p.start_date and p.end_date) d group by d.product_id

---

#### -- Question 12

-- Given a Weather table, write a SQL query to find all dates' Ids with higher temperature compared to its previous (yesterday's) dates. -- +---------+------------------+------------------+ -- | Id(INT) | RecordDate(DATE) | Temperature(INT) | -- +---------+------------------+------------------+ -- |       1 |       2015-01-01 |               10 | -- |       2 |       2015-01-02 |               25 | -- |       3 |       2015-01-03 |               20 | -- |       4 |       2015-01-04 |               30 | -- +---------+------------------+------------------+ -- For example, return the following Ids for the above Weather table: -- +----+ -- | Id | -- +----+ -- |  2 | -- |  4 | -- +----+ -- Solution select a.Id from weather a, weather b where a.Temperature>b.Temperature and  datediff(a.recorddate,b.recorddate)=1

---

#### SELECT TO_CHAR(day,'Day, Month DD, YYYY') AS day

FROM days_1853;

---

#### SELECT *,

CASE WHEN x+y>z AND x+z>y AND y+z>x THEN 'Yes' ELSE 'No' END AS triangle FROM triangle_610;

---

#### Understanding the Role: Advanced Analytics, Sr. Manager, Marketing

From the job description you provided, this role is not just about technical skills; it's a leadership position that requires a blend of technical expertise, business acumen, and strong communication skills. Here's a breakdown of what Airbnb is looking for: ‚óè Leadership & Management: You'll be leading a team of analysts, so be prepared to talk about your management style, how you mentor and develop team members, and your experience in leading projects. ‚óè Technical Expertise: ‚óã SQL is a must: Hive and Presto are the flavors of SQL they use. ‚óã Advanced Analytics: This includes statistical modeling, experimentation (A/B testing), and causal inference. ‚óã Data Storytelling: You need to be able to translate complex data into actionable insights for stakeholders. ‚óè Business Acumen & Strategy: ‚óã Marketing Focus: Understand the nuances of marketing analytics, including campaign measurement, customer segmentation, and marketing channel optimization. ‚óã Product Sense: The case study will test your ability to measure product development and define product metrics. ‚óã Strategic Thinking: You'll be working with senior stakeholders, so you need to demonstrate that you can think strategically and align your team's work with the company's goals. ‚óè Collaboration: You'll be working with various teams (Finance, Data Engineering, Data Science), so be ready to discuss your collaboration and stakeholder management skills.

---

#### Mastering the SQL Technical Interview

The technical screen will focus on "basic and intermediate SQL." While they say you can look up syntax, you should still have a strong command of the concepts. Here's how to prepare: Key SQL Concepts to Master: ‚óè Joining Tables: ‚óã INNER JOIN, LEFT JOIN, RIGHT JOIN, FULL OUTER JOIN. ‚óã Be prepared to explain the differences and when to use each. ‚óã Self-Joins: These are explicitly mentioned, so practice problems that involve joining a table to itself. ‚óè Aggregating and Filtering: ‚óã GROUP BY and aggregate functions (COUNT, SUM, AVG, MAX, MIN). ‚óã WHERE vs. HAVING: Understand the order of operations and when to use each. ‚óè Subqueries: ‚óã Practice using subqueries in SELECT, FROM, and WHERE clauses. ‚óã Understand the difference between correlated and non-correlated subqueries. ‚óè Window Functions: This is an intermediate/advanced topic that they've called out. Master these: ‚óã ROW_NUMBER(), RANK(), DENSE_RANK(): For ranking items. ‚óã LEAD(), LAG(): For accessing data in subsequent or preceding rows. ‚óã SUM(), AVG(), COUNT() as window functions with OVER(PARTITION BY ...): For running totals and moving averages. ‚óè Common Table Expressions (CTEs): Using the WITH clause to break down complex queries and improve readability. Practice Platforms: ‚óè DataLemur: Created by the author of "Ace the Data Science Interview," this site has a great collection of SQL interview questions from top tech companies. ‚óè StrataScratch: Offers real interview questions from companies like Airbnb, with a built-in SQL editor to practice. ‚óè LeetCode: Known for software engineering questions, but its database section has excellent SQL problems. Hive and Presto Specifics: ‚óè Hive and Presto are SQL query engines designed for big data. While the syntax is very similar to standard SQL, it's good to be aware of some differences, especially in performance and available functions. A quick search for "Hive vs. Presto syntax" will give you the key distinctions. For the interview, a strong grasp of standard SQL will be sufficient.

---

#### Nailing the Case Study Interview

The case study will assess your product sense and analytical thinking. They want to see how you structure your thoughts and approach a problem. Here's a framework to guide you: The CIRCLES Method‚Ñ¢ for Product Case Studies: This is a popular framework for product-related case studies. It's a great way to structure your response:

---

#### C - Clarify: Ask clarifying questions to understand the problem fully. What's the goal?

Who are the users? What are the constraints?

---

#### I - Identify Users: Who are the key user segments for this product or feature? (For

Airbnb, this is often Hosts and Guests).

---

#### C - Cut Through and Prioritize: Brainstorm potential solutions or metrics, then

prioritize them based on impact and effort.

---

#### S - Summarize: Conclude with a clear summary of your recommendation and next

steps. Example Case Study Prompt: "We've just launched a new feature that allows guests to add ‚Äòexperiences‚Äô to their bookings. How would you measure the success of this feature?" Applying a Framework to the Example:

---

#### Clarify:

‚óã "What is the primary goal of this feature? Is it to increase revenue, improve user engagement, or drive more bookings?" ‚óã "Is this feature available on all platforms (web, iOS, Android)?" ‚óã "What is the timeline for measuring success (e.g., first week, first month, first quarter)?"

---

#### Define Success Metrics: Structure your metrics into categories. For Airbnb, a

two-sided marketplace, consider both sides. ‚óã Guest-Side Metrics (The User): ‚ñ† Adoption Rate: % of users who see the feature vs. % who interact with it. ‚ñ† Conversion Rate: % of users who book an experience after seeing the feature. ‚ñ† Average Order Value (AOV): How much does the feature add to the average booking value? ‚ñ† User Satisfaction: Net Promoter Score (NPS) or user surveys on the new feature. ‚ñ† Retention: Do users who book experiences have a higher retention rate than those who don't? ‚óã Host-Side Metrics (The Provider): ‚ñ† Host Engagement: # of hosts creating experiences. ‚ñ† Host Revenue: Increase in earnings for hosts offering experiences. ‚ñ† Host Satisfaction: NPS from hosts on the new feature. ‚óã Ecosystem Metrics (The Business): ‚ñ† Overall Revenue: Incremental revenue generated by the feature. ‚ñ† Impact on Core Business: Does this feature lead to more or fewer accommodation bookings? (This is a "guardrail" metric to ensure the new feature isn't hurting the core business).

---

#### Propose an Analytical Approach:

‚óã A/B Testing: This is the gold standard. "I would propose an A/B test where a control group of users does not see the new feature, and a treatment group does. We can then compare the key metrics between the two groups to measure the causal impact of the feature." ‚óã Pre-Post Analysis (if A/B testing isn't possible): "If an A/B test isn't feasible, we could do a pre-post analysis, comparing user behavior before and after the feature launch. We would need to be mindful of seasonality and other external factors."

---

#### Data and Dashboarding:

‚óã "To track these metrics, I would work with the data engineering team to ensure the necessary data is being logged. Then, I would create a dashboard in a tool like Tableau or Superset to monitor the performance of the feature in real-time."

---

#### Airbnb-Specific Preparation

Show them you've done your homework. Spend some time researching: ‚óè Airbnb's Business Model: Understand how they make money, their key markets, and their competitive landscape. ‚óè Recent Product Launches: What new features have they launched recently? Think about how you would measure their success. ‚óè Marketing Campaigns: Look at their recent marketing campaigns. What channels are they using? Who are they targeting? ‚óè The Travel Industry: Be aware of the current trends in the travel and hospitality industry.

---

#### General Interview Tips

‚óè Think Out Loud: During both the technical and case study portions, communicate your thought process. They want to see how you think, not just the final answer. ‚óè Prepare Your Questions: Have thoughtful questions ready to ask your interviewers. This shows your interest and engagement. Examples: ‚óã "What is the biggest analytical challenge the marketing team is currently facing?" ‚óã "How does the data and analytics team collaborate with the marketing and product teams?" ‚óã "What does success look like for someone in this role in the first 6-12 months?" ‚óè Be a Storyteller: When answering behavioral questions ("Tell me about a time when..."), use the STAR method (Situation, Task, Action, Result) to structure your answers and make them compelling.

---

#### Write a SQL query that retrieves the `first_name`, `last_name`, and `email` columns from a table named `users`, where the `email` domain is ‚Äúexample.com‚Äù. Assume that `email` is a `VARCHAR` type.

Example Answer: SELECT first_name, last_name, email FROM users WHERE email LIKE '%@example.com'; Explanation: This query selects the `first_name`, `last_name`, and `email` columns from the `users` table and filters the rows to include only those with an email domain of ‚Äúexample.com‚Äù. The `LIKE` operator is used with a wildcard (`%`) to match any characters before ‚Äú@example.com‚Äù. SQL joins and relationships

---

#### Write a SQL query to retrieve the `order_id` and `order_date` from an `orders` table and the `product_name` from a `products` table for all orders. Assume that the `orders` table has a `product_id` foreign key that references the `product_id` in the `products` table.

Example Answer: SELECT o.order_id, o.order_date, p.product_name FROM orders o JOIN products p ON o.product_id = p.product_id; Explanation: This query retrieves data from both the `orders` and `products` tables using an `INNER JOIN`. The `JOIN` is performed on the `product_id` column, which is common between the two tables, allowing the query to combine rows from each table where there is a matching `product_id`. Basic data manipulation

---

#### Write a SQL query to update the `salary` column in the `employees` table, increasing it by 10% for all employees who work in the ‚ÄúSales‚Äù department. Assume the `department` column is of type `VARCHAR`.

Example Answer: UPDATE employees SET salary = salary * 1.10 WHERE department = 'Sales'; Explanation: This query updates the `salary` field in the `employees` table by multiplying the current salary by 1.10 (a 10% increase) for all employees in the ‚ÄúSales‚Äù department. The `WHERE` clause ensures that only rows where the `department` is ‚ÄúSales‚Äù are affected. Learning tip: Want to review SQL basics before your next interview? Journey into SQL with Taylor Swift is a fun and accessible learning path in CodeSignal Learn where you‚Äôll practice key querying skills using Taylor Swift‚Äôs discography as your database. Intermediate SQL interview questions (2 to 5 years of experience) Complex SQL queries and subqueries

---

#### Write a SQL query to find the top 3 customers with the highest total `order_amount` from the `orders` table. Assume that each order is linked to a customer via a `customer_id` column, and the `order_amount` is a numeric column.

Example Answer: SELECT customer_id, SUM(order_amount) AS total_spent FROM orders GROUP BY customer_id ORDER BY total_spent DESC LIMIT 3; Explanation: This query calculates the total `order_amount` spent by each customer using the `SUM()` function and groups the results by `customer_id`. The `ORDER BY` clause sorts the results in descending order of total spent, and the `LIMIT` clause restricts the output to the top 3 customers. This type of query is essential for analyzing customer behavior and identifying high-value customers. Subqueries and data integrity

---

#### Write a SQL query to find all employees in the `employees` table whose `salary` is greater than the average salary in their department. Assume that the table has `employee_id`, `department_id`, and `salary` columns.

Example Answer: SELECT employee_id, department_id, salary FROM employees e WHERE salary > ( SELECT AVG(salary) FROM employees WHERE department_id = e.department_id ); Explanation: This query uses a subquery to calculate the average salary within each department. The main query then selects employees whose salary exceeds the average salary of their respective department. The use of correlated subqueries (where the subquery references a column from the outer query) is a powerful technique for comparing data within grouped contexts. Indexes, performance, and transaction control

---

#### Suppose you need to delete a large number of records from the `transactions` table where the `transaction_date` is older than one year. Write a SQL script that includes steps to ensure the deletion is efficient and doesn‚Äôt affect the performance of the database during the operation. Assume an index exists on the `transaction_date` column.

Example Answer: BEGIN; SET TRANSACTION ISOLATION LEVEL READ COMMITTED; DELETE FROM transactions WHERE transaction_date < NOW() - INTERVAL '1 year'; COMMIT; Explanation: This script begins with a `BEGIN` statement to start a transaction. The `SET TRANSACTION ISOLATION LEVEL` command ensures that the operation uses the appropriate isolation level to prevent reading data that has been modified but not committed by other transactions (dirty reads), improving performance during the deletion. The `DELETE` operation then removes records older than one year, leveraging the existing index on `transaction_date` for faster execution. Finally, the `COMMIT` statement ensures that all changes are saved permanently, maintaining data integrity and consistency. Learning tip: Refresh your SQL scripting skills before your next interview or assessment with the Learning SQL Scripting with Leo Messi learning path in CodeSignal Learn. Practice joins, functions, conditional logic, and more using stats from soccer star Lionel Messi‚Äôs career as your database. Advanced SQL interview questions (5 years experience or more) SQL optimization techniques and handling large datasets

---

#### You have a table `large_sales` with millions of rows and a composite index on `(customer_id, sale_date) named `idx_customer_date`. Write an optimized SQL query to retrieve the total sales amount for each `customer_id` in the year 2023, considering the potential performance impact due to the dataset size.

Example Answer: SELECT customer_id, SUM(sale_amount) AS total_sales FROM large_sales WHERE sale_date BETWEEN '2023-01-01' AND '2023-12-31' GROUP BY customer_id USE INDEX (idx_customer_date); Explanation: This query retrieves the total sales amount for each `customer_id` for the year 2023 from a very large dataset. By specifying the `USE INDEX` hint, the query explicitly directs the database to utilize the composite index on `(customer_id, sale_date)` to optimize the filtering and grouping operations instead of an index on just `sale_date`. This is crucial for maintaining performance when dealing with large datasets, as it minimizes the amount of data scanned. Advanced data modeling and stored procedures

---

#### Design a stored procedure named `UpdateEmployeeDepartment` that transfers an employee to a new department while ensuring that the new department‚Äôs `budget` is not exceeded. Assume that `employees` and `departments` tables exist, with `employees` containing `employee_id`, `department_id`, and `salary`, and `departments` containing `department_id`, `budget`, and `current_expenditure`.

Example Answer: DELIMITER // CREATE PROCEDURE UpdateEmployeeDepartment(IN emp_id INT, IN new_dept_id INT) BEGIN DECLARE emp_salary DECIMAL(10,2); DECLARE current_expenditure DECIMAL(10,2); DECLARE dept_budget DECIMAL(10,2); SELECT salary INTO emp_salary FROM employees WHERE employee_id = emp_id; SELECT current_expenditure, budget INTO current_expenditure, dept_budget FROM departments WHERE department_id = new_dept_id; IF current_expenditure + emp_salary <= dept_budget THEN UPDATE employees SET department_id = new_dept_id WHERE employee_id = emp_id; UPDATE departments SET current_expenditure = current_expenditure + emp_salary WHERE department_id = new_dept_id; ELSE SIGNAL SQLSTATE '45000' SET MESSAGE_TEXT = 'Budget exceeded for the new department'; END IF; END // DELIMITER ; Explanation: This stored procedure first retrieves the salary of the employee being transferred and the budget and current expenditure of the target department. It then checks if adding the employee‚Äôs salary to the department‚Äôs current expenditure would exceed the department‚Äôs budget. If not, the employee is transferred, and the department‚Äôs expenditure is updated. If the budget would be exceeded, the procedure raises an error, ensuring budget constraints are respected. This approach demonstrates advanced data modeling by handling complex relationships between entities in the database. Database architecture considerations and triggers

---

#### Write a trigger named `CheckInventoryBeforeInsert` that prevents the insertion of a new order in the `orders` table if the total quantity of items ordered exceeds the available stock in the `inventory` table. Assume the `orders` table has `product_id` and `quantity` columns, and the `inventory` table has `product_id` and `stock_quantity` columns.

Example Answer: DELIMITER // CREATE TRIGGER CheckInventoryBeforeInsert BEFORE INSERT ON orders FOR EACH ROW BEGIN DECLARE available_stock INT; SELECT stock_quantity INTO available_stock FROM inventory WHERE product_id = NEW.product_id; IF NEW.quantity > available_stock THEN SIGNAL SQLSTATE '45000' SET MESSAGE_TEXT = 'Insufficient stock for the product'; END IF; END // DELIMITER ; Explanation: This trigger executes before a new order is inserted into the `orders` table. It checks if the quantity being ordered exceeds the available stock in the `inventory` table. If the order quantity is greater than the available stock, the trigger prevents the insert operation by raising an error. This ensures that the database maintains data integrity and consistency, crucial for systems where inventory management is critical. It also reflects an understanding of how triggers can enforce business rules at the database level, which is a key consideration in robust database architecture. Hard SQL server interview questions for senior developers (10+ years of experience) High-availability solutions and disaster recovery strategies

---

#### Can you describe a high-availability solution for an SQL Server environment, and how you would implement a disaster recovery plan to minimize downtime and data loss?

Example Answer: I would use Always On Availability Groups for high availability, setting up primary and secondary replicas across different servers, ideally in separate geographic locations. The primary replica handles transactions, while secondary replicas are kept in sync. For disaster recovery, I‚Äôd configure a secondary replica in a remote data center with automatic failover. This setup ensures minimal downtime and no data loss if the primary server fails. I‚Äôd also establish regular backups and test the failover process to ensure reliability. Performance tuning complex systems

---

#### Can you walk me through your approach to diagnosing and resolving performance issues in a complex SQL Server system with multiple large databases?

Example Answer: I start by analyzing wait statistics to find bottlenecks like CPU or I/O issues. Then, I examine query execution plans to spot inefficiencies, such as unnecessary table scans. For optimization, I may tune indexes, rewrite queries, or partition large tables. I also check system configurations, such as memory and I/O settings, and ensure regular maintenance tasks like index rebuilding are in place to keep performance stable. Security best practices in SQL server management

---

#### What are some of the security best practices you follow when setting up and managing SQL Server databases?

Example Answer: I follow the principle of least privilege, assigning minimal permissions needed for tasks. I integrate SQL Server with Active Directory for secure authentication and use encryption for sensitive data with tools like Transparent Data Encryption (TDE). I also ensure SQL Server is regularly patched and perform security audits to monitor for unauthorized access. Regular reviews of activity logs help me quickly detect and respond to any security issues. SQL performance tuning interview questions Query optimization and execution plans analysis

---

#### How do you approach optimizing a slow-running query in SQL Server, and what role do execution plans play in this process?

Example Answer: When optimizing a slow query, I start by analyzing its execution plan to identify bottlenecks like full table scans or expensive joins. The execution plan shows how SQL Server processes the query, helping me spot inefficiencies. Based on the plan, I might rewrite the query, add or modify indexes, or adjust the query structure to reduce processing time. I continually review the updated execution plan to ensure the changes improve performance. Index management and query optimization

---

#### Can you explain your process for managing indexes to ensure efficient query performance in SQL Server?

Example Answer: I regularly monitor index usage to identify underutilized or missing indexes. If a query is slow, I check the execution plan to see if an index could improve performance. I also evaluate existing indexes to ensure they are not redundant or overlapping, which could cause unnecessary overhead. Periodically, I perform index maintenance, such as rebuilding or reorganizing fragmented indexes, to keep the database performing optimally.

---

#### SELECT customer_number

FROM orders_586 GROUP BY customer_number ORDER BY COUNT(order_number) DESC LIMIT 1; --ANSWER OF EXTRA QUESTION: WITH cte AS ( SELECT COUNT(order_number) AS count FROM orders_586 GROUP BY customer_number ORDER BY count DESC LIMIT 1) SELECT customer_number FROM orders_586 GROUP BY customer_number HAVING COUNT(order_number) IN (SELECT count FROM cte);

---

#### WITH fixed_amount AS (

SELECT account_id,day, CASE WHEN type = 'Deposit' THEN amount ELSE amount*-1 END AS amount FROM transactions_2066 ) SELECT account_id,day, SUM(amount) OVER (PARTITION BY account_id ORDER BY day) AS balance FROM fixed_amount ORDER BY account_id,day;

---

#### WITH cte AS(

SELECT dept_id,COUNT(*) AS student_count FROM student_580 GROUP BY dept_id ) SELECT dept_name,COALESCE(student_count,0) AS student_count FROM department_580 d LEFT JOIN cte c ON c.dept_id = d.dept_id ORDER BY student_count DESC,dept_name ASC;

---

#### SELECT user_id,SUM(s.quantity*p.price) AS spending

FROM sales_2329 s INNER JOIN product_2329 p ON s.product_id = p.product_id GROUP BY user_id ORDER BY spending DESC,user_id;

---

#### SELECT COUNT(cnt) AS member_count

FROM ( SELECT COUNT(policy_holder_id) AS cnt FROM callers GROUP BY policy_holder_id HAVING COUNT(policy_holder_id) >= 3 ) AS TEMP

---

#### SELECT b.book_id, b.name

FROM books_1098 b LEFT JOIN ( SELECT book_id, SUM(quantity) nsold FROM orders_1098 WHERE dispatch_date BETWEEN '2018-06-23' AND '2019-06-23' GROUP BY book_id ) o ON b.book_id = o.book_id WHERE (o.nsold < 10 OR o.nsold IS NULL) AND '2019-06-23'::DATE-b.available_from > 30;

---

#### WITH RECURSIVE ac_rides AS (

SELECT ar.ride_id,r.requested_at FROM accepted_rides_1635 ar INNER JOIN rides_1635 r ON ar.ride_id = r.ride_id AND EXTRACT(YEAR FROM r.requested_at)<=2020 ), months AS ( SELECT 1 AS num UNION SELECT num+1 AS num FROM months WHERE num<=11 ), ride_details AS ( SELECT * FROM months m LEFT JOIN ac_rides ar ON EXTRACT(MONTH FROM ar.requested_at)=m.num ), aggr_details AS ( SELECT num,COUNT(DISTINCT ride_id) AS rides FROM ride_details GROUP BY num ), avail_drivers AS ( SELECT *, ROW_NUMBER() OVER (ORDER BY join_date) AS drivers FROM drivers_1635 ), drivers_2020 AS ( SELECT * FROM months m LEFT JOIN avail_drivers a ON EXTRACT(YEAR FROM a.join_date)=2020 AND m.num>=EXTRACT(MONTH FROM a.join_date) ), driver_count AS ( SELECT num,MAX(drivers) AS drivers FROM drivers_2020 GROUP BY num ) SELECT a.num AS month,a.rides,d.drivers FROM aggr_details a INNER JOIN driver_count d ON a.num=d.num;

---

#### -- Question 60

-- In social network like Facebook or Twitter, people send friend requests and accept others' requests as well. -- Table request_accepted -- +--------------+-------------+------------+ -- | requester_id | accepter_id | accept_date| -- |--------------|-------------|------------| -- | 1            | 2           | 2016_06-03 | -- | 1            | 3           | 2016-06-08 | -- | 2            | 3           | 2016-06-08 | -- | 3            | 4           | 2016-06-09 | -- +--------------+-------------+------------+ -- This table holds the data of friend acceptance, while requester_id and accepter_id both are the id of a person. -- Write a query to find the the people who has most friends and the most friends number under the following rules: -- It is guaranteed there is only 1 people having the most friends. -- The friend request could only been accepted once, which mean there is no multiple records with the same requester_id and accepter_id value. -- For the sample data above, the result is: -- Result table: -- +------+------+ -- | id   | num  | -- |------|------| -- | 3    | 3    | -- +------+------+ -- The person with id '3' is a friend of people '1', '2' and '4', so he has 3 friends in total, which is the most number than any others. -- Solution select requester_id as id, b.total as num from( select requester_id, sum(one) as total from(( select requester_id, count(distinct accepter_id) as one from request_accepted group by requester_id) union all (select accepter_id, count(distinct requester_id) as two from request_accepted group by accepter_id)) a group by requester_id order by total desc) b limit 1

---

#### SELECT DISTINCT s1.*

FROM stadium_601 s1 JOIN stadium_601 s2 JOIN stadium_601 s3 ON ((s1.id = s2.id-1 AND s1.id = s3.id-2) OR (s1.id = s2.id+1 AND s1.id = s3.id-1) OR (s1.id = s2.id+1 AND s1.id = s3.id+2)) WHERE s1.people >= 100 AND s2.people >= 100 AND s3.people>=100 ORDER BY visit_date; ------------------------------------------------------------------------------------------------------------------------------------ WITH ranked AS( SELECT *, ROW_NUMBER() OVER w AS rn, (id - ROW_NUMBER() OVER w) AS diff FROM stadium_601 WHERE people>=100 WINDOW w AS (ORDER BY visit_date) ), consecutive AS( SELECT diff,COUNT(diff) count FROM ranked GROUP BY diff ) SELECT id,visit_date,people FROM ranked r LEFT JOIN consecutive c ON r.diff = c.diff WHERE c.count >=3 ORDER BY visit_date; ------------------------------------------------------------------------------------------------------------------------------------ WITH ranked AS ( SELECT *, id-ROW_NUMBER() OVER (ORDER BY id) AS diff FROM stadium_601 WHERE people >= 100 ), consecutives AS ( SELECT *, COUNT(id) OVER (PARTITION BY diff) AS cnt FROM ranked ) SELECT id,visit_date,people FROM consecutives WHERE cnt >= 3 ORDER BY visit_date;

---

#### SELECT *

FROM users_1517 WHERE mail SIMILAR TO '[a-zA-Z][a-zA-Z0-9_.-]*@leetcode[.]com';

---

#### SELECT p.project_id,ROUND(AVG(e.experience_years),2)

FROM project_1075 p JOIN employee_1075 e ON p.employee_id=e.employee_id GROUP BY p.project_id ORDER BY 1;

---

#### SELECT ad_id,

COALESCE(ROUND(AVG( CASE WHEN action = 'Clicked' THEN 1 WHEN action = 'Viewed' THEN 0 ELSE NULL END)*100,2),0.00) AS ctr FROM ads_1322 GROUP BY ad_id ORDER BY ctr DESC;

---

#### -- Question 84

-- Table: Friendship -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | user1_id      | int     | -- | user2_id      | int     | -- +---------------+---------+ -- (user1_id, user2_id) is the primary key for this table. -- Each row of this table indicates that there is a friendship relation between user1_id and user2_id. -- Table: Likes -- +-------------+---------+ -- | Column Name | Type    | -- +-------------+---------+ -- | user_id     | int     | -- | page_id     | int     | -- +-------------+---------+ -- (user_id, page_id) is the primary key for this table. -- Each row of this table indicates that user_id likes page_id. -- Write an SQL query to recommend pages to the user with user_id = 1 using the pages that your friends liked. It should not recommend pages you already liked. -- Return result table in any order without duplicates. -- The query result format is in the following example: -- Friendship table: -- +----------+----------+ -- | user1_id | user2_id | -- +----------+----------+ -- | 1        | 2        | -- | 1        | 3        | -- | 1        | 4        | -- | 2        | 3        | -- | 2        | 4        | -- | 2        | 5        | -- | 6        | 1        | -- +----------+----------+ -- Likes table: -- +---------+---------+ -- | user_id | page_id | -- +---------+---------+ -- | 1       | 88      | -- | 2       | 23      | -- | 3       | 24      | -- | 4       | 56      | -- | 5       | 11      | -- | 6       | 33      | -- | 2       | 77      | -- | 3       | 77      | -- | 6       | 88      | -- +---------+---------+ -- Result table: -- +------------------+ -- | recommended_page | -- +------------------+ -- | 23               | -- | 24               | -- | 56               | -- | 33               | -- | 77               | -- +------------------+ -- User one is friend with users 2, 3, 4 and 6. -- Suggested pages are 23 from user 2, 24 from user 3, 56 from user 3 and 33 from user 6. -- Page 77 is suggested from both user 2 and user 3. -- Page 88 is not suggested because user 1 already likes it. -- Solution select distinct page_id as recommended_page from likes where user_id = any(select user2_id as id from friendship where user1_id = 1 or user2_id = 1 and user2_id !=1 union all select user1_id from friendship where user2_id = 1) and page_id != all(select page_id from likes where user_id = 1)

---

#### WITH GP AS

( SELECT age_bucket, SUM(CASE WHEN activity_type = 'open' THEN time_spent END) open, SUM(CASE WHEN activity_type = 'send' THEN time_spent END) send FROM activities, age_breakdown WHERE age_breakdown.user_id = activities.user_id GROUP BY age_bucket ) SELECT GP.age_bucket, ROUND( send / (SUM(open) + SUM(send)) * 100.0, 2) AS send_perc, ROUND( open / (SUM(open) + SUM(send)) * 100.0, 2) AS open_perc FROM GP GROUP BY GP.age_bucket, open, send ORDER BY age_bucket;

---

#### WITH player_scores AS(

(SELECT first_player AS player,first_score AS score FROM matches_1194) UNION ALL (SELECT second_player AS player,second_score AS score FROM matches_1194) ), all_player_scores AS( SELECT player,SUM(score) AS score FROM player_scores GROUP BY player ORDER BY player ), ranked AS ( SELECT p.*,ps.score AS score, DENSE_RANK() OVER(PARTITION BY group_id ORDER BY score DESC,player_id ASC) AS rnk FROM players_1194 p INNER JOIN all_player_scores ps ON p.player_id = ps.player ) SELECT group_id,player_id FROM ranked WHERE rnk=1 ORDER BY group_id;

---

#### -- Question 49

-- In social network like Facebook or Twitter, people send friend requests and accept others‚Äô requests as well. Now given two tables as below: -- Table: friend_request -- | sender_id | send_to_id |request_date| -- |-----------|------------|------------| -- | 1         | 2          | 2016_06-01 | -- | 1         | 3          | 2016_06-01 | -- | 1         | 4          | 2016_06-01 | -- | 2         | 3          | 2016_06-02 | -- | 3         | 4          | 2016-06-09 | -- Table: request_accepted -- | requester_id | accepter_id |accept_date | -- |--------------|-------------|------------| -- | 1            | 2           | 2016_06-03 | -- | 1            | 3           | 2016-06-08 | -- | 2            | 3           | 2016-06-08 | -- | 3            | 4           | 2016-06-09 | -- | 3            | 4           | 2016-06-10 | -- Write a query to find the overall acceptance rate of requests rounded to 2 decimals, which is the number of acceptance divide the number of requests. -- For the sample data above, your query should return the following result. -- |accept_rate| -- |-----------| -- |       0.80| -- Note: -- The accepted requests are not necessarily from the table friend_request. In this case, you just need to simply count the total accepted requests (no matter whether they are in the original requests), and divide it by the number of requests to get the acceptance rate. -- It is possible that a sender sends multiple requests to the same receiver, and a request could be accepted more than once. In this case, the ‚Äòduplicated‚Äô requests or acceptances are only counted once. -- If there is no requests at all, you should return 0.00 as the accept_rate. -- Explanation: There are 4 unique accepted requests, and there are 5 requests in total. -- So the rate is 0.80. -- Solution with t1 as ( select distinct sender_id, send_to_id from friend_request ), t2 as ( select distinct requester_id, accepter_id from request_accepted ) Select ifnull(( select distinct round((select count(*) from t2) / ( select count(*) from t1),2) from t1,t2 ),0) 'accept_rate'

---

#### -- Question 109

-- Table: Players -- +-------------+-------+ -- | Column Name | Type  | -- +-------------+-------+ -- | player_id   | int   | -- | group_id    | int   | -- +-------------+-------+ -- player_id is the primary key of this table. -- Each row of this table indicates the group of each player. -- Table: Matches -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | match_id      | int     | -- | first_player  | int     | -- | second_player | int     | -- | first_score   | int     | -- | second_score  | int     | -- +---------------+---------+ -- match_id is the primary key of this table. -- Each row is a record of a match, first_player and second_player contain the player_id of each match. -- first_score and second_score contain the number of points of the first_player and second_player respectively. -- You may assume that, in each match, players belongs to the same group. -- The winner in each group is the player who scored the maximum total points within the group. In the case of a tie, -- the lowest player_id wins. -- Write an SQL query to find the winner in each group. -- The query result format is in the following example: -- Players table: -- +-----------+------------+ -- | player_id | group_id   | -- +-----------+------------+ -- | 15        | 1          | -- | 25        | 1          | -- | 30        | 1          | -- | 45        | 1          | -- | 10        | 2          | -- | 35        | 2          | -- | 50        | 2          | -- | 20        | 3          | -- | 40        | 3          | -- +-----------+------------+ -- Matches table: -- +------------+--------------+---------------+-------------+--------------+ -- | match_id   | first_player | second_player | first_score | second_score | -- +------------+--------------+---------------+-------------+--------------+ -- | 1          | 15           | 45            | 3           | 0            | -- | 2          | 30           | 25            | 1           | 2            | -- | 3          | 30           | 15            | 2           | 0            | -- | 4          | 40           | 20            | 5           | 2            | -- | 5          | 35           | 50            | 1           | 1            | -- +------------+--------------+---------------+-------------+--------------+ -- Result table: -- +-----------+------------+ -- | group_id  | player_id  | -- +-----------+------------+ -- | 1         | 15         | -- | 2         | 35         | -- | 3         | 40         | -- +-----------+------------+ -- Solution with t1 as( select first_player, sum(first_score) as total from (select first_player, first_score from matches union all select second_player, second_score from matches) a group by 1), t2 as( select *, coalesce(total,0) as score from players p left join t1 on p.player_id = t1.first_player) select group_id, player_id from (select *, row_number() over(partition by group_id order by group_id, score desc) as rn from t2) b where b.rn = 1

---

#### SELECT *

FROM cinema_620 WHERE id%2 = 1 AND description <> 'boring' ORDER BY rating DESC;

---

#### -- Question 92

-- Table: Traffic -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | user_id       | int     | -- | activity      | enum    | -- | activity_date | date    | -- +---------------+---------+ -- There is no primary key for this table, it may have duplicate rows. -- The activity column is an ENUM type of ('login', 'logout', 'jobs', 'groups', 'homepage'). -- Write an SQL query that reports for every date within at most 90 days from today, -- the number of users that logged in for the first time on that date. Assume today is 2019-06-30. -- The query result format is in the following example: -- Traffic table: -- +---------+----------+---------------+ -- | user_id | activity | activity_date | -- +---------+----------+---------------+ -- | 1       | login    | 2019-05-01    | -- | 1       | homepage | 2019-05-01    | -- | 1       | logout   | 2019-05-01    | -- | 2       | login    | 2019-06-21    | -- | 2       | logout   | 2019-06-21    | -- | 3       | login    | 2019-01-01    | -- | 3       | jobs     | 2019-01-01    | -- | 3       | logout   | 2019-01-01    | -- | 4       | login    | 2019-06-21    | -- | 4       | groups   | 2019-06-21    | -- | 4       | logout   | 2019-06-21    | -- | 5       | login    | 2019-03-01    | -- | 5       | logout   | 2019-03-01    | -- | 5       | login    | 2019-06-21    | -- | 5       | logout   | 2019-06-21    | -- +---------+----------+---------------+ -- Result table: -- +------------+-------------+ -- | login_date | user_count  | -- +------------+-------------+ -- | 2019-05-01 | 1           | -- | 2019-06-21 | 2           | -- +------------+-------------+ -- Note that we only care about dates with non zero user count. -- The user with id 5 first logged in on 2019-03-01 so he's not counted on 2019-06-21. -- Solution with t1 as ( select user_id, min(activity_date) as login_date from Traffic where activity = 'login' group by user_id ) select login_date, count(distinct user_id) as user_count from t1 where login_date between '2019-04-01' and '2019-06-30' group by login_date

---

#### SELECT name,population,area

FROM world_595 WHERE area > 3000000 OR population > 25000000;

---

#### WITH ranked AS (

SELECT *, DENSE_RANK() OVER (PARTITION BY customer_id ORDER BY order_date DESC) AS rn FROM orders_1532 ) SELECT c.name AS customer_name,r.customer_id,r.order_id,r.order_date FROM ranked r INNER JOIN customers_1532 c ON r.customer_id=c.customer_id WHERE rn<=3 ORDER BY c.name,c.customer_id,r.order_date DESC; ---------------Without Window function--------------- SELECT o1.customer_id,o1.order_date,COUNT(o2.order_date) FROM orders_1532 o1 INNER JOIN orders_1532 o2 ON o1.customer_id=o2.customer_id AND o1.order_date<=o2.order_date GROUP BY o1.customer_id,o1.order_date HAVING COUNT(o2.order_date)<=3 ORDER BY 1,2 DESC; -- Main logic is over now we only need to apply 2 joins to bring other columns.

---

#### -- Question 26

-- Table: Project -- +-------------+---------+ -- | Column Name | Type    | -- +-------------+---------+ -- | project_id  | int     | -- | employee_id | int     | -- +-------------+---------+ -- (project_id, employee_id) is the primary key of this table. -- employee_id is a foreign key to Employee table. -- Table: Employee -- +------------------+---------+ -- | Column Name      | Type    | -- +------------------+---------+ -- | employee_id      | int     | -- | name             | varchar | -- | experience_years | int     | -- +------------------+---------+ -- employee_id is the primary key of this table. -- Write an SQL query that reports the average experience years of all the employees for each project, rounded to 2 digits. -- The query result format is in the following example: -- Project table: -- +-------------+-------------+ -- | project_id  | employee_id | -- +-------------+-------------+ -- | 1           | 1           | -- | 1           | 2           | -- | 1           | 3           | -- | 2           | 1           | -- | 2           | 4           | -- +-------------+-------------+ -- Employee table: -- +-------------+--------+------------------+ -- | employee_id | name   | experience_years | -- +-------------+--------+------------------+ -- | 1           | Khaled | 3                | -- | 2           | Ali    | 2                | -- | 3           | John   | 1                | -- | 4           | Doe    | 2                | -- +-------------+--------+------------------+ -- Result table: -- +-------------+---------------+ -- | project_id  | average_years | -- +-------------+---------------+ -- | 1           | 2.00          | -- | 2           | 2.50          | -- +-------------+---------------+ -- The average experience years for the first project is (3 + 2 + 1) / 3 = 2.00 and for the second project is (3 + 2) / 2 = 2.50 -- Solution Select a.project_id, round(sum(b.experience_years)/count(b.employee_id),2) as average_years from project as a join employee as b on a.employee_id=b.employee_id group by a.project_id

---

#### -- Question 105

-- The Employee table holds all employees. The employee table has three columns: Employee Id, Company Name, and Salary. -- +-----+------------+--------+ -- |Id   | Company    | Salary | -- +-----+------------+--------+ -- |1    | A          | 2341   | -- |2    | A          | 341    | -- |3    | A          | 15     | -- |4    | A          | 15314  | -- |5    | A          | 451    | -- |6    | A          | 513    | -- |7    | B          | 15     | -- |8    | B          | 13     | -- |9    | B          | 1154   | -- |10   | B          | 1345   | -- |11   | B          | 1221   | -- |12   | B          | 234    | -- |13   | C          | 2345   | -- |14   | C          | 2645   | -- |15   | C          | 2645   | -- |16   | C          | 2652   | -- |17   | C          | 65     | -- +-----+------------+--------+ -- Write a SQL query to find the median salary of each company. Bonus points if you can solve it without using any built-in SQL functions. -- +-----+------------+--------+ -- |Id   | Company    | Salary | -- +-----+------------+--------+ -- |5    | A          | 451    | -- |6    | A          | 513    | -- |12   | B          | 234    | -- |9    | B          | 1154   | -- |14   | C          | 2645   | -- +-----+------------+--------+ -- Solution select id, company, salary from (select *, row_number() over(partition by company order by salary) as rn, count(*) over(partition by company) as cnt from employee) a where rn between cnt/2 and cnt/2+1

---

#### 8 Upstart SQL Interview Questions (Updated 2025)

By Nick Singh (Ex-Facebook & Best-Selling Data Science Author) Updated on January 10, 2025 At Upstart, SQL is often used for analyzing loan databases for risk assessment, and for customer analytics. That's the reason behind why Upstart almost always asks SQL query questions during interviews for Data Analytics, Data Science, and Data Engineering jobs. As such, to help you prepare for the Upstart SQL interview, this blog covers 8 Upstart SQL interview questions ‚Äì able to solve them? 8 Upstart SQL Interview Questions SQL Question 1: Calculate Monthly Average Loan Amount Upstart, being an online lending platform, wants to understand how their average loan amount changes over time. This could help them identify any trends or seasonality in their loans business to make better business decisions. They specifically want to understand the monthly average loan amount for each unique loan purpose over the last year. You're provided with a loans table with the following schema: loans Example Input: loan_id	loan_purpose	loan_amount	loan_date 2345	Car	18000	2019-03-23 3782	Investment	15000	2019-03-23 8542	Education	25000	2019-04-14 9529	Investment	20000	2019-04-14 1654	Car	12000	2019-04-14 Write a SQL query to get the monthly average loan amount for each unique loan purpose over the last year. The output should include the year, the month, the loan purpose, and the relevant monthly average loan amount. The output of the SQL query should look like this: Example Output: yr	mth	purpose	avg_loan_amount 2019	03	Car	18000.00 2019	03	Investment	15000.00 2019	04	Car	12000.00 2019	04	Investment	20000.00 2019	04	Education	25000.00 Answer: SELECT EXTRACT(YEAR FROM loan_date) AS yr, EXTRACT(MONTH FROM loan_date) AS mth, loan_purpose AS purpose, AVG(loan_amount) AS avg_loan_amount FROM loans WHERE loan_date >= NOW() - INTERVAL '1 year' GROUP BY yr, mth, purpose ORDER BY yr, mth, purpose; This SQL query uses the EXTRACT function to break down the loan_date into yr and mth. The AVG is then used as our window function to compute the average loan_amount for each combination of yr, mth, and purpose. The WHERE clause limits our data to the last year. Grouping and ordering is done by yr, mth, and purpose to break down the average loan amounts as per the requirements. For more window function practice, try this Uber SQL problem on DataLemur's online SQL code editor: Uber Data Science SQL Interview Question SQL Question 2: Loan Distribution Analysis Upstart is a leading AI lending platform that partners with banks to improve access to affordable credit. A part of their business is to understand how their loans are distributed among different customers in terms of loan size, occupation. They have two tables borrowers and loans. borrowers table: This table contains information about each borrower who took a loan with upstart. borrower_id	age	occupation 101	25	Engineer 102	32	Teacher 103	28	Doctor 104	35	Engineer 105	30	Teacher loans table: This table contains information about the loans taken by the borrowers. loan_id	borrower_id	loan_size 201	101	10000 202	102	15000 203	103	8000 204	104	20000 205	105	5000 The business problem: Upstart wants to know the average loan size by occupation of borrowers and their age. They want to check if occupation and age are factors that determine the size of the loan a customer takes. Answer: We can solve this problem by joining the two tables on 'borrower_id' and then grouping by 'occupation' and 'age' to calculate the average loan size. SELECT b.occupation, b.age, AVG(l.loan_size) AS avg_loan_size FROM borrowers AS b JOIN loans AS l ON b.borrower_id = l.borrower_id GROUP BY b.occupation, b.age This query will return a table with each row representing a unique combination of occupation and age, and a column representing the average loan size for that combination. This will allow Upstart to analyze whether certain occupations or age groups tend to take out larger loans. SQL Question 3: What sets a cross join apart from a natural join? Imagine you are organizing a party and have two database tables: one table of people you want to invite and another list of food items you want to serve. A cross join would be like inviting every person on your list to the party and serving them every food item on the menu, regardless of whether they like the food or not. So, if you had 10 people on your invite list and 5 food items on the menu, you would generate all 50 different combinations of people and food (10 x 5 = 50). On the other hand, a natural join would be like inviting only the people who like the food items on the menu (based on doing a inner/left/right/outer JOIN on a common key like food_id). Upstart SQL Interview Questions SQL Question 4: Calculating Product View to Cart Conversion Rate Upstart wants to understand the click-through-rate from viewing a product to adding a product to the cart. They have two tables: product_views table, which records every time a user views a product. cart_adds table, which records every time a user adds a product to their cart. Calculate the conversion rate from viewing a product to adding a product to cart, for each product. product_views Example Input: view_id	user_id	product_id	time_stamp 8171	123	10001	06/08/2022 00:00:00 5802	265	20002	06/10/2022 00:00:00 8293	362	10001	06/18/2022 00:00:00 9352	192	30003	07/26/2022 00:00:00 9517	981	20002	07/05/2022 00:00:00 cart_adds Example Input: add_id	user_id	product_id	time_stamp 4171	123	10001	06/08/2022 00:01:00 2802	265	20002	06/10/2022 00:01:00 6293	362	10001	06/18/2022 00:01:00 8352	981	20002	07/05/2022 00:01:00 Answer: SELECT pv.product_id, COUNT(DISTINCT pv.user_id) as view_count, COUNT(DISTINCT ca.user_id) as add_to_cart_count, COUNT(DISTINCT ca.user_id)::float / GREATEST(COUNT(DISTINCT pv.user_id)::float, 1) as conversion_rate FROM product_views pv LEFT JOIN cart_adds ca ON pv.user_id = ca.user_id AND pv.product_id = ca.product_id GROUP BY pv.product_id; This query counts the distinct users who viewed and added each product to their cart. We make a LEFT JOIN from product_views to cart_adds on user_id and product_id to see which product views led to adds. The conversion rate is then calculated by dividing add_to_cart_count by view_count. We use GREATEST function to avoid division by zero. To solve a similar SQL problem on DataLemur's free interactive SQL code editor, try this SQL interview question asked by Facebook:SQL interview question asked by Facebook SQL Question 5: In database normalization, what's the distinction between 1NF, 2NF, and 3NF? Normal forms are guidelines that are used to help design a relational database in a way that minimizes redundancy and ensures the integrity of the data. The 3 most commonly use normal forms are the 1st, 2nd, and 3rd normal forms. Here's a brief explanation of each: 1st Normal Form (1NF) is all about keeping it simple - each column should only have one value and there should be no repeating groups of data. 2nd Normal Form (2NF) is about organization - your database should already be in 1NF and all the non-key columns should depend on the primary key. This means that each non-key column should be completely dependent on the entire primary key, not just part of it. 3rd Normal Form (3NF) is about independence - if your database is already in 2NF, then all the non-key columns should not depend on each other. They should be self-sufficient and not rely on other non-key columns. SQL Question 6: Calculate Average Loan Amount by State Upstart provides personal loans to customers. The loans table contains information about each loan issued by Upstart, including the loan ID, the customer ID, the loan amount, and the date the loan was issued. The customers table contains data about each customer, including their state of residence. Given the loans and customers tables, write a SQL query to calculate the average loan amount by state for the past year. Here are the sample tables: loans Example Input: loan_id	customer_id	loan_amount	loan_date 6171	123	7000	09/05/2021 7802	265	5000	11/20/2021 5293	362	9000	12/10/2021 6352	192	8000	04/25/2021 4517	981	6000	07/15/2021 customers Example Input: customer_id	state 123	NY 265	CA 362	TX 192	NY 981	CA Answer: SELECT c.state, AVG(l.loan_amount) as average_loan_amount FROM loans l JOIN customers c ON c.customer_id = l.customer_id WHERE l.loan_date >= '2021-01-01' AND l.loan_date <= '2021-12-31' GROUP BY c.state; This query joins the loans and customers tables on customer_id, and then selects the state and average_loan_amount after grouping the data by state. The WHERE clause filters the data to include only loans issued in the past year. Because join questions come up routinely during SQL interviews, take a stab at this Spotify JOIN SQL question:Spotify JOIN SQL question SQL Question 7: What is denormalization, and in what situations might it be a useful? Denormalization is the practice of altering a database schema in a way that breaks the normalization rules (1st, 2nd, 3rd normal forms). For example, in a database that stores Upstart sales analytics data, you might have separate tables for "customers," "orders," and "products," with foreign key constraints linking the tables together. This helps to ensure the integrity of the data and reduces redundancy, but it can also make queries that involve multiple tables more complex and slower to execute. By de-normalizing the database, you can combine some of the data from separate tables into a single table, which can reduce the number of joins that are required to retrieve the data you need. This can speed up queries and improve the performance of your database. However, it's important to carefully consider the trade-offs of de-normalization before making any changes to your database. De-normalization can make it more difficult to maintain the integrity and reliability of your data, and can also increase the risk of data redundancy. It's generally best to use de-normalization as a performance optimization technique only when necessary, and to carefully evaluate the benefits and drawbacks in the context of your specific database and workload. SQL Question 8: Average Loan Amount by Month As an analyst at Upstart, a company providing personal loans online, you have been tasked to monitor the average loan amount provided per month. Given a table 'loans', create a SQL query to find the average loan amount for each month. loans Example Input: loan_id	user_id	loan_date	loan_amount 6789	345	01/22/2022 00:00:00	15000 7980	256	03/10/2022 00:00:00	22000 3284	563	03/25/2022 00:00:00	18000 5382	785	07/19/2022 00:00:00	30000 1478	143	10/09/2022 00:00:00	24000 Example Output: month	average_loan_amount 1	15000.00 3	20000.00 7	30000.00 10	24000.00 Answer: SELECT EXTRACT(MONTH FROM loan_date) AS month, AVG(loan_amount) AS average_loan_amount FROM loans GROUP BY EXTRACT(MONTH FROM loan_date) ORDER BY month In this query, we use the PostgreSQL specific EXTRACT function to get the month from loan_date. The AVG() function is used to calculate average loan amount for each month. We then GROUP BY month to find average loan amount for each distinct month. Finally, we ORDER BY month to provide a chronologically ordered output.

---

#### WITH cte AS (

SELECT id,company,salary, ABS(ROW_NUMBER() OVER (PARTITION BY company ORDER BY salary,id) - ROW_NUMBER() OVER (PARTITION BY company ORDER BY salary DESC,id DESC)) AS diff FROM employee_569 ) SELECT id,company,salary FROM cte WHERE diff = 0 OR diff = 1;

---

#### WITH cte AS(

SELECT d.name AS Department,e.name AS Employee,e.salary AS Salary, DENSE_RANK() OVER w rnk FROM employee_185 e JOIN department_185 d ON e.department_id = d.id WINDOW w AS (PARTITION BY d.name ORDER BY e.salary DESC) ) SELECT Department,Employee,Salary,rnk FROM cte WHERE rnk BETWEEN 1 AND 3;

---

#### WITH cte AS(

SELECT host_team,guest_team,host_goals,guest_goals FROM matches_1212 UNION ALL SELECT guest_team AS host_team,host_team AS guest_team,host_goals,guest_goals FROM matches_1212 WHERE host_goals=guest_goals ), cte2 AS ( SELECT CASE WHEN host_goals > guest_goals THEN host_team WHEN host_goals < guest_goals THEN guest_team ELSE host_team END AS winner, CASE WHEN host_goals > guest_goals THEN 3 WHEN host_goals < guest_goals THEN 3 ELSE 1 END AS points FROM cte ) SELECT t.team_id,t.team_name,COALESCE(SUM(c.points),0) AS points FROM cte2 c RIGHT JOIN teams_1212 t ON t.team_id = c.winner GROUP BY t.team_id,t.team_name ORDER BY points DESC;

---

#### WITH RECURSIVE exploded_sales AS (

SELECT product_id,period_start,period_end,average_daily_sales FROM sales_1384 UNION SELECT product_id,period_start+1 AS period_start,period_end,average_daily_sales FROM exploded_sales WHERE period_start < period_end ) SELECT es.product_id,p.product_name,EXTRACT(YEAR FROM period_start) AS report_year,SUM(average_daily_sales) FROM exploded_sales es INNER JOIN product_1384 p ON es.product_id=p.product_id GROUP BY es.product_id,p.product_name,EXTRACT(YEAR FROM period_start) ORDER BY es.product_id,report_year;

---

#### --Question 94

-- Table Accounts: -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | id            | int     | -- | name          | varchar | -- +---------------+---------+ -- the id is the primary key for this table. -- This table contains the account id and the user name of each account. -- Table Logins: -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | id            | int     | -- | login_date    | date    | -- +---------------+---------+ -- There is no primary key for this table, it may contain duplicates. -- This table contains the account id of the user who logged in and the login date. A user may log in multiple times in the day. -- Write an SQL query to find the id and the name of active users. -- Active users are those who logged in to their accounts for 5 or more consecutive days. -- Return the result table ordered by the id. -- The query result format is in the following example: -- Accounts table: -- +----+----------+ -- | id | name     | -- +----+----------+ -- | 1  | Winston  | -- | 7  | Jonathan | -- +----+----------+ -- Logins table: -- +----+------------+ -- | id | login_date | -- +----+------------+ -- | 7  | 2020-05-30 | -- | 1  | 2020-05-30 | -- | 7  | 2020-05-31 | -- | 7  | 2020-06-01 | -- | 7  | 2020-06-02 | -- | 7  | 2020-06-02 | -- | 7  | 2020-06-03 | -- | 1  | 2020-06-07 | -- | 7  | 2020-06-10 | -- +----+------------+ -- Result table: -- +----+----------+ -- | id | name     | -- +----+----------+ -- | 7  | Jonathan | -- +----+----------+ -- User Winston with id = 1 logged in 2 times only in 2 different days, so, Winston is not an active user. -- User Jonathan with id = 7 logged in 7 times in 6 different days, five of them were consecutive days, so, Jonathan is an active user. -- Solution with t1 as ( select id,login_date, lead(login_date,4) over(partition by id order by login_date) date_5 from (select distinct * from Logins) b ) select distinct a.id, a.name from t1 inner join accounts a on t1.id = a.id where datediff(t1.date_5,login_date) = 4 order by id

---

#### -- Question 28

-- Table: Project -- +-------------+---------+ -- | Column Name | Type    | -- +-------------+---------+ -- | project_id  | int     | -- | employee_id | int     | -- +-------------+---------+ -- (project_id, employee_id) is the primary key of this table. -- employee_id is a foreign key to Employee table. -- Table: Employee -- +------------------+---------+ -- | Column Name      | Type    | -- +------------------+---------+ -- | employee_id      | int     | -- | name             | varchar | -- | experience_years | int     | -- +------------------+---------+ -- employee_id is the primary key of this table. -- Write an SQL query that reports all the projects that have the most employees. -- The query result format is in the following example: -- Project table: -- +-------------+-------------+ -- | project_id  | employee_id | -- +-------------+-------------+ -- | 1           | 1           | -- | 1           | 2           | -- | 1           | 3           | -- | 2           | 1           | -- | 2           | 4           | -- +-------------+-------------+ -- Employee table: -- +-------------+--------+------------------+ -- | employee_id | name   | experience_years | -- +-------------+--------+------------------+ -- | 1           | Khaled | 3                | -- | 2           | Ali    | 2                | -- | 3           | John   | 1                | -- | 4           | Doe    | 2                | -- +-------------+--------+------------------+ -- Result table: -- +-------------+ -- | project_id  | -- +-------------+ -- | 1           | -- +-------------+ -- The first project has 3 employees while the second one has 2. -- Solution select a.project_id from( select project_id, rank() over(order by count(employee_id) desc) as rk from project group by project_id) a where a.rk = 1

---

#### WITH sales AS (

SELECT c.salesperson_id,SUM(s.price) AS total FROM customer_2372 c INNER JOIN sales_2372 s ON c.customer_id = s.customer_id GROUP BY c.salesperson_id ) SELECT sp.salesperson_id,sp.name,COALESCE(s.total,0) AS total FROM salesperson_2372 sp LEFT JOIN sales s ON sp.salesperson_id = s.salesperson_id;

---

#### -- Question 112

-- Table: Orders -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | order_id      | int     | -- | customer_id   | int     | -- | order_date    | date    | -- | item_id       | varchar | -- | quantity      | int     | -- +---------------+---------+ -- (ordered_id, item_id) is the primary key for this table. -- This table contains information of the orders placed. -- order_date is the date when item_id was ordered by the customer with id customer_id. -- Table: Items -- +---------------------+---------+ -- | Column Name         | Type    | -- +---------------------+---------+ -- | item_id             | varchar | -- | item_name           | varchar | -- | item_category       | varchar | -- +---------------------+---------+ -- item_id is the primary key for this table. -- item_name is the name of the item. -- item_category is the category of the item. -- You are the business owner and would like to obtain a sales report for category items and day of the week. -- Write an SQL query to report how many units in each category have been ordered on each day of the week. -- Return the result table ordered by category. -- The query result format is in the following example: -- Orders table: -- +------------+--------------+-------------+--------------+-------------+ -- | order_id   | customer_id  | order_date  | item_id      | quantity    | -- +------------+--------------+-------------+--------------+-------------+ -- | 1          | 1            | 2020-06-01  | 1            | 10          | -- | 2          | 1            | 2020-06-08  | 2            | 10          | -- | 3          | 2            | 2020-06-02  | 1            | 5           | -- | 4          | 3            | 2020-06-03  | 3            | 5           | -- | 5          | 4            | 2020-06-04  | 4            | 1           | -- | 6          | 4            | 2020-06-05  | 5            | 5           | -- | 7          | 5            | 2020-06-05  | 1            | 10          | -- | 8          | 5            | 2020-06-14  | 4            | 5           | -- | 9          | 5            | 2020-06-21  | 3            | 5           | -- +------------+--------------+-------------+--------------+-------------+ -- Items table: -- +------------+----------------+---------------+ -- | item_id    | item_name      | item_category | -- +------------+----------------+---------------+ -- | 1          | LC Alg. Book   | Book          | -- | 2          | LC DB. Book    | Book          | -- | 3          | LC SmarthPhone | Phone         | -- | 4          | LC Phone 2020  | Phone         | -- | 5          | LC SmartGlass  | Glasses       | -- | 6          | LC T-Shirt XL  | T-Shirt       | -- +------------+----------------+---------------+ -- Result table: -- +------------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+ -- | Category   | Monday    | Tuesday   | Wednesday | Thursday  | Friday    | Saturday  | Sunday    | -- +------------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+ -- | Book       | 20        | 5         | 0         | 0         | 10        | 0         | 0         | -- | Glasses    | 0         | 0         | 0         | 0         | 5         | 0         | 0         | -- | Phone      | 0         | 0         | 5         | 1         | 0         | 0         | 10        | -- | T-Shirt    | 0         | 0         | 0         | 0         | 0         | 0         | 0         | -- +------------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+ -- On Monday (2020-06-01, 2020-06-08) were sold a total of 20 units (10 + 10) in the category Book (ids: 1, 2). -- On Tuesday (2020-06-02) were sold a total of 5 units  in the category Book (ids: 1, 2). -- On Wednesday (2020-06-03) were sold a total of 5 units in the category Phone (ids: 3, 4). -- On Thursday (2020-06-04) were sold a total of 1 unit in the category Phone (ids: 3, 4). -- On Friday (2020-06-05) were sold 10 units in the category Book (ids: 1, 2) and 5 units in Glasses (ids: 5). -- On Saturday there are no items sold. -- On Sunday (2020-06-14, 2020-06-21) were sold a total of 10 units (5 +5) in the category Phone (ids: 3, 4). -- There are no sales of T-Shirt. -- Solution with t1 as( select distinct item_category, case when dayname(order_date)='Monday' then sum(quantity) over(partition by item_category,dayname(order_date)) else 0 end as Monday, Case when dayname(order_date)='Tuesday' then sum(quantity) over(partition by item_category,dayname(order_date)) else 0 end as Tuesday, Case when dayname(order_date)='Wednesday' then sum(quantity) over(partition by item_category,dayname(order_date)) else 0 end as Wednesday, Case when dayname(order_date)='Thursday' then sum(quantity) over(partition by item_category,dayname(order_date)) else 0 end as Thursday, Case when dayname(order_date)='Friday' then sum(quantity) over(partition by item_category,dayname(order_date)) else 0 end as Friday, Case when dayname(order_date)='Saturday' then sum(quantity) over(partition by item_category,dayname(order_date)) else 0 end as Saturday, Case when dayname(order_date)='Sunday' then sum(quantity) over(partition by item_category,dayname(order_date)) else 0 end as Sunday from orders o right join items i using (item_id)) select item_category as category, sum(Monday) as Monday, sum(Tuesday) as Tuesday, sum(Wednesday) Wednesday, sum(Thursday) Thursday, sum(Friday) Friday, sum(Saturday) Saturday, sum(Sunday) Sunday from t1 group by item_category

---

#### SELECT v.customer_id,COUNT(v.visit_id)

FROM visits_1581 v LEFT JOIN transactions_1581 t ON v.visit_id = t.visit_id WHERE t.transaction_id IS NULL GROUP BY v.customer_id ORDER BY v.customer_id;

---

#### WITH spammed AS(

SELECT * FROM actions_1132 WHERE extra = 'spam' ), percentage AS( SELECT (COUNT(r.post_id)::NUMERIC/COUNT(s.post_id))*100 AS per FROM spammed s LEFT JOIN removals_1132 r ON s.post_id = r.post_id GROUP BY s.action_date ) SELECT ROUND(AVG(per),2) AS avg_daily_percent FROM percentage; --------------------------- OR --------------------------- WITH cte AS ( SELECT a.action_date, ROUND(COUNT(CASE WHEN a.extra = 'spam' AND r.post_id IS NOT NULL THEN 1 ELSE NULL END)*100::NUMERIC/COUNT(DISTINCT a.post_id),2) AS removed_spammed_post_percentage FROM actions_1132 a LEFT JOIN removals_1132 r ON a.post_id = r.post_id GROUP BY a.action_date ) SELECT ROUND(AVG(removed_spammed_post_percentage),2) FROM cte WHERE removed_spammed_post_percentage <> 0;

---

#### -- Question 31

-- Table: Submissions -- +---------------+----------+ -- | Column Name   | Type     | -- +---------------+----------+ -- | sub_id        | int      | -- | parent_id     | int      | -- +---------------+----------+ -- There is no primary key for this table, it may have duplicate rows. -- Each row can be a post or comment on the post. -- parent_id is null for posts. -- parent_id for comments is sub_id for another post in the table. -- Write an SQL query to find number of comments per each post. -- Result table should contain post_id and its corresponding number_of_comments, -- and must be sorted by post_id in ascending order. -- Submissions may contain duplicate comments. You should count the number of unique comments per post. -- Submissions may contain duplicate posts. You should treat them as one post. -- The query result format is in the following example: -- Submissions table: -- +---------+------------+ -- | sub_id  | parent_id  | -- +---------+------------+ -- | 1       | Null       | -- | 2       | Null       | -- | 1       | Null       | -- | 12      | Null       | -- | 3       | 1          | -- | 5       | 2          | -- | 3       | 1          | -- | 4       | 1          | -- | 9       | 1          | -- | 10      | 2          | -- | 6       | 7          | -- +---------+------------+ -- Result table: -- +---------+--------------------+ -- | post_id | number_of_comments | -- +---------+--------------------+ -- | 1       | 3                  | -- | 2       | 2                  | -- | 12      | 0                  | -- +---------+--------------------+ -- The post with id 1 has three comments in the table with id 3, 4 and 9. The comment with id 3 is -- repeated in the table, we counted it only once. -- The post with id 2 has two comments in the table with id 5 and 10. -- The post with id 12 has no comments in the table. -- The comment with id 6 is a comment on a deleted post with id 7 so we ignored it. -- Solution Select a.sub_id as post_id, coalesce(b.number_of_comments,0) as number_of_comments from( select distinct sub_id from submissions where parent_id is null) a left join( select parent_id, count(distinct(sub_id)) as number_of_comments from submissions group by parent_id having parent_id = any(select sub_id from submissions where parent_id is null)) b on a.sub_id = b.parent_id order by post_id

---

#### WITH similar_friends AS(

SELECT l1.user_id AS user_id1,l2.user_id AS user_id2,COUNT(l1.song_id) FROM listens_1919 l1 INNER JOIN listens_1919 l2 ON l1.user_id < l2.user_id AND l1.song_id = l2.song_id AND l1.day = l2.day GROUP BY l1.user_id,l2.user_id HAVING COUNT(l1.song_id) >= 3 ) SELECT f.* FROM similar_friends sf INNER JOIN friendship_1919 f ON sf.user_id1 = f.user1_id AND sf.user_id2 = f.user2_id;

---

#### SELECT advertiser_id, ROUND((SUM(revenue) / SUM(spend))::decimal, 2) AS ROAS

FROM ad_campaigns GROUP BY advertiser_id ORDER BY advertiser_id;

---

#### WITH tagged_accounts AS (

SELECT *, CASE WHEN income < 20000 THEN 'Low Salary' WHEN income >= 20000 AND income <= 50000 THEN 'Average Salary' ELSE 'High Salary' END AS salary_tag FROM accounts_1907 ), salary_tags AS ( SELECT UNNEST(ARRAY['Low Salary','Average Salary','High Salary']) AS salary_tag ) SELECT st.salary_tag,COALESCE(COUNT(account_id),0) AS accounts_count FROM salary_tags st LEFT JOIN tagged_accounts ta ON st.salary_tag = ta.salary_tag GROUP BY st.salary_tag;

---

#### WITH bins AS (

SELECT '[0-5>' AS bin,  0 AS min_duration, 5*60 AS max_duration UNION ALL SELECT '[5-10>' AS bin,  5*60 AS min_duration, 10*60 AS max_duration UNION ALL SELECT '[10-15>' AS bin, 10*60 AS min_duration, 15*60 AS max_duration UNION ALL SELECT '15 or more' AS bin,  15*60 as min_duration, 2147483647 AS max_duration ) SELECT b.bin, COUNT(s.session_id) AS total FROM bins b LEFT JOIN sessions_1435 s ON s.duration >= min_duration AND s.duration < max_duration GROUP BY b.bin;

---

#### WITH cte AS(

SELECT *, SUM(frequency) OVER w AS e, SUM(frequency) OVER () AS t FROM numbers_571_tc_2 WINDOW w AS (ORDER BY number) ), cte2 AS( SELECT number,frequency, CASE WHEN (LAG(e::INT,1) OVER w) IS NULL THEN 1 ELSE (LAG(e::INT,1) OVER w)+1 END AS s, e,t FROM cte WINDOW w AS (ORDER BY number) ) SELECT ROUND(AVG(number),1) FROM cte2 WHERE (t::NUMERIC/2 BETWEEN s AND e) OR (t::NUMERIC/2+1 BETWEEN s AND e); --------------------------- OR --------------------------- WITH RECURSIVE cte AS ( SELECT number,frequency,1 AS cnt FROM numbers_571 UNION ALL SELECT number,frequency,cnt+1 AS cnt FROM cte WHERE cnt < frequency ), cte2 AS ( SELECT number, ROW_NUMBER() OVER (ORDER BY number) AS a, COUNT(*) OVER () c FROM cte ) SELECT ROUND(AVG(number),1) FROM cte2 WHERE a BETWEEN (SELECT CEIL(AVG(c)::NUMERIC/2) FROM cte2) AND (SELECT CEIL((AVG(c)+1::NUMERIC)/2) FROM cte2) --------------------------- OR --------------------------- WITH RECURSIVE cte AS ( SELECT number,frequency,1 AS cnt FROM numbers_571 UNION ALL SELECT number,frequency,cnt+1 AS cnt FROM cte WHERE cnt < frequency ), cte2 AS ( SELECT number, ROW_NUMBER() OVER (ORDER BY number) AS a FROM cte ), cte3 AS ( SELECT number,a, ROW_NUMBER() OVER (ORDER BY a DESC) AS d FROM cte2 ) SELECT ROUND(AVG(number),1) FROM cte3 WHERE ABS(a-d) = 0 OR ABS(a-d) = 1;

---

#### SELECT candidate_id

FROM candidates_2041 WHERE years_of_exp >= 2 AND interview_id IN (SELECT interview_id FROM rounds_2041 GROUP BY interview_id HAVING SUM(score) > 15);

---

#### -- Question 46

-- Table: Countries -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | country_id    | int     | -- | country_name  | varchar | -- +---------------+---------+ -- country_id is the primary key for this table. -- Each row of this table contains the ID and the name of one country. -- Table: Weather -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | country_id    | int     | -- | weather_state | varchar | -- | day           | date    | -- +---------------+---------+ -- (country_id, day) is the primary key for this table. -- Each row of this table indicates the weather state in a country for one day. -- Write an SQL query to find the type of weather in each country for November 2019. -- The type of weather is Cold if the average weather_state is less than or equal 15, Hot if the average weather_state is greater than or equal 25 and Warm otherwise. -- Return result table in any order. -- The query result format is in the following example: -- Countries table: -- +------------+--------------+ -- | country_id | country_name | -- +------------+--------------+ -- | 2          | USA          | -- | 3          | Australia    | -- | 7          | Peru         | -- | 5          | China        | -- | 8          | Morocco      | -- | 9          | Spain        | -- +------------+--------------+ -- Weather table: -- +------------+---------------+------------+ -- | country_id | weather_state | day        | -- +------------+---------------+------------+ -- | 2          | 15            | 2019-11-01 | -- | 2          | 12            | 2019-10-28 | -- | 2          | 12            | 2019-10-27 | -- | 3          | -2            | 2019-11-10 | -- | 3          | 0             | 2019-11-11 | -- | 3          | 3             | 2019-11-12 | -- | 5          | 16            | 2019-11-07 | -- | 5          | 18            | 2019-11-09 | -- | 5          | 21            | 2019-11-23 | -- | 7          | 25            | 2019-11-28 | -- | 7          | 22            | 2019-12-01 | -- | 7          | 20            | 2019-12-02 | -- | 8          | 25            | 2019-11-05 | -- | 8          | 27            | 2019-11-15 | -- | 8          | 31            | 2019-11-25 | -- | 9          | 7             | 2019-10-23 | -- | 9          | 3             | 2019-12-23 | -- +------------+---------------+------------+ -- Result table: -- +--------------+--------------+ -- | country_name | weather_type | -- +--------------+--------------+ -- | USA          | Cold         | -- | Austraila    | Cold         | -- | Peru         | Hot          | -- | China        | Warm         | -- | Morocco      | Hot          | -- +--------------+--------------+ -- Average weather_state in USA in November is (15) / 1 = 15 so weather type is Cold. -- Average weather_state in Austraila in November is (-2 + 0 + 3) / 3 = 0.333 so weather type is Cold. -- Average weather_state in Peru in November is (25) / 1 = 25 so weather type is Hot. -- Average weather_state in China in November is (16 + 18 + 21) / 3 = 18.333 so weather type is Warm. -- Average weather_state in Morocco in November is (25 + 27 + 31) / 3 = 27.667 so weather type is Hot. -- We know nothing about average weather_state in Spain in November -- so we don't include it in the result table. -- Solution Select c.country_name, case when avg(w.weather_state)<=15 then 'Cold' when avg(w.weather_state)>=25 then 'Hot' else 'Warm' end as weather_type from weather w join countries c on w.country_id = c.country_id where month(day) = 11 group by c.country_name

---

#### SELECT email

FROM person_182 GROUP BY email HAVING cnt>2;

---

#### WITH CT AS

( SELECT *, ROW_NUMBER() OVER(PARTITION BY user_id ORDER BY transaction_date) AS RN FROM user_transactions ) SELECT COUNT(user_id) AS users FROM CT WHERE RN = 1 AND spend >= 50;

---

#### WITH SuperCloud AS

( SELECT customer_id, COUNT(DISTINCT products.product_category) AS NumberOfProducts FROM customer_contracts RIGHT JOIN products ON customer_contracts.product_id = products.product_id GROUP BY customer_id ) SELECT customer_id FROM SuperCloud WHERE NumberOfProducts = ( SELECT COUNT(DISTINCT product_category) FROM products )

---

#### SELECT ROUND(COUNT(DISTINCT b.player_id)::NUMERIC/COUNT(DISTINCT a.player_id),2)

FROM activity_550 a LEFT JOIN activity_550 b ON a.player_id = b.player_id AND a.event_date + 1 = b.event_date;

---

#### SELECT ROUND(COUNT(DISTINCT CASE WHEN a.requester_id IS NOT NULL AND a.accepter_id IS NOT NULL THEN CONCAT(a.requester_id,' ',a.accepter_id) END)::NUMERIC/COUNT(DISTINCT CASE WHEN r.sender_id IS NOT NULL AND r.send_to_id IS NOT NULL THEN CONCAT(r.sender_id,' ',r.send_to_id) END ),2) AS accept_rate

FROM friend_request_597 r LEFT JOIN request_accepted_597 a ON r.sender_id = a.requester_id AND r.send_to_id = a.accepter_id;

---

#### -- Question 14

-- Table: Person -- +-------------+---------+ -- | Column Name | Type    | -- +-------------+---------+ -- | PersonId    | int     | -- | FirstName   | varchar | -- | LastName    | varchar | -- +-------------+---------+ -- PersonId is the primary key column for this table. -- Table: Address -- +-------------+---------+ -- | Column Name | Type    | -- +-------------+---------+ -- | AddressId   | int     | -- | PersonId    | int     | -- | City        | varchar | -- | State       | varchar | -- +-------------+---------+ -- AddressId is the primary key column for this table. -- Write a SQL query for a report that provides the following information for each person in the Person table, -- regardless if there is an address for each of those people: -- FirstName, LastName, City, State -- Solution select FirstName, LastName, City, State from Person P left join Address A on P.PersonId = A.PersonId

---

#### What does the GROUP BY clause do in SQL?

It groups rows that have the same values in specified columns into summary rows (e.g., COUNT, SUM). SELECT department, COUNT(*) FROM employees GROUP BY department; Input Table: employees id | name  | department ---+-------+----------- 1  | John  | HR 2  | Alice | IT 3  | Bob   | HR Output department | COUNT(*) -----------+---------- HR         | 2 IT         | 1

---

#### What is the purpose of the HAVING clause?

It filters groups based on aggregate results (e.g., groups with COUNT > 1). SELECT department, COUNT(*) FROM employees GROUP BY department HAVING COUNT(*) > 1; Output department | COUNT(*) -----------+---------- HR         | 2

---

#### What‚Äôs the difference between WHERE and HAVING?

WHERE filters rows before grouping. HAVING filters groups after aggregation. SELECT department, COUNT(*) FROM employees WHERE name != 'Bob' GROUP BY department HAVING COUNT(*) > 0;

---

#### How to count employees per department and show only departments with more than 2 employees?

SELECT department, COUNT(*) FROM employees GROUP BY department HAVING COUNT(*) > 2;

---

#### Can you use GROUP BY without aggregation?

Yes, but it‚Äôs rare and mostly used with SELECT DISTINCT-like behavior. SELECT department FROM employees GROUP BY department;

---

#### Can you use aggregate functions without GROUP BY?

Yes, aggregate functions can be used on the entire result set. SELECT COUNT(*) FROM employees;

---

#### How do you get the total salary per department?

SELECT department, SUM(salary) FROM employees GROUP BY department;

---

#### How to find the average salary of each department?

SELECT department, AVG(salary) FROM employees GROUP BY department;

---

#### Show departments where the average salary is above 50,000.

SELECT department, AVG(salary) AS avg_salary FROM employees GROUP BY department HAVING AVG(salary) > 50000;

---

#### Can you group by multiple columns?

Yes. SELECT department, job_title, COUNT(*) FROM employees GROUP BY department, job_title;

---

#### Show the department with the highest average salary.

SELECT department, AVG(salary) AS avg_salary FROM employees GROUP BY department ORDER BY avg_salary DESC LIMIT 1;

---

#### How to find how many employees joined each year?

Assuming a join_date column: SELECT YEAR(join_date) AS year_joined, COUNT(*) FROM employees GROUP BY YEAR(join_date);

---

#### How to find duplicate employee names?

SELECT name, COUNT(*) FROM employees GROUP BY name HAVING COUNT(*) > 1;

---

#### How to filter rows where total salary exceeds 100,000 per department?

SELECT department, SUM(salary) AS total_salary FROM employees GROUP BY department HAVING SUM(salary) > 100000;

---

#### Can we use column aliases in the HAVING clause?

Most databases do not support using aliases in HAVING. Use the function directly. Works: SELECT department, SUM(salary) AS total_salary FROM employees GROUP BY department HAVING SUM(salary) > 50000; Avoid: HAVING total_salary > 50000;

---

#### How do NULLs affect GROUP BY?

Rows with NULL values in GROUP BY columns are grouped together. SELECT manager_id, COUNT(*) FROM employees GROUP BY manager_id;

---

#### How to get a count of different job titles per department?

SELECT department, COUNT(DISTINCT job_title) FROM employees GROUP BY department;

---

#### How to show departments with at least one employee earning more than 90,000?

SELECT department FROM employees WHERE salary > 90000 GROUP BY department;

---

#### How to get the max salary in each department, but only show departments where the max is over 100,000?

SELECT department, MAX(salary) AS max_salary FROM employees GROUP BY department HAVING MAX(salary) > 100000;

---

#### How to include aggregated results along with non-aggregated data?

Use GROUP BY for all non-aggregated columns. SELECT department, job_title, COUNT(*) FROM employees GROUP BY department, job_title;

---

#### -- Question 14

-- The Employee table holds all employees. Every employee has an Id, and there is also a column for the department Id. -- +----+-------+--------+--------------+ -- | Id | Name  | Salary | DepartmentId | -- +----+-------+--------+--------------+ -- | 1  | Joe   | 85000  | 1            | -- | 2  | Henry | 80000  | 2            | -- | 3  | Sam   | 60000  | 2            | -- | 4  | Max   | 90000  | 1            | -- | 5  | Janet | 69000  | 1            | -- | 6  | Randy | 85000  | 1            | -- | 7  | Will  | 70000  | 1            | -- +----+-------+--------+--------------+ -- The Department table holds all departments of the company. -- +----+----------+ -- | Id | Name     | -- +----+----------+ -- | 1  | IT       | -- | 2  | Sales    | -- +----+----------+ -- Write a SQL query to find employees who earn the top three salaries in each of the department. For the above tables, your SQL query should return the following rows (order of rows does not matter). -- +------------+----------+--------+ -- | Department | Employee | Salary | -- +------------+----------+--------+ -- | IT         | Max      | 90000  | -- | IT         | Randy    | 85000  | -- | IT         | Joe      | 85000  | -- | IT         | Will     | 70000  | -- | Sales      | Henry    | 80000  | -- | Sales      | Sam      | 60000  | -- +------------+----------+--------+ -- Explanation: -- In IT department, Max earns the highest salary, both Randy and Joe earn the second highest salary, -- and Will earns the third highest salary. -- There are only two employees in the Sales department, -- Henry earns the highest salary while Sam earns the second highest salary. -- Solution select a.department, a.employee, a.salary from ( select d.name as department, e.name as employee, salary, dense_rank() over(Partition by d.name order by salary desc) as rk from Employee e join Department d on e.departmentid = d.id) a where a.rk<4

---

#### How would you find the month-over-month growth rate for a company‚Äôs total revenue?

Sample Table: transactions (transaction_id, transaction_date, revenue) The SQL Answer: SQL WITH MonthlyRevenue AS ( SELECT STRFTIME('%Y-%m', transaction_date) AS sales_month, SUM(revenue) AS total_revenue FROM transactions GROUP BY sales_month ) SELECT sales_month, total_revenue, LAG(total_revenue, 1) OVER (ORDER BY sales_month) AS previous_month_revenue, (total_revenue - LAG(total_revenue, 1) OVER (ORDER BY sales_month)) * 100.0 / LAG(total_revenue, 1) OVER (ORDER BY sales_month) AS growth_rate FROM MonthlyRevenue ORDER BY sales_month; Interviewer‚Äôs Intent: This is a classic question that tests your ability to perform time-series analysis. They are looking for your knowledge of window functions, specifically LAG(), which allows you to access a row from a previous record in the same result set without a complex self-join. The use of a CTE also demonstrates your ability to break down a multi-step problem into a readable solution.

---

#### Given a table of employees, how would you find each employee‚Äôs manager‚Äôs name?

Sample Table: employees (employee_id, employee_name, manager_id) The SQL Answer: SQL SELECT e1.employee_name AS employee, e2.employee_name AS manager FROM employees e1 JOIN employees e2 ON e1.manager_id = e2.employee_id; Interviewer‚Äôs Intent: This question tests your understanding of self-joins. The interviewer wants to see if you can join a table to itself to handle hierarchical or relational data. The use of clear table aliases (e1 and e2) is key here to make the query understandable.

---

#### How would you pivot a table to show total sales by product category and region, with regions as columns?

Sample Table: sales_data (product_category, region, sales_amount) The SQL Answer (using Conditional Aggregation): SQL SELECT product_category, SUM(CASE WHEN region = 'North' THEN sales_amount ELSE 0 END) AS total_sales_north, SUM(CASE WHEN region = 'South' THEN sales_amount ELSE 0 END) AS total_sales_south, SUM(CASE WHEN region = 'East' THEN sales_amount ELSE 0 END) AS total_sales_east FROM sales_data GROUP BY product_category; Interviewer‚Äôs Intent: This tests your ability to transform data from a tall format to a wide format. They are looking for the common and portable solution of using GROUP BY with conditional aggregation (CASE WHEN) instead of a database-specific PIVOT function. This shows you can prepare data for business intelligence tools.

---

#### You have a log of user sessions. How would you find the average time between a user‚Äôs consecutive logins?

Sample Table: sessions (user_id, session_start_time) The SQL Answer: SQL WITH SessionDurations AS ( SELECT user_id, session_start_time, LAG(session_start_time, 1) OVER (PARTITION BY user_id ORDER BY session_start_time) AS previous_session_time FROM sessions ) SELECT AVG(JULIANDAY(session_start_time) - JULIANDAY(previous_session_time)) AS average_time_between_logins_days FROM SessionDurations WHERE previous_session_time IS NOT NULL; Interviewer‚Äôs Intent: This is a comprehensive problem that combines several advanced concepts. The interviewer is testing your ability to use LAG() with PARTITION BY. The PARTITION BY user_id is crucial, as it tells the function to restart the time-series calculation for each unique user, which is what's needed for the correct answer. It also tests your ability to handle date calculations.

---

#### Write a query to find the top 3 best-selling products in each sales region.

Sample Table: sales (sale_id, region, product_id, quantity) The SQL Answer: SQL WITH ProductSales AS ( SELECT region, product_id, SUM(quantity) as total_quantity FROM sales GROUP BY region, product_id ), RankedSales AS ( SELECT region, product_id, total_quantity, RANK() OVER (PARTITION BY region ORDER BY total_quantity DESC) as ranking FROM ProductSales ) SELECT region, product_id, total_quantity FROM RankedSales WHERE ranking <= 3; Interviewer‚Äôs Intent: This is the classic ‚ÄúTop-N per Group‚Äù problem. The interviewer is testing your mastery of window functions (RANK()) and CTEs (WITH). An answer that uses PARTITION BY and RANK() is far more efficient and scalable than a solution that tries to use subqueries or self-joins to achieve the same result. Advanced SQL Cheat Sheet This guide provides a quick, scannable summary of the key concepts for your post. LAG/LEAD: Compare a value to the previous or next row in a result set. Syntax: LAG(column, offset) OVER (ORDER BY column) Use Case: Calculating month-over-month revenue growth. PARTITION BY: Divide a table‚Äôs rows into partitions, to which a window function is applied. Syntax: RANK() OVER (PARTITION BY column ORDER BY column) Use Case: Finding the top N products in each region. Self-Joins: Join a table to itself. Syntax: SELECT ... FROM table t1 JOIN table t2 ON t1.id = t2.parent_id Use Case: Finding each employee‚Äôs manager in a single table. CTEs (Common Table Expressions): Define a temporary named result set within the scope of a single query. Syntax: WITH CTE_Name AS (SELECT ...) SELECT ... FROM CTE_Name Use Case: Breaking down a complex, multi-step query into readable parts. Conditional Aggregation: Aggregate data based on specific conditions. Syntax: SUM(CASE WHEN condition THEN column ELSE 0 END) Use Case: Pivoting rows into columns (e.g., total sales per region). Press enter or click to view image in full size Conclusion: Go in with Confidence These questions might seem intimidating, but they are all solvable with a few key concepts. Mastering them demonstrates not only your technical skills but also your logical thinking and ability to break down complex problems. Go in with confidence. You have the skills. You know the concepts. Now, you also know what the interviewer is really looking for.

---

#### -- Question 33

-- Table: Product -- +--------------+---------+ -- | Column Name  | Type    | -- +--------------+---------+ -- | product_id   | int     | -- | product_name | varchar | -- | unit_price   | int     | -- +--------------+---------+ -- product_id is the primary key of this table. -- Table: Sales -- +-------------+---------+ -- | Column Name | Type    | -- +-------------+---------+ -- | seller_id   | int     | -- | product_id  | int     | -- | buyer_id    | int     | -- | sale_date   | date    | -- | quantity    | int     | -- | price       | int     | -- +------ ------+---------+ -- This table has no primary key, it can have repeated rows. -- product_id is a foreign key to Product table. -- Write an SQL query that reports the buyers who have bought S8 but not iPhone. Note that S8 and iPhone are products present in the Product table. -- The query result format is in the following example: -- Product table: -- +------------+--------------+------------+ -- | product_id | product_name | unit_price | -- +------------+--------------+------------+ -- | 1          | S8           | 1000       | -- | 2          | G4           | 800        | -- | 3          | iPhone       | 1400       | -- +------------+--------------+------------+ -- Sales table: -- +-----------+------------+----------+------------+----------+-------+ -- | seller_id | product_id | buyer_id | sale_date  | quantity | price | -- +-----------+------------+----------+------------+----------+-------+ -- | 1         | 1          | 1        | 2019-01-21 | 2        | 2000  | -- | 1         | 2          | 2        | 2019-02-17 | 1        | 800   | -- | 2         | 1          | 3        | 2019-06-02 | 1        | 800   | -- | 3         | 3          | 3        | 2019-05-13 | 2        | 2800  | -- +-----------+------------+----------+------------+----------+-------+ -- Result table: -- +-------------+ -- | buyer_id    | -- +-------------+ -- | 1           | -- +-------------+ -- The buyer with id 1 bought an S8 but didn't buy an iPhone. The buyer with id 3 bought both. -- Solution Select distinct a.buyer_id from sales a join product b on a.product_id = b.product_id where a.buyer_id in (Select a.buyer_id from sales a join product b on a.product_id = b.product_id where b.product_name = 'S8') and a.buyer_id not in (Select a.buyer_id from sales a join product b on a.product_id = b.product_id where b.product_name = 'iPhone')

---

#### -- Question 87

-- A university uses 2 data tables, student and department, to store data about its students -- and the departments associated with each major. -- Write a query to print the respective department name and number of students majoring in each -- department for all departments in the department table (even ones with no current students). -- Sort your results by descending number of students; if two or more departments have the same number of students, -- then sort those departments alphabetically by department name. -- The student is described as follow: -- | Column Name  | Type      | -- |--------------|-----------| -- | student_id   | Integer   | -- | student_name | String    | -- | gender       | Character | -- | dept_id      | Integer   | -- where student_id is the student's ID number, student_name is the student's name, gender is their gender, and dept_id is the department ID associated with their declared major. -- And the department table is described as below: -- | Column Name | Type    | -- |-------------|---------| -- | dept_id     | Integer | -- | dept_name   | String  | -- where dept_id is the department's ID number and dept_name is the department name. -- Here is an example input: -- student table: -- | student_id | student_name | gender | dept_id | -- |------------|--------------|--------|---------| -- | 1          | Jack         | M      | 1       | -- | 2          | Jane         | F      | 1       | -- | 3          | Mark         | M      | 2       | -- department table: -- | dept_id | dept_name   | -- |---------|-------------| -- | 1       | Engineering | -- | 2       | Science     | -- | 3       | Law         | -- The Output should be: -- | dept_name   | student_number | -- |-------------|----------------| -- | Engineering | 2              | -- | Science     | 1              | -- | Law         | 0              | -- Solution select dept_name, count(s.dept_id) as student_number from department d left join student s on d.dept_id = s.dept_id group by d.dept_id order by count(s.dept_id) desc, dept_name

---

#### WITH friends AS (

SELECT user1_id,user2_id FROM friendship_1949 UNION SELECT user2_id,user1_id FROM friendship_1949 ) SELECT f1.user1_id,f2.user1_id,COUNT(f2.user1_id) AS num_mututal_friends FROM friends f1 INNER JOIN friends f2 ON f1.user1_id <> f2.user1_id AND f1.user2_id = f2.user2_id WHERE f1.user1_id < f2.user1_id GROUP BY f1.user1_id,f2.user1_id HAVING COUNT(f2.user1_id) >=3

---

#### SELECT account_id,

SUM(CASE WHEN transaction_type = 'Deposit' THEN amount ELSE -amount END) AS final_balance FROM transactions GROUP BY account_id;

---

#### SELECT b.followee AS follower,COUNT(b.follower) AS num

FROM follow_614 a JOIN follow_614 b ON a.follower = b.followee GROUP BY b.followee;

---

#### -- Question 13

-- Table: Ads -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | ad_id         | int     | -- | user_id       | int     | -- | action        | enum    | -- +---------------+---------+ -- (ad_id, user_id) is the primary key for this table. -- Each row of this table contains the ID of an Ad, the ID of a user and the action taken by this user regarding this Ad. -- The action column is an ENUM type of ('Clicked', 'Viewed', 'Ignored'). -- A company is running Ads and wants to calculate the performance of each Ad. -- Performance of the Ad is measured using Click-Through Rate (CTR) where: -- Write an SQL query to find the ctr of each Ad. -- Round ctr to 2 decimal points. Order the result table by ctr in descending order and by ad_id in ascending order in case of a tie. -- The query result format is in the following example: -- Ads table: -- +-------+---------+---------+ -- | ad_id | user_id | action  | -- +-------+---------+---------+ -- | 1     | 1       | Clicked | -- | 2     | 2       | Clicked | -- | 3     | 3       | Viewed  | -- | 5     | 5       | Ignored | -- | 1     | 7       | Ignored | -- | 2     | 7       | Viewed  | -- | 3     | 5       | Clicked | -- | 1     | 4       | Viewed  | -- | 2     | 11      | Viewed  | -- | 1     | 2       | Clicked | -- +-------+---------+---------+ -- Result table: -- +-------+-------+ -- | ad_id | ctr   | -- +-------+-------+ -- | 1     | 66.67 | -- | 3     | 50.00 | -- | 2     | 33.33 | -- | 5     | 0.00  | -- +-------+-------+ -- for ad_id = 1, ctr = (2/(2+1)) * 100 = 66.67 -- for ad_id = 2, ctr = (1/(1+2)) * 100 = 33.33 -- for ad_id = 3, ctr = (1/(1+1)) * 100 = 50.00 -- for ad_id = 5, ctr = 0.00, Note that ad_id = 5 has no clicks or views. -- Note that we don't care about Ignored Ads. -- Result table is ordered by the ctr. in case of a tie we order them by ad_id -- Solution with t1 as( select ad_id, sum(case when action in ('Clicked') then 1 else 0 end) as clicked from ads group by ad_id ) , t2 as ( Select ad_id as ad, sum(case when action in ('Clicked','Viewed') then 1 else 0 end) as total from ads group by ad_id ) Select a.ad_id, coalesce(round((clicked +0.0)/nullif((total +0.0),0)*100,2),0) as ctr from ( select * from t1 join t2 on t1.ad_id = t2.ad) a order by ctr desc, ad_id

---

#### SELECT P.page_id

FROM pages P WHERE P.page_id NOT IN ( SELECT PL.page_id FROM page_likes PL ); -- Another Solution SELECT page_id FROM pages EXCEPT SELECT page_id FROM page_likes ORDER BY page_id

---

#### -- Question 37

-- Several friends at a cinema ticket office would like to reserve consecutive available seats. -- Can you help to query all the consecutive available seats order by the seat_id using the following cinema table? -- | seat_id | free | -- |---------|------| -- | 1       | 1    | -- | 2       | 0    | -- | 3       | 1    | -- | 4       | 1    | -- | 5       | 1    | -- Your query should return the following result for the sample case above. -- | seat_id | -- |---------| -- | 3       | -- | 4       | -- | 5       | -- Note: -- The seat_id is an auto increment int, and free is bool ('1' means free, and '0' means occupied.). -- Consecutive available seats are more than 2(inclusive) seats consecutively available. -- Solution Select seat_id from( select seat_id, free, lead(free,1) over() as next, lag(free,1) over() as prev from cinema) a where a.free=True and (next = True or prev=True) order by seat_id

---

#### -- Question 2

-- Table: Sessions -- +---------------------+---------+ -- | Column Name         | Type    | -- +---------------------+---------+ -- | session_id          | int     | -- | duration            | int     | -- +---------------------+---------+ -- session_id is the primary key for this table. -- duration is the time in seconds that a user has visited the application. -- You want to know how long a user visits your application. You decided to create bins of "[0-5>", "[5-10>", "[10-15>" and "15 minutes or more" and count the number of sessions on it. -- Write an SQL query to report the (bin, total) in any order. -- The query result format is in the following example. -- Sessions table: -- +-------------+---------------+ -- | session_id  | duration      | -- +-------------+---------------+ -- | 1           | 30            | -- | 2           | 199           | -- | 3           | 299           | -- | 4           | 580           | -- | 5           | 1000          | -- +-------------+---------------+ -- Result table: -- +--------------+--------------+ -- | bin          | total        | -- +--------------+--------------+ -- | [0-5>        | 3            | -- | [5-10>       | 1            | -- | [10-15>      | 0            | -- | 15 or more   | 1            | -- +--------------+--------------+ -- For session_id 1, 2 and 3 have a duration greater or equal than 0 minutes and less than 5 minutes. -- For session_id 4 has a duration greater or equal than 5 minutes and less than 10 minutes. -- There are no session with a duration greater or equial than 10 minutes and less than 15 minutes. -- For session_id 5 has a duration greater or equal than 15 minutes. -- Solution 2 (Select '[0-5>' as bin, sum(case when duration/60 < 5 then 1 else 0 end) as total from Sessions) union (Select '[5-10>' as bin, sum(case when ((duration/60 >= 5) and (duration/60 < 10)) then 1 else 0 end) as total from Sessions) union (Select '[10-15>' as bin, sum(case when ((duration/60 >= 10) and (duration/60 < 15)) then 1 else 0 end) as total from Sessions) union (Select '15 or more' as bin, sum(case when duration/60 >= 15 then 1 else 0 end) as total from Sessions)

---

#### SELECT manufacturer,

CONCAT('$', total_result, ' million') AS sale FROM ( SELECT manufacturer, ROUND( SUM(total_sales) / 1000000) AS total_result FROM pharmacy_sales GROUP BY manufacturer ORDER BY SUM(total_sales) DESC, manufacturer ) AS TP

---

#### SELECT viewer_id

FROM views_1149 GROUP BY viewer_id,view_date HAVING COUNT(DISTINCT article_id)>1 ORDER BY 1 ASC;

---

#### -- Question 8

-- Query the customer_number from the orders table for the customer who has placed the largest number of orders. -- It is guaranteed that exactly one customer will have placed more orders than any other customer. -- The orders table is defined as follows: -- | Column            | Type      | -- |-------------------|-----------| -- | order_number (PK) | int       | -- | customer_number   | int       | -- | order_date        | date      | -- | required_date     | date      | -- | shipped_date      | date      | -- | status            | char(15)  | -- | comment           | char(200) | -- Sample Input -- | order_number | customer_number | order_date | required_date | shipped_date | status | comment | -- |--------------|-----------------|------------|---------------|--------------|--------|---------| -- | 1            | 1               | 2017-04-09 | 2017-04-13    | 2017-04-12   | Closed |         | -- | 2            | 2               | 2017-04-15 | 2017-04-20    | 2017-04-18   | Closed |         | -- | 3            | 3               | 2017-04-16 | 2017-04-25    | 2017-04-20   | Closed |         | -- | 4            | 3               | 2017-04-18 | 2017-04-28    | 2017-04-25   | Closed |         | -- Sample Output -- | customer_number | -- |-----------------| -- | 3               | -- Explanation -- The customer with number '3' has two orders, -- which is greater than either customer '1' or '2' because each of them  only has one order. -- So the result is customer_number '3'. -- Solution -- Ranking them according to the number of orders to have same rank for -- customers with same number of orders With t1 as ( Select customer_number, Rank() over(order by count(customer_number) desc) as rk from orders group by customer_number ) Select t1.customer_number from t1 where t1.rk=1

---

#### SELECT l1.account_id

FROM log_info_1747 l1 INNER JOIN log_info_1747 l2 ON l1.account_id = l2.account_id AND l1.login BETWEEN l2.login AND l2.logout AND l1.ip_address <> l2.ip_address;

---

#### Write a SQL query that retrieves the `first_name`, `last_name`, and `email` columns from a table named `users`, where the `email` domain is ‚Äúexample.com‚Äù. Assume that `email` is a `VARCHAR` type.

Example Answer: SELECT first_name, last_name, email FROM users WHERE email LIKE '%@example.com'; Explanation: This query selects the `first_name`, `last_name`, and `email` columns from the `users` table and filters the rows to include only those with an email domain of ‚Äúexample.com‚Äù. The `LIKE` operator is used with a wildcard (`%`) to match any characters before ‚Äú@example.com‚Äù. SQL joins and relationships

---

#### Write a SQL query to retrieve the `order_id` and `order_date` from an `orders` table and the `product_name` from a `products` table for all orders. Assume that the `orders` table has a `product_id` foreign key that references the `product_id` in the `products` table.

Example Answer: SELECT o.order_id, o.order_date, p.product_name FROM orders o JOIN products p ON o.product_id = p.product_id; Explanation: This query retrieves data from both the `orders` and `products` tables using an `INNER JOIN`. The `JOIN` is performed on the `product_id` column, which is common between the two tables, allowing the query to combine rows from each table where there is a matching `product_id`. Basic data manipulation

---

#### Write a SQL query to update the `salary` column in the `employees` table, increasing it by 10% for all employees who work in the ‚ÄúSales‚Äù department. Assume the `department` column is of type `VARCHAR`.

Example Answer: UPDATE employees SET salary = salary * 1.10 WHERE department = 'Sales'; Explanation: This query updates the `salary` field in the `employees` table by multiplying the current salary by 1.10 (a 10% increase) for all employees in the ‚ÄúSales‚Äù department. The `WHERE` clause ensures that only rows where the `department` is ‚ÄúSales‚Äù are affected. Learning tip: Want to review SQL basics before your next interview? Journey into SQL with Taylor Swift is a fun and accessible learning path in CodeSignal Learn where you‚Äôll practice key querying skills using Taylor Swift‚Äôs discography as your database. Intermediate SQL interview questions (2 to 5 years of experience) Complex SQL queries and subqueries

---

#### Write a SQL query to find the top 3 customers with the highest total `order_amount` from the `orders` table. Assume that each order is linked to a customer via a `customer_id` column, and the `order_amount` is a numeric column.

Example Answer: SELECT customer_id, SUM(order_amount) AS total_spent FROM orders GROUP BY customer_id ORDER BY total_spent DESC LIMIT 3; Explanation: This query calculates the total `order_amount` spent by each customer using the `SUM()` function and groups the results by `customer_id`. The `ORDER BY` clause sorts the results in descending order of total spent, and the `LIMIT` clause restricts the output to the top 3 customers. This type of query is essential for analyzing customer behavior and identifying high-value customers. Subqueries and data integrity

---

#### Write a SQL query to find all employees in the `employees` table whose `salary` is greater than the average salary in their department. Assume that the table has `employee_id`, `department_id`, and `salary` columns.

Example Answer: SELECT employee_id, department_id, salary FROM employees e WHERE salary > ( SELECT AVG(salary) FROM employees WHERE department_id = e.department_id ); Explanation: This query uses a subquery to calculate the average salary within each department. The main query then selects employees whose salary exceeds the average salary of their respective department. The use of correlated subqueries (where the subquery references a column from the outer query) is a powerful technique for comparing data within grouped contexts. Indexes, performance, and transaction control

---

#### Suppose you need to delete a large number of records from the `transactions` table where the `transaction_date` is older than one year. Write a SQL script that includes steps to ensure the deletion is efficient and doesn‚Äôt affect the performance of the database during the operation. Assume an index exists on the `transaction_date` column.

Example Answer: BEGIN; SET TRANSACTION ISOLATION LEVEL READ COMMITTED; DELETE FROM transactions WHERE transaction_date < NOW() - INTERVAL '1 year'; COMMIT; Explanation: This script begins with a `BEGIN` statement to start a transaction. The `SET TRANSACTION ISOLATION LEVEL` command ensures that the operation uses the appropriate isolation level to prevent reading data that has been modified but not committed by other transactions (dirty reads), improving performance during the deletion. The `DELETE` operation then removes records older than one year, leveraging the existing index on `transaction_date` for faster execution. Finally, the `COMMIT` statement ensures that all changes are saved permanently, maintaining data integrity and consistency. Learning tip: Refresh your SQL scripting skills before your next interview or assessment with the Learning SQL Scripting with Leo Messi learning path in CodeSignal Learn. Practice joins, functions, conditional logic, and more using stats from soccer star Lionel Messi‚Äôs career as your database. Advanced SQL interview questions (5 years experience or more) SQL optimization techniques and handling large datasets

---

#### You have a table `large_sales` with millions of rows and a composite index on `(customer_id, sale_date) named `idx_customer_date`. Write an optimized SQL query to retrieve the total sales amount for each `customer_id` in the year 2023, considering the potential performance impact due to the dataset size.

Example Answer: SELECT customer_id, SUM(sale_amount) AS total_sales FROM large_sales WHERE sale_date BETWEEN '2023-01-01' AND '2023-12-31' GROUP BY customer_id USE INDEX (idx_customer_date); Explanation: This query retrieves the total sales amount for each `customer_id` for the year 2023 from a very large dataset. By specifying the `USE INDEX` hint, the query explicitly directs the database to utilize the composite index on `(customer_id, sale_date)` to optimize the filtering and grouping operations instead of an index on just `sale_date`. This is crucial for maintaining performance when dealing with large datasets, as it minimizes the amount of data scanned. Advanced data modeling and stored procedures

---

#### Design a stored procedure named `UpdateEmployeeDepartment` that transfers an employee to a new department while ensuring that the new department‚Äôs `budget` is not exceeded. Assume that `employees` and `departments` tables exist, with `employees` containing `employee_id`, `department_id`, and `salary`, and `departments` containing `department_id`, `budget`, and `current_expenditure`.

Example Answer: DELIMITER // CREATE PROCEDURE UpdateEmployeeDepartment(IN emp_id INT, IN new_dept_id INT) BEGIN DECLARE emp_salary DECIMAL(10,2); DECLARE current_expenditure DECIMAL(10,2); DECLARE dept_budget DECIMAL(10,2); SELECT salary INTO emp_salary FROM employees WHERE employee_id = emp_id; SELECT current_expenditure, budget INTO current_expenditure, dept_budget FROM departments WHERE department_id = new_dept_id; IF current_expenditure + emp_salary <= dept_budget THEN UPDATE employees SET department_id = new_dept_id WHERE employee_id = emp_id; UPDATE departments SET current_expenditure = current_expenditure + emp_salary WHERE department_id = new_dept_id; ELSE SIGNAL SQLSTATE '45000' SET MESSAGE_TEXT = 'Budget exceeded for the new department'; END IF; END // DELIMITER ; Explanation: This stored procedure first retrieves the salary of the employee being transferred and the budget and current expenditure of the target department. It then checks if adding the employee‚Äôs salary to the department‚Äôs current expenditure would exceed the department‚Äôs budget. If not, the employee is transferred, and the department‚Äôs expenditure is updated. If the budget would be exceeded, the procedure raises an error, ensuring budget constraints are respected. This approach demonstrates advanced data modeling by handling complex relationships between entities in the database. Database architecture considerations and triggers

---

#### Write a trigger named `CheckInventoryBeforeInsert` that prevents the insertion of a new order in the `orders` table if the total quantity of items ordered exceeds the available stock in the `inventory` table. Assume the `orders` table has `product_id` and `quantity` columns, and the `inventory` table has `product_id` and `stock_quantity` columns.

Example Answer: DELIMITER // CREATE TRIGGER CheckInventoryBeforeInsert BEFORE INSERT ON orders FOR EACH ROW BEGIN DECLARE available_stock INT; SELECT stock_quantity INTO available_stock FROM inventory WHERE product_id = NEW.product_id; IF NEW.quantity > available_stock THEN SIGNAL SQLSTATE '45000' SET MESSAGE_TEXT = 'Insufficient stock for the product'; END IF; END // DELIMITER ; Explanation: This trigger executes before a new order is inserted into the `orders` table. It checks if the quantity being ordered exceeds the available stock in the `inventory` table. If the order quantity is greater than the available stock, the trigger prevents the insert operation by raising an error. This ensures that the database maintains data integrity and consistency, crucial for systems where inventory management is critical. It also reflects an understanding of how triggers can enforce business rules at the database level, which is a key consideration in robust database architecture. Hard SQL server interview questions for senior developers (10+ years of experience) High-availability solutions and disaster recovery strategies

---

#### Can you describe a high-availability solution for an SQL Server environment, and how you would implement a disaster recovery plan to minimize downtime and data loss?

Example Answer: I would use Always On Availability Groups for high availability, setting up primary and secondary replicas across different servers, ideally in separate geographic locations. The primary replica handles transactions, while secondary replicas are kept in sync. For disaster recovery, I‚Äôd configure a secondary replica in a remote data center with automatic failover. This setup ensures minimal downtime and no data loss if the primary server fails. I‚Äôd also establish regular backups and test the failover process to ensure reliability. Performance tuning complex systems

---

#### Can you walk me through your approach to diagnosing and resolving performance issues in a complex SQL Server system with multiple large databases?

Example Answer: I start by analyzing wait statistics to find bottlenecks like CPU or I/O issues. Then, I examine query execution plans to spot inefficiencies, such as unnecessary table scans. For optimization, I may tune indexes, rewrite queries, or partition large tables. I also check system configurations, such as memory and I/O settings, and ensure regular maintenance tasks like index rebuilding are in place to keep performance stable. Security best practices in SQL server management

---

#### What are some of the security best practices you follow when setting up and managing SQL Server databases?

Example Answer: I follow the principle of least privilege, assigning minimal permissions needed for tasks. I integrate SQL Server with Active Directory for secure authentication and use encryption for sensitive data with tools like Transparent Data Encryption (TDE). I also ensure SQL Server is regularly patched and perform security audits to monitor for unauthorized access. Regular reviews of activity logs help me quickly detect and respond to any security issues. SQL performance tuning interview questions Query optimization and execution plans analysis

---

#### How do you approach optimizing a slow-running query in SQL Server, and what role do execution plans play in this process?

Example Answer: When optimizing a slow query, I start by analyzing its execution plan to identify bottlenecks like full table scans or expensive joins. The execution plan shows how SQL Server processes the query, helping me spot inefficiencies. Based on the plan, I might rewrite the query, add or modify indexes, or adjust the query structure to reduce processing time. I continually review the updated execution plan to ensure the changes improve performance. Index management and query optimization

---

#### Can you explain your process for managing indexes to ensure efficient query performance in SQL Server?

Example Answer: I regularly monitor index usage to identify underutilized or missing indexes. If a query is slow, I check the execution plan to see if an index could improve performance. I also evaluate existing indexes to ensure they are not redundant or overlapping, which could cause unnecessary overhead. Periodically, I perform index maintenance, such as rebuilding or reorganizing fragmented indexes, to keep the database performing optimally. SQL server profiler and database tuning advisor

---

#### How do you use SQL Server Profiler and Database Tuning Advisor to enhance database performance?

Example Answer: I use SQL Server Profiler to capture and analyze slow-running queries or resource-intensive operations. The trace data helps me identify patterns and specific queries that need optimization. Then, I run these queries through the Database Tuning Advisor, which provides recommendations for indexing, partitioning, and other optimizations. This combination allows me to make data-driven decisions to enhance performance while avoiding guesswork. Role-based SQL interview questions SQL developer interview questions Development environment setup and debugging SQL scripts

---

#### Write a SQL script that sets up a development environment by creating a new schema named `dev_environment`, and within that schema, create a table `test_data` with columns `id` (INT, primary key) and `value` (VARCHAR). Then, include a statement to debug by inserting a sample record into the `test_data` table and verifying that the record was correctly inserted.

Example Answer: CREATE SCHEMA dev_environment; CREATE TABLE dev_environment.test_data ( id INT PRIMARY KEY, value VARCHAR(100) ); INSERT INTO dev_environment.test_data (id, value) VALUES (1, 'Sample Data'); -- Debugging step: Check the inserted record SELECT * FROM dev_environment.test_data WHERE id = 1; Explanation: This script first creates a new schema named `dev_environment` to organize the development environment. It then creates a `test_data` table within that schema with an `id` column as the primary key and a `value` column for storing text data. The script includes a sample `INSERT` statement to add a record to the `test_data` table and a `SELECT` statement to verify that the insertion was successful. This approach helps in setting up a consistent development environment while also incorporating basic debugging practices. Code versioning in SQL and best practices in database schema design

---

#### Write a SQL script to create a version-controlled stored procedure that adds a new column `email` (VARCHAR) to an existing `users` table. Include comments that explain the purpose of the changes and a method to rollback the change if needed.

Example Answer: -- Version 1.1: Adding an email column to users table -- Purpose: To store email addresses of users ALTER TABLE users ADD email VARCHAR(255); -- Rollback script: Remove the email column if the change needs to be undone -- Version 1.1 Rollback -- Purpose: To rollback the addition of the email column in case of issues -- ALTER TABLE users -- DROP COLUMN email; Explanation: This script demonstrates best practices in code versioning and schema design. It includes an `ALTER TABLE` statement to add an `email` column to the `users` table, following a versioning format in the comments to track changes. The comments clearly explain the purpose of the update. Additionally, the script provides a rollback mechanism (commented out) to remove the `email` column if the change needs to be undone, promoting safe and controlled schema changes. SQL interview questions for data analysts SQL for data extraction and analytical functions in SQL

---

#### Write a SQL query that extracts the total sales and calculates the average sales per month for each product in the `sales` table. The table contains `product_id`, `sale_date`, and `sale_amount` columns. Use SQL analytical functions to achieve this.

Example Answer: WITH monthly_sales AS ( SELECT product_id, EXTRACT(YEAR FROM sale_date) AS sale_year, EXTRACT(MONTH FROM sale_date) AS sale_month, SUM(sale_amount) AS monthly_total_sales FROM sales GROUP BY product_id, EXTRACT(YEAR FROM sale_date), EXTRACT(MONTH FROM sale_date) ) SELECT product_id, SUM(monthly_total_sales) AS total_sales, AVG(monthly_total_sales) AS avg_monthly_sales FROM monthly_sales GROUP BY product_id; Explanation: This query uses SQL analytical functions to calculate the total sales and the average monthly sales for each product. The `SUM(sale_amount)` function aggregates the sales by `product_id`, month, and year. The `AVG()` function calculates the average of these monthly totals. This allows for a detailed analysis of sales patterns across products on a monthly basis. Advanced reporting techniques and data visualization with SQL

---

#### Write a SQL query to generate a report that shows the cumulative sales by month for the current year for each region. The `sales` table includes `region`, `sale_date`, and `sale_amount` columns. Ensure the report is ordered by region and month.

Example Answer: SELECT region, EXTRACT(MONTH FROM sale_date) AS sale_month, SUM(sale_amount) AS monthly_sales, SUM(SUM(sale_amount)) OVER (PARTITION BY region ORDER BY EXTRACT(MONTH FROM sale_date)) AS cumulative_sales FROM sales WHERE EXTRACT(YEAR FROM sale_date) = EXTRACT(YEAR FROM CURRENT_DATE) GROUP BY region, EXTRACT(MONTH FROM sale_date) ORDER BY region, sale_month; Explanation: This query produces an advanced report that shows both monthly and cumulative sales by region for the current year. The `SUM(sale_amount)` function calculates the monthly sales per region. The cumulative sales are calculated using `SUM(SUM(sale_amount)) OVER (PARTITION BY region ORDER BY EXTRACT(MONTH FROM sale_date))`, which sums the monthly totals progressively. The report is ordered by region and then by month, making it useful for visualizations that track sales trends across regions over time. SQL interview questions for data engineers ETL processes and data quality + cleaning

---

#### Write a SQL script that performs an ETL (Extract, Transform, Load) process to clean and load data from a `raw_sales` table into a `cleaned_sales` table. The `raw_sales` table contains `sale_id`, `sale_date`, `product_id`, `sale_amount`, and `customer_id`, where `sale_amount` may contain null or negative values. Clean the data by removing rows with null or negative `sale_amount`, and load the cleaned data into the `cleaned_sales` table.

Example Answer: -- Step 1: Extract and Clean Data INSERT INTO cleaned_sales (sale_id, sale_date, product_id, sale_amount, customer_id) SELECT sale_id, sale_date, product_id, sale_amount, customer_id FROM raw_sales WHERE sale_amount IS NOT NULL AND sale_amount > 0; -- Step 2: Optional additional transformations can be applied here Explanation: This script performs a basic ETL operation by extracting data from the `raw_sales` table, cleaning it by removing rows where `sale_amount` is null or negative, and then loading the cleaned data into the `cleaned_sales` table. This ensures that only valid sales data is stored in the `cleaned_sales` table, improving data quality for further analysis or reporting. Data warehousing with SQL and SQL in data pipeline design

---

#### Design a SQL query that aggregates daily sales data from a `daily_sales` table and loads it into a `monthly_sales_summary` table. The `daily_sales` table contains `sale_date`, `product_id`, and `sale_amount`. The `monthly_sales_summary` table should store `year`, `month`, `product_id`, and `total_sales`.

Example Answer: -- Step 1: Aggregate Daily Sales into Monthly Totals INSERT INTO monthly_sales_summary (year, month, product_id, total_sales) SELECT EXTRACT(YEAR FROM sale_date) AS year, EXTRACT(MONTH FROM sale_date) AS month, product_id, SUM(sale_amount) AS total_sales FROM daily_sales GROUP BY EXTRACT(YEAR FROM sale_date), EXTRACT(MONTH FROM sale_date), product_id; -- Step 2: This data can now be used for reporting or further analysis Explanation: This query aggregates daily sales data into monthly totals, which are then stored in the `monthly_sales_summary` table. The `EXTRACT(YEAR FROM sale_date)` and `EXTRACT(MONTH FROM sale_date)` functions are used to group the data by year and month. The `SUM(sale_amount)` function calculates the total sales per product for each month. This process is a common step in data warehousing, where data is aggregated and summarized for more efficient storage and faster querying. Scenario-based SQL interview questions Real-world problem-solving with SQL and handling corrupt data

---

#### Can you describe how you would handle a situation where you find corrupt data in a critical production table, such as missing or invalid values in key columns?

Example Answer: If I encounter corrupt data in a production table, my first step would be to identify the extent of the corruption by running queries that check for anomalies like nulls in non-nullable columns or invalid data types. Once identified, I would create a backup of the affected data to ensure we have a recovery point. Next, I‚Äôd isolate the problematic records and attempt to correct them, either by referencing backup data, if available, or by applying business rules to regenerate the correct values. If the corruption is widespread, I might consider restoring the table from a backup, followed by reapplying any subsequent valid changes. I would also investigate the root cause to prevent future occurrences, possibly by adding constraints or triggers to enforce data integrity. Optimizing slow-running queries and simulating concurrency scenarios

---

#### How would you approach optimizing a slow-running query in a high-traffic database, especially considering potential concurrency issues?

Example Answer: I would start by analyzing the query execution plan to identify inefficiencies like table scans, missing indexes, or suboptimal join operations. If the issue is related to indexing, I would add or adjust indexes to reduce the query‚Äôs execution time. Additionally, I‚Äôd consider query refactoring to eliminate unnecessary complexity. Given the high-traffic environment, I‚Äôd also assess the query‚Äôs impact on concurrency. For example, I would check for locking or blocking issues that could be slowing down the system and might use techniques like query hints or isolation level adjustments to minimize contention. Finally, I would test the optimized query in a staging environment under simulated load to ensure that it performs well and doesn‚Äôt introduce new concurrency issues. SQL for data migration tasks

---

#### Can you walk me through your process for migrating large datasets from one SQL Server to another, ensuring minimal downtime and data integrity?

Example Answer: In a large-scale data migration, my first step is to plan and document the migration process, including identifying dependencies, assessing data volume, and estimating downtime. I usually start by performing a full backup of the source database to ensure we have a recovery point. To minimize downtime, I‚Äôd consider using techniques like log shipping or database mirroring to keep the target database up-to-date with changes made during the migration process. Before the final cutover, I‚Äôd perform a series of test migrations on a staging environment to verify that the data is correctly transferred and that the target environment functions as expected. During the final migration, I‚Äôd carefully monitor the process, validating data integrity through checksums or row counts, and ensure that all necessary application connections are redirected to the new server. Post-migration, I‚Äôd run thorough tests to confirm everything is working correctly and that there are no data integrity issues. Learning tip: Practice interview skills for behavioral interviews, recruiter screens, and panel interviews in CodeSignal Learn‚Äôs Behavioral Interview Practice for CS Students learning path. Engage in live mock interviews with an advanced AI agent and get immediate feedback on your performance from our AI tutor and guide, Cosmo. Common SQL interview questions (if you have limited time to practice) Essential SQL functions

---

#### Write a SQL query to calculate the total number of orders and the average order amount from an `orders` table. The table contains columns `order_id`, `order_date`, and `order_amount`.

Example Answer: SELECT COUNT(order_id) AS total_orders, AVG(order_amount) AS average_order_amount FROM orders; Explanation: This query uses two essential SQL aggregate functions: `COUNT()` and `AVG()`. The `COUNT(order_id)` function calculates the total number of orders, while `AVG(order_amount)` calculates the average order amount across all orders. These functions are fundamental for summarizing data and generating insights from an SQL table. SQL debugging

---

#### You‚Äôve written a query that doesn‚Äôt return the expected results. Describe how you would debug the issue, assuming you are dealing with a simple `SELECT` statement.

Example Answer: -- Original query SELECT * FROM customers WHERE last_name = 'Smith'; -- Debugging steps -- 1. Check if the condition is too restrictive or misspelled SELECT * FROM customers WHERE last_name LIKE '%Smith%'; -- 2. Verify the data SELECT DISTINCT last_name FROM customers; -- 3. Test a simplified version of the query SELECT * FROM customers WHERE 1 = 1; -- 4. Check for case sensitivity issues (if the database is case-sensitive) SELECT * FROM customers WHERE LOWER(last_name) = 'smith'; -- 5. Ensure there are no leading/trailing spaces SELECT * FROM customers WHERE TRIM(last_name) = 'Smith'; Explanation: The debugging process involves several steps. First, I‚Äôd check if the condition might be too restrictive or if there‚Äôs a typo by using a broader condition, like `LIKE`. Then, I‚Äôd verify the data by querying distinct values to see if the data matches the expected condition. Next, I‚Äôd run a simplified version of the query (`WHERE 1 = 1`) to confirm the basic query structure is sound. If your database is case-sensitive, Smith and smith would be treated differently. To avoid case sensitivity issues, you can use LOWER(last_name) = ‚Äòsmith‚Äô or UPPER(last_name) = ‚ÄòSMITH‚Äô.  Finally, data might have leading or trailing spaces that affect the match. Using TRIM(last_name) = ‚ÄòSmith‚Äô ensures that such spaces are removed before comparison. These steps help quickly identify common issues. Efficient query writing and key SQL clauses

---

#### Write an efficient SQL query to retrieve all unique product names from a `products` table that has a `product_name` column, and ensure the results are sorted alphabetically.

Example Answer: SELECT DISTINCT product_name FROM products ORDER BY product_name ASC; Explanation: This query retrieves all unique product names using the `DISTINCT` clause, ensuring that no duplicates appear in the results. The `ORDER BY` clause sorts the product names alphabetically (`ASC`). Using `DISTINCT` in combination with `ORDER BY` is a common practice to write efficient queries that provide meaningful, well-organized results. Critical performance factors

---

#### Given a `sales` table with millions of records, write an optimized SQL query to retrieve the total sales amount for each `region` from the current year. The table includes `sale_id`, `region`, `sale_date`, and `sale_amount` columns.

Example Answer: SELECT region, SUM(sale_amount) AS total_sales FROM sales WHERE EXTRACT(YEAR FROM sale_date) = EXTRACT(YEAR FROM CURRENT_DATE) GROUP BY region; Explanation: This query efficiently calculates the total sales amount for each `region` by limiting the dataset to the current year using the `EXTRACT(YEAR FROM sale_date)` function in the `WHERE` clause. The `SUM(sale_amount)` function aggregates the sales for each `region`, and the `GROUP BY` clause organizes the results by region. This approach optimizes performance by reducing the data processed and ensures that the query scales well with large datasets.

---

#### SELECT mgr.employee_id,mgr.name,COUNT(emp.name) AS reports_count,ROUND(AVG(emp.age)) AS average_age

FROM employees_1731 mgr INNER JOIN employees_1731 emp ON mgr.employee_id = emp.reports_to GROUP BY mgr.employee_id,mgr.name ORDER BY mgr.employee_id;

---

#### WITH employee_departments AS (

SELECT *, COUNT(employee_id) OVER (PARTITION BY employee_id) AS cnt FROM employee_1789 ) SELECT employee_id,department_id FROM employee_departments WHERE primary_flag = 'Y' OR (primary_flag = 'N' AND cnt = 1);

---

#### -- Question 42

-- Table: Views -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | article_id    | int     | -- | author_id     | int     | -- | viewer_id     | int     | -- | view_date     | date    | -- +---------------+---------+ -- There is no primary key for this table, it may have duplicate rows. -- Each row of this table indicates that some viewer viewed an article (written by some author) on some date. -- Note that equal author_id and viewer_id indicate the same person. -- Write an SQL query to find all the authors that viewed at least one of their own articles, sorted in ascending order by their id. -- The query result format is in the following example: -- Views table: -- +------------+-----------+-----------+------------+ -- | article_id | author_id | viewer_id | view_date  | -- +------------+-----------+-----------+------------+ -- | 1          | 3         | 5         | 2019-08-01 | -- | 1          | 3         | 6         | 2019-08-02 | -- | 2          | 7         | 7         | 2019-08-01 | -- | 2          | 7         | 6         | 2019-08-02 | -- | 4          | 7         | 1         | 2019-07-22 | -- | 3          | 4         | 4         | 2019-07-21 | -- | 3          | 4         | 4         | 2019-07-21 | -- +------------+-----------+-----------+------------+ -- Result table: -- +------+ -- | id   | -- +------+ -- | 4    | -- | 7    | -- +------+ -- Solution select distinct author_id as id from views where author_id = viewer_id order by author_id

---

#### SELECT num

FROM number_619 GROUP BY num HAVING COUNT(num) = 1 ORDER BY num DESC LIMIT 1;

---

#### SELECT COUNT(DISTINCT t1.company_id) AS co_w_duplicate_jobs

FROM  job_listings t1 JOIN job_listings t2 on t1.company_id = t2.company_id WHERE t1.title = t2.title AND t1.description = t2.description AND t1.job_id !=t2.job_id

---

#### CREATE OR REPLACE FUNCTION unpivot_products_2253()

RETURNS TEXT LANGUAGE PLPGSQL AS $$ DECLARE stores_array TEXT[]; query_text TEXT := ''; store_name TEXT; BEGIN --query to find all the stores columns of the products table except product_id column SELECT ARRAY_AGG(column_name) INTO stores_array FROM information_schema.columns WHERE table_name = 'products_2253' AND column_name <> 'product_id'; -- prepare query FOREACH store_name IN ARRAY stores_array LOOP query_text := query_text || 'SELECT product_id, ''' || store_name || ''' AS store, "' || store_name ||'" FROM products_2253 WHERE "' || store_name || '" IS NOT NULL'; query_text := query_text || ' UNION '; END LOOP; query_text := LEFT(query_text,LENGTH(query_text)-6); query_text := query_text || ' ORDER BY product_id,store;'; --return the query as text RETURN query_text; END $$; SELECT unpivot_products_2253(); -- output of the function: SELECT product_id, 'LC_Store' AS store, "LC_Store" FROM products_2253 WHERE "LC_Store" IS NOT NULL UNION SELECT product_id, 'Nozama' AS store, "Nozama" FROM products_2253 WHERE "Nozama" IS NOT NULL UNION SELECT product_id, 'Shop' AS store, "Shop" FROM products_2253 WHERE "Shop" IS NOT NULL UNION SELECT product_id, 'Souq' AS store, "Souq" FROM products_2253 WHERE "Souq" IS NOT NULL ORDER BY product_id,store; --running this query manually will give us expected results

---

#### SELECT a.player_id,a.event_date,SUM(b.games_played)

FROM activity_534 a JOIN activity_534 b ON a.player_id = b.player_id AND a.event_date >= b.event_date GROUP BY a.player_id,a.event_date ORDER BY 1,2; (OR) SELECT player_id,event_date, SUM(games_played) OVER w AS games_played FROM activity_534 WINDOW w AS (PARTITION BY player_id ORDER BY event_date);

---

#### -- Question 27

-- Table: Product -- +--------------+---------+ -- | Column Name  | Type    | -- +--------------+---------+ -- | product_id   | int     | -- | product_name | varchar | -- | unit_price   | int     | -- +--------------+---------+ -- product_id is the primary key of this table. -- Table: Sales -- +-------------+---------+ -- | Column Name | Type    | -- +-------------+---------+ -- | seller_id   | int     | -- | product_id  | int     | -- | buyer_id    | int     | -- | sale_date   | date    | -- | quantity    | int     | -- | price       | int     | -- +------ ------+---------+ -- This table has no primary key, it can have repeated rows. -- product_id is a foreign key to Product table. -- Write an SQL query that reports the best seller by total sales price, If there is a tie, report them all. -- The query result format is in the following example: -- Product table: -- +------------+--------------+------------+ -- | product_id | product_name | unit_price | -- +------------+--------------+------------+ -- | 1          | S8           | 1000       | -- | 2          | G4           | 800        | -- | 3          | iPhone       | 1400       | -- +------------+--------------+------------+ -- Sales table: -- +-----------+------------+----------+------------+----------+-------+ -- | seller_id | product_id | buyer_id | sale_date  | quantity | price | -- +-----------+------------+----------+------------+----------+-------+ -- | 1         | 1          | 1        | 2019-01-21 | 2        | 2000  | -- | 1         | 2          | 2        | 2019-02-17 | 1        | 800   | -- | 2         | 2          | 3        | 2019-06-02 | 1        | 800   | -- | 3         | 3          | 4        | 2019-05-13 | 2        | 2800  | -- +-----------+------------+----------+------------+----------+-------+ -- Result table: -- +-------------+ -- | seller_id   | -- +-------------+ -- | 1           | -- | 3           | -- +-------------+ -- Both sellers with id 1 and 3 sold products with the most total price of 2800. -- Solution Select a.seller_id from (select seller_id, rank() over(order by sum(price) desc) as rk from sales group by seller_id) a where a.rk=1

---

#### -- Question 52

-- Write a SQL query to find all numbers that appear at least three times consecutively. -- +----+-----+ -- | Id | Num | -- +----+-----+ -- | 1  |  1  | -- | 2  |  1  | -- | 3  |  1  | -- | 4  |  2  | -- | 5  |  1  | -- | 6  |  2  | -- | 7  |  2  | -- +----+-----+ -- For example, given the above Logs table, 1 is the only number that appears consecutively for at least three times. -- +-----------------+ -- | ConsecutiveNums | -- +-----------------+ -- | 1               | -- +-----------------+ -- Solution select distinct a.num as ConsecutiveNums from( select *, lag(num) over() as prev, lead(num) over() as next from logs) a where a.num = a.prev and a.num=a.next

---

#### -- Question 65

-- Table: Events -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | business_id   | int     | -- | event_type    | varchar | -- | occurences    | int     | -- +---------------+---------+ -- (business_id, event_type) is the primary key of this table. -- Each row in the table logs the info that an event of some type occured at some business for a number of times. -- Write an SQL query to find all active businesses. -- An active business is a business that has more than one event type with occurences greater than the average occurences of that event type among all businesses. -- The query result format is in the following example: -- Events table: -- +-------------+------------+------------+ -- | business_id | event_type | occurences | -- +-------------+------------+------------+ -- | 1           | reviews    | 7          | -- | 3           | reviews    | 3          | -- | 1           | ads        | 11         | -- | 2           | ads        | 7          | -- | 3           | ads        | 6          | -- | 1           | page views | 3          | -- | 2           | page views | 12         | -- +-------------+------------+------------+ -- Result table: -- +-------------+ -- | business_id | -- +-------------+ -- | 1           | -- +-------------+ -- Average for 'reviews', 'ads' and 'page views' are (7+3)/2=5, (11+7+6)/3=8, (3+12)/2=7.5 respectively. -- Business with id 1 has 7 'reviews' events (more than 5) and 11 'ads' events (more than 8) so it is an active business. -- Solution select c.business_id from( select * from events e join (select event_type as event, round(avg(occurences),2) as average from events group by event_type) b on e.event_type = b.event) c where c.occurences>c.average group by c.business_id having count(*) > 1

---

#### WITH trans AS (

SELECT paid_by AS usr,amount*-1 AS amount FROM transactions_1555 UNION ALL SELECT paid_to AS usr,amount FROM transactions_1555 ), agg_trans AS ( SELECT usr,SUM(amount) AS cr FROM trans GROUP BY usr ) SELECT u.user_id,u.user_name,(COALESCE(t.cr,0)+u.credit) AS credit, CASE WHEN (COALESCE(t.cr,0)+u.credit) < 0 THEN 'Yes' ELSE 'No' END AS credit_limit_breached FROM users_1555 u LEFT JOIN agg_trans t ON t.usr = u.user_id;

---

#### WITH cte AS(

SELECT product_id,MAX(change_date) AS max_date FROM products_1164 WHERE change_date <= '2019-08-16' GROUP BY product_id ) SELECT p.product_id, MAX(CASE WHEN c.product_id IS NULL THEN 10 WHEN p.change_date = c.max_date THEN p.new_price END) AS price FROM products_1164 p LEFT JOIN cte c ON p.product_id = c.product_id GROUP BY p.product_id ORDER BY p.product_id;

---

#### SELECT player_id,MIN(event_date) AS first_login

FROM activity_511 GROUP BY player_id ORDER BY player_id; (OR) WITH ranked AS( SELECT *,DENSE_RANK() OVER w AS rnk FROM activity_511 WINDOW w AS (PARTITION BY player_id ORDER BY event_date) ) SELECT player_id,event_date FROM ranked WHERE rnk = 1 ORDER BY player_id;

---

#### SELECT actor_id,director_id

FROM actor_director_1050 GROUP BY actor_id,director_id HAVING COUNT(1)>=3;

---

#### SELECT product_id,year,quantity,price

FROM sales_1068 WHERE (product_id,year) IN (SELECT product_id,MIN(year) FROM sales_1068 GROUP BY product_id);

---

#### -- Question 45

-- Table: Products -- +------------------+---------+ -- | Column Name      | Type    | -- +------------------+---------+ -- | product_id       | int     | -- | product_name     | varchar | -- | product_category | varchar | -- +------------------+---------+ -- product_id is the primary key for this table. -- This table contains data about the company's products. -- Table: Orders -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | product_id    | int     | -- | order_date    | date    | -- | unit          | int     | -- +---------------+---------+ -- There is no primary key for this table. It may have duplicate rows. -- product_id is a foreign key to Products table. -- unit is the number of products ordered in order_date. -- Write an SQL query to get the names of products with greater than or equal to 100 units ordered in February 2020 and their amount. -- Return result table in any order. -- The query result format is in the following example: -- Products table: -- +-------------+-----------------------+------------------+ -- | product_id  | product_name          | product_category | -- +-------------+-----------------------+------------------+ -- | 1           | Leetcode Solutions    | Book             | -- | 2           | Jewels of Stringology | Book             | -- | 3           | HP                    | Laptop           | -- | 4           | Lenovo                | Laptop           | -- | 5           | Leetcode Kit          | T-shirt          | -- +-------------+-----------------------+------------------+ -- Orders table: -- +--------------+--------------+----------+ -- | product_id   | order_date   | unit     | -- +--------------+--------------+----------+ -- | 1            | 2020-02-05   | 60       | -- | 1            | 2020-02-10   | 70       | -- | 2            | 2020-01-18   | 30       | -- | 2            | 2020-02-11   | 80       | -- | 3            | 2020-02-17   | 2        | -- | 3            | 2020-02-24   | 3        | -- | 4            | 2020-03-01   | 20       | -- | 4            | 2020-03-04   | 30       | -- | 4            | 2020-03-04   | 60       | -- | 5            | 2020-02-25   | 50       | -- | 5            | 2020-02-27   | 50       | -- | 5            | 2020-03-01   | 50       | -- +--------------+--------------+----------+ -- Result table: -- +--------------------+---------+ -- | product_name       | unit    | -- +--------------------+---------+ -- | Leetcode Solutions | 130     | -- | Leetcode Kit       | 100     | -- +--------------------+---------+ -- Products with product_id = 1 is ordered in February a total of (60 + 70) = 130. -- Products with product_id = 2 is ordered in February a total of 80. -- Products with product_id = 3 is ordered in February a total of (2 + 3) = 5. -- Products with product_id = 4 was not ordered in February 2020. -- Products with product_id = 5 is ordered in February a total of (50 + 50) = 100. -- Solution Select a.product_name, a.unit from (select p.product_name, sum(unit) as unit from orders o join products p on o.product_id = p.product_id where month(order_date)=2 and year(order_date) = 2020 group by o.product_id) a where a.unit>=100

---

#### -- Question 25

-- Table point holds the x coordinate of some points on x-axis in a plane, which are all integers. -- Write a query to find the shortest distance between two points in these points. -- | x   | -- |-----| -- | -1  | -- | 0   | -- | 2   | -- The shortest distance is '1' obviously, which is from point '-1' to '0'. So the output is as below: -- | shortest| -- |---------| -- | 1       | -- Note: Every point is unique, which means there is no duplicates in table point -- Solution select min(abs(abs(a.x)-abs(a.next_closest))) as shortest from( select *, lead(x) over(order by x) as next_closest from point) a

---

#### Basic Filtering and Aggregation

Scenario: Find top performing listings in a specific city -- Given tables: listings (listing_id, host_id, city, price_per_night, property_type, created_date) -- Write a query to find all listings in Paris with price > $100 per night,  -- showing the average price by property_type, ordered by average price descending

---

#### Simple JOIN

Scenario: Match hosts with their booking performance -- Given tables:  -- hosts (host_id, host_name, join_date, host_status) -- bookings (booking_id, listing_id, host_id, guest_id, check_in_date, check_out_date, total_price) -- Find all hosts who joined in 2024 and their total booking revenue

---

#### Multiple JOINs with Aggregation

Scenario: Analyze guest booking patterns and satisfaction -- Given tables: -- bookings (booking_id, guest_id, listing_id, check_in_date, nights_stayed, total_paid) -- reviews (review_id, booking_id, rating, review_date) -- guests (guest_id, signup_date, country) -- Find the average rating by guest country for bookings in the last 90 days

---

#### Subquery - Identifying High-Value Guests

Scenario: Find guests who spend above average -- Using the bookings table, identify guests whose average booking value  -- is higher than the overall average booking value -- Show guest_id and their average booking value

---

#### Self-JOIN - Finding Repeat Guests

Scenario: Identify guests who rebooked within 30 days -- Given bookings table, find all instances where the same guest  -- made another booking within 30 days of their previous checkout -- Show both booking IDs and the gap in days

---

#### Window Functions - Ranking

Scenario: Rank hosts by revenue within each city -- Given bookings and listings tables, rank hosts by their total revenue  -- within each city using ROW_NUMBER() or RANK() -- Show only the top 3 hosts per city

---

#### Window Functions - Running Totals

Scenario: Calculate cumulative bookings for marketing campaign analysis -- Given tables: -- bookings (booking_id, booking_date, channel_source) -- marketing_campaigns (campaign_id, channel_source, start_date, end_date, budget) -- Calculate daily bookings and cumulative bookings by channel_source  -- for the last 30 days using window functions

---

#### Complex Subquery with EXISTS

Scenario: Find hosts who've never received a bad review -- Find all hosts who have at least 10 bookings but have never  -- received a review with rating < 4 -- Use EXISTS or NOT EXISTS in your solution

---

#### Advanced Window Function - Lead/Lag

Scenario: Analyze pricing changes and occupancy -- Given tables: -- listing_calendar (listing_id, date, price, available) -- Calculate the price change from previous day for each listing -- and identify dates where price increased by more than 20% -- Also show the occupancy rate (7-day moving average) using window functions

---

#### Comprehensive Business Question

Scenario: Marketing Attribution and Customer Lifetime Value -- Given tables: -- users (user_id, signup_date, acquisition_channel, first_booking_date) -- bookings (booking_id, user_id, booking_date, total_value, booking_status) -- marketing_spend (date, channel, daily_spend) -- Calculate: -- 1. Customer acquisition cost (CAC) by channel for Q1 2024 -- 2. Average customer lifetime value (CLV) by acquisition channel -- 3. The ratio of CLV to CAC by channel -- 4. Identify channels where CLV/CAC > 3 -- Use CTEs or subqueries to build this analysis step by step Key SQL Concepts to Review: Essential Functions: ‚óè GROUP BY with HAVING ‚óè CASE WHEN statements ‚óè Date functions (DATE_DIFF, DATE_ADD, DATE_TRUNC) ‚óè String functions (CONCAT, SUBSTRING, REGEXP) Window Functions: ‚óè ROW_NUMBER(), RANK(), DENSE_RANK() ‚óè LAG(), LEAD() ‚óè SUM() OVER(), AVG() OVER() ‚óè Partition and ordering clauses Performance Considerations: ‚óè When to use CTEs vs subqueries ‚óè Index usage implications ‚óè Query optimization basics Tips for the Interview:

---

#### Business context - Connect your queries to business impact

I'll provide detailed solutions for all 10 questions with explanations and alternative approaches where relevant. SQL Solutions for Airbnb Interview Practice

---

#### Basic Filtering and Aggregation -- Solution:

SELECT property_type, AVG(price_per_night) as avg_price, COUNT(*) as listing_count FROM listings WHERE city = 'Paris' AND price_per_night > 100 GROUP BY property_type ORDER BY avg_price DESC; -- Alternative with ROUND for cleaner output: SELECT property_type, ROUND(AVG(price_per_night), 2) as avg_price, COUNT(*) as listing_count, MIN(price_per_night) as min_price, MAX(price_per_night) as max_price FROM listings WHERE city = 'Paris' AND price_per_night > 100 GROUP BY property_type HAVING COUNT(*) >= 5  -- Only show property types with at least 5 listings ORDER BY avg_price DESC;

---

#### Simple JOIN -- Solution:

SELECT h.host_id, h.host_name, h.join_date, COUNT(DISTINCT b.booking_id) as total_bookings, SUM(b.total_price) as total_revenue FROM hosts h LEFT JOIN bookings b ON h.host_id = b.host_id WHERE YEAR(h.join_date) = 2024 GROUP BY h.host_id, h.host_name, h.join_date ORDER BY total_revenue DESC; -- Note: Using LEFT JOIN to include hosts with no bookings yet -- Could use COALESCE to handle NULL values: SELECT h.host_id, h.host_name, h.join_date, COALESCE(COUNT(DISTINCT b.booking_id), 0) as total_bookings, COALESCE(SUM(b.total_price), 0) as total_revenue FROM hosts h LEFT JOIN bookings b ON h.host_id = b.host_id WHERE YEAR(h.join_date) = 2024 GROUP BY h.host_id, h.host_name, h.join_date ORDER BY total_revenue DESC;

---

#### Multiple JOINs with Aggregation -- Solution:

SELECT g.country, COUNT(DISTINCT b.booking_id) as total_bookings, AVG(r.rating) as avg_rating, COUNT(DISTINCT r.review_id) as total_reviews FROM bookings b INNER JOIN reviews r ON b.booking_id = r.booking_id INNER JOIN guests g ON b.guest_id = g.guest_id WHERE b.check_in_date >= CURRENT_DATE - INTERVAL '90 days' -- Or: WHERE b.check_in_date >= DATE_SUB(CURRENT_DATE, INTERVAL 90 DAY) GROUP BY g.country HAVING COUNT(DISTINCT b.booking_id) >= 10  -- Countries with meaningful sample size ORDER BY avg_rating DESC; -- Alternative with review completion rate: SELECT g.country, COUNT(DISTINCT b.booking_id) as total_bookings, ROUND(AVG(r.rating), 2) as avg_rating, COUNT(DISTINCT r.review_id) as total_reviews, ROUND(100.0 * COUNT(DISTINCT r.review_id) / COUNT(DISTINCT b.booking_id), 1) as review_rate FROM bookings b LEFT JOIN reviews r ON b.booking_id = r.booking_id INNER JOIN guests g ON b.guest_id = g.guest_id WHERE b.check_in_date >= CURRENT_DATE - INTERVAL '90 days' GROUP BY g.country ORDER BY avg_rating DESC;

---

#### Subquery - Identifying High-Value Guests -- Solution using subquery in WHERE:

SELECT guest_id, AVG(total_paid) as avg_booking_value, COUNT(*) as booking_count FROM bookings GROUP BY guest_id HAVING AVG(total_paid) > ( SELECT AVG(total_paid) FROM bookings ) ORDER BY avg_booking_value DESC; -- Alternative using CTE (often clearer): WITH overall_metrics AS ( SELECT AVG(total_paid) as overall_avg FROM bookings ) SELECT b.guest_id, AVG(b.total_paid) as avg_booking_value, COUNT(*) as booking_count, om.overall_avg, ROUND(AVG(b.total_paid) - om.overall_avg, 2) as diff_from_avg FROM bookings b CROSS JOIN overall_metrics om GROUP BY b.guest_id, om.overall_avg HAVING AVG(b.total_paid) > om.overall_avg ORDER BY avg_booking_value DESC;

---

#### Self-JOIN - Finding Repeat Guests -- Solution:

SELECT b1.guest_id, b1.booking_id as first_booking, b2.booking_id as repeat_booking, b1.check_in_date as first_checkin, b2.check_in_date as repeat_checkin, DATEDIFF(b2.check_in_date, DATE_ADD(b1.check_in_date, INTERVAL b1.nights_stayed DAY)) as days_between FROM bookings b1 INNER JOIN bookings b2 ON b1.guest_id = b2.guest_id AND b1.booking_id < b2.booking_id  -- Ensure we don't duplicate pairs AND b2.check_in_date <= DATE_ADD(b1.check_in_date, INTERVAL b1.nights_stayed + 30 DAY) AND b2.check_in_date > DATE_ADD(b1.check_in_date, INTERVAL b1.nights_stayed DAY) ORDER BY b1.guest_id, b1.check_in_date; -- Alternative with more details: SELECT b1.guest_id, b1.booking_id as first_booking, b2.booking_id as repeat_booking, b1.check_in_date as first_checkin, DATE_ADD(b1.check_in_date, INTERVAL b1.nights_stayed DAY) as first_checkout, b2.check_in_date as repeat_checkin, DATEDIFF(b2.check_in_date, DATE_ADD(b1.check_in_date, INTERVAL b1.nights_stayed DAY)) as gap_days FROM bookings b1 INNER JOIN bookings b2 ON b1.guest_id = b2.guest_id WHERE b2.check_in_date BETWEEN DATE_ADD(b1.check_in_date, INTERVAL b1.nights_stayed DAY) AND DATE_ADD(b1.check_in_date, INTERVAL b1.nights_stayed + 30 DAY) AND b1.booking_id < b2.booking_id ORDER BY gap_days ASC;

---

#### Window Functions - Ranking -- Solution:

WITH host_revenue AS ( SELECT l.city, b.host_id, SUM(b.total_paid) as total_revenue, COUNT(DISTINCT b.booking_id) as total_bookings FROM bookings b INNER JOIN listings l ON b.listing_id = l.listing_id GROUP BY l.city, b.host_id ), ranked_hosts AS ( SELECT city, host_id, total_revenue, total_bookings, ROW_NUMBER() OVER (PARTITION BY city ORDER BY total_revenue DESC) as revenue_rank, RANK() OVER (PARTITION BY city ORDER BY total_revenue DESC) as revenue_rank_with_ties, DENSE_RANK() OVER (PARTITION BY city ORDER BY total_revenue DESC) as dense_revenue_rank FROM host_revenue ) SELECT city, host_id, total_revenue, total_bookings, revenue_rank FROM ranked_hosts WHERE revenue_rank <= 3 ORDER BY city, revenue_rank; -- Simpler version without CTE: SELECT * FROM ( SELECT l.city, b.host_id, SUM(b.total_paid) as total_revenue, COUNT(*) as booking_count, ROW_NUMBER() OVER (PARTITION BY l.city ORDER BY SUM(b.total_paid) DESC) as rank FROM bookings b INNER JOIN listings l ON b.listing_id = l.listing_id GROUP BY l.city, b.host_id ) ranked WHERE rank <= 3 ORDER BY city, rank;

---

#### Window Functions - Running Totals -- Solution:

WITH daily_bookings AS ( SELECT DATE(booking_date) as booking_day, channel_source, COUNT(*) as daily_count FROM bookings WHERE booking_date >= CURRENT_DATE - INTERVAL '30 days' GROUP BY DATE(booking_date), channel_source ) SELECT booking_day, channel_source, daily_count, SUM(daily_count) OVER ( PARTITION BY channel_source ORDER BY booking_day ROWS UNBOUNDED PRECEDING ) as cumulative_bookings, AVG(daily_count) OVER ( PARTITION BY channel_source ORDER BY booking_day ROWS BETWEEN 6 PRECEDING AND CURRENT ROW ) as moving_avg_7day FROM daily_bookings ORDER BY channel_source, booking_day; -- Alternative with campaign budget utilization: WITH daily_metrics AS ( SELECT DATE(b.booking_date) as booking_day, b.channel_source, COUNT(*) as daily_bookings, SUM(b.total_paid) as daily_revenue, MAX(mc.budget) as campaign_budget FROM bookings b LEFT JOIN marketing_campaigns mc ON b.channel_source = mc.channel_source AND DATE(b.booking_date) BETWEEN mc.start_date AND mc.end_date WHERE b.booking_date >= CURRENT_DATE - INTERVAL '30 days' GROUP BY DATE(b.booking_date), b.channel_source ) SELECT booking_day, channel_source, daily_bookings, daily_revenue, SUM(daily_bookings) OVER (PARTITION BY channel_source ORDER BY booking_day) as cumulative_bookings, SUM(daily_revenue) OVER (PARTITION BY channel_source ORDER BY booking_day) as cumulative_revenue, campaign_budget, ROUND(100.0 * SUM(daily_revenue) OVER (PARTITION BY channel_source ORDER BY booking_day) / campaign_budget, 2) as budget_utilization_pct FROM daily_metrics ORDER BY channel_source, booking_day;

---

#### Complex Subquery with EXISTS -- Solution using NOT EXISTS:

SELECT h.host_id, COUNT(DISTINCT b.booking_id) as total_bookings, AVG(r.rating) as avg_rating FROM hosts h INNER JOIN bookings b ON h.host_id = b.host_id LEFT JOIN reviews r ON b.booking_id = r.booking_id WHERE NOT EXISTS ( SELECT 1 FROM bookings b2 INNER JOIN reviews r2 ON b2.booking_id = r2.booking_id WHERE b2.host_id = h.host_id AND r2.rating < 4 ) GROUP BY h.host_id HAVING COUNT(DISTINCT b.booking_id) >= 10 ORDER BY avg_rating DESC, total_bookings DESC; -- Alternative using subquery in WHERE: SELECT host_id, total_bookings, avg_rating, min_rating FROM ( SELECT b.host_id, COUNT(DISTINCT b.booking_id) as total_bookings, AVG(r.rating) as avg_rating, MIN(r.rating) as min_rating FROM bookings b LEFT JOIN reviews r ON b.booking_id = r.booking_id GROUP BY b.host_id HAVING COUNT(DISTINCT b.booking_id) >= 10 ) host_stats WHERE min_rating >= 4 OR min_rating IS NULL  -- Include hosts with no reviews yet ORDER BY avg_rating DESC, total_bookings DESC;

---

#### Advanced Window Function - Lead/Lag -- Solution:

WITH pricing_analysis AS ( SELECT listing_id, date, price, available, LAG(price, 1) OVER (PARTITION BY listing_id ORDER BY date) as prev_price, LEAD(price, 1) OVER (PARTITION BY listing_id ORDER BY date) as next_price, -- Calculate 7-day occupancy rate AVG(CASE WHEN available = FALSE THEN 1 ELSE 0 END) OVER ( PARTITION BY listing_id ORDER BY date ROWS BETWEEN 3 PRECEDING AND 3 FOLLOWING ) as occupancy_rate_7day FROM listing_calendar ) SELECT listing_id, date, price, prev_price, ROUND((price - prev_price) * 100.0 / prev_price, 2) as price_change_pct, ROUND(occupancy_rate_7day * 100, 2) as occupancy_pct, CASE WHEN (price - prev_price) * 100.0 / prev_price > 20 THEN 'Surge Pricing' WHEN (price - prev_price) * 100.0 / prev_price < -20 THEN 'Deep Discount' ELSE 'Normal' END as pricing_strategy FROM pricing_analysis WHERE prev_price IS NOT NULL AND (price - prev_price) * 100.0 / prev_price > 20  -- Filter for >20% increases ORDER BY listing_id, date; -- Alternative with more insights: WITH calendar_metrics AS ( SELECT listing_id, date, price, available, LAG(price, 1) OVER (PARTITION BY listing_id ORDER BY date) as prev_day_price, LAG(price, 7) OVER (PARTITION BY listing_id ORDER BY date) as prev_week_price, AVG(price) OVER ( PARTITION BY listing_id ORDER BY date ROWS BETWEEN 6 PRECEDING AND CURRENT ROW ) as avg_price_7day, SUM(CASE WHEN available = FALSE THEN 1 ELSE 0 END) OVER ( PARTITION BY listing_id ORDER BY date ROWS BETWEEN 6 PRECEDING AND CURRENT ROW ) * 100.0 / 7 as occupancy_rate_7day FROM listing_calendar ) SELECT listing_id, date, price, prev_day_price, ROUND((price - prev_day_price) * 100.0 / NULLIF(prev_day_price, 0), 2) as daily_price_change_pct, ROUND((price - prev_week_price) * 100.0 / NULLIF(prev_week_price, 0), 2) as weekly_price_change_pct, ROUND(price - avg_price_7day, 2) as diff_from_7day_avg, ROUND(occupancy_rate_7day, 1) as occupancy_pct FROM calendar_metrics WHERE date >= CURRENT_DATE - INTERVAL '30 days' AND prev_day_price IS NOT NULL ORDER BY listing_id, date DESC;

---

#### Comprehensive Business Question -- Solution:

WITH user_cohorts AS ( -- Get users who signed up in Q1 2024 SELECT user_id, acquisition_channel, signup_date, first_booking_date FROM users WHERE signup_date BETWEEN '2024-01-01' AND '2024-03-31' ), channel_acquisitions AS ( -- Count acquisitions by channel SELECT acquisition_channel, COUNT(DISTINCT user_id) as users_acquired, COUNT(DISTINCT CASE WHEN first_booking_date IS NOT NULL THEN user_id END) as users_with_bookings FROM user_cohorts GROUP BY acquisition_channel ), channel_spending AS ( -- Calculate total spend by channel for Q1 2024 SELECT channel, SUM(daily_spend) as total_spend FROM marketing_spend WHERE date BETWEEN '2024-01-01' AND '2024-03-31' GROUP BY channel ), user_ltv AS ( -- Calculate LTV for each user SELECT u.user_id, u.acquisition_channel, COUNT(b.booking_id) as total_bookings, SUM(b.total_value) as lifetime_value FROM user_cohorts u LEFT JOIN bookings b ON u.user_id = b.user_id AND b.booking_status = 'completed' GROUP BY u.user_id, u.acquisition_channel ), channel_ltv AS ( -- Average LTV by channel SELECT acquisition_channel, AVG(lifetime_value) as avg_ltv, PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY lifetime_value) as median_ltv, AVG(total_bookings) as avg_bookings_per_user FROM user_ltv GROUP BY acquisition_channel ), final_metrics AS ( -- Combine all metrics SELECT ca.acquisition_channel, ca.users_acquired, ca.users_with_bookings, ROUND(100.0 * ca.users_with_bookings / ca.users_acquired, 2) as conversion_rate, cs.total_spend, ROUND(cs.total_spend / ca.users_acquired, 2) as cac, ROUND(cl.avg_ltv, 2) as avg_ltv, ROUND(cl.median_ltv, 2) as median_ltv, ROUND(cl.avg_ltv / NULLIF(cs.total_spend / ca.users_acquired, 0), 2) as ltv_cac_ratio, cl.avg_bookings_per_user FROM channel_acquisitions ca LEFT JOIN channel_spending cs ON ca.acquisition_channel = cs.channel LEFT JOIN channel_ltv cl ON ca.acquisition_channel = cl.acquisition_channel ) -- Final output with channels where LTV/CAC > 3 SELECT acquisition_channel, users_acquired, conversion_rate, cac, avg_ltv, median_ltv, ltv_cac_ratio, CASE WHEN ltv_cac_ratio > 3 THEN 'High Performance' WHEN ltv_cac_ratio > 2 THEN 'Good Performance' WHEN ltv_cac_ratio > 1 THEN 'Breaking Even' ELSE 'Underperforming' END as channel_status FROM final_metrics WHERE ltv_cac_ratio IS NOT NULL ORDER BY ltv_cac_ratio DESC; -- Simpler version focusing on key metrics: WITH q1_metrics AS ( SELECT u.acquisition_channel, COUNT(DISTINCT u.user_id) as users_acquired, SUM(ms.daily_spend) as total_spend, SUM(b.total_value) as total_revenue FROM users u LEFT JOIN bookings b ON u.user_id = b.user_id AND b.booking_status = 'completed' LEFT JOIN marketing_spend ms ON u.acquisition_channel = ms.channel AND ms.date BETWEEN '2024-01-01' AND '2024-03-31' WHERE u.signup_date BETWEEN '2024-01-01' AND '2024-03-31' GROUP BY u.acquisition_channel ) SELECT acquisition_channel, users_acquired, ROUND(total_spend / NULLIF(users_acquired, 0), 2) as cac, ROUND(total_revenue / NULLIF(users_acquired, 0), 2) as avg_ltv, ROUND(total_revenue / NULLIF(total_spend, 0), 2) as roi FROM q1_metrics WHERE total_revenue / NULLIF(total_spend, 0) > 3 ORDER BY roi DESC; Key Takeaways and Tips:

---

#### Edge cases - Consider scenarios like new users with no bookings, hosts with no

reviews, etc. Remember during the interview: ‚óè Start with a simple version, then add complexity ‚óè Explain your assumptions about the data ‚óè Mention alternative approaches when relevant ‚óè Think about query performance for large datasets Comprehensive SQL Interview Questions Guide Table of Contents

---

#### Advanced Patterns

Sample Database Schema Let's work with a company database containing employees, departments, projects, and sales data: -- Employees table CREATE TABLE employees ( employee_id INT PRIMARY KEY, f irst_name VARCHAR(50), last_name VARCHAR(50), email VARCHAR(100), phone_number VARCHAR(20), hire_date DATE, job_title VARCHAR(50), salary DECIMAL(10, 2), manager_id INT, department_id INT ); -- Sample data INSERT INTO employees VALUES (1, 'John', 'Smith', 'john.smith@company.com', '555-0101', '2020-01-15', 'Software Engineer', 75000, 5, 1), (2, 'Sarah', 'Johnson', 'sarah.j@company.com', '555-0102', '2019-03-22', 'Senior Software Engineer', 95000, 5, 1), (3, 'Michael', 'Brown', 'michael.b@company.com', '555-0103', '2021-06-01', 'Data Analyst', 65000, 6, 2), (4, 'Emily', 'Davis', 'emily.d@company.com', '555-0104', '2020-09-15', 'Marketing Manager', 80000, 7, 3), (5, 'David', 'Wilson', 'david.w@company.com', '555-0105', '2018-02-01', 'Engineering Manager', 110000, NULL, 1), (6, 'Lisa', 'Anderson', 'lisa.a@company.com', '555-0106', '2019-07-10', 'Analytics Manager', 95000, NULL, 2), (7, 'James', 'Taylor', 'james.t@company.com', '555-0107', '2017-05-15', 'Marketing Director', 120000, NULL, 3), (8, 'Jennifer', 'Martinez', 'jennifer.m@company.com', '555-0108', '2022-01-10', 'Junior Developer', 60000, 2, 1), (9, 'Robert', 'Lee', 'robert.l@company.com', '555-0109', '2021-11-01', 'Sales Representative', 55000, 10, 4), (10, 'Maria', 'Garcia', 'maria.g@company.com', '555-0110', '2018-08-20', 'Sales Manager', 90000, NULL, 4); -- Departments table CREATE TABLE departments ( department_id INT PRIMARY KEY, department_name VARCHAR(50), location VARCHAR(100) ); INSERT INTO departments VALUES (1, 'Engineering', 'San Francisco'), (2, 'Analytics', 'New York'), (3, 'Marketing', 'Los Angeles'), (4, 'Sales', 'Chicago'), (5, 'HR', 'Boston'); -- Projects table CREATE TABLE projects ( project_id INT PRIMARY KEY, project_name VARCHAR(100), start_date DATE, end_date DATE, budget DECIMAL(12, 2) ); INSERT INTO projects VALUES (1, 'Mobile App Development', '2023-01-01', '2023-06-30', 500000), (2, 'Data Warehouse Migration', '2023-03-15', '2023-09-15', 750000), (3, 'Marketing Campaign Q2', '2023-04-01', '2023-06-30', 200000), (4, 'Customer Portal', '2023-02-01', '2023-08-31', 600000); -- Employee_Projects table (many-to-many relationship) CREATE TABLE employee_projects ( employee_id INT, project_id INT, role VARCHAR(50), hours_allocated INT, PRIMARY KEY (employee_id, project_id) ); INSERT INTO employee_projects VALUES (1, 1, 'Developer', 500), (1, 4, 'Developer', 300), (2, 1, 'Lead Developer', 600), (2, 2, 'Consultant', 200), (3, 2, 'Data Analyst', 800), (4, 3, 'Project Manager', 400), (5, 1, 'Technical Lead', 300), (8, 4, 'Developer', 700); -- Sales table CREATE TABLE sales ( sale_id INT PRIMARY KEY, employee_id INT, sale_date DATE, amount DECIMAL(10, 2), product_category VARCHAR(50) ); INSERT INTO sales VALUES (1, 9, '2023-01-15', 15000, 'Software'), (2, 9, '2023-01-20', 8000, 'Services'), (3, 10, '2023-01-22', 25000, 'Software'), (4, 9, '2023-02-10', 12000, 'Hardware'), (5, 10, '2023-02-15', 30000, 'Software'), (6, 9, '2023-03-01', 18000, 'Services'), (7, 10, '2023-03-10', 22000, 'Hardware'), (8, 9, '2023-03-15', 9000, 'Software'); Basic SELECT Queries

---

#### Retrieve all employee information from the employees table.

Answer: SELECT * FROM employees;

---

#### Get the first name, last name, and salary of all employees.

Answer: SELECT first_name, last_name, salary FROM employees;

---

#### Display employee names with their annual salary (use meaningful column aliases).

Answer: SELECT f irst_name + ' ' + last_name AS full_name, salary AS monthly_salary, salary * 12 AS annual_salary FROM employees; -- For MySQL/PostgreSQL use CONCAT: SELECT CONCAT(first_name, ' ', last_name) AS full_name, salary AS monthly_salary, salary * 12 AS annual_salary FROM employees;

---

#### Find all unique job titles in the company.

Answer: SELECT DISTINCT job_title FROM employees ORDER BY job_title; Filtering and Conditional Logic

---

#### Find all employees earning more than $80,000.

Answer: SELECT first_name, last_name, salary FROM employees WHERE salary > 80000 ORDER BY salary DESC;

---

#### Find employees in the Engineering department (id=1) earning between $70,000 and

$100,000. Answer: SELECT first_name, last_name, salary, department_id FROM employees WHERE department_id = 1 AND salary BETWEEN 70000 AND 100000 ORDER BY salary;

---

#### Find all employees whose email starts with 'j'.

Answer: SELECT first_name, last_name, email FROM employees WHERE email LIKE 'j%';

---

#### Find employees who are either managers or directors.

Answer: SELECT first_name, last_name, job_title FROM employees WHERE job_title IN ('Engineering Manager', 'Marketing Director', 'Sales Manager', 'Analytics Manager') ORDER BY job_title;

---

#### Find all employees who don't have a manager (top-level employees).

Answer: SELECT first_name, last_name, job_title FROM employees WHERE manager_id IS NULL;

---

#### Categorize employees by salary ranges.

Answer: SELECT f irst_name, last_name, salary, CASE WHEN salary < 60000 THEN 'Entry Level' WHEN salary BETWEEN 60000 AND 80000 THEN 'Mid Level' WHEN salary BETWEEN 80001 AND 100000 THEN 'Senior Level' ELSE 'Executive Level' END AS salary_category FROM employees ORDER BY salary; JOIN Operations

---

#### List all employees with their department names.

Answer: SELECT e.first_name, e.last_name, e.job_title, d.department_name, d.location FROM employees e INNER JOIN departments d ON e.department_id = d.department_id ORDER BY d.department_name, e.last_name;

---

#### Show all departments and their employees (including departments with no

employees). Answer: SELECT d.department_name, d.location, e.first_name, e.last_name FROM departments d LEFT JOIN employees e ON d.department_id = e.department_id ORDER BY d.department_name, e.last_name;

---

#### List all employees with their manager's name.

Answer: SELECT e.first_name + ' ' + e.last_name AS employee_name, e.job_title, m.first_name + ' ' + m.last_name AS manager_name FROM employees e LEFT JOIN employees m ON e.manager_id = m.employee_id ORDER BY manager_name, employee_name;

---

#### Show employees with their department and project information.

Answer: SELECT e.first_name, e.last_name, d.department_name, p.project_name, ep.role, ep.hours_allocated FROM employees e INNER JOIN departments d ON e.department_id = d.department_id INNER JOIN employee_projects ep ON e.employee_id = ep.employee_id INNER JOIN projects p ON ep.project_id = p.project_id ORDER BY e.last_name, p.project_name;

---

#### Find all employees and all departments, showing matches where they exist.

-- For databases supporting FULL OUTER JOIN: SELECT e.first_name, e.last_name, d.department_name FROM employees e FULL OUTER JOIN departments d ON e.department_id = d.department_id; -- For MySQL (doesn't support FULL OUTER JOIN): SELECT e.first_name, e.last_name, d.department_name FROM employees e LEFT JOIN departments d ON e.department_id = d.department_id UNION SELECT e.first_name, e.last_name, d.department_name FROM employees e RIGHT JOIN departments d ON e.department_id = d.department_id; Aggregations and GROUP BY

---

#### Find the average, minimum, and maximum salary in the company.

Answer: SELECT AVG(salary) AS avg_salary, MIN(salary) AS min_salary, MAX(salary) AS max_salary, COUNT(*) AS total_employees FROM employees;

---

#### Count the number of employees in each department.

Answer: SELECT d.department_name, COUNT(e.employee_id) AS employee_count FROM departments d LEFT JOIN employees e ON d.department_id = e.department_id GROUP BY d.department_id, d.department_name ORDER BY employee_count DESC;

---

#### Find departments with average salary above $80,000.

Answer: SELECT d.department_name, AVG(e.salary) AS avg_salary, COUNT(e.employee_id) AS employee_count FROM departments d INNER JOIN employees e ON d.department_id = e.department_id GROUP BY d.department_id, d.department_name HAVING AVG(e.salary) > 80000 ORDER BY avg_salary DESC;

---

#### For each department, show total salary expense and average salary.

Answer: SELECT d.department_name, COUNT(e.employee_id) AS num_employees, SUM(e.salary) AS total_salary_expense, AVG(e.salary) AS average_salary, MIN(e.salary) AS min_salary, MAX(e.salary) AS max_salary FROM departments d LEFT JOIN employees e ON d.department_id = e.department_id GROUP BY d.department_id, d.department_name ORDER BY total_salary_expense DESC;

---

#### Find the number of employees by department and job title.

Answer: SELECT d.department_name, e.job_title, COUNT(*) AS employee_count, AVG(e.salary) AS avg_salary FROM employees e INNER JOIN departments d ON e.department_id = d.department_id GROUP BY d.department_name, e.job_title ORDER BY d.department_name, employee_count DESC; Subqueries

---

#### Find employees who earn more than the average salary.

Answer: SELECT first_name, last_name, salary FROM employees WHERE salary > (SELECT AVG(salary) FROM employees) ORDER BY salary DESC;

---

#### Find employees who work on projects with budget over $600,000.

Answer: SELECT DISTINCT e.first_name, e.last_name FROM employees e WHERE e.employee_id IN ( SELECT ep.employee_id FROM employee_projects ep INNER JOIN projects p ON ep.project_id = p.project_id WHERE p.budget > 600000 ) ORDER BY e.last_name;

---

#### Find employees who earn more than the average salary in their department.

Answer: SELECT e1.first_name, e1.last_name, e1.salary, e1.department_id FROM employees e1 WHERE e1.salary > ( SELECT AVG(e2.salary) FROM employees e2 WHERE e2.department_id = e1.department_id ) ORDER BY e1.department_id, e1.salary DESC;

---

#### Find departments that have at least one employee earning over $100,000.

Answer: SELECT d.department_name, d.location FROM departments d WHERE EXISTS ( SELECT 1 FROM employees e WHERE e.department_id = d.department_id AND e.salary > 100000 );

---

#### Show each employee with their department's average salary.

Answer: SELECT e.first_name, e.last_name, e.salary, (SELECT AVG(salary) FROM employees e2 WHERE e2.department_id = e.department_id) AS dept_avg_salary, e.salary - (SELECT AVG(salary) FROM employees e2 WHERE e2.department_id = e.department_id) AS salary_diff FROM employees e ORDER BY e.department_id, salary_diff DESC; Window Functions

---

#### Rank employees by salary within each department.

Answer: SELECT first_name, last_name, department_id, salary, ROW_NUMBER() OVER (PARTITION BY department_id ORDER BY salary DESC) AS salary_rank FROM employees ORDER BY department_id, salary_rank;

---

#### Show the difference between RANK and DENSE_RANK for employee salaries.

Answer: SELECT first_name, last_name, salary, RANK() OVER (ORDER BY salary DESC) AS rank, DENSE_RANK() OVER (ORDER BY salary DESC) AS dense_rank, ROW_NUMBER() OVER (ORDER BY salary DESC) AS row_num FROM employees ORDER BY salary DESC;

---

#### Calculate running total of sales by date.

Answer: SELECT sale_date, employee_id, amount, SUM(amount) OVER (ORDER BY sale_date) AS running_total, SUM(amount) OVER (PARTITION BY employee_id ORDER BY sale_date) AS running_total_by_employee FROM sales ORDER BY sale_date;

---

#### Compare each sale with the previous and next sale.

Answer: SELECT sale_id, sale_date, amount, LAG(amount, 1) OVER (ORDER BY sale_date) AS previous_sale, LEAD(amount, 1) OVER (ORDER BY sale_date) AS next_sale, amount - LAG(amount, 1) OVER (ORDER BY sale_date) AS diff_from_previous FROM sales ORDER BY sale_date;

---

#### Calculate 3-month moving average of sales.

Answer: SELECT sale_date, amount, AVG(amount) OVER ( ORDER BY sale_date ROWS BETWEEN 2 PRECEDING AND CURRENT ROW ) AS moving_avg_3 FROM sales ORDER BY sale_date;

---

#### Divide employees into salary quartiles.

Answer: SELECT first_name, last_name, salary, NTILE(4) OVER (ORDER BY salary) AS salary_quartile FROM employees ORDER BY salary; Common Table Expressions (CTEs)

---

#### Use a CTE to find high-earning employees (top 25%).

Answer: WITH salary_stats AS ( SELECT PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY salary) AS percentile_75 FROM employees ) SELECT e.first_name, e.last_name, e.salary FROM employees e, salary_stats s WHERE e.salary >= s.percentile_75 ORDER BY e.salary DESC; -- Alternative using subquery for databases without PERCENTILE_CONT: WITH salary_ranked AS ( SELECT first_name, last_name, salary, NTILE(4) OVER (ORDER BY salary DESC) AS quartile FROM employees ) SELECT first_name, last_name, salary FROM salary_ranked WHERE quartile = 1 ORDER BY salary DESC;

---

#### Calculate department statistics and identify departments above average.

Answer: WITH dept_stats AS ( SELECT department_id, COUNT(*) AS employee_count, AVG(salary) AS avg_salary, SUM(salary) AS total_salary FROM employees GROUP BY department_id ), company_avg AS ( SELECT AVG(avg_salary) AS overall_avg_salary FROM dept_stats ) SELECT d.department_name, ds.employee_count, ds.avg_salary, ca.overall_avg_salary, ds.avg_salary - ca.overall_avg_salary AS diff_from_company_avg FROM dept_stats ds CROSS JOIN company_avg ca INNER JOIN departments d ON ds.department_id = d.department_id WHERE ds.avg_salary > ca.overall_avg_salary ORDER BY diff_from_company_avg DESC;

---

#### Build an employee hierarchy tree showing reporting structure.

Answer: WITH RECURSIVE emp_hierarchy AS ( -- Anchor: top-level employees SELECT employee_id, first_name, last_name, manager_id, job_title, 0 AS level, CAST(employee_id AS VARCHAR(200)) AS path FROM employees WHERE manager_id IS NULL UNION ALL -- Recursive part SELECT e.employee_id, e.first_name, e.last_name, e.manager_id, e.job_title, h.level + 1, CONCAT(h.path, '->', e.employee_id) FROM employees e INNER JOIN emp_hierarchy h ON e.manager_id = h.employee_id ) SELECT level, REPEAT('  ', level) || first_name || ' ' || last_name AS employee_name, job_title, path FROM emp_hierarchy ORDER BY path; Data Modification

---

#### Create a backup of high-salary employees.

-- First create the backup table CREATE TABLE high_earners_backup AS SELECT * FROM employees WHERE 1=0; -- Structure only -- Insert high earners INSERT INTO high_earners_backup SELECT * FROM employees WHERE salary > 90000;

---

#### Give a 10% raise to all employees in the Engineering department.

Answer: UPDATE employees e SET e.salary = e.salary * 1.10 WHERE e.department_id IN ( SELECT department_id FROM departments WHERE department_name = 'Engineering' ); -- Alternative with JOIN (MySQL syntax): UPDATE employees e INNER JOIN departments d ON e.department_id = d.department_id SET e.salary = e.salary * 1.10 WHERE d.department_name = 'Engineering';

---

#### Delete employees who haven't been assigned to any projects.

Answer: DELETE FROM employees WHERE employee_id NOT IN ( SELECT DISTINCT employee_id FROM employee_projects ); -- Alternative using NOT EXISTS: DELETE FROM employees e WHERE NOT EXISTS ( SELECT 1 FROM employee_projects ep WHERE ep.employee_id = e.employee_id );

---

#### Update or insert employee records based on a staging table.

-- SQL Server / Oracle MERGE syntax: MERGE employees AS target USING staging_employees AS source ON target.employee_id = source.employee_id WHEN MATCHED THEN UPDATE SET target.salary = source.salary, target.job_title = source.job_title WHEN NOT MATCHED THEN INSERT (employee_id, first_name, last_name, salary, job_title) VALUES (source.employee_id, source.first_name, source.last_name, source.salary, source.job_title); -- MySQL UPSERT: INSERT INTO employees (employee_id, first_name, last_name, salary) VALUES (1, 'John', 'Smith', 80000) ON DUPLICATE KEY UPDATE salary = VALUES(salary); -- PostgreSQL UPSERT: INSERT INTO employees (employee_id, first_name, last_name, salary) VALUES (1, 'John', 'Smith', 80000) ON CONFLICT (employee_id) DO UPDATE SET salary = EXCLUDED.salary; Advanced Patterns

---

#### Find duplicate email addresses in the employees table.

-- Method 1: Using GROUP BY and HAVING SELECT email, COUNT(*) AS duplicate_count FROM employees GROUP BY email HAVING COUNT(*) > 1; -- Method 2: Using Window Functions WITH email_counts AS ( SELECT *, COUNT(*) OVER (PARTITION BY email) AS email_count FROM employees ) SELECT * FROM email_counts WHERE email_count > 1 ORDER BY email, employee_id;

---

#### Find gaps in employee IDs.

Answer: WITH id_gaps AS ( SELECT employee_id, LEAD(employee_id) OVER (ORDER BY employee_id) AS next_id FROM employees ) SELECT employee_id + 1 AS gap_start, next_id - 1 AS gap_end FROM id_gaps WHERE next_id - employee_id > 1;

---

#### Create a pivot table showing employee count by department and job title.

-- Using CASE statements (works in all databases): SELECT job_title, SUM(CASE WHEN department_id = 1 THEN 1 ELSE 0 END) AS Engineering, SUM(CASE WHEN department_id = 2 THEN 1 ELSE 0 END) AS Analytics, SUM(CASE WHEN department_id = 3 THEN 1 ELSE 0 END) AS Marketing, SUM(CASE WHEN department_id = 4 THEN 1 ELSE 0 END) AS Sales FROM employees GROUP BY job_title; -- SQL Server PIVOT syntax: SELECT * FROM ( SELECT job_title, department_id FROM employees ) AS source_table PIVOT ( COUNT(department_id) FOR department_id IN ([1], [2], [3], [4]) ) AS pivot_table;

---

#### Calculate cumulative percentage of total salary by employee.

Answer: WITH salary_ordered AS ( SELECT first_name, last_name, salary, SUM(salary) OVER (ORDER BY salary DESC) AS cumulative_salary, SUM(salary) OVER () AS total_salary FROM employees ) SELECT first_name, last_name, salary, cumulative_salary, ROUND(100.0 * cumulative_salary / total_salary, 2) AS cumulative_percentage FROM salary_ordered ORDER BY salary DESC;

---

#### Find the top 2 highest-paid employees in each department.

-- Using ROW_NUMBER() WITH ranked_employees AS ( SELECT e.*, d.department_name, ROW_NUMBER() OVER (PARTITION BY e.department_id ORDER BY e.salary DESC) AS rank FROM employees e INNER JOIN departments d ON e.department_id = d.department_id ) SELECT department_name, first_name, last_name, salary, rank FROM ranked_employees WHERE rank <= 2 ORDER BY department_name, rank;

---

#### Compare monthly sales with the same month from the previous year.

Answer: WITH monthly_sales AS ( SELECT DATE_FORMAT(sale_date, '%Y-%m') AS month, SUM(amount) AS total_sales FROM sales GROUP BY DATE_FORMAT(sale_date, '%Y-%m') ), yoy_comparison AS ( SELECT month, total_sales, LAG(total_sales, 12) OVER (ORDER BY month) AS prev_year_sales FROM monthly_sales ) SELECT month, total_sales, prev_year_sales, ROUND(100.0 * (total_sales - prev_year_sales) / prev_year_sales, 2) AS yoy_growth_percent FROM yoy_comparison WHERE prev_year_sales IS NOT NULL;

---

#### Find employees hired on consecutive days.

Answer: WITH consecutive_hires AS ( SELECT e1.first_name AS emp1_first, e1.last_name AS emp1_last, e1.hire_date AS emp1_hire_date, e2.first_name AS emp2_first, e2.last_name AS emp2_last, e2.hire_date AS emp2_hire_date FROM employees e1 INNER JOIN employees e2 ON e2.hire_date = DATE_ADD(e1.hire_date, INTERVAL 1 DAY) ) SELECT * FROM consecutive_hires ORDER BY emp1_hire_date;

---

#### Show the complete reporting chain for each employee.

Answer: WITH RECURSIVE reporting_chain AS ( SELECT e.employee_id, e.first_name, e.last_name, e.manager_id, e.first_name || ' ' || e.last_name AS reporting_chain, 1 AS chain_level FROM employees e UNION ALL SELECT rc.employee_id, rc.first_name, rc.last_name, e.manager_id, e.first_name || ' ' || e.last_name || ' -> ' || rc.reporting_chain AS reporting_chain, rc.chain_level + 1 FROM reporting_chain rc INNER JOIN employees e ON rc.manager_id = e.employee_id WHERE e.manager_id IS NOT NULL ) SELECT employee_id, first_name || ' ' || last_name AS employee_name, reporting_chain, chain_level FROM reporting_chain WHERE manager_id IS NULL ORDER BY employee_id;

---

#### Find data quality issues in the employees table.

-- Check for various data quality issues WITH data_issues AS ( -- Check for null values in required fields SELECT 'NULL in required field' AS issue_type, COUNT(*) AS issue_count FROM employees WHERE first_name IS NULL OR last_name IS NULL OR email IS NULL UNION ALL -- Check for duplicate emails SELECT 'Duplicate email' AS issue_type, COUNT(*) - COUNT(DISTINCT email) AS issue_count FROM employees UNION ALL -- Check for invalid salary values SELECT 'Invalid salary' AS issue_type, COUNT(*) AS issue_count FROM employees WHERE salary <= 0 OR salary > 1000000 UNION ALL -- Check for future hire dates SELECT 'Future hire date' AS issue_type, COUNT(*) AS issue_count FROM employees WHERE hire_date > CURRENT_DATE UNION ALL -- Check for employees reporting to themselves SELECT 'Self-reporting' AS issue_type, COUNT(*) AS issue_count FROM employees WHERE employee_id = manager_id ) SELECT * FROM data_issues WHERE issue_count > 0;

---

#### Calculate employee tenure and categorize by experience level.

Answer: SELECT first_name, last_name, hire_date, DATEDIFF(CURRENT_DATE, hire_date) AS days_employed, FLOOR(DATEDIFF(CURRENT_DATE, hire_date) / 365.25) AS years_employed, FLOOR((DATEDIFF(CURRENT_DATE, hire_date) % 365.25) / 30) AS months_employed, CASE WHEN DATEDIFF(CURRENT_DATE, hire_date) < 365 THEN 'New Employee (<1 year)' WHEN DATEDIFF(CURRENT_DATE, hire_date) < 365 * 3 THEN 'Junior (1-3 years)' WHEN DATEDIFF(CURRENT_DATE, hire_date) < 365 * 5 THEN 'Mid-level (3-5 years)' ELSE 'Senior (5+ years)' END AS experience_level FROM employees ORDER BY days_employed DESC;

---

#### Parse and clean employee email addresses.

Answer: SELECT email, SUBSTRING_INDEX(email, '@', 1) AS username, SUBSTRING_INDEX(email, '@', -1) AS domain, UPPER(LEFT(first_name, 1)) || LOWER(SUBSTRING(first_name, 2)) AS proper_first_name, LENGTH(email) - LENGTH(REPLACE(email, '.', '')) AS dot_count, CASE WHEN email REGEXP '^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}$' THEN 'Valid' ELSE 'Invalid' END AS email_validation FROM employees;

---

#### Rewrite this inefficient query to find employees not assigned to projects.

Inefficient Query: SELECT * FROM employees WHERE employee_id NOT IN (SELECT employee_id FROM employee_projects); Optimized Answer: -- Method 1: Using NOT EXISTS (typically fastest) SELECT e.* FROM employees e WHERE NOT EXISTS ( SELECT 1 FROM employee_projects ep WHERE ep.employee_id = e.employee_id ); -- Method 2: Using LEFT JOIN SELECT e.* FROM employees e LEFT JOIN employee_projects ep ON e.employee_id = ep.employee_id WHERE ep.employee_id IS NULL; -- Method 3: Using EXCEPT (PostgreSQL/SQL Server) SELECT employee_id, first_name, last_name FROM employees EXCEPT SELECT e.employee_id, e.first_name, e.last_name FROM employees e INNER JOIN employee_projects ep ON e.employee_id = ep.employee_id; Common Interview Patterns to Remember

---

#### Ranking Patterns

‚óè ROW_NUMBER(): Unique ranking ‚óè RANK(): Allows ties, skips numbers ‚óè DENSE_RANK(): Allows ties, no gaps ‚óè NTILE(): Divides into buckets

---

#### Comparison Patterns

‚óè Self-joins for comparing rows ‚óè LAG/LEAD for sequential comparisons ‚óè Correlated subqueries for group comparisons

---

#### Aggregation Patterns

‚óè GROUP BY for summaries ‚óè Window functions for running totals ‚óè CTEs for multi-level aggregations

---

#### Data Quality Patterns

‚óè Finding duplicates ‚óè Identifying NULL values ‚óè Data validation checks ‚óè Consistency checks across tables

---

#### Performance Patterns

‚óè EXISTS vs IN for better performance ‚óè Proper indexing considerations ‚óè Avoiding SELECT * ‚óè Using appropriate JOIN types

---

#### Date/Time Patterns

‚óè Date arithmetic ‚óè Extracting date parts ‚óè Period-over-period comparisons ‚óè Finding gaps in date sequences Key Tips for Interviews:

---

#### Know the differences between database systems (MySQL vs PostgreSQL vs SQL

Server)

---

#### -- Question 23

-- Table: Students -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | student_id    | int     | -- | student_name  | varchar | -- +---------------+---------+ -- student_id is the primary key for this table. -- Each row of this table contains the ID and the name of one student in the school. -- Table: Subjects -- +--------------+---------+ -- | Column Name  | Type    | -- +--------------+---------+ -- | subject_name | varchar | -- +--------------+---------+ -- subject_name is the primary key for this table. -- Each row of this table contains the name of one subject in the school. -- Table: Examinations -- +--------------+---------+ -- | Column Name  | Type    | -- +--------------+---------+ -- | student_id   | int     | -- | subject_name | varchar | -- +--------------+---------+ -- There is no primary key for this table. It may contain duplicates. -- Each student from the Students table takes every course from Subjects table. -- Each row of this table indicates that a student with ID student_id attended the exam of subject_name. -- Write an SQL query to find the number of times each student attended each exam. -- Order the result table by student_id and subject_name. -- The query result format is in the following example: -- Students table: -- +------------+--------------+ -- | student_id | student_name | -- +------------+--------------+ -- | 1          | Alice        | -- | 2          | Bob          | -- | 13         | John         | -- | 6          | Alex         | -- +------------+--------------+ -- Subjects table: -- +--------------+ -- | subject_name | -- +--------------+ -- | Math         | -- | Physics      | -- | Programming  | -- +--------------+ -- Examinations table: -- +------------+--------------+ -- | student_id | subject_name | -- +------------+--------------+ -- | 1          | Math         | -- | 1          | Physics      | -- | 1          | Programming  | -- | 2          | Programming  | -- | 1          | Physics      | -- | 1          | Math         | -- | 13         | Math         | -- | 13         | Programming  | -- | 13         | Physics      | -- | 2          | Math         | -- | 1          | Math         | -- +------------+--------------+ -- Result table: -- +------------+--------------+--------------+----------------+ -- | student_id | student_name | subject_name | attended_exams | -- +------------+--------------+--------------+----------------+ -- | 1          | Alice        | Math         | 3              | -- | 1          | Alice        | Physics      | 2              | -- | 1          | Alice        | Programming  | 1              | -- | 2          | Bob          | Math         | 1              | -- | 2          | Bob          | Physics      | 0              | -- | 2          | Bob          | Programming  | 1              | -- | 6          | Alex         | Math         | 0              | -- | 6          | Alex         | Physics      | 0              | -- | 6          | Alex         | Programming  | 0              | -- | 13         | John         | Math         | 1              | -- | 13         | John         | Physics      | 1              | -- | 13         | John         | Programming  | 1              | -- +------------+--------------+--------------+----------------+ -- The result table should contain all students and all subjects. -- Alice attended Math exam 3 times, Physics exam 2 times and Programming exam 1 time. -- Bob attended Math exam 1 time, Programming exam 1 time and didn't attend the Physics exam. -- Alex didn't attend any exam. -- John attended Math exam 1 time, Physics exam 1 time and Programming exam 1 time. -- Solution Select a.student_id as student_id, a.student_name as student_name, a.subject_name as subject_name, coalesce(attended_exams,0) as attended_exams from( select * from students cross join subjects group by student_id, student_name, subject_name) a left join (Select e.student_id, student_name, subject_name, count(*) as attended_exams from examinations e join students s on e.student_id = s.student_id group by e.student_id, student_name, subject_name) b on a.student_id = b.student_id and a.subject_name =b.subject_name order by a.student_id asc, a.subject_name asc

---

#### WITH CTE AS

( SELECT user_id, transaction_date, product_id, DENSE_RANK() OVER(PARTITION BY user_id ORDER BY transaction_date DESC) AS rank FROM user_transactions ) SELECT transaction_date, user_id, COUNT(product_id) AS purchase_count FROM CTE WHERE rank = 1 GROUP BY transaction_date, user_id ORDER BY transaction_date

---

#### SELECT firstname,lastname,city,state

FROM person_175 p LEFT JOIN address_175 a ON p.personid = a.personid;

---

#### WITH flagged_coffee AS (

SELECT *, ROW_NUMBER() OVER () AS rn, CASE WHEN drink IS NOT NULL THEN 1 ELSE 0 END AS null_flag FROM coffee_shop_2388 ), running_sum AS ( SELECT *, SUM(null_flag) OVER (ORDER BY rn) AS rsum FROM flagged_coffee ) SELECT id, FIRST_VALUE(drink) OVER (PARTITION BY rsum) AS drink FROM running_sum;

---

#### SELECT seller_id

FROM sales_1082 GROUP BY seller_id HAVING SUM(price) IN ( SELECT SUM(price) AS m_sum FROM sales_1082 GROUP BY seller_id ORDER BY m_sum DESC LIMIT 1 );

---

#### WITH CT AS

( SELECT measurement_id, CAST(measurement_time AS DATE) AS measurement_day, measurement_value, ROW_NUMBER() OVER(PARTITION BY(CAST(measurement_time AS DATE)) ORDER BY measurement_id) AS RN FROM measurements ) SELECT measurement_day, SUM(CASE WHEN RN % 2 != 0 THEN measurement_value END) AS odd_sum, SUM(CASE WHEN RN % 2 = 0 THEN measurement_value END) AS even_sum FROM CT GROUP BY measurement_day;

---

#### -- Question 95

-- Table: Transactions -- +----------------+---------+ -- | Column Name    | Type    | -- +----------------+---------+ -- | id             | int     | -- | country        | varchar | -- | state          | enum    | -- | amount         | int     | -- | trans_date     | date    | -- +----------------+---------+ -- id is the primary key of this table. -- The table has information about incoming transactions. -- The state column is an enum of type ["approved", "declined"]. -- Table: Chargebacks -- +----------------+---------+ -- | Column Name    | Type    | -- +----------------+---------+ -- | trans_id       | int     | -- | charge_date    | date    | -- +----------------+---------+ -- Chargebacks contains basic information regarding incoming chargebacks from some transactions placed in Transactions table. -- trans_id is a foreign key to the id column of Transactions table. -- Each chargeback corresponds to a transaction made previously even if they were not approved. -- Write an SQL query to find for each month and country, the number of approved transactions and their total amount, the number of chargebacks and their total amount. -- Note: In your query, given the month and country, ignore rows with all zeros. -- The query result format is in the following example: -- Transactions table: -- +------+---------+----------+--------+------------+ -- | id   | country | state    | amount | trans_date | -- +------+---------+----------+--------+------------+ -- | 101  | US      | approved | 1000   | 2019-05-18 | -- | 102  | US      | declined | 2000   | 2019-05-19 | -- | 103  | US      | approved | 3000   | 2019-06-10 | -- | 104  | US      | approved | 4000   | 2019-06-13 | -- | 105  | US      | approved | 5000   | 2019-06-15 | -- +------+---------+----------+--------+------------+ -- Chargebacks table: -- +------------+------------+ -- | trans_id   | trans_date | -- +------------+------------+ -- | 102        | 2019-05-29 | -- | 101        | 2019-06-30 | -- | 105        | 2019-09-18 | -- +------------+------------+ -- Result table: -- +----------+---------+----------------+-----------------+-------------------+--------------------+ -- | month    | country | approved_count | approved_amount | chargeback_count  | chargeback_amount  | -- +----------+---------+----------------+-----------------+-------------------+--------------------+ -- | 2019-05  | US      | 1              | 1000            | 1                 | 2000               | -- | 2019-06  | US      | 3              | 12000           | 1                 | 1000               | -- | 2019-09  | US      | 0              | 0               | 1                 | 5000               | -- +----------+---------+----------------+-----------------+-------------------+--------------------+ -- Solution with t1 as (select country, extract('month' from trans_date), state, count(*) as approved_count, sum(amount) as approved_amount from transactions where state = 'approved' group by 1, 2, 3), t2 as( select t.country, extract('month' from c.trans_date), sum(amount) as chargeback_amount, count(*) as chargeback_count from chargebacks c left join transactions t on trans_id = id group by t.country, extract('month' from c.trans_date)), t3 as( select t2.date_part, t2.country, coalesce(approved_count,0) as approved_count, coalesce(approved_amount,0) as approved_amount, coalesce(chargeback_count,0) as chargeback_count, coalesce(chargeback_amount,0) as chargeback_amount from t2 left join t1 on t2.date_part = t1.date_part and t2.country = t1.country), t4 as( select t1.date_part, t1.country, coalesce(approved_count,0) as approved_count, coalesce(approved_amount,0) as approved_amount, coalesce(chargeback_count,0) as chargeback_count, coalesce(chargeback_amount,0) as chargeback_amount from t2 right join t1 on t2.date_part = t1.date_part and t2.country = t1.country) select * from t3 union select * from t4

---

#### SELECT employee_id,

COUNT(employee_id) OVER (PARTITION BY team_id) AS team_size FROM employee_1303 ORDER BY employee_id;

---

#### WITH RECURSIVE customer_purchase_years AS (

SELECT customer_id,MIN(EXTRACT(YEAR FROM order_date)) AS min_year,MAX(EXTRACT(YEAR FROM order_date)) AS max_year FROM orders_2474 GROUP BY customer_id ), all_years AS ( SELECT customer_id,min_year AS year,max_year FROM customer_purchase_years UNION SELECT customer_id,year+1 AS year,max_year FROM all_years WHERE year<max_year ), all_year_purchases AS ( SELECT ay.customer_id,ay.year,COALESCE(SUM(o.price),0) AS total_purchase FROM all_years ay LEFT JOIN orders_2474 o ON ay.customer_id = o.customer_id AND ay.year = EXTRACT(YEAR FROM o.order_date) GROUP BY ay.customer_id,ay.year ), ranked AS ( SELECT *, DENSE_RANK() OVER (PARTITION BY customer_id ORDER BY year) - DENSE_RANK() OVER (PARTITION BY customer_id ORDER BY total_purchase) AS diff FROM all_year_purchases ) SELECT DISTINCT customer_id FROM ranked WHERE customer_id NOT IN (SELECT DISTINCT customer_id FROM ranked WHERE diff <> 0); --OR-- WITH cte AS( SELECT customer_id, EXTRACT(YEAR FROM order_date) AS year, price FROM orders_2474 ), cte1 AS( SELECT customer_id,year,SUM(price) AS prices FROM cte GROUP BY customer_id,year ), cte2 AS( SELECT *, DENSE_RANK() OVER(PARTITION BY customer_id ORDER BY prices) AS rn FROM cte1 ), cte3 AS( SELECT DISTINCT customer_id,year-rn AS new_line FROM cte2 ) SELECT customer_id FROM cte3 GROUP BY customer_id HAVING (COUNT(new_line)=1);

---

#### -- Question 108

-- Given two tables as below, write a query to display the comparison result (higher/lower/same) of the -- average salary of employees in a department to the company's average salary. -- Table: salary -- | id | employee_id | amount | pay_date   | -- |----|-------------|--------|------------| -- | 1  | 1           | 9000   | 2017-03-31 | -- | 2  | 2           | 6000   | 2017-03-31 | -- | 3  | 3           | 10000  | 2017-03-31 | -- | 4  | 1           | 7000   | 2017-02-28 | -- | 5  | 2           | 6000   | 2017-02-28 | -- | 6  | 3           | 8000   | 2017-02-28 | -- The employee_id column refers to the employee_id in the following table employee. -- | employee_id | department_id | -- |-------------|---------------| -- | 1           | 1             | -- | 2           | 2             | -- | 3           | 2             | -- So for the sample data above, the result is: -- | pay_month | department_id | comparison  | -- |-----------|---------------|-------------| -- | 2017-03   | 1             | higher      | -- | 2017-03   | 2             | lower       | -- | 2017-02   | 1             | same        | -- | 2017-02   | 2             | same        | -- Explanation -- In March, the company's average salary is (9000+6000+10000)/3 = 8333.33... -- The average salary for department '1' is 9000, which is the salary of employee_id '1' since there is only one employee in this department. So the comparison result is 'higher' since 9000 > 8333.33 obviously. -- The average salary of department '2' is (6000 + 10000)/2 = 8000, which is the average of employee_id '2' and '3'. So the comparison result is 'lower' since 8000 < 8333.33. -- With he same formula for the average salary comparison in February, the result is 'same' since both the department '1' and '2' have the same average salary with the company, which is 7000. -- Solution with t1 as( select date_format(pay_date,'%Y-%m') as pay_month, department_id, avg(amount) over(partition by month(pay_date),department_id) as dept_avg, avg(amount) over(partition by month(pay_date)) as comp_avg from salary s join employee e using (employee_id)) select distinct pay_month, department_id, case when dept_avg>comp_avg then "higher" when dept_avg = comp_avg then "same" else "lower" end as comparison from t1 order by 1 desc

---

#### WITH CTE AS

( SELECT searches FROM search_frequency GROUP BY searches, GENERATE_SERIES(1, num_users) ) SELECT ROUND(PERCENTILE_CONT(0.50) WITHIN GROUP(ORDER BY searches)::DECIMAL, 1) AS median FROM CTE;

---

#### SELECT u.city, COUNT(t.user_id) AS total_orders

FROM trades t INNER JOIN users u ON t.user_id = u.user_id WHERE t.status = 'Completed' GROUP BY u.city ORDER BY total_orders DESC LIMIT 3;

---

#### WITH cte AS(

SELECT *, MIN(score) OVER (PARTITION BY exam_id) AS lowest_score, MAX(score) OVER (PARTITION BY exam_id) AS highest_score FROM exams_1412 ), cte1 AS( SELECT DISTINCT student_id FROM exams_1412 EXCEPT SELECT DISTINCT student_id FROM cte c WHERE score = lowest_score OR score = highest_score ) SELECT s.* FROM cte1 c INNER JOIN students_1412 s ON c.student_id = s.student_id;

---

#### SELECT gender,day,

SUM(score_points) OVER (PARTITION BY gender ORDER BY day) FROM scores_1308;

---

#### WITH par_spent AS (

SELECT c.name,DATE_TRUNC('MONTH',o.order_date)::DATE,SUM(quantity*price) AS spent FROM orders_1511 o INNER JOIN product_1511 p ON o.product_id = p.product_id AND (DATE_TRUNC('MONTH',o.order_date)::DATE = '2020-06-01' OR DATE_TRUNC('MONTH',o.order_date)::DATE = '2020-07-01') INNER JOIN customers_1511 c ON c.customer_id = o.customer_id GROUP BY c.name,DATE_TRUNC('MONTH',o.order_date)::DATE HAVING SUM(quantity*price)>=100 ) SELECT name FROM par_spent GROUP BY name HAVING COUNT(name) = 2;

---

#### SELECT DISTINCT user_id

FROM purchases_2230 WHERE (DATE_TRUNC('DAY',time_stamp) BETWEEN '2022-03-08' AND '2022-03-20') AND amount >= 1000;

---

#### WITH ranked AS(

SELECT *, RANK() OVER (PARTITION BY student_id ORDER BY grade DESC,course_id ASC) AS rnk FROM enrollments_1112 ) SELECT student_id,course_id,grade FROM ranked WHERE rnk = 1;

---

#### WITH posts AS (

SELECT * FROM submissions_1241 WHERE parent_id IS NULL ), cmnts AS ( SELECT * FROM submissions_1241 WHERE parent_id IS NOT NULL ), cte AS ( SELECT DISTINCT p.sub_id AS post_id,c.sub_id AS cmnt_id FROM posts p LEFT JOIN cmnts c ON p.sub_id = c.parent_id ) SELECT post_id,COUNT(cmnt_id) FROM cte GROUP BY post_id ORDER BY post_id;

---

#### SELECT customer_id

FROM customer_1045 GROUP BY customer_id HAVING COUNT(customer_id) = (SELECT COUNT(product_key) FROM product_1045) ORDER BY customer_id;

---

#### WITH ranked AS(

SELECT *, ROW_NUMBER() OVER w AS rnk FROM student_618 WINDOW w AS (PARTITION BY continent ORDER BY name) ) SELECT MAX(CASE WHEN continent = 'America' THEN name END) AS America, MAX(CASE WHEN continent = 'Europe' THEN name END) AS Europe, MAX(CASE WHEN continent = 'Asia' THEN name END) AS Asia FROM ranked GROUP BY rnk ORDER BY rnk; --Why we need to rank the rows? Without it below will be the result. SELECT CASE WHEN continent = 'America' THEN name END AS America, CASE WHEN continent = 'Europe' THEN name END AS Europe, CASE WHEN continent = 'Asia' THEN name END AS Asia FROM student_618;

---

#### -- Question 43

-- Table: Actions -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | user_id       | int     | -- | post_id       | int     | -- | action_date   | date    | -- | action        | enum    | -- | extra         | varchar | -- +---------------+---------+ -- There is no primary key for this table, it may have duplicate rows. -- The action column is an ENUM type of ('view', 'like', 'reaction', 'comment', 'report', 'share'). -- The extra column has optional information about the action such as a reason for report or a type of reaction. -- Write an SQL query that reports the number of posts reported yesterday for each report reason. Assume today is 2019-07-05. -- The query result format is in the following example: -- Actions table: -- +---------+---------+-------------+--------+--------+ -- | user_id | post_id | action_date | action | extra  | -- +---------+---------+-------------+--------+--------+ -- | 1       | 1       | 2019-07-01  | view   | null   | -- | 1       | 1       | 2019-07-01  | like   | null   | -- | 1       | 1       | 2019-07-01  | share  | null   | -- | 2       | 4       | 2019-07-04  | view   | null   | -- | 2       | 4       | 2019-07-04  | report | spam   | -- | 3       | 4       | 2019-07-04  | view   | null   | -- | 3       | 4       | 2019-07-04  | report | spam   | -- | 4       | 3       | 2019-07-02  | view   | null   | -- | 4       | 3       | 2019-07-02  | report | spam   | -- | 5       | 2       | 2019-07-04  | view   | null   | -- | 5       | 2       | 2019-07-04  | report | racism | -- | 5       | 5       | 2019-07-04  | view   | null   | -- | 5       | 5       | 2019-07-04  | report | racism | -- +---------+---------+-------------+--------+--------+ -- Result table: -- +---------------+--------------+ -- | report_reason | report_count | -- +---------------+--------------+ -- | spam          | 1            | -- | racism        | 2            | -- +---------------+--------------+ -- Note that we only care about report reasons with non zero number of reports. -- Solution Select extra as report_reason, count(distinct post_id) as report_count from actions where action_date = DATE_SUB("2019-07-5", INTERVAL 1 DAY) and action='report' group by extra

---

#### SELECT COUNT(*) AS nyc_count

FROM phone_info AS pf INNER JOIN phone_calls AS pc ON pf.caller_id = pc.caller_id OR pf.caller_id = pc.receiver_id WHERE LEFT(phone_number, 6) = '+1-212';

---

#### WITH ranked AS(

SELECT *,DENSE_RANK() OVER w AS rnk FROM activity_511 WINDOW w AS (PARTITION BY player_id ORDER BY event_date) ) SELECT player_id,device_id FROM ranked WHERE rnk = 1 ORDER BY player_id; (OR) WITH cte AS( SELECT player_id,MIN(event_date) AS first_login FROM activity_511 GROUP BY player_id ) SELECT player_id,device_id FROM activity_511 WHERE (player_id,event_date) IN (SELECT * FROM cte);

---

#### SELECT name

FROM customers_183 WHERE id NOT IN (SELECT DISTINCT customer_id FROM orders_183);

---

#### WITH cte AS(

SELECT *, AVG(occurences) OVER(PARTITION BY event_type) AS avg FROM events_1126 ) SELECT business_id FROM cte WHERE occurences > avg GROUP BY business_id HAVING COUNT(business_id) > 1;

---

#### SELECT r1.driver_id,COUNT(DISTINCT r2.ride_id) AS cnt

FROM rides_2238 r1 LEFT JOIN rides_2238 r2 ON r1.driver_id = r2.passenger_id GROUP BY r1.driver_id;

---

#### SELECT LOWER(TRIM(product_name)) AS product_name,TO_CHAR(sale_date,'YYYY-MM') AS sale_date,COUNT(sale_id) AS total

FROM sales_1543 GROUP BY LOWER(TRIM(product_name)),TO_CHAR(sale_date,'YYYY-MM') ORDER BY product_name,sale_date;

---

#### -- Question 76

-- Table: Scores -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | player_name   | varchar | -- | gender        | varchar | -- | day           | date    | -- | score_points  | int     | -- +---------------+---------+ -- (gender, day) is the primary key for this table. -- A competition is held between females team and males team. -- Each row of this table indicates that a player_name and with gender has scored score_point in someday. -- Gender is 'F' if the player is in females team and 'M' if the player is in males team. -- Write an SQL query to find the total score for each gender at each day. -- Order the result table by gender and day -- The query result format is in the following example: -- Scores table: -- +-------------+--------+------------+--------------+ -- | player_name | gender | day        | score_points | -- +-------------+--------+------------+--------------+ -- | Aron        | F      | 2020-01-01 | 17           | -- | Alice       | F      | 2020-01-07 | 23           | -- | Bajrang     | M      | 2020-01-07 | 7            | -- | Khali       | M      | 2019-12-25 | 11           | -- | Slaman      | M      | 2019-12-30 | 13           | -- | Joe         | M      | 2019-12-31 | 3            | -- | Jose        | M      | 2019-12-18 | 2            | -- | Priya       | F      | 2019-12-31 | 23           | -- | Priyanka    | F      | 2019-12-30 | 17           | -- +-------------+--------+------------+--------------+ -- Result table: -- +--------+------------+-------+ -- | gender | day        | total | -- +--------+------------+-------+ -- | F      | 2019-12-30 | 17    | -- | F      | 2019-12-31 | 40    | -- | F      | 2020-01-01 | 57    | -- | F      | 2020-01-07 | 80    | -- | M      | 2019-12-18 | 2     | -- | M      | 2019-12-25 | 13    | -- | M      | 2019-12-30 | 26    | -- | M      | 2019-12-31 | 29    | -- | M      | 2020-01-07 | 36    | -- +--------+------------+-------+ -- For females team: -- First day is 2019-12-30, Priyanka scored 17 points and the total score for the team is 17. -- Second day is 2019-12-31, Priya scored 23 points and the total score for the team is 40. -- Third day is 2020-01-01, Aron scored 17 points and the total score for the team is 57. -- Fourth day is 2020-01-07, Alice scored 23 points and the total score for the team is 80. -- For males team: -- First day is 2019-12-18, Jose scored 2 points and the total score for the team is 2. -- Second day is 2019-12-25, Khali scored 11 points and the total score for the team is 13. -- Third day is 2019-12-30, Slaman scored 13 points and the total score for the team is 26. -- Fourth day is 2019-12-31, Joe scored 3 points and the total score for the team is 29. -- Fifth day is 2020-01-07, Bajrang scored 7 points and the total score for the team is 36. -- Solution select gender, day, sum(score_points) over(partition by gender order by day) as total from scores group by 1,2 order by 1,2

---

#### SELECT E.user_id

FROM texts T INNER JOIN emails E ON E.email_id = T.email_id WHERE T.signup_action = 'Confirmed' AND DATE(T.action_date) - DATE(E.signup_date) = 1;

---

#### -- Question 83

-- Table: Transactions -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | id            | int     | -- | country       | varchar | -- | state         | enum    | -- | amount        | int     | -- | trans_date    | date    | -- +---------------+---------+ -- id is the primary key of this table. -- The table has information about incoming transactions. -- The state column is an enum of type ["approved", "declined"]. -- Write an SQL query to find for each month and country, the number of transactions and their total amount, the number of approved transactions and their total amount. -- The query result format is in the following example: -- Transactions table: -- +------+---------+----------+--------+------------+ -- | id   | country | state    | amount | trans_date | -- +------+---------+----------+--------+------------+ -- | 121  | US      | approved | 1000   | 2018-12-18 | -- | 122  | US      | declined | 2000   | 2018-12-19 | -- | 123  | US      | approved | 2000   | 2019-01-01 | -- | 124  | DE      | approved | 2000   | 2019-01-07 | -- +------+---------+----------+--------+------------+ -- Result table: -- +----------+---------+-------------+----------------+--------------------+-----------------------+ -- | month    | country | trans_count | approved_count | trans_total_amount | approved_total_amount | -- +----------+---------+-------------+----------------+--------------------+-----------------------+ -- | 2018-12  | US      | 2           | 1              | 3000               | 1000                  | -- | 2019-01  | US      | 1           | 1              | 2000               | 2000                  | -- | 2019-01  | DE      | 1           | 1              | 2000               | 2000                  | -- +----------+---------+-------------+----------------+--------------------+-----------------------+ -- Solution with t1 as( select DATE_FORMAT(trans_date,'%Y-%m') as month, country, count(state) as trans_count, sum(amount) as trans_total_amount from transactions group by country, month(trans_date)), t2 as ( Select DATE_FORMAT(trans_date,'%Y-%m') as month, country, count(state) as approved_count, sum(amount) as approved_total_amount from transactions where state = 'approved' group by country, month(trans_date)) select t1.month, t1.country, coalesce(t1.trans_count,0) as trans_count, coalesce(t2.approved_count,0) as approved_count, coalesce(t1.trans_total_amount,0) as trans_total_amount, coalesce(t2.approved_total_amount,0) as approved_total_amount from t1 left join t2 on t1.country = t2.country and t1.month = t2.month

---

#### WITH cte AS(

SELECT customer_id,MIN(order_date) AS first_order FROM delivery_1174 GROUP BY customer_id ) SELECT ROUND((COUNT(CASE WHEN d.order_date = d.customer_pref_delivery_date THEN 1 ELSE NULL END)::NUMERIC/COUNT(*))*100,2) AS immediate_percentage FROM delivery_1174 d INNER JOIN cte c ON d.customer_id = c.customer_id AND d.order_date = c.first_order;

---

#### -- Question 70

-- In facebook, there is a follow table with two columns: followee, follower. -- Please write a sql query to get the amount of each follower‚Äôs follower if he/she has one. -- For example: -- +-------------+------------+ -- | followee    | follower   | -- +-------------+------------+ -- |     A       |     B      | -- |     B       |     C      | -- |     B       |     D      | -- |     D       |     E      | -- +-------------+------------+ -- should output: -- +-------------+------------+ -- | follower    | num        | -- +-------------+------------+ -- |     B       |  2         | -- |     D       |  1         | -- +-------------+------------+ -- Explaination: -- Both B and D exist in the follower list, when as a followee, B's follower is C and D, and D's follower is E. A does not exist in follower list. -- Note: -- Followee would not follow himself/herself in all cases. -- Please display the result in follower's alphabet order. -- Solution select followee as follower, count(distinct(follower)) as num from follow where followee = any(select follower from follow) group by followee order by followee

---

#### -- Question 75

-- The Employee table holds all employees including their managers. Every employee has an Id, and there is also a column for the manager Id. -- +------+----------+-----------+----------+ -- |Id    |Name 	  |Department |ManagerId | -- +------+----------+-----------+----------+ -- |101   |John 	  |A 	      |null      | -- |102   |Dan 	  |A 	      |101       | -- |103   |James 	  |A 	      |101       | -- |104   |Amy 	  |A 	      |101       | -- |105   |Anne 	  |A 	      |101       | -- |106   |Ron 	  |B 	      |101       | -- +------+----------+-----------+----------+ -- Given the Employee table, write a SQL query that finds out managers with at least 5 direct report. For the above table, your SQL query should return: -- +-------+ -- | Name  | -- +-------+ -- | John  | -- +-------+ -- Note: -- No one would report to himself. -- Solution with t1 as ( select managerid, count(name) as total from employee group by managerid ) select e.name from t1 join employee e on t1.managerid = e.id where t1.total>=5

---

#### -- Question 59

-- Table: Movies -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | movie_id      | int     | -- | title         | varchar | -- +---------------+---------+ -- movie_id is the primary key for this table. -- title is the name of the movie. -- Table: Users -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | user_id       | int     | -- | name          | varchar | -- +---------------+---------+ -- user_id is the primary key for this table. -- Table: Movie_Rating -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | movie_id      | int     | -- | user_id       | int     | -- | rating        | int     | -- | created_at    | date    | -- +---------------+---------+ -- (movie_id, user_id) is the primary key for this table. -- This table contains the rating of a movie by a user in their review. -- created_at is the user's review date. -- Write the following SQL query: -- Find the name of the user who has rated the greatest number of the movies. -- In case of a tie, return lexicographically smaller user name. -- Find the movie name with the highest average rating in February 2020. -- In case of a tie, return lexicographically smaller movie name. -- Query is returned in 2 rows, the query result format is in the folowing example: -- Movies table: -- +-------------+--------------+ -- | movie_id    |  title       | -- +-------------+--------------+ -- | 1           | Avengers     | -- | 2           | Frozen 2     | -- | 3           | Joker        | -- +-------------+--------------+ -- Users table: -- +-------------+--------------+ -- | user_id     |  name        | -- +-------------+--------------+ -- | 1           | Daniel       | -- | 2           | Monica       | -- | 3           | Maria        | -- | 4           | James        | -- +-------------+--------------+ -- Movie_Rating table: -- +-------------+--------------+--------------+-------------+ -- | movie_id    | user_id      | rating       | created_at  | -- +-------------+--------------+--------------+-------------+ -- | 1           | 1            | 3            | 2020-01-12  | -- | 1           | 2            | 4            | 2020-02-11  | -- | 1           | 3            | 2            | 2020-02-12  | -- | 1           | 4            | 1            | 2020-01-01  | -- | 2           | 1            | 5            | 2020-02-17  | -- | 2           | 2            | 2            | 2020-02-01  | -- | 2           | 3            | 2            | 2020-03-01  | -- | 3           | 1            | 3            | 2020-02-22  | -- | 3           | 2            | 4            | 2020-02-25  | -- +-------------+--------------+--------------+-------------+ -- Result table: -- +--------------+ -- | results      | -- +--------------+ -- | Daniel       | -- | Frozen 2     | -- +--------------+ -- Daniel and Maria have rated 3 movies ("Avengers", "Frozen 2" and "Joker") but Daniel is smaller lexicographically. -- Frozen 2 and Joker have a rating average of 3.5 in February but Frozen 2 is smaller lexicographically. -- Solution select name as results from( (select a.name from( select name, count(*), rank() over(order by count(*) desc) as rk from movie_rating m join users u on m.user_id = u.user_id group by name, m.user_id order by rk, name) a limit 1) union (select title from( select title, round(avg(rating),1) as rnd from movie_rating m join movies u on m.movie_id = u.movie_id where month(created_at) = 2 group by title order by rnd desc, title) b limit 1)) as d

---

#### -- Table name for Test-Case1 : matches_2173

-- Table name for Test-Case2 : matches_2173_tc_2 WITH ranked_all_matches AS ( SELECT *, ROW_NUMBER() OVER (PARTITION BY player_id ORDER BY match_day) AS rn FROM matches_2173 ), ranked_won_matches AS ( SELECT player_id,result,rn, ROW_NUMBER() OVER (PARTITION BY player_id ORDER BY match_day) AS wrn FROM ranked_all_matches WHERE result = 'Win' ), winning_streaks AS ( SELECT player_id,result,rn-wrn AS diff,COUNT(1) AS winning_streak FROM ranked_won_matches GROUP BY player_id,result,rn-wrn ), players AS ( SELECT DISTINCT player_id FROM matches_2173 ) SELECT p.player_id,COALESCE(MAX(winning_streak),0) AS longest_streak FROM players p LEFT JOIN winning_streaks w ON w.player_id = p.player_id GROUP BY p.player_id; /* pid	rn	wrn	diff ----------------------------- 1 	1	1   	0 1 	2	2   	0 1 	3	3   	0 1 	4	-   	- 1 	5	4   	1 1 	6	5   	1 1 	7	-   	- 1 	8	6   	2 1 	9	7   	2 1 	10	8   	2 1 	11	9   	2 1 	12	-   	- 2 	1 	-   	- 2 	2 	1   	1 2 	3 	-   	- 2 	4   	2   	2 2 	5   	3   	2 3 	1   	1   	0 */

---

#### WITH RECURSIVE months AS (

SELECT 1 AS m UNION SELECT m+1 AS m FROM months WHERE m <= 11 ), accepted_rides_2020 AS ( SELECT mn.m,COUNT(ar.ride_id) AS accepted_rides FROM accepted_rides_1645 ar INNER JOIN rides_1645 r ON ar.ride_id = r.ride_id AND EXTRACT(year FROM r.requested_at)=2020 RIGHT JOIN months mn ON mn.m = EXTRACT(month FROM r.requested_at) GROUP BY m ), running_drivers AS ( SELECT *, COUNT(driver_id) OVER (ORDER BY join_date) AS drivers_cnt FROM drivers_1645 ), drivers AS ( SELECT mn.m,ar.accepted_rides,MAX(d.drivers_cnt) AS drivers FROM running_drivers d RIGHT JOIN months mn ON mn.m >= EXTRACT(month FROM d.join_date) AND EXTRACT(year FROM d.join_date)=2020 INNER JOIN accepted_rides_2020 ar ON ar.m=mn.m GROUP BY mn.m,ar.accepted_rides ) SELECT m AS month,ROUND(accepted_rides*100.0/drivers,2) AS working_percentage FROM drivers ORDER BY month;

---

#### SELECT q.id,q.year,COALESCE(n.npv,0)

FROM queries_1421 q LEFT JOIN npv_1421 n ON q.id = n.id AND q.year = n.year;

---

#### -- Question 67

-- Table: Products -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | product_id    | int     | -- | new_price     | int     | -- | change_date   | date    | -- +---------------+---------+ -- (product_id, change_date) is the primary key of this table. -- Each row of this table indicates that the price of some product was changed to a new price at some date. -- Write an SQL query to find the prices of all products on 2019-08-16. Assume the price of all products before any change is 10. -- The query result format is in the following example: -- Products table: -- +------------+-----------+-------------+ -- | product_id | new_price | change_date | -- +------------+-----------+-------------+ -- | 1          | 20        | 2019-08-14  | -- | 2          | 50        | 2019-08-14  | -- | 1          | 30        | 2019-08-15  | -- | 1          | 35        | 2019-08-16  | -- | 2          | 65        | 2019-08-17  | -- | 3          | 20        | 2019-08-18  | -- +------------+-----------+-------------+ -- Result table: -- +------------+-------+ -- | product_id | price | -- +------------+-------+ -- | 2          | 50    | -- | 1          | 35    | -- | 3          | 10    | -- +------------+-------+ -- Solution with t1 as ( select a.product_id, new_price from( Select product_id, max(change_date) as date from products where change_date<='2019-08-16' group by product_id) a join products p on a.product_id = p.product_id and a.date = p.change_date), t2 as ( select distinct product_id from products) select t2.product_id, coalesce(new_price,10) as price from t2 left join t1 on t2.product_id = t1.product_id order by price desc

---

#### SELECT c1.user_id

FROM confirmations_1939 c1 INNER JOIN confirmations_1939 c2 ON c1.user_id = c2.user_id AND c1.time_stamp < c2.time_stamp WHERE EXTRACT(EPOCH FROM (c2.time_stamp-c1.time_stamp)) <= 24*60*60;

---

#### SELECT * FROM orders_2084

WHERE (customer_id, order_type) IN (SELECT customer_id, MIN(order_type) FROM orders_2084 GROUP BY customer_id)

---

#### SELECT DISTINCT TO_CHAR(pay_date,'YYYY-MM') AS pay_month,b.department_id,

CASE WHEN (AVG(amount) OVER w1) = (AVG(amount) OVER w2) THEN 'same' WHEN (AVG(amount) OVER w1) > (AVG(amount) OVER w2) THEN 'lower' ELSE 'higher' END AS comparison FROM salary_615 a JOIN employee_615 b ON a.employee_id=b.employee_id WINDOW w1 AS (PARTITION BY TO_CHAR(pay_date,'YYYY-MM')), w2 AS (PARTITION BY TO_CHAR(pay_date,'YYYY-MM'),department_id) ORDER BY 1;

---

#### -- More Readable, But Requires two Joins

WITH before_update_ranked_teams AS ( SELECT *, DENSE_RANK() OVER (ORDER BY points DESC,name) before_rn FROM team_points_2175 ), after_update_ranked_teams AS ( SELECT tp.team_id,tp.name,tp.points+pc.points_change AS points, DENSE_RANK() OVER (ORDER BY tp.points+pc.points_change DESC,tp.name) after_rn FROM team_points_2175 tp INNER JOIN points_change_2175 pc ON tp.team_id = pc.team_id ) SELECT au.team_id,au.name,au.points,au.after_rn-bu.before_rn AS rank_diff FROM before_update_ranked_teams bu INNER JOIN after_update_ranked_teams au ON bu.team_id = au.team_id ORDER BY au.points DESC,au.name; -- Using a single Join SELECT tp.team_id,tp.name, DENSE_RANK() OVER (ORDER BY tp.points+pc.points_change DESC,tp.name)- DENSE_RANK() OVER (ORDER BY tp.points DESC,name) AS rank_diff FROM team_points_2175 tp INNER JOIN points_change_2175 pc ON tp.team_id = pc.team_id ORDER BY tp.points+pc.points_change DESC,tp.name;

---

#### -- Question 109

-- Table: UserActivity -- +---------------+---------+ -- | Column Name   | Type    | -- +---------------+---------+ -- | username      | varchar | -- | activity      | varchar | -- | startDate     | Date    | -- | endDate       | Date    | -- +---------------+---------+ -- This table does not contain primary key. -- This table contain information about the activity performed of each user in a period of time. -- A person with username performed a activity from startDate to endDate. -- Write an SQL query to show the second most recent activity of each user. -- If the user only has one activity, return that one. -- A user can't perform more than one activity at the same time. Return the result table in any order. -- The query result format is in the following example: -- UserActivity table: -- +------------+--------------+-------------+-------------+ -- | username   | activity     | startDate   | endDate     | -- +------------+--------------+-------------+-------------+ -- | Alice      | Travel       | 2020-02-12  | 2020-02-20  | -- | Alice      | Dancing      | 2020-02-21  | 2020-02-23  | -- | Alice      | Travel       | 2020-02-24  | 2020-02-28  | -- | Bob        | Travel       | 2020-02-11  | 2020-02-18  | -- +------------+--------------+-------------+-------------+ -- Result table: -- +------------+--------------+-------------+-------------+ -- | username   | activity     | startDate   | endDate     | -- +------------+--------------+-------------+-------------+ -- | Alice      | Dancing      | 2020-02-21  | 2020-02-23  | -- | Bob        | Travel       | 2020-02-11  | 2020-02-18  | -- +------------+--------------+-------------+-------------+ -- The most recent activity of Alice is Travel from 2020-02-24 to 2020-02-28, before that she was dancing from 2020-02-21 to 2020-02-23. -- Bob only has one record, we just take that one. -- Solution select username, activity, startdate, enddate from (select *, rank() over(partition by username order by startdate desc) as rk, count(username) over(partition by username) as cnt from useractivity) a where a.rk = 2 or cnt = 1

---

#### -- Question 12

-- Description -- Given three tables: salesperson, company, orders. -- Output all the names in the table salesperson, who didn‚Äôt have sales to company 'RED'. -- Example -- Input -- Table: salesperson -- +----------+------+--------+-----------------+-----------+ -- | sales_id | name | salary | commission_rate | hire_date | -- +----------+------+--------+-----------------+-----------+ -- |   1      | John | 100000 |     6           | 4/1/2006  | -- |   2      | Amy  | 120000 |     5           | 5/1/2010  | -- |   3      | Mark | 65000  |     12          | 12/25/2008| -- |   4      | Pam  | 25000  |     25          | 1/1/2005  | -- |   5      | Alex | 50000  |     10          | 2/3/2007  | -- +----------+------+--------+-----------------+-----------+ -- The table salesperson holds the salesperson information. Every salesperson has a sales_id and a name. -- Table: company -- +---------+--------+------------+ -- | com_id  |  name  |    city    | -- +---------+--------+------------+ -- |   1     |  RED   |   Boston   | -- |   2     | ORANGE |   New York | -- |   3     | YELLOW |   Boston   | -- |   4     | GREEN  |   Austin   | -- +---------+--------+------------+ -- The table company holds the company information. Every company has a com_id and a name. -- Table: orders -- +----------+------------+---------+----------+--------+ -- | order_id | order_date | com_id  | sales_id | amount | -- +----------+------------+---------+----------+--------+ -- | 1        |   1/1/2014 |    3    |    4     | 100000 | -- | 2        |   2/1/2014 |    4    |    5     | 5000   | -- | 3        |   3/1/2014 |    1    |    1     | 50000  | -- | 4        |   4/1/2014 |    1    |    4     | 25000  | -- +----------+----------+---------+----------+--------+ -- The table orders holds the sales record information, salesperson and customer company are represented by sales_id and com_id. -- output -- +------+ -- | name | -- +------+ -- | Amy  | -- | Mark | -- | Alex | -- +------+ -- Explanation -- According to order '3' and '4' in table orders, it is easy to tell only salesperson 'John' and 'Pam' have sales to company 'RED', -- so we need to output all the other names in the table salesperson. -- Solution # Takes higher time # Select distinct a.name # from( # select s.sales_id as sales, name # from salesperson s left join orders o # on s.sales_id = o.sales_id) a # where a.sales != all(select distinct sales_id from orders o join company c on o.com_id = c.com_id where o.com_id = any (select com_id from company where name = 'RED')) # Faster solution SELECT name FROM salesperson WHERE sales_id NOT IN (SELECT DISTINCT sales_id FROM orders WHERE com_id = (SELECT com_id FROM company WHERE name = 'RED')) ;

---

#### SELECT item_count AS mode

FROM items_per_order WHERE order_occurrences = ( SELECT MODE() WITHIN GROUP(ORDER BY order_occurrences DESC) FROM items_per_order ) ORDER BY mode;

---

#### SELECT * FROM customer_584 WHERE reference_id <> 21 OR reference_id IS NULL;

SELECT * FROM customer_584 EXCEPT SELECT * FROM customer_584 WHERE reference_id = 2;

---

#### WITH each_day_platform AS(

SELECT spend_date,UNNEST(ARRAY['both','mobile','desktop']) AS platform_type FROM spending_1127 GROUP BY spend_date ), cte AS( SELECT a.spend_date, CASE WHEN b.user_id IS NOT NULL THEN 'both' WHEN a.platform = 'mobile' THEN 'mobile' ELSE 'desktop' END AS platform_type, COUNT(DISTINCT a.user_id) AS total_users, SUM(a.amount) AS amount FROM spending_1127 a LEFT JOIN spending_1127 b ON a.user_id = b.user_id AND a.spend_date = b.spend_date AND a.platform <> b.platform GROUP BY a.spend_date,platform_type ) SELECT a.spend_date,a.platform_type,COALESCE(total_users,0) AS total_users,COALESCE(amount,0) AS amount FROM each_day_platform a LEFT JOIN cte b ON a.spend_date=b.spend_date AND a.platform_type = b.platform_type;
